<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jaejuning.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="K8s 클러스터 내 rook-ceph을 이용한 Ceph cluster를 구성한다. Update Note  2020.03.30 : yaml 파일이 포함된 github 주소 추가">
<meta property="og:type" content="article">
<meta property="og:title" content="[Cloud] rook-ceph을 이용한 Ceph cluster 구성">
<meta property="og:url" content="https://jaejuning.github.io/2020/02/06/2020-02-06-cloud-install_rook-ceph/index.html">
<meta property="og:site_name" content="Jj블로그">
<meta property="og:description" content="K8s 클러스터 내 rook-ceph을 이용한 Ceph cluster를 구성한다. Update Note  2020.03.30 : yaml 파일이 포함된 github 주소 추가">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://rook.io/docs/rook/v0.9/media/rook-architecture.png">
<meta property="article:published_time" content="2020-02-05T15:00:00.000Z">
<meta property="article:modified_time" content="2020-03-30T15:06:23.567Z">
<meta property="article:author" content="Jaejun Lee">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://rook.io/docs/rook/v0.9/media/rook-architecture.png">

<link rel="canonical" href="https://jaejuning.github.io/2020/02/06/2020-02-06-cloud-install_rook-ceph/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>[Cloud] rook-ceph을 이용한 Ceph cluster 구성 | Jj블로그</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Jj블로그</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">burning@</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jaejuning.github.io/2020/02/06/2020-02-06-cloud-install_rook-ceph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jaejun Lee">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jj블로그">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [Cloud] rook-ceph을 이용한 Ceph cluster 구성
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-06 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-06T00:00:00+09:00">2020-02-06</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Cloud/" itemprop="url" rel="index"><span itemprop="name">Cloud</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>K8s 클러스터 내 rook-ceph을 이용한 Ceph cluster를 구성한다.</p>
<p><strong>Update Note</strong></p>
<ul>
<li>2020.03.30 : yaml 파일이 포함된 github 주소 추가</li>
</ul>
<a id="more"></a>

<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><img src="https://rook.io/docs/rook/v0.9/media/rook-architecture.png" alt=""></p>
<p>rook-ceph은 Ceph 클러스터 및 다른 component들을 CRD(Custom Resource Definition)으로 관리하며 CRD의 변경사항을 Rook Operator를 이용해 일괄 적용할 수 있다</p>
<h1 id="설치-순서"><a href="#설치-순서" class="headerlink" title="설치 순서"></a>설치 순서</h1><h2 id="아래-순서와-같이-설치를-진행"><a href="#아래-순서와-같이-설치를-진행" class="headerlink" title="아래 순서와 같이 설치를 진행"></a>아래 순서와 같이 설치를 진행</h2><ul>
<li><p>특정 위치에 git repository를 clone 한다. 이후 common.yaml, operator.yaml 을 이용해 rook-ceph에서 제공하는 CRD와 operator를 생성한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/rook/rook.git</span><br><span class="line"><span class="built_in">cd</span> /rook/cluster/example/kubenetes/cephfs</span><br><span class="line">kubectl apply -f common.yamlkubectl apply -f operator.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>ceph_config_override.yaml 과 cluster.yaml 을 이용해 configmap을 생성하고 cluster를 구성한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ceph_config_override.yaml</span><br><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure>

<p><em>ceph_config_override.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-config-override</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">[global]</span></span><br><span class="line">    <span class="string">mon</span> <span class="string">osd</span> <span class="string">down</span> <span class="string">out</span> <span class="string">interval</span> <span class="string">=</span> <span class="string">&#123;osd_down_out_interval&#125;</span></span><br><span class="line">    <span class="string">mon</span> <span class="string">clock</span> <span class="string">drift</span> <span class="string">allowed</span> <span class="string">=</span> <span class="number">0.2</span></span><br></pre></td></tr></table></figure>

<p><em>cluster.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephCluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">cephVersion:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ceph/ceph:v14.2.4-20190917</span></span><br><span class="line">    <span class="attr">allowUnsupported:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">dataDirHostPath:</span> <span class="string">/var/lib/rook</span></span><br><span class="line">  <span class="attr">skipUpgradeChecks:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">mon:</span></span><br><span class="line">    <span class="attr">count:</span> <span class="number">1</span>    <span class="comment"># Recommendation: Use odd numbers (ex. 3, 5)</span></span><br><span class="line">  <span class="attr">dashboard:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ssl:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">monitoring:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span>  <span class="comment"># Require Prometheus to be pre-installed</span></span><br><span class="line">    <span class="attr">rulesNamespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">hostNetwork:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">rbdMirroring:</span></span><br><span class="line">    <span class="attr">workers:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">mgr:</span></span><br><span class="line">    <span class="attr">modules:</span></span><br><span class="line">    <span class="comment"># The pg_autoscaler is only available on nautilus or newer. remove this if testing mimic.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pg_autoscaler</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">storage:</span></span><br><span class="line">    <span class="attr">useAllNodes:</span> <span class="literal">true</span>      <span class="comment"># Apply ceph-osd to all nodes.</span></span><br><span class="line">    <span class="attr">useAllDevices:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">deviceFilter:</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">journalSizeMB:</span> <span class="string">"1024"</span>  <span class="comment"># This value can be removed for environments with normal sized disks (20 GB or larger)</span></span><br><span class="line">      <span class="attr">osdsPerDevice:</span> <span class="string">"1"</span>   <span class="comment"># This value can be overridden at the node or device level</span></span><br><span class="line">    <span class="attr">directories:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/var/lib/rook</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>toolbox.yaml 을 이용해 ceph 클러스터 이용을 위한 client를 설치한다</p>
<p><code>kubectl apply -f toolbox.yaml</code></p>
</li>
<li><p>block_pool.yaml  과 file_system.yaml을 이용해 block / file storage 배포 준비</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f block_pool.yaml</span><br><span class="line">kubectl apply -f file_system.yaml</span><br></pre></td></tr></table></figure>

<p><em>block_pool.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephBlockPool</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">replicapool</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">failureDomain:</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">replicated:</span></span><br><span class="line">    <span class="attr">size:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p><em>file_system.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephFilesystem</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">metadataPool:</span></span><br><span class="line">  <span class="comment"># failureDomain - values are possible for 'osd' and 'host'</span></span><br><span class="line">    <span class="attr">failureDomain:</span> <span class="string">host</span>  <span class="comment"># ceph-osd must exist equal or more than replicated size</span></span><br><span class="line">    <span class="attr">replicated:</span></span><br><span class="line">      <span class="attr">size:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">dataPools:</span></span><br><span class="line">  <span class="comment"># failureDomain - values are possible for 'osd' and 'host'</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">failureDomain:</span> <span class="string">host</span>  <span class="comment"># ceph-osd must exist equal or more than replicated size</span></span><br><span class="line">      <span class="attr">replicated:</span></span><br><span class="line">        <span class="attr">size:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">metadataServer:</span></span><br><span class="line">    <span class="attr">activeCount:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">activeStandby:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>마지막으로 block_sc.yaml 과 file_sc.yaml을 이용해 각 block / file storageclass를 생성한다</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f block_sc.yaml</span><br><span class="line">kubectl apply -f file_sc.yaml</span><br></pre></td></tr></table></figure>

<p><em>block_sc.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">rook-ceph-block</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.rbd.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">    <span class="comment"># clusterID is the namespace where the rook cluster is running</span></span><br><span class="line">    <span class="comment"># If you change this namespace, also change the namespace below where the secret namespaces are defined</span></span><br><span class="line">    <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ceph pool into which the RBD image shall be created</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">replicapool</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image format. Defaults to "2".</span></span><br><span class="line">    <span class="attr">imageFormat:</span> <span class="string">"2"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image features. Available for imageFormat: "2". CSI RBD currently supports only `layering` feature.</span></span><br><span class="line">    <span class="attr">imageFeatures:</span> <span class="string">layering</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The secrets contain Ceph admin credentials. These are generated automatically by the operator</span></span><br><span class="line">    <span class="comment"># in the same namespace as the cluster.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-rbd-provisioner</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-rbd-node</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="comment"># Specify the filesystem type of the volume. If not specified, csi-provisioner</span></span><br><span class="line">    <span class="comment"># will set default as `ext4`.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/fstype:</span> <span class="string">ext4</span></span><br><span class="line"><span class="comment"># uncomment the following to use rbd-nbd as mounter on supported nodes</span></span><br></pre></td></tr></table></figure>

<p><em>file_sc.yaml</em></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">csi-cephfs-sc</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.cephfs.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="comment"># clusterID is the namespace where operator is deployed.</span></span><br><span class="line">  <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># CephFS filesystem name into which the volume shall be created</span></span><br><span class="line">  <span class="attr">fsName:</span> <span class="string">myfs</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Ceph pool into which the volume shall be created</span></span><br><span class="line">  <span class="comment"># Required for provisionVolume: "true"</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">myfs-data0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Root path of an existing CephFS volume</span></span><br><span class="line">  <span class="comment"># Required for provisionVolume: "false"</span></span><br><span class="line">  <span class="comment"># rootPath: /absolute/path</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># The secrets contain Ceph admin credentials. These are generated automatically by the operator</span></span><br><span class="line">  <span class="comment"># in the same namespace as the cluster.</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-cephfs-provisioner</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-cephfs-node</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># (optional) The driver can use either ceph-fuse (fuse) or ceph kernel client (kernel)</span></span><br><span class="line">  <span class="comment"># If omitted, default volume mounter will be used - this is determined by probing for ceph-fuse</span></span><br><span class="line">  <span class="comment"># or by setting the default mounter explicitly via --volumemounter command-line argument.</span></span><br><span class="line">  <span class="comment"># mounter: kernel</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">  <span class="comment"># uncomment the following line for debugging</span></span><br><span class="line">  <span class="comment">#- debug</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>위 단계를 거치고 난 뒤 rook-ceph namespace의 pod와 storageclass 를 확인한다</p>
<p><code>kubectl get pods -n rook-ceph</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/jlee/rook-ceph-master<span class="comment"># kubectl get pods -n rook-ceph</span></span><br><span class="line">NAME                                           READY   STATUS      RESTARTS   AGE</span><br><span class="line">csi-cephfsplugin-7kz7v                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-9rt7t                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-dnggh                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-provisioner-974b566d9-7k2rb   4/4     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-provisioner-974b566d9-kxg2f   4/4     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-xzt9b                         3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-2npvg                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-drzkp                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-hhsm5                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-provisioner-579c546f5-qprb8      5/5     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-provisioner-579c546f5-svhlw      5/5     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-qhsw6                            3/3     Running     0          4d19h</span><br><span class="line">rook-ceph-mds-myfs<span class="_">-a</span>-58ddc89fc8-s4f44          1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mds-myfs-b-85dc7c7cf4-x68lk          1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mgr<span class="_">-a</span>-69df8d6794-glbjb               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon<span class="_">-a</span>-7b9cb64846-zfbwf               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon-b-7fc7c8fbb4-75j9j               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon-c-6c59c89fbc-rn8nv               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-operator-7985c4b57d-8qtht            1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-0-55888686c-pf6wn                1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-1-f56d885d4-tnrmv                1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-2-68f99d999f-zlrl4               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-3-7545f4df9b-ng4tf               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node1-msfs9          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node2-z858m          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node3-lwh4c          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node4-w8rfw          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-tools-8648fbb998-5q7v2               1/1     Running     0          4d19h</span><br><span class="line">rook-discover-85fzl                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-djj97                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-p7cwx                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-zvn5f                            1/1     Running     0          4d19h</span><br></pre></td></tr></table></figure>

<p><code>kubectl get storageclass</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl get storageclass</span></span><br><span class="line">NAME                        PROVISIONER                     AGE</span><br><span class="line">csi-cephfs-sc               rook-ceph.cephfs.csi.ceph.com   16h</span><br><span class="line">rook-ceph-block             rook-ceph.rbd.csi.ceph.com      16h</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>위 언급한 yaml 파일은 github 에 올려 두었다. <a href="https://github.com/jaejuning/rook-ceph-deploy" target="_blank" rel="noopener">https://github.com/jaejuning/rook-ceph-deploy</a></em></p>
</blockquote>
<h1 id="Ceph-cluster-상태-확인"><a href="#Ceph-cluster-상태-확인" class="headerlink" title="Ceph cluster 상태 확인"></a>Ceph cluster 상태 확인</h1><h2 id="설치가-완료되었다면-구축한-ceph-cluster가-정상-구동되었는지-확인하여야-한다-toolbox-pod-를-통해-pod-네임을-확인한다"><a href="#설치가-완료되었다면-구축한-ceph-cluster가-정상-구동되었는지-확인하여야-한다-toolbox-pod-를-통해-pod-네임을-확인한다" class="headerlink" title="설치가 완료되었다면 구축한 ceph cluster가 정상 구동되었는지 확인하여야 한다. toolbox pod 를 통해 pod 네임을 확인한다"></a>설치가 완료되었다면 구축한 ceph cluster가 정상 구동되었는지 확인하여야 한다. toolbox pod 를 통해 pod 네임을 확인한다</h2><p><code>kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot;</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl -n rook-ceph get pod -l "app=rook-ceph-tools"</span></span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">rook-ceph-tools-8648fbb998-dzbbd   1/1     Running   0          15h</span><br></pre></td></tr></table></figure>

<ul>
<li><p>확인된 pod 네임을 통해 exec 명령어로 해당 컨테이너로 접속</p>
<p><code>kubectl exec -it -n rook-ceph [위 결과로 나온 pod NAME] -- /bin/bash</code></p>
</li>
</ul>
<h2 id="Ceph-cluster-상태-확인-1"><a href="#Ceph-cluster-상태-확인-1" class="headerlink" title="Ceph cluster 상태 확인"></a>Ceph cluster 상태 확인</h2><p><code>ceph -s</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node3 /] ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     9d3a534e-797f-4659-af8d-4bfb5f60f76c</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum a (age 16h)</span><br><span class="line">    mgr: a(active, since 15h)</span><br><span class="line">    mds: myfs:1 &#123;0=myfs<span class="_">-a</span>=up:active&#125; 1 up:standby-replay</span><br><span class="line">    osd: 2 osds: 2 up (since 15h), 2 <span class="keyword">in</span> (since 15h)</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   3 pools, 24 pgs</span><br><span class="line">    objects: 537 objects, 1.4 GiB</span><br><span class="line">    usage:   53 GiB used, 45 GiB / 98 GiB avail</span><br><span class="line">    pgs:     24 active+clean</span><br></pre></td></tr></table></figure>

<h2 id="Ceph-cluster-disk-확인"><a href="#Ceph-cluster-disk-확인" class="headerlink" title="Ceph cluster disk 확인"></a>Ceph cluster disk 확인</h2><p><code>ceph df</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node3 /] ceph df</span><br><span class="line">RAW STORAGE:</span><br><span class="line">    CLASS     SIZE       AVAIL      USED       RAW USED     %RAW USED </span><br><span class="line">    ssd       98 GiB     45 GiB     53 GiB       53 GiB         53.87 </span><br><span class="line">    TOTAL     98 GiB     45 GiB     53 GiB       53 GiB         53.87 </span><br><span class="line"></span><br><span class="line">POOLS:</span><br><span class="line">    POOL              ID     STORED      OBJECTS     USED        %USED     MAX AVAIL </span><br><span class="line">    replicapool        1     1.4 GiB         509     1.4 GiB      3.50        19 GiB </span><br><span class="line">    myfs-metadata      2     2.2 KiB          28     2.2 KiB         0        19 GiB </span><br><span class="line">    myfs-data0         3         0 B           0         0 B         0        19 GiB</span><br></pre></td></tr></table></figure>

<h2 id="RBD-image-사용량"><a href="#RBD-image-사용량" class="headerlink" title="RBD image 사용량"></a>RBD image 사용량</h2><p><code>rbd du -p replicapoll</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NAME                                         PROVISIONED USED    </span><br><span class="line">csi-vol-22712573-4815-11ea-9f90-aea9eb69a9f1      10 GiB 344 MiB </span><br><span class="line">csi-vol-6d1536b2-47fc-11ea-9f90-aea9eb69a9f1      10 GiB 300 MiB </span><br><span class="line">csi-vol-d38c964b-4814-11ea-9f90-aea9eb69a9f1      10 GiB 404 MiB </span><br><span class="line">csi-vol-d4745340-4814-11ea-9f90-aea9eb69a9f1      10 GiB 396 MiB </span><br><span class="line">csi-vol-d4937470-4814-11ea-9f90-aea9eb69a9f1      20 GiB 244 MiB </span><br><span class="line">csi-vol-d4a291d9-4814-11ea-9f90-aea9eb69a9f1      20 GiB 400 MiB </span><br><span class="line">&lt;TOTAL&gt;                                           80 GiB 2.0 GiB</span><br></pre></td></tr></table></figure>

<p>reclaimPolicy를 Retain으로 설정할 경우, pv를 지워도 RBD image가 ceph cluster에 남게 되는데, 이 경우에는 <code>rbd ls</code>, <code>rbd rm</code> 등을 통해 rbd 리스트를 확인하고 삭제해야 한다.</p>
<h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><p>내 경우 클러스터의 한 노드에서 csi-rbdplugin pod가 생성되지 않고 CrashLoopBack 이 걸리는 현상이 발생하였다. 노드 문제를 해결하지 못하여 우회하는 방안으로 <strong>해당 노드에 파드가 설정되지 않게 taint 조건을 추가</strong>하여 문제를 해결하였다.</p>
<p><code>kubectl taint nodes {csi-rbdplugin pod를 생성하지 못하는 노드} key=value:NoSchedule-</code></p>
<p>이후에 rook-ceph cluster를 재 구축하면 csi-rbdplugin이 정상 작동함을 확인할 수 있다.</p>
<hr>
<p>2020.02.06 made by <em>jaejun.lee</em></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Kubernetes/" rel="tag"># Kubernetes</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/04/2020-02-04-cloud-delete_ns_at_terminating_state/" rel="prev" title="[Cloud] Terminating State에 빠진 Namespace 삭제">
      <i class="fa fa-chevron-left"></i> [Cloud] Terminating State에 빠진 Namespace 삭제
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/07/2020-02-07-cloud-deploy_es_cluster/" rel="next" title="[Cloud] Elasticsearch 배포 on K8s">
      [Cloud] Elasticsearch 배포 on K8s <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Architecture"><span class="nav-number">1.</span> <span class="nav-text">Architecture</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#설치-순서"><span class="nav-number">2.</span> <span class="nav-text">설치 순서</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#아래-순서와-같이-설치를-진행"><span class="nav-number">2.1.</span> <span class="nav-text">아래 순서와 같이 설치를 진행</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ceph-cluster-상태-확인"><span class="nav-number">3.</span> <span class="nav-text">Ceph cluster 상태 확인</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#설치가-완료되었다면-구축한-ceph-cluster가-정상-구동되었는지-확인하여야-한다-toolbox-pod-를-통해-pod-네임을-확인한다"><span class="nav-number">3.1.</span> <span class="nav-text">설치가 완료되었다면 구축한 ceph cluster가 정상 구동되었는지 확인하여야 한다. toolbox pod 를 통해 pod 네임을 확인한다</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ceph-cluster-상태-확인-1"><span class="nav-number">3.2.</span> <span class="nav-text">Ceph cluster 상태 확인</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ceph-cluster-disk-확인"><span class="nav-number">3.3.</span> <span class="nav-text">Ceph cluster disk 확인</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RBD-image-사용량"><span class="nav-number">3.4.</span> <span class="nav-text">RBD image 사용량</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Troubleshooting"><span class="nav-number">4.</span> <span class="nav-text">Troubleshooting</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jaejun Lee</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jaejuning" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jaejuning" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jaejun.lee.1991@gmail.com" title="E-Mail → mailto:jaejun.lee.1991@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jaejun Lee</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  

</body>
</html>

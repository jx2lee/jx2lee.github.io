{"meta":{"title":"go hard","subtitle":"focusing@","description":"","author":"JaeJun Lee","url":"https://jx2lee.github.io","root":"/"},"pages":[{"title":"","date":"2020-09-14T14:02:45.425Z","updated":"2020-09-14T14:02:45.425Z","comments":true,"path":"about/index.html","permalink":"https://jx2lee.github.io/about/index.html","excerpt":"","text":"Software Technical Engineerì•ˆë…•í•˜ì„¸ìš”! ë¹…ë°ì´í„°ì™€ Docker/Kubernetes ì— ê´€ì‹¬ì´ ë§ì€ Software Technical ì—”ì§€ë‹ˆì–´ ì…ë‹ˆë‹¤. í˜„ì¬ í‹°ë§¥ìŠ¤ë°ì´í„° ê³„ì—´ì‚¬ì¸ í‹°ë§¥ìŠ¤ë¹„ì•„ì´ì— ì¬ì§ ì¤‘ì´ë©° ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í”Œë«í¼ HyperData ê¸°ìˆ  ì§€ì›, í”„ë¡œì íŠ¸ ë° POC ë¥¼ ì£¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë¨¸ë¬¼ëŸ¬ ìˆì§€ ì•Šê³  í•­ìƒ ë°°ìš°ê¸° ì¢‹ì•„í•˜ëŠ” ì„±ê²©ì´ë©°, ëª¨ë¥´ëŠ” ê²ƒì´ ìˆìœ¼ë©´ ëê¹Œì§€ ì•Œ ë•Œê¹Œì§€ ë¬¼ê³  ëŠ˜ì–´ì§€ëŠ” ê·¼ì„±ì´ ìˆìŠµë‹ˆë‹¤. ğŸ‘¨ğŸ»â€ğŸ’»Career TmaxData (2018.08.01 ~) BOAZ BigData club (#8) (2017.01 ~ 2018.01) ğŸ“–Education Master of Arts in DataScience, Kookmin Univ (2016.09 ~ 2018.08) Bachelor of Science in Math, Kookmin Univ (2010.03 ~ 2016.02) ğŸ¶Githubjx2lee - Overview íšŒì‚¬ ì—…ë¬´ ë° ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ëŠ” Github ê³„ì •ì…ë‹ˆë‹¤. ğŸ“€Blogë¨¸ë¦¿ì†ì— ì•ˆë‚¨ìœ¼ë‹ˆ ê¸°ë¡í•˜ì: ë§¤ì¼ ìŒ“ì—¬ê°€ëŠ” ì§€ì‹ì„ ì–´ë””ì—”ê°€ ì ì–´ë‘ê³  ìŒ“ê¸° ìœ„í•´ ìš´ì˜í•˜ëŠ” ê°œì¸ ë¸”ë¡œê·¸ ì…ë‹ˆë‹¤. ğŸ³Skills Programming Skills: Python, SQL Backend: Docker, Kubernetes, Linux, Git ğŸ†Project (or POC)í•œêµ­ì¸í„°ë„·ì§„í¥ì› - ê°œì¸ì •ë³´ë…¸ì¶œëŒ€ì‘ì²´ê³„ ë° eí”„ë¼ì´ë²„ì‹œí´ë¦°ì„œë¹„ìŠ¤ ê³ ë„í™”: 2020.06 ~ 2020.11 (ì˜ˆì •)ìˆ˜í–‰ì—…ë¬´: ë¹…ë°ì´í„° í”Œë«í¼ êµ¬ì¶• í´ë¼ìš°ë“œ ì œí’ˆ(HyperCloud)ì„ ì´ìš©í•´ HyperData ì„¤ì¹˜ HyperData ì™€ ì—°ê³„í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ Kubeflow ë°°í¬ (https://github.com/jx2lee/Kubeflower) (ê³¼ì œ1) í™ˆí˜ì´ì§€ ìœ í˜• ë¶„ë¥˜ íƒì§€ ì›¹ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ í™ˆí˜ì´ì§€ ìœ í˜• ë¶„ë¥˜ ìˆ˜í–‰ (TmaxAI ì™€ í˜‘ì—…) ë¶„ë¥˜ ê²°ê³¼ë¥¼ File ë¡œ ë–¨ê¶ˆ ì´ë¥¼ external table ë¡œ ì½ì–´ë“¤ì—¬ í•˜ë‚˜ì˜ Table ë¡œ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤ ì—°ê³„ ë°©ì•ˆ êµ¬ì„± (ê³¼ì œ2) í‚¤ì›Œë“œ ë§¤ì¹­ íƒì§€ ì›¹ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ ê²Œì‹œíŒ / íšŒì›ê°€ì… ì—¬ë¶€ íŒë‹¨ ìˆ˜í–‰ Python module êµ¬í˜„ ë° ì—°ê³„ ì„œë¹„ìŠ¤ êµ¬ì¶• (https://github.com/jx2lee/KeywordMatch) (ê³¼ì œ3) ë°ì´í„°ë§ˆíŠ¸ êµ¬ì¶• ê°œì¸ì •ë³´ ìƒìŠµ êµ¬ë§¤/íŒë§¤ì ë¶„ì„ì„ ìœ„í•œ ë§ˆíŠ¸ êµ¬ì¶• ì¼ ì ì¬ ë°°ì¹˜ì²˜ë¦¬ì™€ ì£¼ ë‹¨ìœ„ ë§ˆê°ì²˜ë¦¬(FLAG)ë¡œ ì •í•©ì„± ê²€ì¦ (https://jx2lee.github.io/database-daily_batch_process/) (POC) í•œì†”PNS - ê°€ìƒí™” ì†”ë£¨ì…˜ ì œí’ˆ ë„ì…ì˜ ê±´: 2019.09.01 ~ 2019.10.31ìˆ˜í–‰ì—…ë¬´: ì œí’ˆ ì„¤ì¹˜ (On-premise) ì œí’ˆ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ í™˜ê²½ ì œê³µ (Connect DB using Python) (POC) ì•ˆë© - ê²½ì˜ì§„ ë³´ê³ ë¥¼ ìœ„í•œ ë§ˆíŠ¸ êµ¬ì¶• ë° ì‹œê°í™”: 2019.07.01 ~ 2019.08.31ìˆ˜í–‰ì—…ë¬´: ì œí’ˆ ì„¤ì¹˜ (On-premise) ì‚¬ë‚´ ì œí’ˆì„ ì´ìš©í•œ ë§ˆíŠ¸ ì‹œê°í™” (HyperData) BOAZ ì»¨í¼ëŸ°ìŠ¤ - ì´ë³„ê°€ì‚¬ Generator (https://github.com/jx2lee/lyric-generator)ìˆ˜í–‰ ì—…ë¬´: ì´ë³„ ê°€ì‚¬ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ì´ë³„ ê°€ì‚¬ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•´ êµ¬í˜„ ì´ë³„ ê°€ì‚¬ Crawling ê³¼ ëª¨ë¸ êµ¬í˜„ (with Python / Tensorflow) ì‚¼ì„±í™”ì¬ ë¹…ë°ì´í„° êµìœ¡ - ìë™ì°¨ë“±ë¡ì¦ ë‚´ ì°¨ëŒ€ë²ˆí˜¸ ê°ì§€ ë° ì˜ˆì¸¡: 2017.10.31 ~ 2018.01.02 (https://github.com/jx2lee/digit-recognition)ìˆ˜í–‰ ì—…ë¬´: êµìœ¡ ë³´ì¡° êµìœ¡ ì´í›„ í”„ë¡œì íŠ¸ ìˆ˜í–‰ ë©˜í†  ì—­í•  (ìë™ì°¨ ë“±ë¡ì¦ ë‚´ ì°¨ëŒ€ë²ˆí˜¸ë¥¼ ê°ì§€í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” í”„ë¡œì íŠ¸ ë©˜í†  ì§„í–‰) python-opencv ë¥¼ ì´ìš©í•œ ì°¨ëŒ€ë²ˆí˜¸ ê°ì§€ support ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ CNN ëª¨ë¸ íŠœë‹ Side ProjectKubeflow ì„¤ì¹˜ ë° ìë™í™” ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„: https://github.com/jx2lee/Kubeflowerìˆ˜í–‰ ì—…ë¬´: ì‚¬ë‚´ ì œí’ˆì— ì‚¬ìš©í•˜ëŠ” Kubeflow ë¥¼ Kubernetes ìœ„ì— ë°°í¬í•˜ëŠ” ìë™í™” ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„ https://github.com/jx2lee/KFimgr: Kubeflow ì´ë¯¸ì§€ë¥¼ ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— Push í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„ íŒ€ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ Kubernetes êµ¬ì¶•: https://jx2lee.github.io/cloud-install_k8s ì‚¬ë‚´ ì œí’ˆ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ Kubernetes í™˜ê²½ êµ¬ì¶• Kubernetes 1.15.3 í´ëŸ¬ìŠ¤í„° êµ¬ì¶• (ë§ˆìŠ¤í„° ì‚¼ì¤‘í™”) ğŸ“„PaperRNNì„ ì´ìš©í•œ í•œêµ­ì–´ ê°ì„±ë¶„ì„ - ì˜¨ë¼ì¸ ì˜í™” í›„ê¸°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ (í•™ìœ„ë…¼ë¬¸): http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&amp;control_no=51909e84bd4b8282ffe0bdc3ef48d419í•œê¸€ ìŒì†Œ ë‹¨ìœ„ ë”¥ëŸ¬ë‹ ëª¨í˜•ì„ ì´ìš©í•œ ê°ì„±ë¶„ì„: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE07282148 í•œêµ­ITì„œë¹„ìŠ¤í•™íšŒ, 17(1), 79-89, 2018, 1/3 í•œêµ­ì–´ ìŒì†Œ ë‹¨ìœ„ LSTM ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•œ ë¬¸ì¥ìƒì„±: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE07189914 í•œêµ­ì§€ëŠ¥ì •ë³´ì‹œìŠ¤í…œí•™íšŒ, 23(2), 71-88, 2017, 3/4 ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì˜ ë¹„êµ: https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE07189911 í•œêµ­ì§€ëŠ¥ì •ë³´ì‹œìŠ¤í…œí•™íšŒ, 23(2), 1-17, 2017, 4/4"},{"title":"","date":"2020-03-30T15:06:23.592Z","updated":"2020-03-30T15:06:23.592Z","comments":true,"path":"categories/index.html","permalink":"https://jx2lee.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-03-30T15:06:23.606Z","updated":"2020-03-30T15:06:23.606Z","comments":true,"path":"tags/index.html","permalink":"https://jx2lee.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"[Jenkins] Jenkins ì„¤ì¹˜ on Instance","slug":"jenkins-install_jenkins","date":"2021-01-08T15:00:00.000Z","updated":"2021-01-09T12:24:00.377Z","comments":true,"path":"jenkins-install_jenkins/","link":"","permalink":"https://jx2lee.github.io/jenkins-install_jenkins/","excerpt":"Docker ë¡œ ì  í‚¨ìŠ¤ í™˜ê²½ì„ ì„¸íŒ…í•˜ë ¤ê³  í–ˆëŠ”ë°.. https://hub.docker.com/_/jenkins ì„ ì‚´í´ë³´ë©´ ë” ì´ìƒ ì§€ì›ì„ ì•ˆí•˜ëŠ” ê²ƒìœ¼ë¡œ íŒŒì•…ëœë‹¤. ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶€ë¶„ì„ í•¨ê»˜ í¬í•¨í•˜ê¸° ìœ„í•´ ê³¼ê°íˆ(?) docker í™˜ê²½ì„ ì ‘ê³  jenkins ì„œë²„ë¥¼ êµ¬ì¶•í•˜ê³  í™˜ê²½ì„ ì„¤ì •í•´ë³´ë„ë¡ í•œë‹¤. Docker ë¡œ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ë„ ì •ë¦¬í•˜ì˜€ë‹¤.","text":"Docker ë¡œ ì  í‚¨ìŠ¤ í™˜ê²½ì„ ì„¸íŒ…í•˜ë ¤ê³  í–ˆëŠ”ë°.. https://hub.docker.com/_/jenkins ì„ ì‚´í´ë³´ë©´ ë” ì´ìƒ ì§€ì›ì„ ì•ˆí•˜ëŠ” ê²ƒìœ¼ë¡œ íŒŒì•…ëœë‹¤. ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶€ë¶„ì„ í•¨ê»˜ í¬í•¨í•˜ê¸° ìœ„í•´ ê³¼ê°íˆ(?) docker í™˜ê²½ì„ ì ‘ê³  jenkins ì„œë²„ë¥¼ êµ¬ì¶•í•˜ê³  í™˜ê²½ì„ ì„¤ì •í•´ë³´ë„ë¡ í•œë‹¤. Docker ë¡œ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ë„ ì •ë¦¬í•˜ì˜€ë‹¤. &#x2728; Contents: Install Java Install Maven .bashrc Install Git Install Jenkins Edit sysconfig (jenkins config) on Docker.. Reference Install Java123456789101112131415161718$ yum list java-1.8.0-openjdk-devel*base | 3.6 kB 00:00:00epel/x86_64/metalink | 7.8 kB 00:00:00epel | 4.7 kB 00:00:00extras | 2.9 kB 00:00:00updates | 2.9 kB 00:00:00(1/7): base/7/x86_64/group_gz | 153 kB 00:00:00(2/7): extras/7/x86_64/primary_db | 222 kB 00:00:00(3/7): updates/7/x86_64/primary_db | 4.7 MB 00:00:00(4/7): epel/x86_64/group_gz | 95 kB 00:00:00(5/7): base/7/x86_64/primary_db | 6.1 MB 00:00:00(6/7): epel/x86_64/primary_db | 6.9 MB 00:00:01(7/7): epel/x86_64/updateinfo | 1.0 MB 00:00:07Available Packagesjava-1.8.0-openjdk-devel.i686 1:1.8.0.275.b01-0.el7_9 updatesjava-1.8.0-openjdk-devel.x86_64 1:1.8.0.275.b01-0.el7_9 updates$ yum install -y java-1.8.0-openjdk-devel.x86_64 ì´í›„ JAVA í™˜ê²½ë³€ìˆ˜ ë“±ë¡ì„ ìœ„í•´ ì‹¤ì œ ì£¼ì†Œë¥¼ ì•Œì•„ë‚´ê³  ì´ë¥¼ .bashrc ì— ì¶”ê°€í•œë‹¤. 123$ readlink -f /usr/bin/javac/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.275.b01-0.el7_9.x86_64/bin/javac#JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.275.b01-0.el7_9.x86_64 Install Maven123$ sudo mkdir -p /app &amp;&amp; sudo chmod 777 /app$ wget https://downloads.apache.org/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz -P /app$ tar -xvzf apache-maven-3.6.3-bin.tar.gz .bashrc123456789# JAVA_HOMEexport JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.275.b01-0.el7_9.x86_64# MAVEN_HOMEexport MAVEN_HOME=/app/apache-maven-3.6.3# PATHPATH=$PATH:$JAVA_HOME/bin:$MAVEN_HOME/binexport PATH Install Gitsudo yum install -y git Install Jenkins1234$ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo$ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key$ sudo yum install -y jenkins$ sudo systemctl enable jenkins Edit sysconfig (jenkins config)1234567891011121314151617181920212223242526272829303132333435363738$ sudo cat /etc/sysconfig/jenkins## Path: Development/Jenkins## Description: Jenkins Automation Server## Type: string## Default: &quot;/var/lib/jenkins&quot;## ServiceRestart: jenkins## Directory where Jenkins store its configuration and working# files (checkouts, build reports, artifacts, ...).#JENKINS_HOME=&quot;/jenkins_home&quot;## Type: string## Default: &quot;&quot;## ServiceRestart: jenkins## Java executable to run Jenkins# When left empty, we&#x27;ll try to find the suitable Java.#......JENKINS_USER=&quot;jenkins&quot;......JENKINS_PORT=&quot;9090&quot;......## Type: string## Default: &quot;&quot;## ServiceRestart: jenkins## Pass arbitrary arguments to Jenkins.# Full option list: java -jar jenkins.war --help#JENKINS_ARGS=&quot;&quot; ì´í›„ ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰ sudo systemctl start jenkins On Docker.. Pull Jenkins Image 1234$ docker pull jenkins/jenkins:lts$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEjenkins/jenkins lts 1920bf702d7d 4 weeks ago 713MB Run Container 123docker run -d -p 8080:8080 --name jenkins_test \\ -v /home/centos/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock -u root jenkins/jenkins:lts /home/centos/jenkins_home í˜¸ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ container /var/jenkins_home ìœ¼ë¡œ mount /var/run/docker.sock íŒŒì¼ì„ ë§ˆìš´íŠ¸í•˜ëŠ” ì´ìœ ëŠ” ì¼ë°˜ user ë„ í•´ë‹¹ ë””ë ‰í† ë¦¬ë¥¼ ë„˜ë‚˜ë“¤ ìˆ˜ ìˆë„ë¡ ì„¤ì •í•˜ê¸° ìœ„í•¨ Add Outbound rule ë³¸ì¸ì€ í† ìŠ¤íŠ¸ í´ë¼ìš°ë“œë¥¼ ì‚¬ìš©ì¤‘ì´ë¯€ë¡œ ì‚¬ìš©ì¤‘ì¸ í´ë¼ìš°ë“œì˜ ë³´ì•ˆê·¸ë£¹ì— outbound rule ì¶”ê°€ (8080í¬íŠ¸) Verify initial admin password ì»¨í…Œì´ë„ˆ ì•ˆìœ¼ë¡œ ë“¤ì–´ê°€ í™•ì¸í•´ë„(ex. docker exec -ti {container_name} sh) ë˜ì§€ë§Œ docker exec ì— cat ë§Œ ì „ë‹¬í•˜ì—¬ initialAdminPassword ë‚´ìš©ì„ í™•ì¸í•œë‹¤12$ docker exec -it jenkins_test cat /var/jenkins_home/secrets/initialAdminPassword75c9d1c35b674306a2ed9f114f49240f Reference https://blog.jiniworld.me/88 https://velog.io/@wimes/Jenkinsë¥¼-ì´ìš©í•´-Dockerí”„ë¡œì íŠ¸-ë¹Œë“œí•´ë³´ê¸° made by jaejun.lee","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://jx2lee.github.io/categories/Jenkins/"}],"tags":[]},{"title":"[Node.js] NVM ì„¤ì¹˜","slug":"nodejs-install_nvm","date":"2021-01-08T15:00:00.000Z","updated":"2021-01-09T12:45:16.815Z","comments":true,"path":"nodejs-install_nvm/","link":"","permalink":"https://jx2lee.github.io/nodejs-install_nvm/","excerpt":"node.js ë²„ì „ ë§¤ë‹ˆì €ì¸ NVM ì„ ì„¤ì¹˜í•˜ê³  ì‚´í´ë³¸ë‹¤.","text":"node.js ë²„ì „ ë§¤ë‹ˆì €ì¸ NVM ì„ ì„¤ì¹˜í•˜ê³  ì‚´í´ë³¸ë‹¤. &#x2728; Contents: NVM? Install NVM .bashrc (or .zsh) Installing a specific version of Nodejs Installing a specific version of Nodejs Reference NVM? node js ë²„ì „ ë§¤ë‹ˆì €ë¡œ ì‹œìŠ¤í…œì— ì—¬ëŸ¬ ê°œì˜ nodejs ë¥¼ ì„¤ì¹˜í•˜ê³  ì‚¬ìš©í•  ë²„ì „ì„ ì‰½ê²Œ ì „í™˜í•  ìˆ˜ë¡ ë„ì™€ì£¼ëŠ” shell script rvm(Ruby Version Manager) ì™€ ë¹„ìŠ·í•œ ì—­í• ì„ ìˆ˜í–‰ Install NVMcurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bash .bashrc (or .zsh)1234$ vi ~/.zshrc# Nodejsexport NVM_DIR=&quot;$HOME/.nvm&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \\. &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm Installing a specific version of Nodejs123456789101112131415$ nvm install 13.1.0$ nvm ls-&gt; v13.1.0 systemdefault -&gt; 13.1.0 (-&gt; v13.1.0)node -&gt; stable (-&gt; v13.1.0) (default)stable -&gt; 13.1 (-&gt; v13.1.0) (default)iojs -&gt; N/A (default)lts/* -&gt; lts/fermium (-&gt; N/A)lts/argon -&gt; v4.9.1 (-&gt; N/A)lts/boron -&gt; v6.17.1 (-&gt; N/A)lts/carbon -&gt; v8.17.0 (-&gt; N/A)lts/dubnium -&gt; v10.23.1 (-&gt; N/A)lts/erbium -&gt; v12.20.1 (-&gt; N/A)lts/fermium -&gt; v14.15.4 (-&gt; N/A) Commands search node version: nvm ls-remote select specific node version: nvm use &#123;node-version&#125; set default version: nvm alias default &#123;node-version&#125; delete version: nvm uninstall &#123;node-version&#125; Reference lesstif.com/javascript/nvm-node-version-manager-nodejs-82214944.html made by jaejun.lee","categories":[],"tags":[]},{"title":"[Hadoop] Single Node Cluster ì„¤ì¹˜","slug":"hadoop-install_singloenode_cluster","date":"2021-01-07T15:00:00.000Z","updated":"2021-01-09T12:21:49.923Z","comments":true,"path":"hadoop-install_singloenode_cluster/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_singloenode_cluster/","excerpt":"CentOS 7 í™˜ê²½ì—ì„œ Single Node Hadoop Clsuter ë¥¼ ì„¤ì¹˜í•œë‹¤. version java: 1.8.0 hadoop: 2.10.1","text":"CentOS 7 í™˜ê²½ì—ì„œ Single Node Hadoop Clsuter ë¥¼ ì„¤ì¹˜í•œë‹¤. version java: 1.8.0 hadoop: 2.10.1 &#x2728; Contents: Install Java SSH setting Install Hadoop Configuring Hadoop $HADOOP_HOME/etc/hadoop/core-site.xml $HADOOP/etc/hadoop/hdfs-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml Running Hadoop Before starting the Cluster, we need to format the Hadoop NN in our local system Start NameNode daemon and DataNode daemon Reference Install Java$ yum install -y java-1.8.0-openjdk SSH settinglocalhost ssh ì ‘ì†ì„ ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. 123456$ ssh-keygen -t rsa -P &#x27;&#x27;$ cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys$ sudo vi /etc/ssh/sshd_config#PasswordAuthentication yes$ sudo systemctl restart sshd$ ssh localhost #Test Install Hadoop binary ë‹¤ìš´ë¡œë“œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì • 12345678910$ wget https://downloads.apache.org/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz$ tar -xvzf hadoop-2.10.1.tar.gz$ vi ~/.bashrc# Hadoop envexport HADOOP_HOME=/app/hadoop-2.10.1export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.275.b01-0.el7_9.x86_64PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin$ source ~/.bashrc Configuring Hadoop $HADOOP_HOME/etc/hadoop/core-site.xml123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop-test.novalocal:8020&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; fs.defaultFS value format: hdfs://&#123;hostname&#125;:&#123;port&#125; $HADOOP/etc/hadoop/hdfs-site.xml1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/hdata/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/hdata/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; ì´í›„ namenode/datanode directory ë¥¼ ìƒì„±í•œë‹¤. $HADOOP_HOME/etc/hadoop/mapred-site.xml123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9001&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; $HADOOP_HOME/etc/hadoop/yarn-site.xml123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Running Hadoop Before starting the Cluster, we need to format the Hadoop NN in our local system1$ $HADOOP_HOME/bin/hadoop namenode -format ì´í›„ namenode path ë¡œ ì„¤ì •í•œ í´ë”ì— ë­”ê°€ê°€ ìƒê¹€ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 123456789$ tree/hdata/name/â””â”€â”€ current â”œâ”€â”€ fsimage_0000000000000000000 â”œâ”€â”€ fsimage_0000000000000000000.md5 â”œâ”€â”€ seen_txid â””â”€â”€ VERSION1 directory, 4 files Start NameNode daemon and DataNode daemon123456789$ $HADOOP_HOME/sbin/start-dfs.sh$ $HADOOP_HOME/sbin/start-yarn.sh$ jps12960 Jps10161 NodeManager12625 SecondaryNameNode10051 ResourceManager12435 DataNode12287 NameNode Reference https://helei.pro/doc/Setup-Hadoop-2.7.3-(single-node)-on-AWS-EC2-Ubuntu-AMI.pdf https://www.tecmint.com/install-hadoop-single-node-on-centos-7/ made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Cloud] Docker ì„¤ì¹˜ On CentOS7","slug":"cloud-install_docker_on_centos","date":"2021-01-06T15:00:00.000Z","updated":"2021-01-09T12:23:07.452Z","comments":true,"path":"cloud-install_docker_on_centos/","link":"","permalink":"https://jx2lee.github.io/cloud-install_docker_on_centos/","excerpt":"CentOS 7 í™˜ê²½ì—ì„œ Docker ì„¤ì¹˜ ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. CentOS Linux release 7.5.1804 (Core)","text":"CentOS 7 í™˜ê²½ì—ì„œ Docker ì„¤ì¹˜ ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. CentOS Linux release 7.5.1804 (Core) &#x2728; Contents: ì´ì „ ì„¤ì¹˜ëœ Docker ì‚­ì œ yum-utils íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° Docker repo ì¶”ê°€ Docker ì„¤ì¹˜ (with yum) Referenece ì´ì „ ì„¤ì¹˜ëœ Docker ì‚­ì œ12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine yum-utils íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° Docker repo ì¶”ê°€123$ sudo yum install -y yum-utils$ sudo yum-config-manager \\ --add-repo https://download.docker.com/linux/centos/docker-ce.repo Docker ì„¤ì¹˜ (with yum)123456789101112131415161718192021222324252627$ yum install -y docker-ce$ systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.$ systemctl status dockerâ— docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2021-01-04 13:19:54 KST; 1s ago Docs: https://docs.docker.com Main PID: 11889 (dockerd) Tasks: 13 Memory: 47.3M CGroup: /system.slice/docker.service â””â”€11889 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockJan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.036061899+09:00&quot; leve...rpcJan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.036084134+09:00&quot; leve...rpcJan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.036094510+09:00&quot; leve...rpcJan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.066676014+09:00&quot; leve...t.&quot;Jan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.197938418+09:00&quot; leve...ss&quot;Jan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.247887261+09:00&quot; leve...e.&quot;Jan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.275547502+09:00&quot; leve...0.1Jan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.275733738+09:00&quot; leve...on&quot;Jan 04 13:19:54 test-centos.novalocal systemd[1]: Started Docker Application Container Engine.Jan 04 13:19:54 test-centos.novalocal dockerd[11889]: time=&quot;2021-01-04T13:19:54.303691925+09:00&quot; leve...ck&quot;Hint: Some lines were ellipsized, use -l to show in full.$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Reference https://docs.docker.com/engine/install/centos/ made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] ìì²´ íŠœë‹ Docker ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ë³´ìêµ¬ìš”.","slug":"cloud-docker_image_test","date":"2020-10-27T15:00:00.000Z","updated":"2020-10-29T15:00:24.596Z","comments":true,"path":"cloud-docker_image_test/","link":"","permalink":"https://jx2lee.github.io/cloud-docker_image_test/","excerpt":"ê¸‰íˆ ë‚˜ì£¼ ì¶œì¥ì„ ê°ˆ ì˜ˆì •ì¸ë° ë¬´ìŠ¨ í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì¸ë° ì„œë²„ 1ê°œë¡œ êµ¬ì¶•ì„ í•´ë‹¬ë¼ëŠ” í™©ë‹¹í•œ ìš”ì²­ì´ ìˆì—ˆë‹¤. ìš°ì„  ì„¤ì¹˜ë¥¼ í•˜ê³  ë´ì•¼ í•˜ë‹ˆ.. ê° íŒŒë“œ resource ë¥¼ ìµœì €ë¡œ ì£¼ê³  í…ŒìŠ¤íŠ¸ í•˜ë˜ ë„ì¤‘ ìš°ë¦¬ ì œí’ˆ ë°”ì´ë„ˆë¦¬ì— ìˆ˜ì •ì‚¬í•­ì´ ë°œìƒí•˜ì˜€ë‹¤. ì´ìŠˆë¥¼ ì˜¬ë ¤ì„œ í•´ë„ ë˜ì§€ë§Œ ì–´ì°¨í”¼ ê²€ìˆ˜ ëª©ì ìœ¼ë¡œ ìº¡ì³ë§Œ ëœ¨ëŠ” ì„¤ì¹˜ê±´ì´ë¼ ë°”ì´ë„ˆë¦¬ë¥¼ ìˆ˜ì •í•˜ì—¬ ë®ì–´ ì”Œìš°ëŠ” ìì²´ íŠœë‹ ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤. ì—­ì‹œ GODì •í¬ë‹˜ ìµœê³ ","text":"ê¸‰íˆ ë‚˜ì£¼ ì¶œì¥ì„ ê°ˆ ì˜ˆì •ì¸ë° ë¬´ìŠ¨ í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì¸ë° ì„œë²„ 1ê°œë¡œ êµ¬ì¶•ì„ í•´ë‹¬ë¼ëŠ” í™©ë‹¹í•œ ìš”ì²­ì´ ìˆì—ˆë‹¤. ìš°ì„  ì„¤ì¹˜ë¥¼ í•˜ê³  ë´ì•¼ í•˜ë‹ˆ.. ê° íŒŒë“œ resource ë¥¼ ìµœì €ë¡œ ì£¼ê³  í…ŒìŠ¤íŠ¸ í•˜ë˜ ë„ì¤‘ ìš°ë¦¬ ì œí’ˆ ë°”ì´ë„ˆë¦¬ì— ìˆ˜ì •ì‚¬í•­ì´ ë°œìƒí•˜ì˜€ë‹¤. ì´ìŠˆë¥¼ ì˜¬ë ¤ì„œ í•´ë„ ë˜ì§€ë§Œ ì–´ì°¨í”¼ ê²€ìˆ˜ ëª©ì ìœ¼ë¡œ ìº¡ì³ë§Œ ëœ¨ëŠ” ì„¤ì¹˜ê±´ì´ë¼ ë°”ì´ë„ˆë¦¬ë¥¼ ìˆ˜ì •í•˜ì—¬ ë®ì–´ ì”Œìš°ëŠ” ìì²´ íŠœë‹ ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤. ì—­ì‹œ GODì •í¬ë‹˜ ìµœê³  &#x2728; Contents: ë¬¸ì œ ë°œìƒ ë°”ì´ë„ˆë¦¬ ìˆ˜ì • í›„ docker image ë””ë ‰í† ë¦¬ ìƒì„±í•˜ê¸° ë¹Œë“œí•˜ì! ë¬¸ì œ ë°œìƒJEUS ë¥¼ í†µí•´ ë‘ ê°œ ì„œë²„ë¥¼ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì—ì„œ, ThreadPool min/max ê°’ì´ ì˜ëª» ì„¤ì •ë˜ì–´ ë°°í¬í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ ë•Œë¬¸ì— 3ê°œ ì¤‘ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ê°€ ë™ì‘í•˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ install script ë‚´ modify command ë¥¼ ì¶”ê°€í•˜ì—¬ min ê°’ì„ ìˆ˜ì •í•˜ì˜€ë‹¤. ê·¼ë°.. ë‹¹ì¥ ë‚´ì¼ ë‚˜ì˜¤ëŠ” ë°”ì´ë„ˆë¦¬ë¡œ ë‚˜ê°ˆ í•„ìš”ë„ ì—†ê³  ì„œë²„ ìŠ¤í™ë„ ì¶©ë¶„í•˜ì§€ ëª»í•œ ìƒí™©ì—ì„œ ì´ì „ ë²„ì ¼ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²Œ ë² ìŠ¤íŠ¸ ì¼ ê²ƒ ê°™ì•„ ìì²´ì ìœ¼ë¡œ Docker ì´ë¯¸ì§€ë¥¼ íŠœë‹í•´ë³´ê³ ì í•œë‹¤. ë°”ì´ë„ˆë¦¬ ìˆ˜ì • í›„ docker image ë””ë ‰í† ë¦¬ ìƒì„±í•˜ê¸°ìœ„ ë¬¸ì œ ë°œìƒì—ì„œ í•´ê²°í•œ ë°”ì´ë„ˆë¦¬ë¥¼ ë‹¤ì‹œ ë˜‘ê°™ì€ ë°”ì´ë„ˆë¦¬ë¡œ ì••ì¶•í•œ ë’¤ docker ì´ë¯¸ì§€ ë¹Œë“œë¥¼ ìœ„í•œ ê³³ì— ìœ„ì¹˜í•œë‹¤. ê·¸ë¦¬ê³  Dockerfile ë¥¼ ìƒì„±í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•œë‹¤. 12FROM hyperdata8.3_hd_v8.3.2:20201016_v1COPY HyperData_8.3_r874bb4-20201016030033_v8.3.2.tar.gz /deploy_src/src/hyperdata/HyperData_8.3_r874bb4-20201016030033_v8.3.2.tar.gz ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ base ë¡œ FROM ìœ¼ë¡œ í˜¸ì¶œ êµ‰ì¥íˆ ì‰¬ì› ë‹¤. í•´ë‹¹ ìˆ˜ì •í•œ ë°”ì´ë„ˆë¦¬ íŒŒì¼ì„ ì´ë¯¸ì§€ ë‚´ ì›ë˜ ìˆë˜ ë””ë ‰í† ë¦¬ì— ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì‘ì„±ë§Œ í•˜ë©´ Docker build ì‹œ ìµœì¢… ë°”ì´ë„ˆë¦¬ëŠ” ë‚´ê°€ ìˆ˜ì •í•œ ë°”ì´ë„ˆë¦¬ë¡œ ì••ì¶•ì„ í•´ì œí•  ê²ƒì´ë‹¤. Dockerfile ì— ìˆœì„œëŠ” ë¬´ê´€í•˜ë‹¤ëŠ” ê±¸ ì˜¤ëŠ˜ ê¹¨ë‹¬ì•˜ê³  ë‚˜ì˜ ë¬´ì§€í•¨ ë˜ëŠ” ê¹¨ë‹¬ì•˜ë‹¤. Docker image build ì— ëŒ€í•´ ë” ì‚´í´ë³¼ í•„ìš”ê°€ ìˆì–´ë³´ì¸ë‹¤. ë¹Œë“œí•˜ì!í•´ë‹¹ ë””ë ‰í† ë¦¬ ì•ˆì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì»¤ë§¨ë“œë¡œ ë¹Œë“œí•œë‹¤. 1docker build -t &#123;ê¸°ì¡´_ì´ë¯¸ì§€ëª…&#125;:&#123;íƒœê·¸_ë³€ê²½_ì•„ë¬´ê±°ë‚˜_í•˜ì„¸ìš”&#125; . ë§ˆì§€ë§‰ ì¤„ .(ì ) ì¤‘ìš”í•˜ë‹¤. ë¬¼ë¡  ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì´ ìˆì§€ë§Œ ì£¼ì§€ ì•Šì„ ê²½ìš° ì ì„ í†µí•´ ë¹Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì¸ì‹í•œë‹¤. íƒœê·¸ëª…ì˜ ê²½ìš° ì´ì „ íƒœê·¸ëª…ì—ì„œ ë‚˜ëŠ” ê³ ê°ì‚¬ ì˜ë¬¸ ì¤„ì„ë§Œ ë¶™ì˜€ë‹¤. ì–‘ì•„ì·¨ docker images ì»¤ë§¨ë“œë¡œ ìƒì„±ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. ë‚˜ì˜ ê²½ìš° ì´ë ‡ê²Œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê³  í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ë‹ˆ, ë‚´ê°€ ìˆ˜ì •í•œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ë°˜ì˜ë˜ì—ˆê³  ëª¨ë“ ê²Œ Dockerfile ë‘ ì¤„ë¡œ ëë‚˜ë²„ë ¸ë‹¤. ì¡°ê¸ˆì€ í—ˆë¬´í•˜ì§€ë§Œ Container ì´ë¯¸ì§€ ë¹Œë“œ ê³¼ì •ì— ëŒ€í•´ ê´€ì‹¬ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê³„ê¸°ê°€ ë˜ì—ˆë‹¤! ê³µë¶€í•  ê²Œ ì‚°ë”ë¯¸ë‹¤. made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] cri-o ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ì‚¬ìš© ì‹œ docker registry ì„¸íŒ…","slug":"cloud-crio_registry_setting","date":"2020-10-02T15:00:00.000Z","updated":"2020-10-29T14:32:47.546Z","comments":true,"path":"cloud-crio_registry_setting/","link":"","permalink":"https://jx2lee.github.io/cloud-crio_registry_setting/","excerpt":"kubernetes ë²„ì ¼ì´ ì˜¬ë¼ê°ì— ë”°ë¼ (1.15.3 â†’ 1.17.6) ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì„ cri-o ë¡œ ë³€ê²½í•˜ì˜€ë‹¤. ì´ë¯¸ì§€ ì €ì¥ì†ŒëŠ” ê·¸ëŒ€ë¡œ docker ì‚¬ìš©í•˜ëŠ”ë° ì´ë•Œ docker registry ì™€ ì—°ë™í•˜ì—¬ image ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³¸ë‹¤. Updata Note 2020.10.29 : config ì¶”ê°€ ìˆ˜ì •","text":"kubernetes ë²„ì ¼ì´ ì˜¬ë¼ê°ì— ë”°ë¼ (1.15.3 â†’ 1.17.6) ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì„ cri-o ë¡œ ë³€ê²½í•˜ì˜€ë‹¤. ì´ë¯¸ì§€ ì €ì¥ì†ŒëŠ” ê·¸ëŒ€ë¡œ docker ì‚¬ìš©í•˜ëŠ”ë° ì´ë•Œ docker registry ì™€ ì—°ë™í•˜ì—¬ image ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³¸ë‹¤. Updata Note 2020.10.29 : config ì¶”ê°€ ìˆ˜ì • &#x2728; Contents: config ìˆ˜ì • cri-o ì¬ê¸°ë™ í…ŒìŠ¤íŠ¸ í•´ë³´ì! config ìˆ˜ì •/etc/crio/crio.conf ë‚´ ì¤‘ê°„ì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ì´ insecure_registries ì— docker registry endpoint ë¥¼ ì¶”ê°€í•œë‹¤. 1234# List of registries to skip TLS verification for pulling images. Please# consider configuring the registries via /etc/containers/registries.conf before# changing them here.insecure_registries = [\"192.168.179.185:5000\", \"192.168.179.189:5000\"] ì²« ë²ˆì§¸ endpoint ëŠ” ê¸°ì¡´, ë’¤ì— ì¶”ê°€í•œ endpoint ê°€ ìƒˆë¡œ í…ŒìŠ¤íŠ¸í•  docker registry endpoint ì´ë‹¤. ì¶”ê°€ì ìœ¼ë¡œ config ì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•´ì•¼í•œë‹¤. registries = [â€œ{registry}:{port}â€ , â€œdocker.ioâ€] plugin_dirs : â€œ/opt/cni/binâ€ ì¶”ê°€ ë§Œì•½ íì‡„ë§ í™˜ê²½ì¼ ê²½ìš°, pause_image ë¶€ë¶„ ì•ì— registry enpointë¥¼ ì¶”ê°€í•´ì•¼í•œë‹¤. cri-o ì¬ê¸°ë™cri-o ì„œë¹„ìŠ¤ë¥¼ ì¬ê¸°ë™í•œë‹¤. 1$ systemctl restart crio í…ŒìŠ¤íŠ¸ í•´ë³´ì!crictl ë¡œ ì¶”ê°€í•œ docker registry ì™€ ì—°ë™ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í…ŒìŠ¤íŠ¸ í•´ë³´ì! 1234$ crictl pull 192.168.179.189:5000/hyperdata8.3_tb:20200717_v3Image is up to date for 192.168.179.189:5000/hyperdata8.3_tb@sha256:85e0f94a90a26090488b929e3ef9475b2cab35ad425effdf5e79a7f2f7029a06$ crictl images |grep hyperdata8.3_tb192.168.179.189:5000/hyperdata8.3_tb 20200717_v3 76063ea49aadd 3.1GB ê°™ì€ ë°©ë²•ìœ¼ë¡œ push í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì„ ê´€ë¦¬í•˜ëŠ” ë†ˆì´ crio ì´ê³ , crictl config ëŠ” /etc/crio/crio.conf ì´ë©° docker registry ì™€ ì—°ë™ì„ ìœ„í•´ í•´ë‹¹ config ë¥¼ ìˆ˜ì •í•˜ê³  crio service ë¥¼ ì¬ ì‹œì‘í•œë‹¤. ì´ì „ì—ëŠ” ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„, ì´ë¯¸ì§€ ê´€ë¦¬ë¥¼ ëª¨ë‘ docker ì—ì„œ ê´€ë¦¬í•˜ì—¬ í¸í•˜ê¸´ í–ˆëŠ”ë°.. cri-oì— ëŒ€í•œ ê°œë…ì„ ì •ë¦¬í•´ë³¼ í•„ìš”ê°€ ìˆë‹¤. made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Linux] Timezone ë³€ê²½","slug":"linux-change_timezone","date":"2020-10-02T15:00:00.000Z","updated":"2020-10-03T14:14:42.565Z","comments":true,"path":"linux-change_timezone/","link":"","permalink":"https://jx2lee.github.io/linux-change_timezone/","excerpt":"tzdata íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ê¸°ì¡´ UTC timezone ì„ KST ë¡œ ë³€ê²½í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤.","text":"tzdata íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ê¸°ì¡´ UTC timezone ì„ KST ë¡œ ë³€ê²½í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤. &#x2728; Contents: íŒ¨í‚¤ì§€ ì„¤ì¹˜ Symbolic link ì„¤ì • ë° íŒ¨í‚¤ì§€ ì¬ì„¤ì • Reference íŒ¨í‚¤ì§€ ì„¤ì¹˜Ubuntu íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €ì¸ apt ë¥¼ ì´ìš©í•˜ì—¬ tzdata ë¥¼ ì„¤ì¹˜í•œë‹¤. 1$ apt-get install tzdata Symbolic link ì„¤ì • ë° íŒ¨í‚¤ì§€ ì¬ì„¤ì •default timezone UTC ì—ì„œ KST ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ link ë¥¼ ìƒì„±í•œë‹¤. 123$ ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime$ dateFri Sep 18 13:19:40 KST 2020 ì´í›„ ì¬ ì„¤ì •ì„ ìœ„í•´ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ timezone ì´ KST ë¡œ ì ìš©í•˜ì˜€ëŠ”ì§€ í™•ì¸í•œë‹¤. 1$ dpkg-reconfigure tzdata ë! Reference https://www.lesstif.com/lpt/ubuntu-linux-timezone-setting-61899162.html made by jaejun.lee","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jx2lee.github.io/categories/Linux/"}],"tags":[]},{"title":"[Linux] ssh ë¹„ë°€ë²ˆí˜¸ ë¬»ì§€ë§ˆ!","slug":"linux-ssh_nopasswd","date":"2020-10-02T15:00:00.000Z","updated":"2020-10-03T14:14:41.094Z","comments":true,"path":"linux-ssh_nopasswd/","link":"","permalink":"https://jx2lee.github.io/linux-ssh_nopasswd/","excerpt":"Kubernetes ë…¸ë“œ ê´€ë¦¬ë¥¼ ìœ„í•´ ê° ë…¸ë“œë³„ ì ‘ê·¼ ì‹œ ë¹„ë°€ë²ˆí˜¸ ì—†ì´ í¸í•˜ê²Œ ì ‘ì†í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•˜ì˜€ë‹¤. Aì„œë²„ì—ì„œ B ì„œë²„ë¡œ ì ‘ì†í•˜ëŠ” ìƒí™©ì´ë‹¤.","text":"Kubernetes ë…¸ë“œ ê´€ë¦¬ë¥¼ ìœ„í•´ ê° ë…¸ë“œë³„ ì ‘ê·¼ ì‹œ ë¹„ë°€ë²ˆí˜¸ ì—†ì´ í¸í•˜ê²Œ ì ‘ì†í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•˜ì˜€ë‹¤. Aì„œë²„ì—ì„œ B ì„œë²„ë¡œ ì ‘ì†í•˜ëŠ” ìƒí™©ì´ë‹¤. &#x2728; Contents: Key ìƒì„± Key ë³µì‚¬ Reference Key ìƒì„±ì´ë¯¸ A ì„œë²„ì— ssh Key ê°€ ì¡´ì¬í•œë‹¤ë©´ ì´ ë¶€ë¶„ì€ íŒ¨ìŠ¤í•´ë„ ì¢‹ë‹¤. ë§Œì•½ ì²˜ìŒ ì„¸íŒ…í•˜ëŠ”ê±°ë¼ë©´, ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ ssh Key ë¥¼ ìƒì„±í•˜ì. 12$ # A ì„œë²„ì—ì„œ ì‹¤í–‰$ ssh-keygen Key ë³µì‚¬ìƒì„±í•œ Key ë¥¼ ssh-copy-id ë¥¼ ì´ìš©í•´ B ì„œë²„ì— ë“±ë¡í•œë‹¤. 123$ ssh-copy-id -i ~/.ssh/id_rsa.pub [user]@[ip]$ # user/ipëŠ” ë‹¹ì—° B ì„œë²„ ì •ë³´ë¥¼ ì…ë ¥$ # ìœ„ ì»¤ë§¨ë“œ ì´í›„ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë¬¼ì–´ë³¼í…ë° ì˜ ì…ë ¥í•˜ì. ì´í›„ A ì„œë²„ (host: k8s-master) ì—ì„œ B ì„œë²„ (host: k8s-node1) ë¡œ ì›ê²©ì ‘ì† í•´ë³´ì. 12345678910111213141516171819202122232425262728293031$ ssh k8s-node1Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-112-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sat Oct 3 23:03:28 KST 2020 System load: 0.34 Users logged in: 1 Usage of /home: 0.2% of 19.56GB IP address for enp6s0: 192.168.179.173 Memory usage: 16% IP address for docker0: 172.17.0.1 Swap usage: 0% IP address for tunl0: 10.244.36.64 Processes: 332 * Kubernetes 1.19 is out! Get it in one command with: sudo snap install microk8s --channel=1.19 --classic https://microk8s.io/ has docs and details. * Canonical Livepatch is available for installation. - Reduce system reboots and improve kernel security. Activate at: https://ubuntu.com/livepatch92 packages can be updated.1 update is a security update.*** System restart required ***Last login: Mon Sep 28 17:41:53 2020 from 192.168.188.101 ë! Reference [https://itzone.tistory.com/694]https://itzone.tistory.com/694) made by jaejun.lee","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jx2lee.github.io/categories/Linux/"}],"tags":[]},{"title":"[TroubleShoot] PyTorch 1.5.0+cu101 ë²„ì ¼ ì„¤ì¹˜ ì‹œ ì—ëŸ¬","slug":"troubleshoot-torch_error","date":"2020-10-02T15:00:00.000Z","updated":"2020-10-03T14:29:56.984Z","comments":true,"path":"troubleshoot-torch_error/","link":"","permalink":"https://jx2lee.github.io/troubleshoot-torch_error/","excerpt":"pytorch ê´€ë ¨ í”„ë¡œì íŠ¸ë¥¼ clone í•˜ì—¬ í•´ë³´ë˜ ì¤‘ì—, requirements.txt ë‚´ torch==1.5.0+cu101 ë¶€ë¶„ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì—ëŸ¬ë¥¼ í”¼í•˜ê³  ì œëŒ€ë¡œ ì„¤ì¹˜í•´ë³´ì!","text":"pytorch ê´€ë ¨ í”„ë¡œì íŠ¸ë¥¼ clone í•˜ì—¬ í•´ë³´ë˜ ì¤‘ì—, requirements.txt ë‚´ torch==1.5.0+cu101 ë¶€ë¶„ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì—ëŸ¬ë¥¼ í”¼í•˜ê³  ì œëŒ€ë¡œ ì„¤ì¹˜í•´ë³´ì! &#x2728; Contents: error ë©”ì‹œì§€ í•´ê²°ì€ ì€ê·¼ ì‰½ë„¤ìš”? Reference error ë©”ì‹œì§€pip install -r requirements.txt ë¡œ ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹œ ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ë¥¼ ë§ì´í•˜ì˜€ë‹¤. 12ERROR: Could not find a version that satisfies the requirement torch==1.5.0+cu101 (from -r requirements.txt (line 59)) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 0.3.1, 0.4.0, 0.4.1, 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0)ERROR: No matching distribution found for torch==1.5.0+cu101 (from -r requirements.txt (line 59)) í•´ê²°ì€ ì€ê·¼ ì‰½ë„¤ìš”?ë³„ ê±° ì—†ì—ˆë‹¤. pip install ì‹œ -f ì˜µì…˜ì„ ì´ìš©í•´ stable version ì„ ì°¾ì•„ê°€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆë‹¤. 1$ pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html f ì˜µì…˜: html íŒŒì¼ì˜ URL ë˜ëŠ” ê²½ë¡œë¥¼ ì´ìš©í•´ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ Reference https://huvso.github.io/2020/07/02/python-pip-option.html made by jaejun.lee","categories":[{"name":"TroubleShoot","slug":"TroubleShoot","permalink":"https://jx2lee.github.io/categories/TroubleShoot/"}],"tags":[]},{"title":"[Cloud] Kubernetes ì•„í‚¤í…ì²˜ì— ëŒ€í•´","slug":"cloud-kubernetes_chapter_02.md","date":"2020-09-27T15:00:00.000Z","updated":"2020-10-03T13:50:53.848Z","comments":true,"path":"cloud-kubernetes_chapter_02.md/","link":"","permalink":"https://jx2lee.github.io/cloud-kubernetes_chapter_02.md/","excerpt":"ì‹ ì… ì§ì› êµìœ¡ìë£Œë¥¼ ìœ„í•´ ì‘ì„±í•œ Kubernetes ì†Œê°œ ìë£Œì´ë‹¤. ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ê³ , ì´ë²ˆ ì¥ì—ëŠ” Kubernetes ì•„í‚¤í…ì³ë¥¼ ê°„ëµíˆ ì†Œê°œí•œë‹¤.","text":"ì‹ ì… ì§ì› êµìœ¡ìë£Œë¥¼ ìœ„í•´ ì‘ì„±í•œ Kubernetes ì†Œê°œ ìë£Œì´ë‹¤. ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ê³ , ì´ë²ˆ ì¥ì—ëŠ” Kubernetes ì•„í‚¤í…ì³ë¥¼ ê°„ëµíˆ ì†Œê°œí•œë‹¤. Contents: Architecture Control Plane (Master) íŠ¹ì§• ë° ê¸°ëŠ¥ Component in Control Plane Node Worker Node íŠ¹ì§• ë° ê¸°ëŠ¥ Component in Worker Node Object Basic Object Controller Reference Architecture [ê·¸ë¦¼] kubernetes architecture ver1.17 í´ëŸ¬ìŠ¤í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” Controlplane ì™€ ì»¨í…Œì´ë„ˆê°€ ë°°í¬ë˜ëŠ” ë¨¸ì‹  (ê°€ìƒë¨¸ì‹ ì´ê±°ë‚˜ ì‹¤ì œ ì„œë²„) ì¸ Worker Nodeë¡œ êµ¬ì„±í•œë‹¤. Control Plane (í•œê¸€ ë²ˆì—­ ì‹œ Master ë¼ê³  ë‚˜ì™€ìˆëŠ”ë° Control Plane == Master ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.) ê³¼ Worker Node ë¥¼ í™•ì¸í•˜ê³  Kubernetes ë‚´ì—ì„œì˜ Object ë¥¼ ì‚´í´ë³¸ë‹¤. Control Plane (Master) íŠ¹ì§• ë° ê¸°ëŠ¥ ê´€ë¦¬ìë§Œ ì ‘ì†í•˜ì—¬ ë³´ì•ˆ ì„¤ì •ì´ í•„ìš”í•˜ë‹¤. Conrol Plane Node ë‹¤ìš´ì´ ë°œìƒí•˜ë©´ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ì— ì¥ì• ê°€ ìƒê¸°ë¯€ë¡œ ë³´í†µ 3ëŒ€ë¡œ êµ¬ì„±í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•œë‹¤. í™€ìˆ˜ëŒ€ë¡œ êµ¬ì„±í•˜ëŠ” ì´ìœ ëŠ” ì»¨í…Œì´ë„ˆ ë°°í¬ì— ëŒ€í•œ voting ë¥¼ ìˆ˜ì›”í•˜ê²Œ í•˜ê¸° ìœ„í•¨ì´ë¼ê³  í•œë‹¤. ì†Œê·œëª¨ í™˜ê²½ì—ì„œëŠ” Control Plane ê³¼ Worker Node ë¥¼ ë¶„ë¦¬í•˜ì§€ ì•Šê³  ê°™ì€ ì„œë²„ì— êµ¬ì„±í•œë‹¤. ì¦‰, Control Plane ì´ë©´ì„œ ë™ì‹œì— ì»¨í…Œì´ë„ˆë¥¼ ë„ìš´ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. Component in Control Plane NodeAPI server: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ê°„ í†µì‹ ì˜ ë©”ì¹´ì´ë‹¤. kubectl ìš”ì²­ ë° ë‚´ë¶€ ëª¨ë“ˆì˜ ìš”ì²­ì„ ì²˜ë¦¬í•œë‹¤. kubectl ëª…ë ¹ì–´ëŠ” Control Plane ì—ì„œë§Œ ê°€ëŠ¥í•˜ë‹¤. (ë¬¼ë¡  ì„¤ì¹˜ëŠ” ëª¨ë“  ë…¸ë“œì—ì„œ ìˆ˜í–‰í•œë‹¤.) ê¶Œí•œ ì²´í¬ë¥¼ í†µí•´ ìš”ì²­ì„ í—ˆìš©í•˜ê±°ë‚˜ ê±°ë¶€í•œë‹¤. Etcd ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¡°íšŒí•œë‹¤. RESTful API ì œê³µí•œë‹¤. Etcd: ë¶„ì‚°í˜• key/value ì˜¤í”ˆì†ŒìŠ¤ Storage. Kubernetes clusterì˜ DB ì—­í• ì„ í•˜ëŠ” ì„œë²„ë¡œ ì„¤ì •ê°’ì´ë‚˜ cluster ìƒíƒœë¥¼ ì €ì¥í•œë‹¤. Etcd ë°±ì—…ì„ í†µí•´ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë³µêµ¬ê°€ ê°€ëŠ¥í•˜ë‹¤. (ex. ì˜¤ëŠ˜ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì´ ì‚¬ë§í–ˆë‹¤. ì´ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë°±ì—…í•œ Etcd ìŠ¤ëƒ…ìƒ·ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸í•  ìˆ˜ ìˆë‹¤.) kube-scheduler: í• ë‹¹ì´ í•„ìš”í•œ Podë¥¼ ì—¬ëŸ¬ ì¡°ê±´(source, label)ì— ë”°ë¼ ì ì ˆí•œ ë…¸ë“œì— í• ë‹¹í•˜ëŠ” ì—­í• ì„ í•œë‹¤. kube-controller-manager: Kubernetes ì˜ Object (Pod, ReplicaSet, Deployment ë“±) ìƒíƒœë“¤ì„ ê´€ë¦¬í•œë‹¤. Kubernetes ì˜ Controller ì‹¤í–‰ì„ ë‹´ë‹¹í•œë‹¤. cloud-controller-manager: ì˜¤í”ˆ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì™€ ì—°ê²°í•˜ì—¬ ê´€ë¦¬í•˜ëŠ” controller manger ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. AWS, GCE, Azure ë“±ì˜ í´ë¼ìš°ë“œ íŠ¹í™”ë˜ì–´ ìˆë‹¤ê³  í•œë‹¤! ì´ë²ˆ ìë£Œë¥¼ ì¤€ë¹„í•˜ë©´ì„œ ì•ˆ ì‚¬ì‹¤ì€ api-server, etcd, kube-scheduler, kube-controller-manager ìš”ë†ˆì´ container ë‹¨ìœ„ë¡œ ì‹¤í–‰í•˜ì—¬ ê´€ë¦¬í•˜ëŠ” ì¤„ ì•Œì•˜ëŠ”ë° ë§‰ìƒ ë³´ë‹ˆ ì•„ë‹ˆì—ˆë‹¤. ps -ef |grep {each_component} ë¥¼ ìˆ˜í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345root@k8s-node1:~# ps -ef|grep -E \"kube-apiserver|etcd|kube-controller-manager|kube-scheduler\"root 3368 3311 1 Aug31 ? 10:17:51 kube-apiserver --advertise-address=192.&gt; 168.179.185 --allow-privileged=true --authorization-mode=Node,RBAC ...root 3584 3554 1 Aug31 ? 05:58:22 etcd --advertise-client-urls=https://192.&gt; 168.179.173:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt ...root 3677 3636 0 Aug31 ? 00:20:07 kube-controller-manager &gt; --allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/&gt; controller-manager.conf ... root 3678 3626 0 Aug31 ? 00:38:15 kube-scheduler --bind-address=127.0.0.1 &gt; --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true Worker Node íŠ¹ì§• ë° ê¸°ëŠ¥ Podë¥¼ ìƒì„±í•˜ê³  ë„¤íŠ¸ì›Œí¬ì™€ ë³¼ë¥¨ì„ ì„¤ì •í•©ë‹ˆë‹¤. kubelet ì´ë¼ëŠ” kubernetes Agent ë¥¼ í†µí•´ â€œì–´ë–¤ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” Pod ë¥¼ ë„ì›Œ!â€ ë¼ëŠ” ì„ë¬´ë¥¼ ë°›ëŠ”ë‹¤. ì‹¤ì œ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ëŠ” ì„œë²„ì´ë‹¤. ë…¸ì˜ˆë¼ê³  ìƒê°í•˜ë©´ í¸í•˜ë‹¤. ê° ì„œë²„ì— ë¼ë²¨ì„ ë¶™ì—¬ ì‚¬ìš©ëª©ì ì— ë”°ë¼ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ë“¤ì–´, GPU ë…¸ë“œë¡œë§Œ ì‚¬ìš©í•˜ì—¬ ì´ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ë§Œ ë°°í¬í•˜ê³ ì í•˜ë©´ yaml ì‘ì„± ì‹œ ê´€ë ¨ label ì„ ì„¤ì •í•œë‹¤. Component in Worker Nodekubelet: í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ë…¸ë“œë¡œ ë°°í¬ë˜ëŠ” Agent ì´ë‹¤. Control Plane ì—ë„ ë°°í¬í•˜ì§€ë§Œ Control Plane ì— ì‘ì„±í•˜ë©´ ë„ˆë¬´ ì—†ì–´ë³´ì¼ê¹Œ Worker Node ì— ì‘ì„±í•˜ì˜€ë‹¤. ë…¸ë“œì— í• ë‹¹í•œ Pod ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ë‹¤. Pod ì•ˆ ì»¨í…Œì´ë„ˆ ìƒíƒœë¥¼ ì²´í¬í•˜ê³  ì£¼ê¸°ì ìœ¼ë¡œ Masterì— ì „ë‹¬í•œë‹¤. Control Plane ì˜ APIì„œë²„ì™€ í†µì‹ ì„ í•˜ê³  ì„ë¬´ë¥¼ ë°›ê²Œë˜ë©´ ë…¸ë“œê°€ ìˆ˜í–‰í•´ì•¼ í•  ì„ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤. kube-proxy: Kubernetes ë‚´ë¶€ ë³„ë„ì˜ ê°€ìƒ ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ì •í•˜ê³  ê´€ë¦¬í•˜ëŠ”ë°, ì´ëŸ¬í•œ ê°€ìƒ ë„¤íŠ¸ì›Œí¬ê°€ ë™ì‘í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì—­í• ì„ í•œë‹¤. í˜¸ìŠ¤íŠ¸ì˜ (ê° ë…¸ë“œì˜) ë„¤íŠ¸ì›Œí¬ ê·œì¹™ì„ ê´€ë¦¬í•˜ê³  connection forwarding ì„ ìˆ˜í–‰í•œë‹¤. ì°¸ê³ ìë£Œ ObjectKubernetsëŠ” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ëŒ€ìƒì„ Objectë¼ ì¹­í•˜ë©° í¬ê²Œ Basic Object(ê¸°ë³¸ ì˜¤ë¸Œì íŠ¸)ì™€ Controller(ì»¨íŠ¸ë¡¤ëŸ¬)ë¡œ êµ¬ë¶„í•œë‹¤. Basic ObjectBasic Object ëŠ” Namespace, Pod, Service, Volume 4ê°€ì§€ê°€ ì¡´ì¬í•œë‹¤. Namespace: Kubernetes cluster ë‚´ ë…¼ë¦¬ì ì¸ êµ¬ë¶„ ë‹¨ìœ„ì´ë‹¤. Pod, Service ë“±ì„ namespace ë³„ë¡œ ìƒì„±í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, user ê¶Œí•œ ì—­ì‹œ namespace ë³„ ë¶€ì—¬(ê³ êµ¬ë ¤)í•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„¸ ê°œì˜ namepsace ë¥¼ ìƒì„±í•˜ì—¬ ê°ê° í…ŒìŠ¤íŠ¸ê°€ ê°€ëŠ¥í•˜ë‹¤. ëŒ€ì‹ , ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬í–ˆê¸° ë•Œë¬¸ì— ë‘ namepsace ê°„ íŒŒë“œì˜ í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤. ë”°ë¼ì„œ ë†’ì€ ìˆ˜ì¤€ì˜ ë¶„ë¦¬ë¥¼ ì›í•˜ë©´ í´ëŸ¬ìŠ¤í„° ìì²´ë¥¼ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤. namespace ë‚´ object ëª…ì€ ìœ ì¼í•´ì•¼í•˜ì§€ë§Œ ì „ì²´ namespace ë‚´ object ëª…ì€ ìœ ì¼í•˜ì§€ ì•Šì•„ë„ ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, A namespace ë‚´ Pod ì´ë¦„ì„ test ë¡œ ë°°í¬í•˜ë©´ B namespace ë‚´ Pod ì´ë¦„ì„ test ë¡œ ë°°í¬í•  ìˆ˜ ìˆë‹¤. ì˜ˆì‹œ: kubernetes cluster ë‚´ namespace ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•œë‹¤. 1234567891011121314151617root@k8s-master:~# kubectl get namespaceNAME STATUS AGEanonymous Active 23ddefault Active 191dhyperdata Active 170distio-system Active 23dkfserving-system Active 23dknative-serving Active 23dkube-node-lease Active 191dkube-public Active 191dkube-system Active 191dkubeflow Active 23dmetallb-system Active 171dnps Active 191drook-ceph Active 24dtibero Active 7d23h Pod: Kubernetesì˜ ìµœì†Œ ì‹¤í–‰ ë‹¨ìœ„ì´ë‹¤. KubernetesëŠ” ì»¨í…Œì´ë„ˆë¥¼ ê°œë³„ì ìœ¼ë¡œ ë°°í¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ Pod ë‹¨ìœ„ë¡œ ë°°í¬í•œë‹¤. ì¦‰, ì—¬ëŸ¬ ê°œ ì»¨í…Œì´ë„ˆê°€ í•˜ë‚˜ì˜ Pod ë¡œ ë°°í¬í•  ìˆ˜ë„ ìˆê³  í•˜ë‚˜ì˜ ì»¨í…Œì´ë„ˆë¥¼ í•˜ë‚˜ì˜ Pod ë¡œ ë°°í¬í•  ìˆ˜ ìˆë‹¤. (í›„ìì˜ ê²½ìš° Pod concept ê³¼ ë§ì§€ ì•Šì•„ ì§€ì–‘í•´ì•¼ í•  ë¶€ë¶„ì´ë‹¤) Pod ë‚´ ë„¤íŠ¸ì›Œí¬ í™˜ê²½(IP, Port)ê³¼ ë””ìŠ¤í¬(Volume) ê³µìœ í•œë‹¤. A Container(Port 8080)ì™€ B Container(Port 7001)ê°€ í•˜ë‚˜ì˜ Podë¡œ ë°°í¬ë˜ì—ˆì„ë•Œ, localhost:{ê° í¬íŠ¸}ë¥¼ í†µí•´ ë‘ ì»¨í…Œì´ë„ˆ ê°„ í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤. ë””ìŠ¤í¬ë¥¼ ê³µìœ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ë‘ ì„±ê²©ì˜ ì»¨í…Œì´ë„ˆë¥¼ ë°°í¬í•  ë•Œ íƒ€ ì»¨í…Œì´ë„ˆì˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆë‹¤. YAML / JSON í˜•ì‹ìœ¼ë¡œ ì„ ì–¸(config)í•˜ëŠ”ë°, ì£¼ë¡œ ì„ ì–¸í•  ë•ŒëŠ” YAML ì„ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤. Service: Pod ëŠ” Controller ì— ì˜í•´ ê´€ë¦¬ë˜ëŠ”ë°, ë§Œì•½ ë…¸ë“œ ë‚´ ì¥ì• ê°€ ë°œìƒí•˜ì—¬ ë‹¤ë¥¸ ë…¸ë“œì— Pod ë¥¼ ì¬ ë°°í¬í•˜ê²Œë˜ë©´ Pod ì˜ IPê°€ ë³€ê²½ëœë‹¤. ì´ë ‡ê²Œ Pod IPê°€ ë³€ê²½ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ ì IPë¥¼ íŠ¹ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ Serviceë‹¤. label ê³¼ label selector ë¥¼ ì´ìš©í•˜ì—¬ ê°™ì€ ì„œë¹„ìŠ¤ë¡œ ë¬¶ì„ íŒŒë“œë¥¼ ì •ì˜í•  ìˆ˜ ìˆê³ , ê°™ì€ ì„œë¹„ìŠ¤ë¡œ ë¬¶ì´ë©´ ê³ ì • ì£¼ì†Œë¥¼ ì´ìš©í•´ ë¬¶ì¸ íŒŒë“œê°„ í†µì‹ ì„ ì›í™œíˆ í•  ìˆ˜ ìˆë‹¤. Service Type ClusterIP: kubernetes cluster ë‚´ì—ì„œë§Œ ì‚¬ìš©ê°€ëŠ¥í•œ IPë¡œ ì™¸ë¶€ì—ì„œëŠ” ì ‘ê·¼ì´ ë¶ˆê°€í•˜ë‹¤. NodePort: cluster ë‚´ ëª¨ë“  ë…¸ë“œì˜ ì§€ì •ëœ í¬íŠ¸ë¥¼ í• ë‹¹í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, A ë…¸ë“œì— ë– ìˆëŠ” a íŒŒë“œë¡œ ì ‘ê·¼í•˜ê³  ì‹¶ì„ ë•Œ a íŒŒë“œë¥¼ NodePort ì„œë¹„ìŠ¤ë¡œ ë¬¶ì–´ì£¼ë©´ B ë…¸ë“œ IP:Port ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. LoadBalancer: NodePort ì˜ í™•ì¥ìœ¼ë¡œ ì„œë¹„ìŠ¤ IP, ë“± ì™¸ë¶€ë¡œ ë…¸ì¶œí•˜ê³ ì í•˜ëŠ” íŠ¹ì • IP ë¥¼ ì´ìš©í•˜ì—¬ ì™¸ë¶€ì—ì„œ íŠ¹ì • IPë¥¼ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” Service Type ì´ë‹¤. ExternalName: ì™¸ë¶€ ì„œë¹„ìŠ¤ë¥¼ Kubernetes ë‚´ë¶€ì— í˜¸ì¶œí•˜ê³ ì í•  ë•Œ ì‚¬ìš©í•˜ëŠ” Service Type ì´ë‹¤. (ì‚¬ìš©ì„ ì•ˆí•´ë´¤ë‹¤..) Volume Container ì¬ì‹œì‘ì— ìƒê´€ì—†ì´ íŒŒì¼ì„ ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥í•´ì•¼í•˜ëŠ” ìŠ¤í† ë¦¬ì§€ì´ë‹¤. Pod ë‚´ Container ë“¤ì€ í•´ë‹¹ ë””ìŠ¤í¬ë¥¼ ê³µìœ í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì¢…ë¥˜: emptyDir: Pod ì™€ í•¨ê»˜ ìƒì„±í•˜ê³  ì‚¬ë¼ì§€ëŠ” ì„ì‹œ ë³¼ë¥¨ì´ë‹¤. hostPath: í•´ë‹¹ ë…¸ë“œì˜ ë””ìŠ¤í¬ ê²½ë¡œë¥¼ Pod ì— ë§ˆìš´íŠ¸í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. í•´ë‹¹ ë…¸ë“œ ë””ìŠ¤í¬ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ëŠ” ê¼­ í™•ì¸ì´ í•„ìš”í•˜ë‹¤. Kubernetes ì—ì„œëŠ” emptyDir, hostPath ì´ì™¸ì— PV(PersistentVolumne) ì™€ PVC(PersistentVolumnClaim) ë¼ëŠ” ì¶”ìƒí™”í•œ ê°œë…ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤. Pod ì™€ ë³„ë„ì˜ ìƒëª…ì£¼ê¸°ë¥¼ ê°€ì§€ê³  ìˆì–´ í•´ë‹¹ ë³¼ë¥¨ì„ ë¬¼ê³  ìˆëŠ” Pod ê°€ ì£½ë”ë¼ë„ PV ë˜ëŠ” PVC ë¥¼ ì§€ìš°ì§€ ì•ŠëŠ” í•œ ë°ì´í„°ëŠ” ì†Œë©¸í•˜ì§€ ì•ŠëŠ”ë‹¤. ì‰½ê²Œ ë§í•´ ë…¸íŠ¸ë¶ ë””ìŠ¤í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì™¸ì¥ í•˜ë“œë¥¼ ì´ìš©í•œë‹¤ê³  ìƒê°í•˜ì. PV: í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ìì›ìœ¼ë¡œ ë‹¤ë¤„ì§€ëŠ” ë³¼ë¥¨ ìì²´ë¥¼ ì˜ë¯¸í•œë‹¤. í•˜ë‚˜ì˜ ì €ì¥ì†Œë¡œ ìƒê°í•˜ì. PVC: ì‚¬ìš©ìê°€ PVì— ìš”ì²­í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì–¼ë§Œí¼, ì½ê³ ì“°ê¸°ê°€ ê°€ëŠ¥í•œ ì§€ spec ì„ ì •ì˜í•˜ì—¬ ë°°í¬í•˜ë©´ ê·¸ì— ë§ëŠ” PVê°€ ìƒì„±ëœë‹¤. Controller Controller ëŠ” ë‹¤ì¤‘ Pod ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì—­í• ë¡œ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ replication handling, rollout ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í´ëŸ¬ìŠ¤í„° ë‚´ í•œ Node ê°€ ë‹¤ìš´ë˜ì—ˆì„ ê²½ìš° Controller ëŠ” ë‹¤ë¥¸ ë…¸ë“œì— í•´ë‹¹ íŒŒë“œë¥¼ ë°°í¬(ìŠ¤ì¼€ì¥´ë§) í•¨ìœ¼ë¡œì¨ ê´€ë¦¬í•œë‹¤. êµ‰ì¥íˆ ë§ì€ Controller ê°€ ìˆëŠ”ë° ê·¸ ì¤‘ì—ì„œ ReplicaSet, Deployment, DaemonSet ì„ ì‚´í´ë³¸ë‹¤. ReplicaSet Pod ë¥¼ ë³µì œí•˜ì—¬ ìƒì„±í•˜ê³  ì´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ìœ ì§€í•˜ëŠ” Controller ì´ë‹¤. ì‹¤í–‰í•˜ê³ ì í•˜ëŠ” Pod ì˜ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì›í•˜ëŠ” ê°¯ìˆ˜ë§Œí¼ ì„¤ì •í•˜ì—¬ ë°°í¬í•˜ë©´, ê·¸ ê°¯ìˆ˜ë§Œí¼ Pod ê°€ ì‹¤í–‰ë˜ê²Œë” ê´€ë¦¬í•˜ëŠ” Controller ì´ë‹¤. ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ë³´ë‹¨ Deployment ë“± ë‹¤ë¥¸ ì˜¤ë¸Œì íŠ¸ì— ì˜í•´ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì˜ˆì‹œ: nginx ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì»¨í…Œì´ë„ˆ (ì´ ì˜ˆì‹œëŠ” 1 container == 1 pod) ë¥¼ spec.replicas value ë§Œí¼ ìœ ì§€í•˜ì„¸ìš”. 1234567891011121314151617181920apiVersion: apps/v1kind: ReplicaSetmetadata: name: test-replicasetspec: template: metadata: name: test-replicaset labels: app: test-replicaset spec: containers: - name: test-replicaset image: nginx ports: - containerPort: 80 replicas: 3 selector: matchLabels: app: test-replicaset Deployment Kubernetes ì—ì„œ ìƒíƒœê°€ ì—†ëŠ”(stateless) ì•±ì„ ë°°í¬í•  ë•Œ ê°€ì¥ ê¸°ë³¸ì ì¸ ì»¨íŠ¸ë¡¤ëŸ¬, ì´ì „ ë²„ì ¼ì—ì„œëŠ” ReplicaSet ì´ ë‹´ë‹¹í–ˆì§€ë§Œ ì´ì œëŠ” Deployment ê°€ ë‹´ë‹¹í•œë‹¤. Pod ê°œìˆ˜ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒ ë¿ ì•„ë‹ˆë¼ ë¬´ì¤‘ë‹¨ ë°°í¬ë¥¼ ìœ„í•œ ë°©ì‹ (blue/green deployment, canary deployment, rolling deployment) ì„ ì œê³µí•œë‹¤. ReplicaSet ê³¼ ë¹„êµí•˜ë©´ Pod ê°œìˆ˜ ìœ ì§€ëŠ” ê°™ì§€ë§Œ ì¶”ê°€ì ìœ¼ë¡œ ë¬´ì¤‘ë‹¨ ë°°í¬ ë°©ì‹ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. deployment ë°°í¬ ì‹œ ì—…ë°ì´íŠ¸ ë°©ì‹ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. (ì¡°ëŒ€í˜‘ë‹˜ ë¸”ë¡œê·¸ì— ë”°ë¥´ë©´ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ë°°í¬ ë°©ì‹ì´ë©°, ë”°ë¡œ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ rolling ë°°í¬ë¥¼ ìˆ˜í–‰í•œë‹¤. ì°¸ê³ ) ë¬´ì¤‘ë‹¨ ë°°í¬ë°©ì‹: ì°¸ê³ ìë£Œ DaemonSet í´ëŸ¬ìŠ¤í„° ì „ì²´ì— Podë¥¼ ë„ì›Œì£¼ëŠ” Controller ì´ë‹¤. Daemonset ì„ ë°°í¬í•˜ë©´ í•­ìƒ ê·¸ Pod ê°€ ì „ì²´ ë…¸ë“œì— ë°°í¬í•œë‹¤. ìƒˆë¡­ê²Œ ë…¸ë“œê°€ ì¶”ê°€ë˜ì—ˆì„ë•Œ ìë™ìœ¼ë¡œ Pod ë¥¼ ë°°í¬í•œë‹¤. ë°˜ëŒ€ë¡œ ë…¸ë“œê°€ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë¹ ì¡Œì„ ë•Œ ê·¸ ë…¸ë“œì— ìˆë˜ í¬ë“œëŠ” ê·¸ëŒ€ë¡œ ì‚¬ë¼ì§€ê³  ë‹¤ë¥¸ ê³³ìœ¼ë¡œ ì˜®ê²¨ê°€ì„œ ë°°í¬í•˜ì§„ ì•ŠëŠ”ë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•Œë¬¸ì— ë³´í†µ ë¡œê·¸ìˆ˜ì§‘ê¸°ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ëª¨ë‹ˆí„°ë§ìš© ë°ëª¬ë“± í´ëŸ¬ìŠ¤í„° ì „ì²´ì— í•­ìƒ ì‹¤í–‰ì‹œì¼œ ë‘ì–´ì•¼ í•  ë•Œ ì‚¬ìš©í•œë‹¤. StatefulSet ì•ì„œ ì‚´í´ë³¸ Controller ì™€ ë‹¬ë¦¬ ìƒíƒœë¥¼ ê°€ì§€ê³  ìˆëŠ” Pod ë“¤ì„ ê´€ë¦¬í•˜ëŠ” Controller ë¡œ, ë³¼ë¥¨ì„ ì‚¬ìš©í•´ íŠ¹ì • ë°ì´í„°ë¥¼ ê¸°ë¡í•´ë‘ê³  Pod ê°€ ì¬ì‹œì‘ í•´ë„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤. ì—¬ëŸ¬ Pod ë¥¼ ë°°í¬í•  ë•Œ ìˆœì„œë¥¼ ì§€ì •í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ë°°í¬í•  ìˆ˜ ìˆë‹¤. Pod ì´ë¦„ì„ ì—°ì†ì„± ìˆê²Œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. (name-number ì™€ ê°™ì´ í‘œí˜„) ê° Pod ì— ëŒ€í•œ PVC ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆë‹¤. Reference https://ooeunz.tistory.com/118 https://www.slideshare.net/lahuman1/kubernetes-object https://bcho.tistory.com/1259 https://blog.2dal.com/2018/04/30/kubernetes-02-replicaset/ https://perfectacle.github.io/2019/04/21/non-stop-deployment/ https://arisu1000.tistory.com/27834 https://www.joinc.co.kr/w/man/12/kubernetes/overview","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] Kubernetes ì†Œê°œ","slug":"cloud-kubernetes_chapter_01","date":"2020-09-23T15:00:00.000Z","updated":"2020-10-03T13:50:21.081Z","comments":true,"path":"cloud-kubernetes_chapter_01/","link":"","permalink":"https://jx2lee.github.io/cloud-kubernetes_chapter_01/","excerpt":"ì‹ ì… ì§ì› êµìœ¡ìë£Œë¥¼ ìœ„í•´ ì‘ì„±í•œ Kubernetes ì†Œê°œ ìë£Œì´ë‹¤. ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ê³ , ì´ë²ˆ ì¥ì—ëŠ” ë°°ê²½ì„ ì‹œì‘ìœ¼ë¡œ íŠ¹ì§•ê¹Œì§€ ì‚´í´ë³¸ë‹¤.","text":"ì‹ ì… ì§ì› êµìœ¡ìë£Œë¥¼ ìœ„í•´ ì‘ì„±í•œ Kubernetes ì†Œê°œ ìë£Œì´ë‹¤. ë§ì€ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ê³ , ì´ë²ˆ ì¥ì—ëŠ” ë°°ê²½ì„ ì‹œì‘ìœ¼ë¡œ íŠ¹ì§•ê¹Œì§€ ì‚´í´ë³¸ë‹¤. &#x2728; Contents: ë°°ê²½ ê·¸ëŸ¼ ì™œ Kubernetes ê°€ ë–´ì„ê¹Œ? Kubernetes ? Kubernetes íŠ¹ì§• Reference ë°°ê²½ [ê·¸ë¦¼] ë°°í¬ í™˜ê²½ì˜ ë³€í™” ì»¨í…Œì´ë„ˆ ê¸°ë°˜ì˜ í™˜ê²½ì€ ì„œë¹„ìŠ¤ ë°°í¬ì— ì¥ì ì´ ìˆê³  ë§ˆì´í¬ë¡œ ì„œë¹„ìŠ¤ ì•„í‚¤í…ì³(MSA)ì— ë¶€í•©í•œ ë“¯ ì‹¶ì§€ë§Œ, ê°€ìƒ ë¨¸ì‹ ìœ¼ë¡œë„ ì¶©ë¶„íˆ íŒ¨í‚¤ì§•ì´ ê°€ëŠ¥í•˜ê³  ë¡œì»¬ì˜ ê°œë°œí™˜ê²½ì„ ë™ê¸°í™” ì‹œí‚¤ëŠ” ì¼ì€ vagrant ë¡œë„ ì¶©ë¶„í•˜ì˜€ë‹¤. MSA: ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ ì „ì²´ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ íŠ¹ì • ëª©ì ì„ ê°€ì§„ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ê²ƒ, ë‹¨ìœ„ ì–´í”Œë¦¬ì¼€ì´ì…˜ ê°„ ì•½í•œ ê²°í•©ë„ì™€ ê°•í•œ ì‘ì§‘ë„ë¥¼ ëª©í‘œë¡œ í•œë‹¤. vargrant: ê°„ì†Œí™”í•œ VM ê´€ë¦¬ ì„œë¹„ìŠ¤ë¡œ ê°€ìƒ ë¨¸ì‹ ê³¼ ë¡œì»¬ê°„ì˜ ë™ê¸°í™” ì„œë¹„ìŠ¤ë„ ì œê³µí•œë‹¤. ê·¸ë¦¬ê³  ê²°ì •ì ìœ¼ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ìš´ìš©í•˜ê¸° ìœ„í•œ ê´€ë¦¬ í™˜ê²½ì´ ì„±ìˆ™í•˜ì§€ ì•Šì•˜ë‹¤. Mesos DC/OS, Docker Swarm, Kubernetes ë“± ë‹¤ì–‘í•œ í™˜ê²½ì´ ë‚˜ì˜¤ê¸°ëŠ” í•˜ì˜€ì§€ë§Œ ê¸°ëŠ¥ì ìœ¼ë¡œ ë¶€ì¡±í•˜ë©° ì–´ë–¤ í”Œë«í¼ì´ ëŒ€ì„¸ë¼ê³  ì •í•´ì§€ì§€ ì•Šì•˜ë‹¤. Mesos DC/OS: Apache Mesos ë¶„ì‚° ì‹œìŠ¤í…œ ì»¤ë„ì„ ê¸°ë°˜ìœ¼ë¡œí•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤, ì°¸ê³ ìë£Œ Docker Swarm: ë„ì»¤ê°€ ê³µì‹ì ìœ¼ë¡œ ê°œë°œí•œ Container Orchestration ê·¸ëŸ¼ì—ë„ ì»¨í…Œì´ë„ˆ í™˜ê²½ìœ¼ë¡œ ë°”ë€ ì´ìœ ê°€ ë¬´ì—‡ì¼ê¹Œ? ë‘ ê¼­ì§€ë¡œ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. MSAì˜ ë°œì „:MSA(Micro Service Architecture)ê°€ ë‹¨ìˆœ ê°œë…ì—ì„œ ë°œì „í•˜ê¸° ì‹œì‘í•˜ë©° ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì¸í”„ë¼ í”Œë«í¼ë“¤ì´ ë“±ì¥í•˜ê¸° ì‹œì‘í–ˆë‹¤. [ê·¸ë¦¼] Micro Service Architecture ì˜ˆì‹œ- ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ íŠ¹ì • ë‹¨ìœ„ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë¶„ë¦¬í•œ ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ì„œë¹„ìŠ¤ í¬ê¸°ê°€ ì‘ì•„ì§€ë©° CPU 1~2 Core ë¡œë„ ìš´ì˜í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë“¤ì´ ë“±ì¥í•˜ë©´ì„œ ì´ë¥¼ VM í™˜ê²½ì—ì„œ ì„œë¹„ìŠ¤ í•˜ê¸°ì—” ë¦¬ì†ŒìŠ¤ ë‚­ë¹„ê°€ ì‹¬í•´ì¡Œë‹¤. VM í™˜ê²½ì„ ìœ„í•´ì„œ í•„ìš”í•œ ì´ë¯¸ì§€ í¬ê¸°ê°€ í¬ê³ , ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ë¥¼ VMìœ¼ë¡œ ê´€ë¦¬ ë°°í¬í•˜ê¸°ì—ëŠ” ì†ë„ ë“±ì—ì„œ íš¨ìœ¨ì ì´ì§€ ëª»í•˜ë‹¤. ì†”ë£¨ì…˜ ë°œì „ ë° DevOps ì•ˆì°©:ì„œë¹„ìŠ¤ ë°°í¬ ë°©ì‹ë„ VM í˜¹ì€ ì»¨í…Œì´ë„ˆ ë‹¨ìœ„ë¡œ ë°°í¬í•˜ëŠ” í”¼ë‹‰ìŠ¤ ì„œë²„ íŒ¨í„´ì´ ë“±ì¥í•˜ì˜€ê³  ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ Spinnakerì™€ ê°™ì€ ì†”ë£¨ì…˜ì´ ë“±ì¥í•˜ì˜€ë‹¤. ë˜í•œ, ì§€ëŠ¥í˜• ë¼ìš°íŒ…ê³¼ ë¶„ì‚° íŠ¸ë Œì ì…˜ ë¡œê·¸ ì¶”ì ì„ í•˜ëŠ” ê¸°ëŠ¥ë“¤ì´ Envoy ë¼ëŠ” ì†”ë£¨ì…˜ìœ¼ë¡œ ë‚˜ì˜¤ê³  ì´ë¥¼ ì¤‘ì•™ í†µì œí•˜ê¸° ìœ„í•œ Istio.io ì™€ ê°™ì€ Service Mesh ì†”ë£¨ì…˜ ê¹Œì§€ ì£¼ëª©ì„ ë°›ê¸° ì‹œì‘í•˜ì˜€ë‹¤. Phoenix Server Patern: SW í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë³€ê²½í•œ ì„¤ì •ì„ í˜„ ì„œë²„ì— ì ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ OSì„¤ì¹˜ë¶€í„° SW ì„¤ì¹˜-ì„¤ì • ë³€ê²½ê¹Œì§€ ë‹¤ì‹œ &gt; ë°˜ë³µí•˜ëŠ” íŒ¨í„´ì„ ì˜ë¯¸í•œë‹¤. Envoy: ëŒ€í˜• MSAì˜ ë‹¨ì¼ Applicationê³¼ Serviceë¥¼ ìœ„í•´ ì„¤ê³„ëœ ê³ ì„±ëŠ¥ ë¶„ì‚° c++í”„ë¡ì‹œ Istio.io: Envoy proxyë¥¼ ì‚¬ìš©í•˜ë©° ì´ë¥¼ ì»¨íŠ¸ë¡¤ í•´ì£¼ëŠ” Control Planeì˜ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜, ì°¸ê³ ìë£Œ DevOps ê°œë…ë„ ë‚˜ì˜¨ì§€ ì˜¤ë˜ë˜ì—ˆì§€ë§Œ, ìš´ì˜ì„ DevOpsë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë°”ê¾¼ ê²ƒì¼ë¿ ì‹¤ì œì ì¸ ë³€í™”ê°€ ì—†ëŠ” íŒ€ë“¤ì´ ë§ì•˜ë‹¤ê³  í•œë‹¤. ë˜ëŠ” DevOpsë¼ëŠ” ì´ë¦„ ì•„ë˜ ê°œë°œíŒ€ì´ ê°œë°œê³¼ ìš´ì˜ ì—­í• ì„ ë³‘í–‰í•´ì„œ í•˜ëŠ” ì‚¬ë¡€ê°€ ì˜¤íˆë ¤ ë§ì•˜ë‹¤. ì´ëŸ° DevOpsì˜ ê°œë…ë„ ê·¼ë˜ ë“¤ì–´ ê°œë°œíŒ€ì´ ê°œë°œê³¼ ì‹œìŠ¤í…œì— ëŒ€í•œ ë°°í¬/ìš´ì˜ì„ ë‹´ë‹¹í•œë‹¤ë©´, DevOps íŒ€ì€ ê°œë°œíŒ€ì´ ì´ë¥¼ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œë” í”Œë«í¼ê³¼ ìë™í™”ë¥¼ í•˜ëŠ”ë° ëª©í‘œë¥¼ ë‘ëŠ” ì—­í• ë¡œ êµ¬ë¶„ì§€ì–´ì¡Œë‹¤. ê·¸ëŸ¼ ì™œ Kubernetes ê°€ ë–´ì„ê¹Œ?ì»¨í…Œì´ë„ˆ ìš´ìš© í™˜ê²½ì€ ì˜¤í”ˆì†ŒìŠ¤ì— ì˜í•´ í‘œì¤€ì—†ì´ í˜¼ëˆìƒíƒœì˜€ëŠ”ë°, 2017ë…„ ë§ì„ ê¸°ì ìœ¼ë¡œ Kubernetesê°€ de-facto í‘œì¤€ìœ¼ë¡œ ìë¦¬ì¡ì•˜ë‹¤. ì•„ë˜ íŠ¸ëœë“œ ê·¸ë˜í”„ë¥¼ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯ kubernetesì˜ íŠ¸ëœë“œê°€ ì§€ì†ì ìœ¼ë¡œ ì˜¬ë¼ê°€ì„œ ê°€ì¥ ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¶”ê°€ë¡œ github repo star í†µê³„ì— ëŒ€í•´ì„œë„ 2015 ë…„ì„ ê¸°ì ìœ¼ë¡œ í¬ê²Œ ì¦ê°€í•˜ì—¬ 2018ë…„ ë§ì—ëŠ” ì—„ì²­ í° ì°¨ì´ë¥¼ ë³´ì´ê³  ìˆë‹¤. [ê·¸ë¦¼] Container Orchestration Trends [ê·¸ë¦¼] github repo star for Container Orchestration Kubernetes ? ì»¨í…Œì´ë„ˆ ìš´ì˜í™˜ê²½ ì¤‘ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì†”ë£¨ì…˜ì´ë‹¤. (ì•½ì–´ë¡œ k8s, 8ì˜ ì˜ë¯¸ëŠ” kì™€ sì‚¬ì´ ì•ŒíŒŒë²³ ê°¯ìˆ˜) êµ¬ê¸€ì˜ ë‚´ë¶€ ì»¨í…Œì´ë„ˆ ì„œë¹„ìŠ¤ë¥¼ Borgë¼ê³  í•˜ëŠ”ë° ì´ êµ¬ì¡°ë¥¼ ì˜¤í”ˆì†ŒìŠ¤í™” í•œ ê²ƒì´ë‹¤. GO ì–¸ì–´ë¡œ êµ¬í˜„í•˜ì˜€ë‹¤. golang ë²¤ë”ë‚˜ í”Œë«í¼ì— ì¢…ì†ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Public Cloud (Google, Amazone, MS Azure) ì™€ Private CLoud ë° ë² ì–´ë©”íƒˆ í™˜ê²½ (ê°€ìƒí™” í™˜ê²½ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¼ë°˜ ì„œë²„ í•˜ë“œì›¨ì–´, like ê¹¡í†µ) ì—ì„œ êµ¬ì¶• ê°€ëŠ¥ ì´ëŸ¬í•œ ì´ìœ ë¡œ Hybrid Cloud í™˜ê²½ ê°€ëŠ¥ (Private + Public) ë‹¤ì–‘í•œ Container Runtime ì œê³µ Docker ë˜í•œ Container Runitme ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥í•˜ì§€ë§Œ, CRI-O ê°€ í˜„ì¬ Kubernetes ë¥¼ ìœ„í•œ í‘œì¤€ Container Runtime ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆë‹¤. ê´€ë ¨ ìë£Œ http://www.opennaru.com/kubernetes/cri-o/ https://www.samsungsds.com/global/ko/support/insights/docker.html https://bcho.tistory.com/1353 Kubernetes íŠ¹ì§• ìƒíƒœê´€ë¦¬ : ìƒíƒœë¥¼ ì„ ì–¸í•˜ê³  ì„ ì–¸í•œ ìƒíƒœë¥¼ ê³„ì†í•´ì„œ ìœ ì§€í•œë‹¤. ë…¸ë“œê°€ ì£½ê±°ë‚˜ Container ì‘ë‹µì´ ì—†ì„ ê²½ìš°, ìë™ìœ¼ë¡œ ìƒˆë¡œìš´ Container ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìë™ìœ¼ë¡œ íŠ¹ì • ìƒíƒœì— ë„ë‹¬í•˜ì§€ ëª»í•œ Conatiner ë¥¼ ì¤‘ì§€í•˜ëŠ” ë“± ì„ ì–¸í•œ ìƒíƒœë¥¼ ê³„ì†í•´ì„œ ìœ ì§€í•œë‹¤. ìŠ¤ì¼€ì¤„ë§ : ì–´ë–¤ ë…¸ë“œì— Container ë¥¼ ì‹¤í–‰í• ì§€ ê³ ë¯¼í•˜ì§€ ì•Šì•„ë„ Kubernetes ì¡°ê±´ì— ë§ëŠ” ë…¸ë“œë¥¼ ì°¾ì•„ì„œ Conatiner ë¥¼ ë°°ì¹˜í•œë‹¤. (íŠ¹ì • ë…¸ë“œì— ì‹¤í–‰í•˜ê²Œ ì¡°ê±´ ì„¤ì •ë„ ê°€ëŠ¥í•˜ë‹¤) í´ëŸ¬ìŠ¤í„° : ê°€ìƒ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ í†µì‹ í•˜ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ ì„œë²„ì²˜ëŸ¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ : ì„œë¡œ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë¥¼ ì‰½ê²Œ ì°¾ê³  í†µì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Reference ì¿ ë²„ë„¤í‹°ìŠ¤ #1 - ì†Œê°œ [Kubernetes] ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ë“±ì¥ ë°°ê²½ [ì´ˆë³´ê°œë°œì ì¼ì§€] ëŒ€ì„¸ MSA? ë„ˆ ë­ë‹ˆ? made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Database] ì¼ ë‹¨ìœ„ ì ì¬ í”„ë¡œì„¸ìŠ¤ í›‘ì–´ë³´ê¸°","slug":"database-daily_batch_process","date":"2020-09-09T15:00:00.000Z","updated":"2020-09-26T14:08:33.079Z","comments":true,"path":"database-daily_batch_process/","link":"","permalink":"https://jx2lee.github.io/database-daily_batch_process/","excerpt":"í”„ë¡œì íŠ¸ ì‹œë²”ê³¼ì œ ì¤‘ [ë°ì´í„° ë§ˆíŠ¸ êµ¬ì¶•]ì„ ìˆ˜í–‰í•˜ë©´ì„œ ê³ ê°ìš”ê±´ì— ë§ëŠ” í…Œì´ë¸”ì„ ìƒì„±í•˜ê³  ê°±ì‹ í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ê²½í—˜í•˜ì˜€ë‹¤. ë³„ ì–´ë ¤ìš´ ë‚´ìš©ì€ ì—†ì§€ë§Œ ë‚´ ë¨¸ë¦¿ì†ì— ì €ì¥íˆê¸° ìœ„í•´ ê¸€ë¡œ ë‚¨ê²¨ë†“ëŠ”ë‹¤. (ë„ì›€ì„ ì£¼ì‹  ê°“ì •í¬ë‹˜ê»˜ ê°ì‚¬ì˜ ì¸ì‚¬ë¥¼)","text":"í”„ë¡œì íŠ¸ ì‹œë²”ê³¼ì œ ì¤‘ [ë°ì´í„° ë§ˆíŠ¸ êµ¬ì¶•]ì„ ìˆ˜í–‰í•˜ë©´ì„œ ê³ ê°ìš”ê±´ì— ë§ëŠ” í…Œì´ë¸”ì„ ìƒì„±í•˜ê³  ê°±ì‹ í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ê²½í—˜í•˜ì˜€ë‹¤. ë³„ ì–´ë ¤ìš´ ë‚´ìš©ì€ ì—†ì§€ë§Œ ë‚´ ë¨¸ë¦¿ì†ì— ì €ì¥íˆê¸° ìœ„í•´ ê¸€ë¡œ ë‚¨ê²¨ë†“ëŠ”ë‹¤. (ë„ì›€ì„ ì£¼ì‹  ê°“ì •í¬ë‹˜ê»˜ ê°ì‚¬ì˜ ì¸ì‚¬ë¥¼) &#x2728; Contents: ìœ ì € ìƒì„± TARGET í…Œì´ë¸” ìƒì„± ì£¼ ë‹¨ìœ„ ë°ì´í„° ë§ˆê° Reference ìœ ì € ìƒì„±í•´ë‹¹ í…Œì´ë¸”ì„ ê´€ë¦¬í•˜ëŠ” ê³„ì •ì„ ìƒì„±í•˜ì˜€ë‹¤. user/pw: mart_20/*** role: connect, resource User create query123 --Create \"MART_20\" UserCREATE USER MART_20 IDENTIFIED BY '*******';GRANT CONNECT, RESOURCE TO MART_20; TARGET í…Œì´ë¸” ìƒì„±ê³ ê°ì´ ì‚¬ìš©í•˜ë˜ SQL ì¿¼ë¦¬ë¥¼ ì‚´í´ë³´ë©´, ì´ 12ê°œ Table ë° View ë¥¼ ì¡°í•©í•˜ì—¬ ë„¤ ë©ì–´ë¦¬ SELECT ì¡°íšŒ ê²°ê³¼ë¥¼ UNION ALL í•œë‹¤. ìš´ì˜ìê°€ ìˆ˜ì •í•˜ëŠ” ë¶€ë¶„ì€ ë‚ ì§œ ì¹¼ëŸ¼ì„ ì…ë ¥í•˜ê²Œë” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì—¬ ì´ë¥¼ EXCEL ë¡œ ë‹¤ìš´ë°›ì•„ ìš”ì²­ìì—ê²Œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ì´ë‹¤. ìš°ë¦¬ëŠ” ì´ ì¿¼ë¦¬ì˜ ê²°ê³¼ë¬¼ì„ ë¯¸ë¦¬ í…Œì´ë¸”ë¡œ ì •ì˜í•˜ê³ , ì¼ ì ì¬ë¥¼ í†µí•´ ê³ ê°ì´ ì‰½ê²Œ ìš°ë¦¬ ì œí’ˆì„ ì´ìš©í•´ ë¶„ì„í•˜ê³  ì‹¶ì„ ë•Œ ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í™˜ê²½ì„ êµ¬ì„±í•  ì˜ˆì •ì´ë‹¤. í•˜ì§€ë§Œ ìš”ì²­ìë¥¼ ìœ„í•´ ì‘ì„±ëœ QueryëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì œì•½ì‚¬í•­ì´ ìˆë‹¤. Primary Key ë¡œ ì„¤ì •í•œ SEQ ëŠ” ì¶”í›„ ì¤‘ë³µì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ìˆ˜ì§‘ì„ í•˜ë‹¤ë³´ë©´ ì–¸ì  ê°€ UNION ALL ì „ì˜ í•œ ë©ì–´ë¦¬ì—ì„œì˜ SEQ ì¹¼ëŸ¼ê³¼ ë‚˜ë¨¸ì§€ ì„¸ ë©ì–´ë¦¬ì—ì„œì˜ SEQ ì™€ ë™ì¼í•´ì§ˆ ìˆ˜ ìˆë‹¤. ì„œë¡œ ë‹¤ë¥´ê²Œ SEQ Value ê´€ë¦¬í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´ë¥¼ í•´ê²°í•  ë°©ë²•ìœ¼ë¡œ UNION ALL ì „ì˜ ë„¤ ë©ì–´ë¦¬ë¥¼ ì ì¬ í…Œì´ë¸”ë¡œ ê°ê° ê´€ë¦¬í•˜ë©´ ëœë‹¤. ì´í›„ ìƒì„±í•œ ë„¤ ê°œ í…Œì´ë¸”ì„ UNION ALL í•œ VIEW ë¥¼ ë°”ë¼ë³´ë©´ ë˜ëŠ”ë°, ì´ëŠ” 1) ê´€ë¦¬ í¬ì¸íŠ¸ê°€ ë§ì•„ì§€ê³  2) Viewë¥¼ ì‚¬ìš©í•˜ê¸° ëŒ€ë¬¸ì— ì„±ëŠ¥ ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¼ì—ë„ ë‚˜ëŠ” í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ ê´€ë¦¬í•˜ê³ ì í•œë‹¤. Source Table ì—ì„œ ìˆ˜ì •ì´ ë°œìƒí•˜ë©´ ì´ì— ëŒ€í•œ Target Source ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤. ì¦‰, ì´ì „ ë‚ ì§œì˜ ë°ì´í„°ì— ëŒ€í•œ ìˆ˜ì •ì´ ë°œìƒí•˜ë©´ Target Source ì— ëŒ€í•œ ë°˜ì˜ì´ í•„ìš”í•˜ë‹¤. ì´ëŠ” ì£¼ ë˜ëŠ” ì›” ë‹¨ìœ„ DEL_FLAG ë³€ìˆ˜ë¥¼ í™œìš©í•´ ì‚­ì œ ë˜ëŠ” ì¶”ê°€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë°°ì¹˜ ì‘ì—… ìœ¼ë¡œ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤. ë‹¨, Update period ëŠ” í˜‘ì˜ê°€ í•„ìš”í•œ ìƒí™©! HABITAUL_PRACTICE_TEMP í…Œì´ë¸”ì„ ìƒì„±í•˜ì—¬ ë§ˆê° ì²˜ë¦¬ë¥¼ ì§„í–‰í•  ê²ƒì´ë‹¤. í…Œì´ë¸” Create Query ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. 1234567891011121314151617181920212223242526CREATE TABLE MART_20.HABITAUL_PRACTICE_ANALYSIS ( SEQ NUMBER(22) NOT NULL PRIMARY KEY, DOMAIN_SEQ NUMBER(22),...... \"ìœ„ë³€ì¡° í†µì¥\" NUMBER, \"ìœ„ë³€ì¡° ê¸°íƒ€\" NUMBER, DEL_FLAG VARCHAR(2) DEFAULT 'N' );CREATE INDEX MART_20.HABITAUL_PRACTICE_ANALYSIS_IDX_01 ON MART_20.HABITAUL_PRACTICE_ANALYSIS ( TFD_DATE, DOMAIN_LINK, DEL_FLAG );CREATE TABLE MART_20.HABITAUL_PRACTICE_TEMP ( SEQ NUMBER(22) NOT NULL PRIMARY KEY, DOMAIN_SEQ NUMBER(22),...... \"ìœ„ë³€ì¡° í†µì¥\" NUMBER, \"ìœ„ë³€ì¡° ê¸°íƒ€\" NUMBER ); PK: SEQ INDEX: DOMAIN_LINK, TFD_DATE, DEL_FLAG TEMP í…Œì´ë¸”ê³¼ ì›ë³¸ í…Œì´ë¸”ì˜ ì°¨ì´ì ì€ DEL_FLAG ì¹¼ëŸ¼ì˜ ì—¬ë¶€ì´ë‹¤. ì£¼ ë‹¨ìœ„ ë°ì´í„° ë§ˆê°ìš´ì˜ì§„ì—ì„œ ìˆ˜ì •ëœ ë°ì´í„°ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì£¼ ë‹¨ìœ„ ë°ì´í„°ë¥¼ ë§ˆê°í•  ê²ƒì´ë‹¤. ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ ì§„í–‰í•˜ëŠ”ë°, ì´ëŠ” ì‹¤ì‹œê°„ ìˆ˜ì • ë°˜ì˜ì´ ì–´ë ¤ì›Œ(êµ¬ì¡°ìƒ) ê³ ê°ì™€ í˜‘ì˜í•˜ì—¬ ì§„í–‰í•˜ì˜€ë‹¤. (ë§ˆê° ì£¼ê¸°, ì¦‰ Update ë°˜ì˜ì„ í•œ ì£¼ ì „ê¹Œì§€ë§Œ ë°˜ì˜) 1) í˜„ì¬ ê¸°ì¤€ ì´ ì „ ë°ì´í„° ì¡°íšŒ í›„ ì €ì¥ë°ì´í„° ì£¼ ë‹¨ìœ„ ê°±ì‹  ë§ˆê°ì„ ìœ„í•œ ì¡°íšŒ QueryëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889SELECT * FROM ( SELECT SEQ, DOMAIN_SEQ, DOMAIN_LINK,...... CASE WHEN INSTR(ILLE_EXPR, '0209') &gt; 0 THEN 1 END AS \"ìœ„ë³€ì¡° ê¸°íƒ€\" FROM ( SELECT A.SEQ, DECODE(WEB_CACHE_URL,NULL,A.DOMAIN_SEQ,100000001) AS DOMAIN_SEQ, DECODE(WEB_CACHE_URL,NULL,B.DOMAIN_LINK,'webcache.googleusercontent.com') AS DOMAIN_LINK, DECODE(WEB_CACHE_URL,NULL,F.DOMAIN_NAME,'êµ¬ê¸€ì›¹ìºì‹œ') AS DOMAIN_NAME, F.DOMAIN_CODE2,...... WM_CONCAT (E.EXPR_CATEGORY || E.EXPR_SUB_CATE) ILLE_EXPR FROM PIRST_19.DETECTED_URL@DS16 A INNER JOIN PIRST_19.DOMAIN_MASTER@DS16 B ON A.DOMAIN_SEQ = B.DOMAIN_SEQ INNER JOIN PIRST_19.DOMAIN_INFORMATION@DS16 F ON A.DOMAIN_SEQ = F.DOMAIN_SEQ LEFT OUTER JOIN PIRST_19.KEYWORD_MASTER@DS16 C ON A.KEYWORD_SEQ = C.KEYWORD_SEQ LEFT OUTER JOIN PIRST_19.A_ILLEGAL_TRADER_MST@DS16 D ON A.SEQ = D.URL_SEQ LEFT OUTER JOIN PIRST_19.DETECTED_URL_EXPR@DS16 E ON A.SEQ = E.URL_SEQ AND E.EXPR_USE = 'Y' LEFT OUTER JOIN (SELECT * FROM PIRST_19.DETECTED_IMG@DS16 WHERE ROWID IN (SELECT MAX(ROWID) FROM PIRST_19.DETECTED_IMG@DS16 GROUP BY DETECTED_SEQ)) G ON A.SEQ = G.DETECTED_SEQ...... AND C.KEYWORD_REG_USER_ID != 'covid19' GROUP BY A.SEQ, DECODE(WEB_CACHE_URL,NULL,A.DOMAIN_SEQ,100000001), DECODE(WEB_CACHE_URL,NULL,B.DOMAIN_LINK,'webcache.googleusercontent.com'), DECODE(WEB_CACHE_URL,NULL,F.DOMAIN_NAME,'êµ¬ê¸€ì›¹ìºì‹œ'), F.DOMAIN_CODE2, F.DOMAIN_CODE3, ...... D.URL_SEQ, A.POST_DATE ) A LEFT OUTER JOIN PIRST_19.A_ILLEGAL_TRADER_MST@DS16 B ON A.TRADER_SEQ = B.TRADER_SEQ AND A.URL_SEQ = B.URL_SEQ)--í•œ ë©ì–´ë¦¬ ë UNION ALL SELECT A.MANUAL_SEARCH_SEQ, A.DETECTED_DOMAIN_SEQ,...... DECODE(SUBSTR(D.exposure_type, INSTR(D.exposure_type, 'C09'),3),'C09',1) as SIXTEEN FROM PIRST_19.MANUAL_DETECTED_URL@DS16 A,...... PIRST_19.A_ILLEGAL_TRADER_MST@DS16 E WHERE A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ AND A.DETECTED_DOMAIN_SEQ = C.DOMAIN_SEQ...... UNION ALL--ë‘ ë©ì–´ë¦¬ ë SELECT A.MANUAL_SEARCH_SEQ, A.DETECTED_DOMAIN_SEQ,...... DECODE(SUBSTR(D.exposure_type, INSTR(D.exposure_type, 'C08'),3),'C08',1) as FIFTEEN, DECODE(SUBSTR(D.exposure_type, INSTR(D.exposure_type, 'C09'),3),'C09',1) as SIXTEEN FROM PIRST_19.MANUAL_CACHE_URL@DS16 A, PIRST_19.DOMAIN_MASTER@DS16 B,...... WHERE A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ...... AND A.MBER_ID != 'itno_cmbok'----ì„¸ ë©ì–´ë¦¬ ë UNION ALL SELECT A.MANUAL_SEARCH_SEQ,...... DECODE(SUBSTR(D.exposure_type, INSTR(D.exposure_type, 'C08'),3),'C08',1) as FIFTEEN, DECODE(SUBSTR(D.exposure_type, INSTR(D.exposure_type, 'C09'),3),'C09',1) as SIXTEEN FROM PIRST_19.MANUAL_IMAGE_URL@DS16 A, PIRST_19.DOMAIN_MASTER@DS16 B,...... WHERE A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ AND A.DETECTED_DOMAIN_SEQ = C.DOMAIN_SEQ......--ë„¤ ë©ì–´ë¦¬ ë; TFD_DATE ë¥¼ SYSDATE(í˜„ì¬ ì‹œê°„) ê¸°ì¤€ 7ì¼ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰í•œë‹¤. ì¦‰, ì´ì „ ì¼ì£¼ì¼ ì¹˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•œë‹¤. 20.09.03~20.09.09: 3993ê±´ ê²°ê³¼ë¬¼ì„ HABITUAL_TEMP í…Œì´ë¸”ì— ì €ì¥í•œë‹¤. 2) í˜„ì¬ ê¸°ì¤€ ì¼ì£¼ì¼ ì „ ë°ì´í„°ì˜ DEL_FLAG ë³€ê²½HABITUAL_BUYER ì— ìœ„ ê¸°ê°„ ë°ì´í„°ì˜ DEL_FLAG ë³€ê²½ Query ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 1234UPDATE HABITUAL_BUYERSET DEL_FLAG='Y'WHERE TFD_DATE &gt;= TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD'),'YYYYMMDD') - 7 AND TFD_DATE &lt; TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD'),'YYYYMMDD') 3) TEMP í…Œì´ë¸”ê³¼ TARGET í…Œì´ë¸” ê°„ Mergeë‘ í…Œì´ë¸” ê°„ (HABITUAL_BUYER // HABITUAL_TEMP) Merge OueryëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 12345678910111213MERGE INTO (SELECT * FROM HABITUAL_BUYER WHERE TFD_DATE &gt;= TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD'),'YYYYMMDD') - 7 AND TFD_DATE &lt; TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD'),'YYYYMMDD') ) AS AUSING HABITUAL_TEMP AS BON (A.SEQ = B.SEQ)WHEN MATCHED THENUPDATE SETA.DEL_FLAG = 'N'WHEN NOT MATCHED THENINSERT (A.SEQ,A.DOMAIN_SEQ ,A.DOMAIN_LINK ,A.DOMAIN_NAME ,A.CODE_NM2 ,A.CODE_NM3,A.DETECTED_CRAWL_COUNT,A.DETECTED_LINK,A.DETECTED_COUNT ,A.TRUE_DETECTION_COUNT ,A.FALSE_DETECTION_COUNT ,A.DETECTED_NEW_EXPOSURE_COUNT ,A.DETECTED_RE_EXPOSURE,A.DETECTED_RE_EXPOSURE_COUNT ,A.DOMAIN_CATEGORY01,A.DOMAIN_CATEGORY02,A.SEARCH_COL_TYPE,A.DOMAIN_GROUP,A.DETECTED_DEPTH,A.DOMAIN_COUNTRY_CODE,A.DETECTED_STATUS,A.DETECTED_GROUP,A.DETECTED_TYPE,A.DETECTED_CHECK_TYPE,A.KEYWORD_SEQ,A.KEYWORD_VALUE,A.INDI_DOMAIN_SEQ,A.WEB_CACHE_URL,A.DETECTED_TIME ,A.TFD_DATE ,A.DEL_DONE_DATE ,A.UPDATOR,A.REQUEST_ORDINAL,A.DETECTED_POST_TYPE,A.GATHERING_TYPE,A.IMG_DETECTION_TYPE,A.POST_DATE ,A.REFERENCE,A.TRADER_TYPE,A.\"íŒë§¤ìID\",A.\"ì´ë©”ì¼\",A.\"ì¹´ì¹´ì˜¤í†¡\",A.\"ë„¤ì´íŠ¸ì˜¨\",A.\"MSNë©”ì‹ ì €\",A.\"ìŠ¤ì¹´ì´í”„\",A.\"ìœ„ì±—\",A.QQ,A.\"í…”ë ˆê·¸ë¨\",A.\"ê¸°íƒ€1\",A.\"ê¸°íƒ€2\",A.\"í•¸ë“œí°ë²ˆí˜¸\",A.\"ì¼ë°˜ë²ˆí˜¸\",A.\"ê±°ë˜ ê°œì¸ì •ë³´DB\" ,A.\"ê±°ë˜ í†µì¥\" ,A.\"ê±°ë˜ IDíŒë§¤\" ,A.\"ê±°ë˜ ì•„ì´í•€\" ,A.\"ê±°ë˜ ëŒ€í¬í°\" ,A.\"ê±°ë˜ í•´í‚¹\" ,A.\"ê±°ë˜ ê¸°íƒ€\" ,A.\"ìœ„ë³€ì¡° ì¦ëª…ì„œ\" ,A.\"ìœ„ë³€ì¡° ì„±ì í‘œ\" ,A.\"ìœ„ë³€ì¡° ì‹ ë¶„ì¦\" ,A.\"ìœ„ë³€ì¡° ìê²©ì¦\" ,A.\"ìœ„ë³€ì¡° ì—¬ê¶Œ\" ,A.\"ìœ„ë³€ì¡° ê¸°ë¡ë¶€\" ,A.\"ìœ„ë³€ì¡° ë‚´ì—­ì„œ\" ,A.\"ìœ„ë³€ì¡° í†µì¥\" ,A.\"ìœ„ë³€ì¡° ê¸°íƒ€\" )VALUES (B.SEQ,B.DOMAIN_SEQ ,B.DOMAIN_LINK ,B.DOMAIN_NAME ,B.CODE_NM2 ,B.CODE_NM3,B.DETECTED_CRAWL_COUNT,B.DETECTED_LINK,B.DETECTED_COUNT ,B.TRUE_DETECTION_COUNT ,B.FALSE_DETECTION_COUNT ,B.DETECTED_NEW_EXPOSURE_COUNT ,B.DETECTED_RE_EXPOSURE,B.DETECTED_RE_EXPOSURE_COUNT ,B.DOMAIN_CATEGORY01,B.DOMAIN_CATEGORY02,B.SEARCH_COL_TYPE,B.DOMAIN_GROUP,B.DETECTED_DEPTH,B.DOMAIN_COUNTRY_CODE,B.DETECTED_STATUS,B.DETECTED_GROUP,B.DETECTED_TYPE,B.DETECTED_CHECK_TYPE,B.KEYWORD_SEQ,B.KEYWORD_VALUE,B.INDI_DOMAIN_SEQ,B.WEB_CACHE_URL,B.DETECTED_TIME ,B.TFD_DATE ,B.DEL_DONE_DATE ,B.UPDATOR,B.REQUEST_ORDINAL,B.DETECTED_POST_TYPE,B.GATHERING_TYPE,B.IMG_DETECTION_TYPE,B.POST_DATE ,B.REFERENCE,B.TRADER_TYPE,B.\"íŒë§¤ìID\",B.\"ì´ë©”ì¼\",B.\"ì¹´ì¹´ì˜¤í†¡\",B.\"ë„¤ì´íŠ¸ì˜¨\",B.\"MSNë©”ì‹ ì €\",B.\"ìŠ¤ì¹´ì´í”„\",B.\"ìœ„ì±—\",B.QQ,B.\"í…”ë ˆê·¸ë¨\",B.\"ê¸°íƒ€1\",B.\"ê¸°íƒ€2\",B.\"í•¸ë“œí°ë²ˆí˜¸\",B.\"ì¼ë°˜ë²ˆí˜¸\",B.\"ê±°ë˜ ê°œì¸ì •ë³´DB\" ,B.\"ê±°ë˜ í†µì¥\" ,B.\"ê±°ë˜ IDíŒë§¤\" ,B.\"ê±°ë˜ ì•„ì´í•€\" ,B.\"ê±°ë˜ ëŒ€í¬í°\" ,B.\"ê±°ë˜ í•´í‚¹\" ,B.\"ê±°ë˜ ê¸°íƒ€\" ,B.\"ìœ„ë³€ì¡° ì¦ëª…ì„œ\" ,B.\"ìœ„ë³€ì¡° ì„±ì í‘œ\" ,B.\"ìœ„ë³€ì¡° ì‹ ë¶„ì¦\" ,B.\"ìœ„ë³€ì¡° ìê²©ì¦\" ,B.\"ìœ„ë³€ì¡° ì—¬ê¶Œ\" ,B.\"ìœ„ë³€ì¡° ê¸°ë¡ë¶€\" ,B.\"ìœ„ë³€ì¡° ë‚´ì—­ì„œ\" ,B.\"ìœ„ë³€ì¡° í†µì¥\" ,B.\"ìœ„ë³€ì¡° ê¸°íƒ€\" ) SEQ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ DEL_FLAGë¥¼ N ìœ¼ë¡œ ìˆ˜ì •í•œë‹¤. ë§Œì•½ ê¸°ì¡´ ì ì¬ëœ SEQê°€ ì—†ëŠ” ë°ì´í„°ê°€ ìˆë‹¤ë©´, ìƒˆë¡­ê²Œ INSERT (ì‚­ì œë  ê²½ìš°ë„ ìˆì§€ë§Œ ì¶”ê°€ë  ê²½ìš°ë„ ì¡´ì¬) í•œë‹¤. ê° í…Œì´ë¸” ì¡°íšŒí•´ë³´ë©´ FLAGê°€ ë³€ê²½ëœ ê°’ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 12345678910111213141516171819--20.09.03~20.09.09 ìƒˆë¡œ ìˆ˜ì§‘í•œ ë°ì´í„° ì¡°íšŒSELECT COUNT(*)FROM MART_20.HABITUAL_TEMP;--3993--BUYER í…Œì´ë¸”ì—ì„œ ì¼ì£¼ì¼ ì „ ë°ì´í„° FLAG Yë¡œ ìˆ˜ì • í›„ COUNTSELECT COUNT(*)FROM MART_20.HABITUAL_BUYERWHERE DEL_FLAG='Y';--3993--MERGE ì´í›„ COUNTSELECT COUNT(*)FROM MART_20.HABITUAL_BUYERWHERE DEL_FLAG='Y';--0, ì™œëƒë©´ ìˆ˜ì •ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ.. ë°ì´í„° ì£¼ ë‹¨ìœ„ ë§ˆê° ìˆœì„œë¥¼ í•œ ì¤„ë¡œ ìš”ì•½í•˜ë©´, ë§ˆê° ê¸°ì¤€ ì¹˜ ë°ì´í„°ë¥¼ ì¡°íšŒ í›„ TEMP í…Œì´ë¸”ì— ì €ì¥í•˜ê³  TARGET í…Œì´ë¸”(TEMP í…Œì´ë¸”ì— ì €ì¥í•œ ë°ì´í„°ì˜ ê°™ì€ ë‚ ì§œ)ì˜ DEL_FLAG ë¥¼ Yë¡œ ë³€ê²½í•˜ì—¬ TEMP í…Œì´ë¸”ê³¼ Merge í•œë‹¤. ì§ì ‘ ìˆ˜í–‰í•˜ë©´ì„œ ëŠë‚€ì ì€ Merge ë¡œ ì¸í•œ ì„±ëŠ¥ ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ëŠ” ë” ì—°êµ¬í•´ë´ì•¼ê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ë°°ì¹˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ì„œ ìš¸íŒ€ ì„ ë°°ë‹˜ì´ ë§ì€ ë„ì›€ì„ ì£¼ì…¨ë‹¤. ì•ìœ¼ë¡œ ë‚˜ë„ ë‚´ í›„ë°°ì—ê²Œ ë§ì€ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ì„ ë°°ë¡œ ê±°ë“­ë‚˜ê¸¸.. Reference https://kookyungmin.github.io/db/2018/07/30/oracle_32/ https://jennylee4517.github.io/sql/oracle-1ì¼ì°¨/ https://m.blog.naver.com/PostView.nhn?blogId=ojini21c&amp;logNo=221193420479&amp;proxyReferer=https:%2F%2Fwww.google.com%2F made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"Tibero","slug":"Tibero","permalink":"https://jx2lee.github.io/tags/Tibero/"}]},{"title":"[Rook Ceph] Rook ceph dashboard ì‚¬ìš©í•˜ê¸°","slug":"cloud-export_rook_ceph_dashboard","date":"2020-09-02T15:00:00.000Z","updated":"2020-09-26T13:42:48.682Z","comments":true,"path":"cloud-export_rook_ceph_dashboard/","link":"","permalink":"https://jx2lee.github.io/cloud-export_rook_ceph_dashboard/","excerpt":"Toolbox POD ë¡œ ì ‘ê·¼í•˜ì—¬ ceph cluster ë¥¼ í™•ì¸í•˜ê³¤ í•œë‹¤. alias ë¡œ ë°”ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ì„¤ì •í•˜ì˜€ì§€ë§Œ, ì¢€ ë” ì§ê´€ì ìœ¼ë¡œ ë³´ê¸° ìœ„í•´ dashboard ë¥¼ ë°°í¬í•´ ë³´ì!","text":"Toolbox POD ë¡œ ì ‘ê·¼í•˜ì—¬ ceph cluster ë¥¼ í™•ì¸í•˜ê³¤ í•œë‹¤. alias ë¡œ ë°”ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ì„¤ì •í•˜ì˜€ì§€ë§Œ, ì¢€ ë” ì§ê´€ì ìœ¼ë¡œ ë³´ê¸° ìœ„í•´ dashboard ë¥¼ ë°°í¬í•´ ë³´ì! &#x2728; Contents: rook-ceph service í™•ì¸ rook-ceph-mgr-dashboard-external-http ì„œë¹„ìŠ¤ ìƒì„± dashboard ì ‘ì† Reference rook-ceph Service í™•ì¸kubectl get service -n rook-ceph ëª…ë ¹ì–´ë¡œ ê¸°ë™ì¤‘ì¸ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•œë‹¤. 123456789root@k8s-master:~# kubectl get service -n rook-cephNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEcsi-cephfsplugin-metrics ClusterIP 10.96.205.129 &lt;none&gt; 8080/TCP,8081/TCP 2d17hcsi-rbdplugin-metrics ClusterIP 10.96.158.126 &lt;none&gt; 8080/TCP,8081/TCP 2d17hrook-ceph-mgr ClusterIP 10.96.133.224 &lt;none&gt; 9283/TCP 2d17hrook-ceph-mgr-dashboard ClusterIP 10.96.37.245 &lt;none&gt; 8443/TCP 2d17hrook-ceph-mon-a ClusterIP 10.96.59.113 &lt;none&gt; 6789/TCP,3300/TCP 2d17hrook-ceph-mon-b ClusterIP 10.96.26.250 &lt;none&gt; 6789/TCP,3300/TCP 2d17hrook-ceph-mon-c ClusterIP 10.96.235.59 &lt;none&gt; 6789/TCP,3300/TCP 2d17h rook-ceph-mgr-dashboard ì„œë¹„ìŠ¤ê°€ 8443 í¬íŠ¸ë¡œ í†µì‹  ê°€ëŠ¥í•˜ê²Œ ì„¤ì •ë˜ì–´ ìˆë‹¤. ì™¸ë¶€ë¡œ dashboard ë¥¼ ë…¸ì¶œí•˜ëŠ” ë°©ë²•ì€ 1) rook-ceph-mgr ì„œë¹„ìŠ¤ type ë°”ê¾¸ê¸° ì™€ 2) external service ê°€ ìˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” 2ë²ˆ ë°©ë²•ì„ ì´ìš©í•´ dashboard ë¥¼ ì‚¬ìš©í•´ë³´ê² ë‹¤. rook-ceph-mgr-dashboard-external-http ì„œë¹„ìŠ¤ ìƒì„±í•˜ê¸°ë‹¤ìŒê³¼ ê°™ì€ yaml ë¥¼ ì‘ì„±í•œë‹¤. 1234567891011121314151617181920root@k8s-master:~/hypercloud-rook-ceph-master/deploy# cat dashboard-external-http.yamlapiVersion: v1kind: Servicemetadata: name: rook-ceph-mgr-dashboard-external-http namespace: rook-ceph labels: app: rook-ceph-mgr rook_cluster: rook-cephspec: ports: - name: dashboard port: 8443 protocol: TCP targetPort: 8443 selector: app: rook-ceph-mgr rook_cluster: rook-ceph sessionAffinity: None type: NodePort Service íƒ€ì…ì€ NodePort ë¡œ ì„¤ì •í•œë‹¤. ì´ì™¸ ì™¸ë¶€ë¡œ ë…¸ì¶œí•˜ê³  ì‹¶ë‹¤ë©´ LoadBalancer ë¡œ ë³€ê²½í•œë‹¤. (ë¡œë“œë°¸ëŸ°ì„œ ê²½ìš° í¼ë¸”ë¦­ IPê°€ ì¡´ì¬í•´ì•¼í•œë‹¤.) rook-ceph-mgr Port ê°€ ë§Œì•½ ë‚˜ì™€ ë‹¤ë¥¸ ë²ˆí˜¸(ì˜ˆ. 7775) ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´, ìœ„ yaml ì—ì„œë„ ê°™ì€ í¬íŠ¸ë¡œ ì„¤ì •í•´ì•¼í•œë‹¤. ìƒì„±í•œ yaml ì„ ì´ìš©í•´ kubectl apply -f dashboard-external-http.yaml ì»¤ë§¨ë“œë¡œ service ë¥¼ ìƒì„±í•œë‹¤. ì´í›„ ì ‘ì†í•˜ê¸° ìœ„í•œ ì´ˆê¸° admin ë¹„ë°€ë²ˆí˜¸ í™•ì¸ì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì»¤ë§¨ë“œë¥¼ ìˆ˜í–‰í•œë‹¤. kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=&quot;{[&#39;data&#39;][&#39;password&#39;]}&quot; | base64 --decode &amp;&amp; echo dashboard ì ‘ì†í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ https://[ë…¸ë“œip]:[port] ë¡œ ì ‘ì†í•œë‹¤. ID/PW: admin/[ë°”ë¡œ ìœ„ ì»¤ë§¨ë“œ ìˆ˜í–‰ ê²°ê³¼] ìµœì´ˆ ì ‘ì† í›„ ì„¤ì •ì— ë“¤ì–´ê°€ PWë¥¼ ë°”ê¾¸ë„ë¡ í•˜ì. dashboard UI ë¥¼ í†µí•´ ceph cluster ìƒíƒœë¥¼ ì§ê´€ì ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆì–´ í¸ë¦¬í•˜ê¸´ í•˜ë‹¤. ê·¸ë˜ë„ ì¡°ê¸ˆ ë” ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ ì¹œí•´ì§€ê¸° ìœ„í•´ ì»¤ë§¨ë“œë¡œ ceph cluster ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì„ë“¯ í•˜ë‹¤! Reference https://github.com/rook/rook/blob/master/Documentation/ceph-dashboard.md made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[]},{"title":"[Python] ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ ëª¨ë“ˆ","slug":"python-keyword_match","date":"2020-08-19T15:00:00.000Z","updated":"2020-10-29T14:35:49.291Z","comments":true,"path":"python-keyword_match/","link":"","permalink":"https://jx2lee.github.io/python-keyword_match/","excerpt":"í”„ë¡œì íŠ¸ ì‹œë²” ê³¼ì œ ì¤‘ í•˜ë‚˜ì¸ â€œê²Œì‹œíŒ ë° íšŒì›ê°€ì… ì—¬ë¶€ íŒë‹¨â€ì„ ìœ„í•´ íŒŒì´ì¬ìœ¼ë¡œ ëª¨ë“ˆì„ í•˜ë‚˜ ì‘ì„±í–ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ ìì²´ëŠ” ì •ë§ ë‹¨ìˆœí•œë°, í•´ë‹¹ ê²Œì‹œíŒê³¼ íšŒì›ê°€ì… ì—¬ë¶€ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ í†µí•´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ë§Œ í™•ì¸í•˜ì—¬ íŒë‹¨í•œë‹¤. ëª¨ë“ˆ ì‘ì„± ë°°ê²½ê³¼ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•œë‹¤.","text":"í”„ë¡œì íŠ¸ ì‹œë²” ê³¼ì œ ì¤‘ í•˜ë‚˜ì¸ â€œê²Œì‹œíŒ ë° íšŒì›ê°€ì… ì—¬ë¶€ íŒë‹¨â€ì„ ìœ„í•´ íŒŒì´ì¬ìœ¼ë¡œ ëª¨ë“ˆì„ í•˜ë‚˜ ì‘ì„±í–ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ ìì²´ëŠ” ì •ë§ ë‹¨ìˆœí•œë°, í•´ë‹¹ ê²Œì‹œíŒê³¼ íšŒì›ê°€ì… ì—¬ë¶€ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ í†µí•´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ë§Œ í™•ì¸í•˜ì—¬ íŒë‹¨í•œë‹¤. ëª¨ë“ˆ ì‘ì„± ë°°ê²½ê³¼ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•œë‹¤. &#x2728; Contents: ëª¨ë“ˆ ì‘ìƒ ë°°ê²½ ì–´ë–»ê²Œ ì‘ì„±í• ê¹Œ? í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ”ìš”? ì–´ë• ë‚˜ìš”? ëª¨ë“ˆ ì‘ì„± ë°°ê²½ì›ë˜ í‚¤ì›Œë“œ ë§¤ì¹­ ê´€ë ¨ ì‹œë²”ê³¼ì œëŠ” ì£¼ ì‚¬ì—…ì ì˜ì—­ì¸ í¬ë¡¤ëŸ¬ì—ì„œ ìˆ˜í–‰í•˜ê¸°ë¡œ í•˜ì˜€ì§€ë§Œ, ë¹…ë°ì´í„° í”Œë«í¼ì„ êµ¬ì¶•í•˜ë©´ì„œ ë¹…ë°ì´í„° í”Œë«í¼ ì•ˆì—ì„œ ìˆ˜í–‰í•´ì•¼ ê·¸ë¦¼ì´ ì´ì˜ì§€ ì•Šì„ê¹Œ? ë¼ëŠ” ì˜ê²¬ì´ ë‚˜ì™€ ìš°ë¦¬ìª½ì—ì„œ ìˆ˜í–‰í•˜ê¸°ë¡œ ê²°ì •í•˜ì˜€ë‹¤. ê´€ë ¨í•˜ì—¬ ì—°êµ¬ì†Œì— ë¬¸ì˜í–ˆì§€ë§Œ, í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ì— ëŒ€í•œ ì—°êµ¬ëŠ” ì´ë£¨ì–´ì§€ì§€ ì•Šì•„ ìš°ë¦¬ íŒ€ì—ì„œ ë§¡ì•„ ì§„í–‰í•˜ê¸°ë¡œ í˜‘ì˜í•˜ì˜€ë‹¤. êµ¬ê¸€ë§ì„ í†µí•´ì„œ ë§ì€ í‚¤ì›Œë“œ ë§¤ì¹­ ìë£Œë¥¼ ì°¾ì•˜ì§€ë§Œ, ì‹œë²”ê³¼ì œ ì„±ê²©ì´ í¬ê¸° ë•Œë¬¸ì— ê±°ì°½í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì“°ì§€ ì•Šê¸°ë¡œ í•˜ì˜€ë‹¤. ë‹¨ìˆœ í•´ë‹¹ ì—¬ë¶€ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ë°›ì•„ ì´ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€? ì—†ëŠ”ì§€? ë§Œ íŒë‹¨í•˜ëŠ” ìª½ìœ¼ë¡œ ì‹œë²”ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ê¸°ë¡œ í–ˆë‹¤. ìš°ë¦¬ëŠ” ì´ 2ê°œ DB table ì—ì„œ ë°ì´í„°ë¥¼ ë°›ê¸°ë¡œ í–ˆë‹¤. ì²« ë²ˆì§¸ ëŠ” URL / URL ë‚´ í…ìŠ¤íŠ¸ / timestamp ì¹¼ëŸ¼ìœ¼ë¡œ ì´ë£¨ì–´ì§„ í…Œì´ë¸”ì´ë‹¤. ë‘ ë²ˆì§¸ ëŠ” keyword type / keyword value (type: í•´ë‹¹ í”„ë¡œì íŠ¸ì—ì„œëŠ” íšŒì›ê°€ì… ê³¼ ê²Œì‹œíŒ) ìœ¼ë¡œ ì´ë£¨ì–´ì§„ í…Œì´ë¸”ì´ë‹¤. ìœ„ í…Œì´ë¸” ë°ì´í„°ëŠ” ìš°ë¦¬ ì œí’ˆ python API ë¥¼ ì´ìš©í•´ dataframe ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ìƒí™©ì´ë‹¤. ëª¨ë“ˆ ì‘ì„± ë°°ê²½: í”„ë¡œì íŠ¸ ì‹œë²”ê³¼ì œ ì¤‘ í‚¤ì›Œë“œ ë§¤ì¹­ì„ Pyhthon ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì‘ì„±! ì–´ë–»ê²Œ ì‘ì„±í• ê¹Œ?ì‚¬ì‹¤ ë§‰ë§‰í–ˆë‹¤. ì•„ë‹ˆ, ëŒ€ì¶©ëŒ€ì¶© ì§œë©´ ê¸ˆë°© ì§¤ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ì§€ë§Œ Python ì—­ëŸ‰ì„ í‚¤ì›Œë³¼ ê²¸ ëª¨ë“ˆí™”ë¡œ ì§„í–‰í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤. ê·¸ëŸ¬ë˜ ì¤‘, FlashText ì•Œê³ ë¦¬ì¦˜ì„ ì°¾ì•˜ê³  ì´ íŒ¨í‚¤ì§€ë¥¼ ì°¸ê³ í•˜ê³ ì í–ˆë‹¤. ë³¸ íŒ¨í‚¤ì§€ëŠ” string/list/dictionary/file ë¡œ ë°ì´í„°ë¥¼ ì½ì–´ì™€ í•´ë‹¹ í‚¤ì›Œë“œ ì‚¬ì „ì„ ë§Œë“¤ê³ , ë³€í™˜í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. í•˜ì§€ë§Œ ë‚´ê°€ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ê²ƒì€ Pandas Dataframe í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë‹¤ë¤„ì•¼ í•˜ê¸° ë•Œë¬¸ì—, FlashText KeywordProcessor í´ë˜ìŠ¤ë¥¼ ì°¨ìš©í•˜ì—¬ ì‘ì„±í•˜ì˜€ë‹¤. ê´€ë ¨ ëª¨ë“ˆ ì‚¬ìš©ë²•ì€ Githubì— ì˜¬ë ¤ë‘ì—ˆë‹¤. ì°¸ê³ í•˜ê¸¸ ë°”ë¼ë©°, í”„ë¡œì íŠ¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸ˆìœµì¸ì§€, ì£¼íƒì¸ì§€? ì— ëŒ€í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³¸ë‹¤. ì–´ë–»ê²Œ? FlashText ëª¨ë“ˆ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±! í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ”ìš”?Githubì— example.py ë¡œ ì‘ì„±í•˜ì˜€ë‹¤. ê·œì¹™ìœ¼ë¡œëŠ” test í•  ìˆ˜ ìˆëŠ” document ë“±ì„ ì‘ì„±í•´ì•¼ì§€ë§Œ ê·¸ê±´ ì¶”í›„ì— ì‹œê°„ì´ ë‚¨ëŠ”ë‹¤ë©´ ì§„í–‰í•˜ë„ë¡ í•œë‹¤. exmaple.py ëŠ” ë‹¤ìŒê³¼ ê°™ê³  ê° ì¤„ ë§ˆë‹¤ ì§§ì€ ì„¤ëª…ì„ ë‹¬ë„ë¡ í•˜ê² ë‹¤. 1234567891011121314151617181920212223242526from datetime import datetimefrom keywordmatch import MatchingProcessorimport pickleimport pandas as pdif __name__ == \"__main__\": with open(\"example.pickle\", \"rb\") as f: test_df = pickle.load(f) test_df_keyword = pd.DataFrame(&#123;'íƒ€ì…':['ê¸ˆìœµ', 'ì£¼íƒ', 'ê¸ˆìœµ', 'ì£¼íƒ', 'ê¸ˆìœµ', 'ì£¼íƒ'], 'í‚¤ì›Œë“œ':['ì€í–‰', 'ì¤‘ë‘êµ¬', 'ì†¡ê¸ˆ', 'ë¶€ì‚°', 'ì¶œê¸ˆ', 'ê²½ë‚¨']&#125;) instance = MatchingProcessor(test_df, 'ê¸°ì‚¬ë‚´ìš©', ['ì£¼íƒ', 'ê¸ˆìœµ']) instance.set_logger('t1', is_file=False) instance.add_column() instance.get_keyword_processor(test_df_keyword, 'íƒ€ì…', 'í‚¤ì›Œë“œ') result = instance.is_keyword() instance._data['ìˆ˜ì§‘ì‹œê°„'] = datetime(2020, 8, 19).strftime('%Y-%m-%d') tibero = &#123;'ip': '192.168.179.166', 'port': '8629', 'sid': 'tibero', 'id_pw': ['tibero', 'tmax'], 'output_columns': ['ê¸°ì‚¬ì œëª©', 'ê¸°ì‚¬ë‚´ìš©', 'ìˆ˜ì§‘ì‹œê°„'], 'table': 'CRAWLER_DATA', 'table_columns': ['DETECTED_LINK', 'DETECTED_CONTENTS', 'DETECTED_TIME']&#125; instance.save_output_database(jar_file='/Users/jj/python/coding-test/tibero6-jdbc.jar', db_info=tibero) Line 1-4: íŒ¨í‚¤ì§€ import ë¶€ë¶„, ì„¤ì¹˜í•œ íŒ¨í‚¤ì§€ëŠ” Jaydebeapi, pandas Line 7-10: ì²« ë²ˆì§¸ í…Œì´ë¸”ê³¼ ë‘ ë²ˆì§¸ í…Œì´ë¸” ë°ì´í„°ë¥¼ DataFrame ìœ¼ë¡œ ë¡œë“œ Line 12-16: MatchingProcessor í´ë˜ìŠ¤ë¡œ ìƒì„±í•œ ê°ì²´ë¡œ í…ŒìŠ¤íŠ¸ Line 18: í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ TimeStamp ì—´ ì¶”ê°€ Line 19-25: DB info ë¥¼ dictionary í˜•íƒœë¡œ í‘œí˜„ Line 26: í•´ë‹¹ DB ë¡œ Insert í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤: 1234567891011121314~/python/keywordmatch masterkeyword-matching â¯ python example.py[2020-08-20 16:29:16,632][INFO] Finished Adding Columns: ['ì£¼íƒ', 'ê¸ˆìœµ'][2020-08-20 16:29:16,636][INFO] Finished Setting Keyword_processor: &#123;'ì¤‘ë‘êµ¬': 'ì£¼íƒ', 'ë¶€ì‚°': 'ì£¼íƒ', 'ê²½ë‚¨': 'ì£¼íƒ', 'ì€í–‰': 'ê¸ˆìœµ', 'ì†¡ê¸ˆ': 'ê¸ˆìœµ', 'ì¶œê¸ˆ': 'ê¸ˆìœµ'&#125;[2020-08-20 16:29:16,636][INFO] Start Keyword Match.100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8468/8468 [00:05&lt;00:00, 1530.62it/s][2020-08-20 16:29:22,200][INFO] Finished Keyword Match.[2020-08-20 16:29:23,781][INFO] Connected Tibero: 192.168.179.166:8629:tibero[2020-08-20 16:29:23,781][INFO] Started Creating SQL dump.100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8468/8468 [00:00&lt;00:00, 50532.56it/s][2020-08-20 16:29:23,964][INFO] Finished Creating SQL dump. dump size: 8468[2020-08-20 16:29:23,964][INFO] Started pushing data. SQL Query: INSERT INTO CRAWLER_DATA VALUES (?,?,?)[2020-08-20 16:29:25,305][INFO] Finished pushing data.[2020-08-20 16:29:25,305][INFO] Disconnected Tibero. ì–´ë• ë‚˜ìš”?í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì œëŒ€ë¡œ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ëŠ” ì•„ë¬´ë„ ëª¨ë¥¸ë‹¤. ë‚˜ëŠ” ì´ë²ˆ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ Python ì„ ì¢€ ë” ì‚´í´ë³¼ ìˆ˜ ìˆëŠ” ê¸°íšŒì˜€ê³ , ì¢€ ë” ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì‘ì„±í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ì„ í™•ë³´í•œ ê²ƒìœ¼ë¡œ ë§Œì¡±í•œë‹¤. ë¬¼ë¡  í”„ë¡œì íŠ¸ì—ëŠ” ì´ ëª¨ë“ˆì„ ë“¤ê³  ë“¤ì–´ê°ˆ ìƒê°ì´ë‹¤. ì™œ? ê²°ê³¼ê°€ ì œëŒ€ë¡œ ë‚˜ì™”ëŠ”ì§€ëŠ” ê³ ê°ë„ ëª¨ë¥´ê¸° ë•Œë¬¸ì´ë‹¤. ë¬¼ë¡  ì¢€ ë” ê²°ê³¼ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ìƒê°í•˜ê³  ì¶”ê°€í•´ë³´ë„ë¡ ë…¸ë ¥í•˜ê² ì§€ë§Œ.. 10ì›” ë§ ëª©í‘œì¸ ì´ í”„ë¡œì íŠ¸ì—ì„œ(ì•„ ë¬¼ë¡  í•œ ë‹¬ ì •ë„ ë”œë ˆì´ ë  ì˜ˆì •) íŠœë‹ì€ í•„ìš”í•  ì§€ ëª¨ë¥´ê² ë‹¤. ì•„, ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•œ ë¶€ë¶„ì€ ì•„ë§ˆ ì´ëŸ¬í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë°°ì¹˜ì„±ìœ¼ë¡œ ìˆ˜í–‰í• ì§€ëŠ” ì§ì ‘ ë“¤ì–´ê°€ë´ì•¼ ì•Œ ê²ƒ ê°™ë‹¤. í•˜ì—¬íŠ¼, Pythonì„ ë” ì•Œì•„ë³´ê³  ì‹¶ì€ ë§ˆìŒì´ ìƒê²¼ë‹¤. ê²°ë¡ : Python ì„ ì•Œê²Œë˜ë©´ì„œ ì ì  ë¹ ì ¸ë“¤ì—ˆë‹¤. made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[]},{"title":"[SQL] SQL í•¨ìˆ˜ ì •ë¦¬","slug":"sql-function","date":"2020-07-21T15:00:00.000Z","updated":"2020-08-04T04:58:14.240Z","comments":true,"path":"sql-function/","link":"","permalink":"https://jx2lee.github.io/sql-function/","excerpt":"í”„ë¡œì íŠ¸ ì°¸ì—¬ ì¤‘ ë°ì´í„° ë§ˆíŠ¸ êµ¬ì¶•ì„ ìœ„í•œ SQL ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ë©´ì„œ, ê´€ë ¨ëœ ì§€ì‹ì„ ë‚´ ë¨¸ë¦¿ì†ì— ìŒ“ê¸°(?)ìœ„í•´ ì •ë¦¬í•œë‹¤. í•„ìš” ì‹œ ì—…ë°ì´íŠ¸ í•  ì˜ˆì •","text":"í”„ë¡œì íŠ¸ ì°¸ì—¬ ì¤‘ ë°ì´í„° ë§ˆíŠ¸ êµ¬ì¶•ì„ ìœ„í•œ SQL ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ë©´ì„œ, ê´€ë ¨ëœ ì§€ì‹ì„ ë‚´ ë¨¸ë¦¿ì†ì— ìŒ“ê¸°(?)ìœ„í•´ ì •ë¦¬í•œë‹¤. í•„ìš” ì‹œ ì—…ë°ì´íŠ¸ í•  ì˜ˆì • DECODEí‘œì¤€ SQL í•¨ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ ì˜ ì‚¬ìš©í•˜ë©´ í¸í•œ ì˜¤ë¼í´ í•¨ìˆ˜, CASE WHEN êµ¬ë¬¸ì„ ê¶Œì¥í•˜ê¸°ë„ í•˜ì§€ë§Œ ì´ì™• ë‚˜ì™”ìœ¼ë‹ˆ ê³µë¶€í•´ë³´ì.DECODE ëŠ” Programming ì—ì„œì˜ if else ì™€ ê°™ì€ ì—­í• ì„ í•œë‹¤. ì‚¬ìš©ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345DECODE(&#123;column&#125;, &#123;condition_01&#125;, &#123;return_01&#125;, &#123;condition_02&#125;, &#123;return_02&#125;, &#123;condition_03&#125;, &#123;return_03&#125;, ...)--exampleDECODE(WEB_CACHE_URL,NULL,A.DOMAIN_SEQ,100000001) WEB_CACHE_URL ì¹¼ëŸ¼ì´ ë§Œì•½ NULL ì´ë¼ë©´ A í…Œì´ë¸” DOMAIN_SEQ ëŒ€ì… ë§Œì•½ NULLì´ ì•„ë‹ˆë©´ 100000001 ëŒ€ì… ê²°ë¡ : WEB_CACHE_URL ì¹¼ëŸ¼ì´ ë§Œì•½ NULL ì´ë¼ë©´ A í…Œì´ë¸” DOMAIN_SEQ ê°’ì„ ëŒ€ì…í•˜ê³  ì•„ë‹ˆë©´ 100000001 ëŒ€ì… CASE WHENDECODE ëŒ€ì‹  CASE WHEN ì„ ê¶Œì¥í•œë‹¤ë‹ˆ ì•Œì•„ë³´ë„ë¡ í•œë‹¤. DECODE ë‘ ê°™ì´ if else ì™€ ê°™ì€ ì—­í• ì„ í•˜ë©° CASE WHEN ì´ ê°€ë…ì„±ì´ ë” ì¢‹ë‹¤ê³ ë“¤ í•œë‹¤. ì‚¬ìš©ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789101112131415CASE WHEN &#123;condition_01&#125; THEN &#123;return_01&#125; WHEN &#123;condition_02&#125; THEN &#123;return_02&#125; ... ELSE &#123;return_other&#125;END--exampleCASE WHEN ( SELECT CODE_NM FROM COMTCCMMNDETAILCODE WHERE CODE = D.DOMAIN_CODE2) IS NOT NULL OR ( SELECT CODE_NM FROM COMTCCMMNDETAILCODE WHERE CODE = D.DOMAIN_CODE2) != '' THEN ( SELECT CODE_NM FROM COMTCCMMNDETAILCODE WHERE CODE = D.DOMAIN_CODE2) ELSE NULL END AS CODE_NM2 condition COMTCCMMNDETAILCODE í…Œì´ë¸”ì—ì„œ CODEê°€ D í…Œì´ë¸” DOMATIN_CODE2 ì™€ ê°™ì„ë•Œ, CODE_NM ì´ NULL ì´ ì•„ë‹ˆê±°ë‚˜ (or) COMTCCMMNDETAILCODE í…Œì´ë¸”ì—ì„œ CODEê°€ D í…Œì´ë¸” DOMATIN_CODE2 ì™€ ê°™ì„ë•Œ, CODE_NM ì´ â€˜â€™ ì´ ì•„ë‹ˆë¼ë©´ return: COMTCCMMNDETAILCODE í…Œì´ë¸”ì—ì„œ CODEê°€ D í…Œì´ë¸” DOMATIN_CODE2 ì™€ ê°™ì„ë•Œ CODE_NM ëŒ€ì… ELSE: NULL ëŒ€ì… ê²°ë¡ : CODE_NM ê°’ì´ ìˆìœ¼ë©´ CODE_NM, ì—†ìœ¼ë©´ NULL CASTì¹¼ëŸ¼ í˜•ë³€í™˜ì— ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë¡œ UNION(UNION ALL) ì‚¬ìš© ì‹œ ì¹¼ëŸ¼ í˜•íƒœë¥¼ ì¼ì¹˜ì‹œí‚¬ ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345CAST(&#123;column&#125; as &#123;data_type&#123;length&#125;&#125;)--exmapleCAST(A.DETECTED_LINK AS NVARCHAR(4000)) AS DETECTED_LINK A í…Œì´ë¸” DETECTED_LINK ì¹¼ëŸ¼ì„ NVARCHAR length 4000 í˜•íƒœë¡œ ë³€í™˜ INSTRë¬¸ìì—´ì— íŠ¹ì • ë¬¸ìì—´(substring)ì„ ê²€ìƒ‰í•´ì„œ ìœ„ì¹˜ë¥¼ return(ë§Œì•½ ì—†ë‹¤ë©´ 0) í•˜ëŠ” í•¨ìˆ˜ë¡œ ì‚¬ìš©ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345INSTR(&#123;string or column&#125; &#123;substring&#125;)--exampleINSTR(D.exposure_type, 'S01') D í…Œì´ë¸” EXPOSURE_TYPE ì¹¼ëŸ¼ ë‚´ S01 ë¬¸ìì—´ ìœ„ì¹˜ë¥¼ ë°˜í™˜ Reference https://gent.tistory.com/227 https://gent.tistory.com/311 http://www.incodom.kr/SQL/INSTR%2CINSTRB made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Tibero","slug":"Tibero","permalink":"https://jx2lee.github.io/tags/Tibero/"}]},{"title":"[Cloud] Etcd ë°±ì—…ì„ ìœ„í•œ CronJob ìƒì„±","slug":"cloud-etcd_cronjob","date":"2020-06-16T15:00:00.000Z","updated":"2020-09-26T13:42:38.732Z","comments":true,"path":"cloud-etcd_cronjob/","link":"","permalink":"https://jx2lee.github.io/cloud-etcd_cronjob/","excerpt":"ìµœê·¼ Control Plane ë…¸ë“œ ë³µêµ¬ ë•Œë¬¸ì— Etcd ë°±ì—…ì— ëŒ€í•œ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ë‹¤. ë§¤ íŠ¹ì • ì‹œê°„ ìŠ¤ëƒ…ìƒ·ì„ ì°ì–´ë‚´ëŠ” CronJob ì„ ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.","text":"ìµœê·¼ Control Plane ë…¸ë“œ ë³µêµ¬ ë•Œë¬¸ì— Etcd ë°±ì—…ì— ëŒ€í•œ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ë‹¤. ë§¤ íŠ¹ì • ì‹œê°„ ìŠ¤ëƒ…ìƒ·ì„ ì°ì–´ë‚´ëŠ” CronJob ì„ ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. ì¤€ë¹„ì‚¬í•­control plane ë…¸ë“œì˜ ì¸ì¦ì„œ íŒŒì¼ /etc/kubernetes/pki/ca.crt /etc/kubernetes/pki/ca.key etcd ë²„ì „ í™•ì¸ cluster ë‚´ etcd íŒŒë“œë¥¼ ì¡°íšŒí•˜ì—¬ ë²„ì ¼ ì²´í¬12$ kubectl describe pod/etcd-k8s-master -n kube-system | grep Image: Image: k8s.gcr.io/etcd:3.3.10 setup.sh apply í•  yaml íŒŒì¼ ë‚´ docker registry ì™€ node name ì„ ë³€ê²½í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ Usage123$ ./setup.shUsage : ./script.sh &#123;registry_endpoint&#125; &#123;master_node&#125;Example : ./script.sh 192.168.179.185:5000 k8s-master etcd_snapshot.yamlcontrol plane ì¸ì¦ì„œ íŒŒì¼ì„ volume ë¶€ë¶„ /etc/kubernetes/pki/etcd í´ë”ì— ë³µì‚¬etcd ë°±ì—… ìŠ¤ëƒ…ìƒ·ì˜ ì €ì¥ ìœ„ì¹˜ë¥¼ volume ë¶€ë¶„ backup ìœ¼ë¡œ ì„¤ì • ìŠ¤ëƒ…ìƒ·ì´ í•´ë‹¹ ë””ë ‰í† ë¦¬ì— ì €ì¥ ì›í•˜ëŠ” ìŠ¤ëƒ…ìƒ· ì €ì¥ ì£¼ê¸°ë¥¼ crontab ìœ¼ë¡œ í‘œí˜„ ë³¸ì¸ì€ ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ìˆ˜í–‰í•˜ëŠ” 0 6 * * * ìœ¼ë¡œ ì„¤ì • 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: batch/v1beta1kind: CronJobmetadata: name: etcd-backup namespace: kube-systemspec: schedule: \"0 6 * * *\" jobTemplate: spec: template: spec: containers: - name: etcd-backup image: &#123;registry_endpoint&#125;/k8s.gcr.io/etcd:3.3.10 env: - name: ETCDCTL_API value: \"3\" command: [\"/bin/sh\"] args: [\"-c\", \"etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key snapshot save /backup/etcd-snapshot-$(date +%Y-%m-%d_%H-%M-%S_%Z).db\"] volumeMounts: - mountPath: /etc/kubernetes/pki/etcd name: etcd-certs readOnly: true - mountPath: /backup name: backup restartPolicy: OnFailure nodeSelector: kubernetes.io/hostname: &#123;master_node&#125; tolerations: - effect: NoSchedule operator: Exists hostNetwork: true volumes: - name: etcd-certs hostPath: path: /etc/kubernetes/pki/etcd type: DirectoryOrCreate - name: backup hostPath: path: /etc/kubernetes/pki/etcd/snapshot type: DirectoryOrCreate script ì‹¤í–‰ìœ¼ë¡œ etcd_snapshot.yaml ë‚´ node name ê³¼ private registry ì£¼ì†Œ ë³€ê²½1$ ./setup.sh 192.168.179.185:5000 k8s-master ë°°í¬$ kubectl apply -f etcd_snapshot.yaml ë°°í¬ í™•ì¸123456789$ kubectl get cronjob -n kube-systemNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGEetcd-backup 0 6 * * * False 0 &lt;none&gt; 14m$ ll /etc/kubernetes/pki/etcd/snapshotdrwxr-xr-x 2 root root 4096 6ì›” 18 15:00 ./drwxr-xr-x 3 root root 4096 6ì›” 17 15:00 ../-rw-r--r-- 1 root root 41095200 6ì›” 17 15:00 etcd-snapshot-2020-06-17_06-00-04_UTC.db-rw-r--r-- 1 root root 41095200 6ì›” 18 15:00 etcd-snapshot-2020-06-18_06-00-08_UTC.db hostPath ë¡œ ì„¤ì •í•œ /etc/kubernetes/pki/etcd/snapshot ë‚´ snapshot.db í™•ì¸ ì†ŒìŠ¤ì½”ë“œëŠ” https://github.com/jx2lee/etcd-cronjob ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Refernce https://labs.consol.de/kubernetes/2018/05/25/kubeadm-backup.html made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[TroubleShoot] Control Plane Node ì¶”ê°€","slug":"troubleshoot-add_controlplane_node","date":"2020-06-15T15:00:00.000Z","updated":"2020-09-26T13:46:18.422Z","comments":true,"path":"troubleshoot-add_controlplane_node/","link":"","permalink":"https://jx2lee.github.io/troubleshoot-add_controlplane_node/","excerpt":"í´ëŸ¬ìŠ¤í„° ìš´ì˜ ì‹œ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œê°€ ì‚­ì œë˜ì—ˆì„ ë•Œ í´ëŸ¬ìŠ¤í„°ì— ì¬ ì¶”ê°€í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤.","text":"í´ëŸ¬ìŠ¤í„° ìš´ì˜ ì‹œ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œê°€ ì‚­ì œë˜ì—ˆì„ ë•Œ í´ëŸ¬ìŠ¤í„°ì— ì¬ ì¶”ê°€í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤. Kubernetes ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë…¸ë“œ ì¶”ê°€ ë°©ë²•ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ë‚´ /etc/kubernetes/pki í´ë”ë¥¼ ì¶”ê°€ ë…¸ë“œì˜ /etc/kubernetesì— ë³µì‚¬ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ë‚´ /var/lib/etcd/member í´ë”ë¥¼ ì¶”ê°€ ë…¸ë“œ ë‚´ íŠ¹ì • ë””ë ‰í† ë¦¬ (ë‚˜ì˜ ê²½ìš° init í´ë”) ë¡œ ë³µì‚¬ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ë‚´ etcd íŒŒë“œì— ì ‘ê·¼í•˜ì—¬ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ snap db ìƒì„±123ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 \\--cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt \\--key /etc/kubernetes/pki/etcd/server.key snapshot save snap ìƒì„±í•œ snap db ë¥¼ ì¶”ê°€í•˜ê³ ì í•˜ëŠ” ë…¸ë“œì˜ íŠ¹ì • ë””ë ‰í† ë¦¬ (ë‚˜ì˜ ê²½ìš° init í´ë”) ë¡œ ì´ë™ì´ˆê¸° í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ì‹œ ì‚¬ìš©í•œ kubeadm-config.yaml ì¤€ë¹„12345678910apiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: \"v1.15.3\"controlPlaneEndpoint: \"192.168.179.185:6443\" # VIP:6443networking: serviceSubnet: \"10.96.0.0/16\" podSubnet: \"10.244.0.0/16\" # must equal CIDR in calico.yamlapiServer: extraArgs: advertise-address: \"192.168.179.185\" # VIP ìƒˆë¡œ ì¶”ê°€í•  ë…¸ë“œ(k8s-node5 ë¼ ê°€ì •)ì— ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ í†µí•´ etcd ë°ì´í„° ë³µêµ¬123456docker run --rm \\ -v '/root/init:/backup' \\ -v '/var/lib/etcd:/var/lib/etcd' \\ --env ETCDCTL_API=3 \\ 'k8s.gcr.io/etcd:3.3.10' \\ /bin/sh -c \"etcdctl snapshot restore '/backup/snap.db' ; mv /default.etcd/member/ /var/lib/etcd/\" ìƒˆë¡œ ì¶”ê°€í•  ë…¸ë“œ (k8s-node5) ì— kubeadm init ìˆ˜í–‰12kubeadm init --config=kubeadm-config.yaml\\--ignore-preflight-errors=DirAvailable--var-lib-etcd Reference https://codefarm.me/2019/05/22/kubernetes-recovery-master-failure/ made by jaejun.lee","categories":[{"name":"TroubleShoot","slug":"TroubleShoot","permalink":"https://jx2lee.github.io/categories/TroubleShoot/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Etc] DevOps ì¸í„°ë·° ê¸°ìˆ ì§ˆë¬¸ ì •ë¦¬","slug":"etc-devops_interview_questions","date":"2020-06-10T15:00:00.000Z","updated":"2020-09-26T13:49:36.378Z","comments":true,"path":"etc-devops_interview_questions/","link":"","permalink":"https://jx2lee.github.io/etc-devops_interview_questions/","excerpt":"DevOps ì§ë¬´ ì‹¤ë¬´ì ë©´ì ‘ì—ì„œ ë°›ì€ ì¸í„°ë·° ë‚´ìš©ì„ ì •ë¦¬í•˜ì˜€ë‹¤. ê¸°ìˆ ì ì¸ ë‚´ìš©ë§Œ ì •ë¦¬í•˜ì˜€ê³  ì´ì™¸ì—ëŠ” ì´ì§ ì‚¬ìœ ì— ëŒ€í•´ ë§ì´ ê¶ê¸ˆí•´ í•˜ì˜€ë‹¤. ë‚˜ì—ê²Œ ì´ì§ì‚¬ìœ  ë³´ë‹¨ ê¸°ìˆ ì„ ì•Œê³  ë„“íˆëŠ”ê²Œ ì¤‘ìš”í•  ê²ƒ ê°™ì•„.. ì¶”ê°€ì ìœ¼ë¡œ ë©´ì ‘ì„ ì§„í–‰í•˜ë©´ ì•ìœ¼ë¡œ ê³„ì† ì¶”ê°€í•  ì˜ˆì •ì´ë©° ì§ˆë¬¸ì€ ê¸°ìˆ ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤.","text":"DevOps ì§ë¬´ ì‹¤ë¬´ì ë©´ì ‘ì—ì„œ ë°›ì€ ì¸í„°ë·° ë‚´ìš©ì„ ì •ë¦¬í•˜ì˜€ë‹¤. ê¸°ìˆ ì ì¸ ë‚´ìš©ë§Œ ì •ë¦¬í•˜ì˜€ê³  ì´ì™¸ì—ëŠ” ì´ì§ ì‚¬ìœ ì— ëŒ€í•´ ë§ì´ ê¶ê¸ˆí•´ í•˜ì˜€ë‹¤. ë‚˜ì—ê²Œ ì´ì§ì‚¬ìœ  ë³´ë‹¨ ê¸°ìˆ ì„ ì•Œê³  ë„“íˆëŠ”ê²Œ ì¤‘ìš”í•  ê²ƒ ê°™ì•„.. ì¶”ê°€ì ìœ¼ë¡œ ë©´ì ‘ì„ ì§„í–‰í•˜ë©´ ì•ìœ¼ë¡œ ê³„ì† ì¶”ê°€í•  ì˜ˆì •ì´ë©° ì§ˆë¬¸ì€ ê¸°ìˆ ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤. êµ¬ë¶„ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.&#x2728; Contents: Kubernetes Python Database Linux Network Hadoop Kubernetes VM vs container:ë‘ ê°œ ëª¨ë‘ ê°€ìƒí™” ê¸°ìˆ ë¡œ í° ì°¨ì´ëŠ” HyperVisor ìœ ë¬´ì´ë‹¤. VMì˜ ê²½ìš° ìš´ì˜ì²´ì œì—ì„œ í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘í•˜ëŠ” ë°˜ë©´ ì»¨í…Œì´ë„ˆëŠ” í˜¸ìŠ¤íŠ¸ ìš´ì˜ì²´ì œì˜ ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ì–´ ì¢€ ë” ê°€ë³ê³  MSA êµ¬í˜„ì´ ê°€ëŠ¥í•˜ë‹¤. ë˜í•œ, ìš´ì˜ì²´ì œ ì»¤ë„ì˜ ê³µìœ í•¨ìœ¼ë¡œì¨ ë¹ ë¥´ë©° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ë‹¤. Docker Swarm:ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë„êµ¬ ì¤‘ í•˜ë‚˜ë¡œ Docker í˜¸ìŠ¤íŠ¸ë“¤ì„ í•˜ë‚˜ì¸ ê²ƒì²˜ëŸ¼ ë§Œë“¤ì–´ì£¼ëŠ” ë„êµ¬. Master/Worker ë…¸ë“œë¡œ ì‹œìŠ¤í…œì„ êµ¬ì„±í•œë‹¤.:https://medium.com/@chrisjune_13837/infra-docker-swarmì´ë€-595d33160379 proxy (k8s):Pod ë¡œ ì—°ê²°ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ê´€ë¦¬í•˜ë©° íŒŒë“œ ê°„ í†µì‹ ì„ ìœ„í•´ ë¼ìš°íŒ…ì„ ë•ëŠ”ë‹¤. íŒŒë“œ ê°„ í†µì‹ ì„ ê´€ë¦¬í•˜ê¸° ë•Œë¬¸ì— íŒŒë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ì™€ì˜ í†µì‹ ì„ ì›í™œíˆ í•´ì¤€ë‹¤. istio:Data Plane(í”„ë¡ì‹œë“¤ë¡œ ì´ë£¨ì–´ì ¸ íŠ¸ë˜í”½ì„ ì„¤ì •ê°’ì— ë”°ë¼ ì»¨íŠ¸ë¡¤ í•˜ëŠ” ë¶€ë¶„)*ì˜ ë©”ì¸ í”„ë¡ì‹œë¡œ Envoy Proxyë¥¼ ì‚¬ìš©í•˜ë©° ì´ë¥¼ ì»¨íŠ¸ë¡¤ í•´ì£¼ëŠ” Control Plane(í”„ë¡ì‹œë“¤ì— ì„¤ì •ê°’ì„ ì „ë‹¬í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬)*ì˜ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜. ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ í¬ìŠ¤íŠ¸ê°€ ì˜ ì •ë¦¬ë˜ì–´ ìˆë‹¤.:https://gruuuuu.github.io/cloud/service-mesh-istio/# readiness/liveness probe:ì»¨í…Œì´ë„ˆê°€ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” health check ë°©ë²•ì¸ liveness probe, ì»¨í…Œì´ë„ˆê°€ ì„œë¹„ìŠ¤ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸í•˜ëŠ” health check ë°©ë²•ì¸ readiness probe:https://bcho.tistory.com/m/1264 Python global interpreter lock:íŠ¹ì • ì‹œì ì—ì„œì˜ í•˜ë‚˜ì˜ ì“°ë ˆë“œë§Œ ì‹¤í–‰í•˜ë„ë¡ ë§Œë“œëŠ” ê²ƒ:https://m.blog.naver.com/alice_k106/221566619995 async:í•˜ë‚˜ì˜ ì“°ë ˆë“œë¡œ ë™ì‹œ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆëŠ” ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€:https://www.daleseo.com/python-asyncio/ garbage collection:íŒŒì´ì¬ì€ ë³´í†µ garbage collection ê³¼ reference counting ì„ í†µí•´ í• ë‹¹ëœ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•œë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ì°¸ì¡° íšŸìˆ˜ê°€ 0ì´ ëœ ê°ì²´ë¥¼ í•´ì œí•˜ëŠ” reference counting ë°©ì‹ì„ ì‚¬ìš©í•˜ì§€ë§Œ, reference cycles (ìˆœí™˜ì°¸ì¡°) ê°€ ë°œìƒí•˜ë©´ garbage collection ìœ¼ë¡œ ì´ë¥¼ í•´ê²°í•œë‹¤.:https://winterj.me/python-gc/ decorator:ëŒ€ìƒ í•¨ìˆ˜ë¥¼ wrapping í•˜ê³  ì´ wrapping ëœ í•¨ìˆ˜ì˜ ì•ë’¤ì— ì¶”ê°€ì ìœ¼ë¡œ ê¾¸ë©°ì§ˆ êµ¬ë¬¸ë“¤ì„ ì •ì˜í•´ ì†ì‰½ê²Œ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ ê¾¸ë©°ì£¼ëŠ” í•¨ìˆ˜ ë¼ê³  í‘œí˜„í•  ìˆ˜ ìˆë‹¤.:https://bluese05.tistory.com/30:https://nachwon.github.io/decorator/ Database Tibero vs MySQL:ì‚¬ì‹¤ ì´ ì§ˆë¬¸ì— ë‹µë³€ì€ ì˜¤í”ˆì†ŒìŠ¤ vs ìƒìš©ì´ë¼ê³  ë§í–ˆë‹¤.. êµ¬ê¸€ë§ì„ í•˜ë©´ ë¹„êµìë£Œê°€ ë‚˜ì˜¤ê¸´ í•˜ì§€ë§Œ ì–´ë–»ê²Œ ì‘ì„±í•´ì•¼ë  ì§€ ëª°ë¼ ë§í¬ë§Œ ë‚¨ê²¨ë‘ê³  ë©´ì ‘ì „ì— ë³´ê³  ë“¤ì–´ê°€ì!:https://db-engines.com/en/system/MySQL%3BTibero Dead Lock:ë°ì´í„° ì¼ê´€ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ íŠ¸ëœì­ì…˜ ê°„ êµì°©ìƒíƒœë¥¼ ì˜ë¯¸í•œë‹¤. ë‘ ê°œì˜ íŠ¸ëœì­ì…˜ ê°„ ê°ê°ì˜ íŠ¸ëœì­ì…˜ì´ ê°€ì§€ê³  ìˆëŠ” ë¦¬ì†ŒìŠ¤ì˜ Lock ì„ íšë“í•˜ë ¤ê³  í•  ë•Œ ë°œìƒí•œë‹¤. (ì˜ˆë¥¼ë“¤ì–´, A-&gt;D1 íŠ¸ëœì­ì…˜ ë°œìƒ / B-&gt;D2 íŠ¸ëœì­ì…˜ ë°œìƒ ì´í›„ Aê°€ D2ì— ì»¤ë°‹ì„ í•˜ê²Œ ë˜ë©´ Dead Lock ë°œìƒ):https://medium.com/@chrisjune_13837/db-lock-ë½ì´ë€-ë¬´ì—‡ì¸ê°€-d908296d0279 Linux fstrim:ë””ìŠ¤í¬ IO(ì£¼ë¡œ SSD) ì„±ëŠ¥ ì €í•˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ /dev ë””ë ‰í† ë¦¬:ì¥ì¹˜ íŒŒì¼ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ë¡œ Node(ë…¸ë“œ) ë¼ê³  ë¶ˆë¦¬ëŠ” ìš”ì†Œë¥¼ í¬í•¨í•˜ë©°, ê° ë…¸ë“œëŠ” ì‹œìŠ¤í…œì˜ í•œ ì¥ì¹˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. /dev/null ì€ ê°€ìƒì¥ì¹˜ë¡œì¨ í”„ë¡œê·¸ë¨ì˜ ì¶œë ¥ì„ ë¬´ì‹œí•˜ì—¬ í™”ë©´ ìƒ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ì§€ ì•Šì„ ë•Œ ìœ ìš©í•˜ë‹¤. /dev/0(zero) ëŠ” write ìˆ˜í–‰ ì‹œ ì„±ê³µì ì¸ ë¦¬í„´ ì½”ë“œë¥¼ ì œê³µí•˜ë©° íŠ¹ì • í¬ê¸°ì˜ íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ ì €ì¥ ì¥ì¹˜ë¥¼ í¬ë§·í•˜ê¸° ìœ„í•´ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤. LAID (ë¦¬ëˆ…ìŠ¤ ë””ìŠ¤í¬):ì—¬ëŸ¬ ê°œ HDD ë¥¼ í•˜ë‚˜ì˜ HDD ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹:https://infrajp.tistory.com/9 pipe / redirect:pipe) í”„ë¡œì„¸ìŠ¤ í˜¹ì€ ì‹¤í–‰ëœ í”„ë¡œê·¸ë¨ì˜ ê²°ê³¼ë¥¼ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì „ë‹¬í•˜ê±°ë‚˜ ë‚¨ê¸¸ ë•Œ ì‚¬ìš©:redirect) í”„ë¡œê·¸ë¨ì˜ ê²°ê³¼ í˜¹ì€ ì¶œë ¥ì„ íŒŒì¼ì´ë‚˜ ë‹¤ë¥¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ë‹¬í•˜ê±°ë‚˜ ë‚¨ê¸¸ ë•Œ ì‚¬ìš© 0: standard input (stdin) 1: standard output (stdout) 2: standard error (stderr) kernel parameter ë³€ê²½ ì´ìœ  (ì‚¬ìš© ì´ìœ ):kernel parameter ë€ ì»¤ë„(ì‹œìŠ¤í…œì„ ê´€ë¦¬í•˜ëŠ” ê±°ëŒ€í•œ ì–´í”Œë¦¬ì¼€ì´ì…˜)ì´ ë©”ëª¨ë¦¬ì™€ í”„ë¡œì„¸ìŠ¤ë¥¼ í• ë‹¹í•˜ê¸° ìœ„í•œ ê°’ìœ¼ë¡œ, /proc/sys (OSë§ˆë‹¤ ìƒì´í•  ìˆ˜ ìˆìŒ) ë””ë ‰í† ë¦¬ì— ì¡´ì¬í•œë‹¤. Network DNS(Domain Name Server):TCP/IP ë„¤íŠ¸ì›Œí¬ì—ì„œ ì‚¬ëŒì´ ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë¬¸ìë¡œ ë§Œë“¤ì–´ì§„ ë„ë©”ì¸ì„, ì»´í“¨í„°ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì¸í„°ë„· ì£¼ì†Œ(IP)ë¡œ ë°”ê¾¸ëŠ” ì‹œìŠ¤í…œì¸ Domain Name System ë˜ëŠ” ì´ëŸ° ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” Domain Name Server ë¥¼ ì˜ë¯¸:https://samsikworld.tistory.com/489 CNAME, A record:CNAME) Canonical Name ìœ¼ë¡œ í•˜ë‚˜ì˜ ë„ë©”ì¸ì— ë‹¤ë¥¸ ì´ë¦„ì„ ë¶€ì—¬í•˜ëŠ” ë°©ì‹:A record) ë„ë©”ì¸ ì´ë¦„ì— í•˜ë‚˜ì˜ IP address ê°€ ìˆìŒì„ ì˜ë¯¸:https://twpower.github.io/40-difference-between-cname-and-a-record TCP / UDP:TCP/IPì˜ ì „ì†¡ê³„ì¸µì— ì‚¬ìš©í•˜ëŠ” í”„ë¡œí† ì½œë¡œ, ì „ì†¡ê³„ì¸µì´ë€ IPì— ì˜í•´ ì „ë‹¬í•˜ëŠ” íŒ¨í‚·ì˜ ì˜¤ë¥˜ë¥¼ ê²€ì‚¬í•˜ê³  ì¬ì „ì†¡ ìš”êµ¬ ë“±ì˜ ì œì–´ë¥¼ ë‹´ë‹¹í•œë‹¤.:TCP(Transmission Control Protocol) ì‹ ë¢°ì„±ì„ ìš”êµ¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì‚¬ìš©(ì–‘ë°©í–¥ ì „ì†¡):UDP(User Datagram Protocol) ê°„ë‹¨í•œ ë°ì´í„°ë¥¼ ë¹ ë¥¸ ì†ë„ë¡œ ì „ì†¡í•˜ê³ ì í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì‚¬ìš© Hadoop / Spark broadcasting join vs shuffle join:broadcasting join) ë°ì´í„°ë¥¼ executor ë¡œ ë³µì‚¬í•˜ì§€ë§Œ executor ê°„ ë°ì´í„° ë³µì‚¬ê°€ ì—†ì–´ ì†ë„ê°€ ë¹¨ë¼ì§ˆ ìˆ˜ ìˆë‹¤.:shuffle join ì€ ì¡°ì¸ëœ ë°ì´í„°ë¡œ ë™ì¼í•œ executor ë¡œ ì´ë™í•˜ê¸° ìœ„í•´ ì…”í”Œ ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì´ë™ì´ ë§ì´ ë°œìƒí•œë‹¤.:https://knight76.tistory.com/entry/spark-ìŠ¤íŒŒí¬-ì¡°ì¸-ì „ëµ-ì…”í”Œ-ì¡°ì¸-ë¸Œë¡œìºìŠ¤íŠ¸-ì¡°ì¸-shuffle-join-broadcast-join made by jaejun.lee","categories":[{"name":"Etc","slug":"Etc","permalink":"https://jx2lee.github.io/categories/Etc/"}],"tags":[{"name":"Review","slug":"Review","permalink":"https://jx2lee.github.io/tags/Review/"}]},{"title":"[Cloud] ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•œ íŒŒë“œ ë°°í¬ ì‹œ transport endpoint is not connected","slug":"cloud-mount_failed","date":"2020-06-07T15:00:00.000Z","updated":"2020-10-29T14:38:30.347Z","comments":true,"path":"cloud-mount_failed/","link":"","permalink":"https://jx2lee.github.io/cloud-mount_failed/","excerpt":"kubernetes í´ëŸ¬ìŠ¤í„° ìš´ì˜ ì¤‘ control plane ë…¸ë“œ ì¥ì• ê°€ ë°œìƒí•´ ì—¬ëŸ¬ ì‚½ì§ˆì„ í•˜ë˜ ì¤‘.. ê¸°ì¡´ ìš´ì˜ì¤‘ì´ë˜ Pod ê°€ ë–  ìˆì§€ë¥¼ ëª»í•´ í™•ì¸(describe)í•´ë³´ë‹ˆ transport endpoint is not connected ë¬¸êµ¬ì™€ í•¨ê»˜ Mount failed í•˜ì˜€ë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.","text":"kubernetes í´ëŸ¬ìŠ¤í„° ìš´ì˜ ì¤‘ control plane ë…¸ë“œ ì¥ì• ê°€ ë°œìƒí•´ ì—¬ëŸ¬ ì‚½ì§ˆì„ í•˜ë˜ ì¤‘.. ê¸°ì¡´ ìš´ì˜ì¤‘ì´ë˜ Pod ê°€ ë–  ìˆì§€ë¥¼ ëª»í•´ í™•ì¸(describe)í•´ë³´ë‹ˆ transport endpoint is not connected ë¬¸êµ¬ì™€ í•¨ê»˜ Mount failed í•˜ì˜€ë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Describe Podì¥ì• ê°€ ë°œìƒí•œ íŒŒë“œë¥¼ Describe í•œ ê²°ê³¼ì´ë‹¤.ì´ 3 Waring-FailedMount ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ëŠ”ë°, Rook-ceph ì˜ cephfs ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ê³µìœ ë³¼ë¥¨(rserver-share)/Homeë””ë ‰í† ë¦¬(rserver-home)/í† í°(default-token-4w7gr) ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ê³ ì í–ˆë‹¤. 12345Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedMount 13m (x143 over 5h2m) kubelet, k8s-node1 MountVolume.SetUp failed for volume \"pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339\" : stat /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount: transport endpoint is not connected Warning FailedMount 3m1s (x125 over 4h44m) kubelet, k8s-node1 Unable to mount volumes for pod \"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)\": timeout expired waiting for volumes to attach or mount for pod \"nps\"/\"rserver-3.6.3-deployment-776f6b8ddc-gwbk5\". list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr] Pod log ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì—ˆì§€ë§Œ ì• ì´ˆì— ëœ¨ê¸°ë„ ì „ì— Mount Failed ë˜ì—ˆê¸°ì— í•´ë‹¹ ë…¸ë“œë¡œ ì ‘ì†í•˜ì—¬ Kubelet ë¡œê·¸ë¥¼ í™•ì¸í•˜ì˜€ë‹¤. Kubelet logí•´ë‹¹ ë…¸ë“œì— journal -f | grep kubelet ìœ¼ë¡œ ë¡œê·¸ë¥¼ ì‚´í´ë³´ë‹ˆ Describe ì™€ ë‹¤ë¥¸ ì ì´ ì—†ì–´ë³´ì´ì§€ë§Œ, ê° Pod ì˜ ë³¼ë¥¨ì˜ Path (ë©”ì„¸ì§€ì—ëŠ” stat / ìœ¼ë¡œ í‘œí˜„) ë¥¼ ì¶œë ¥í•´ì¤€ë‹¤. 123Jun 08 13:49:57 k8s-node1 kubelet[4638]: E0608 13:49:57.738465 4638 nestedpendingoperations.go:270] Operation for \"\\\"kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com^0001-0009-rook-ceph-0000000000000001-d90262eb-a499-11ea-a466-52c8f6e260ed\\\"\" failed. No retries permitted until 2020-06-08 13:51:59.738429723 +0000 UTC m=+21911.512876014 (durationBeforeRetry 2m2s). Error: \"MountVolume.SetUp failed for volume \\\"pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339\\\" (UniqueName: \\\"kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com^0001-0009-rook-ceph-0000000000000001-d90262eb-a499-11ea-a466-52c8f6e260ed\\\") pod \\\"rserver-3.6.3-deployment-776f6b8ddc-gwbk5\\\" (UID: \\\"eea991e6-9908-4d41-bd01-141af0566079\\\") : stat /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount: transport endpoint is not connected\"Jun 08 13:50:01 k8s-node1 kubelet[4638]: E0608 13:50:01.755308 4638 kubelet.go:1665] Unable to mount volumes for pod \"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)\": timeout expired waiting for volumes to attach or mount for pod \"nps\"/\"rserver-3.6.3-deployment-776f6b8ddc-gwbk5\". list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr]; skipping podJun 08 13:50:01 k8s-node1 kubelet[4638]: E0608 13:50:01.755344 4638 pod_workers.go:190] Error syncing pod eea991e6-9908-4d41-bd01-141af0566079 (\"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)\"), skipping: timeout expired waiting for volumes to attach or mount for pod \"nps\"/\"rserver-3.6.3-deployment-776f6b8ddc-gwbk5\". list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr] 1stat /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount ì´ ë¶€ë¶„ì„ ì£¼ëª©í•´ì„œ ë³´ì. í•´ë‹¹ Path ìœ¼ë¡œ ì ‘ê·¼í•˜ì—¬ mount í´ë”ë¥¼ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789$ pwd/var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339$ llls: cannot access 'mount': Transport endpoint is not connectedtotal 12drwxr-x--- 3 root root 4096 Jun 2 06:27 ./drwxr-x--- 4 root root 4096 Jun 2 06:27 ../d????????? ? ? ? ? ? mount/-rw-r--r-- 1 root root 328 Jun 8 13:54 vol_data.json mount í´ë”ì˜ í‘œí˜„ì´ ì´ìƒí•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë¶„ëª… í´ë”ì— ëŒ€í•œ ì½ê¸°ì“°ê¸°ì‹¤í–‰ ê¶Œí•œê³¼ ì†Œìœ ì/ê·¸ë£¹ì´ ë‚˜ì™€ì•¼ í•˜ì§€ë§Œ ëª¨ë‘ ë¬¼ìŒí‘œë¡œ ì¶œë ¥í•œë‹¤. ì´ì— ëŒ€í•œ êµ¬ê¸€ë§ì„ í•´ë³¸ ê²°ê³¼, í•´ë‹¹ ë””ë ‰í† ë¦¬ì˜ mount ê°€ ë¹„ì •ìƒ ì‘ë™í•˜ì—¬ ì´ë¥¼ í•´ì œí•´ì•¼ í•œë‹¤ê³  í•œë‹¤. ì •í™•í•œ ì›ì¸ì€ ëª¨ë¥´ê² ì§€ë§Œ, í•´ë‹¹ í´ë”ì— ëŒ€í•œ ì˜ëª»ëœ mount ë¡œ ì¸í•´ PVC ê°€ PV ë¥¼ ì œëŒ€ë¡œ ë°”ë¼ë³´ì§€ ëª»í•˜ì—¬ Mount Failed ë‚œ ê²ƒìœ¼ë¡œ ì´í•´í–ˆë‹¤. í•´ë‹¹ ë””ë ‰í† ë¦¬ë¥¼ umount ë¥¼ ì´ìš©í•´ ë§ˆìš´íŠ¸ë¥¼ í•´ì œí•˜ê³ , Kubelet ë¡œê·¸ë¥¼ ë” í™•ì¸í•˜ì—¬ ë‹¤ë¥¸ PV stat ìœ¼ë¡œ ì ‘ê·¼í•´ ë§ˆìš´íŠ¸ í•´ì œë¥¼ ìˆ˜í–‰í•œë‹¤. ë³´ì•„í•˜ë‹ˆ í•œ ë²ˆì˜ umount ë¡œ ëë‚˜ì§€ ì•Šì•„ ë‚˜ì˜ ê²½ìš°,/var/lib/kubelet/pods/{ìœ„UUID}/volumes/kubernetes.io~csi/ ë‚´ ëª¨ë“  PVC ë¡œ ì ‘ê·¼í•˜ì—¬ í´ë”ê°€ ì´ìƒí•˜ë©´ ë§ˆìš´íŠ¸ë¥¼ í•´ì œ í•˜ì˜€ë‹¤. ë¬´ì‹í•  ìˆ˜ ìˆì§€ë§Œ.. ì–´ì¨Œë“  ëª¨ë‘ ìˆ˜í–‰í•˜ì—¬ Kubelet ë¡œê·¸ì— ì´ìƒì´ ì—†ëŠ” ê²ƒì„ í™•ì¸í•œë‹¤. ì •ìƒ ì‘ë™ í™•ì¸kubectl get all -n nps ëª…ë ¹ì–´ë¡œ ê¸°ì¡´ì— ë– ìˆì§€ ëª»í•œ íŒŒë“œê°€ ì •ìƒ ê¸°ë™í•˜ì˜€ëŠ”ì§€ í™•ì¸í•œë‹¤. 1234567root@k8s-node2:~# kubectl get all -n nps -o wideNAME READY STATUS RESTARTS AGEpod/jupyter-3.7-deployment-f798bb7f4-n2kqq 1/1 Running 0 5h21mpod/jupyter-3.8-deployment-d47c78475-9gsb8 0/1 ContainerCreating 0 4d12hpod/pypiserver-deployment-7bbbb48f8c-rkbhk 1/1 Running 0 6d3hpod/rserver-3.5.3-deployment-96f5d6b4-dhgkg 1/1 Running 0 6d7hpod/rserver-3.6.3-deployment-776f6b8ddc-gwbk5 1/1 Running 0 6d7h 3.8 jupyter ì˜ ê²½ìš° í•´ë‹¹ íŒŒë“œëŠ” ë…¸ë“œê°€ ë‹¬ë¼.. ê·€ì°®ì•„ì„œ ì•„ì§ ê³ ì¹˜ì§€ ì•Šì€ ëª¨ìŠµì´ë‹¤. ì´ë¥¼ ê³ ì¹˜ë ¤ë©´ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í•´ë‹¹ ë…¸ë“œë¡œ ì ‘ê·¼í•˜ì—¬ í•´ê²°í•´ì•¼ í•  ê²ƒ ê°™ë‹¤. ê²°ë¡ ì´ë²ˆ ì¥ì• ë¥¼ ê²ªìœ¼ë©´ì„œ ì–»ì€ êµí›ˆìœ¼ë¡œëŠ”,Pod Describe ë„ ì¢‹ì§€ë§Œ ì¥ì• ê°€ ë‚˜ëŠ” ë¦¬ì†ŒìŠ¤ì˜ ë…¸ë“œë¡œ ì ‘ê·¼í•˜ì—¬ Kubelet ë¡œê·¸ë„ í•¨ê»˜ ë³´ëŠ” ìŠµê´€ì„ ê°€ì ¸ì•¼ ê² ë‹¤. ë¬¼ë¡  Describeë¡œë„ ì¶©ë¶„íˆ ì•Œì•„ë‚¼ ìˆ˜ ìˆëŠ” ì •ë³´ì§€ë§Œ, ë…¸ë“œë“¤ ê°„ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” Kubelet ë¡œê·¸ë¥¼ í†µí•´ ì¢€ ë” ì„¸ë¶€ì ì¸ Info ì™€ Warning ì„ í™•ì¸í•˜ì—¬ ì¼ì„ì´ì¡°ì˜ íš¨ê³¼ë¥¼ ëˆ„ë¦´ ìˆ˜ ìˆë‹¤ ìƒê°í•œë‹¤. ì—”ì§€ë‹ˆì–´ì˜ ì‚¶ì€.. ë¡œê·¸ë¼ëŠ” ì„ ë°°ì˜ ë§ì´ ìƒê°ë‚œë‹¤. made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Python] Jupyter Notebook ë¡œê·¸ íŒŒì¼ ìƒì„±","slug":"python-jupyter_logging","date":"2020-05-27T15:00:00.000Z","updated":"2020-09-26T13:43:50.676Z","comments":true,"path":"python-jupyter_logging/","link":"","permalink":"https://jx2lee.github.io/python-jupyter_logging/","excerpt":"Jupyter Notebook ì‹¤í–‰ ì´ë ¥ì„ ë¡œê·¸íŒŒì¼ë¡œ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.","text":"Jupyter Notebook ì‹¤í–‰ ì´ë ¥ì„ ë¡œê·¸íŒŒì¼ë¡œ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. &#x2728; Contents: Environment log_history.py Customize IPython/core/history.py Result Reference EnvironmentKubernetes í™˜ê²½ì—ì„œ Jupyter Notebook ë„ì»¤ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ deployment ë¡œ ê´€ë¦¬í•˜ê³  ì„œë¹„ìŠ¤ëŠ” ë…¸ë“œí¬íŠ¸ë¡œ êµ¬ì„±í•˜ì—¬ íŠ¹ì • í¬íŠ¸ë¡œ Jupyter Notebook ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ì„¤ì •í•˜ì˜€ë‹¤. Python ë²„ì ¼ì€ 3.8ì—ì„œ ì§„í–‰í•˜ì˜€ìœ¼ë©°, Docker imageëŠ” 3.8, 3.7 ë“± ì†Œìˆ˜ ì²« ì§¸ ìë¦¬ê¹Œì§€ì˜ ë²„ì ¼ë§Œ ë¹Œë“œí•  ìˆ˜ ìˆê²Œ ì‘ì„±ë˜ì—ˆë‹¤. í™˜ê²½ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789101112$ kg all -n jupyter-loggingNAME READY STATUS RESTARTS AGEpod/jupyter-3.8-deployment-6676cc56d6-xth7b 1/1 Running 0 13hNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/jupyter-38-svc NodePort 10.96.187.185 &lt;none&gt; 8888:30180/TCP 24dNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/jupyter-3.8-deployment 1/1 1 1 13hNAME DESIRED CURRENT READY AGEreplicaset.apps/jupyter-3.8-deployment-6676cc56d6 1 1 1 13h Dockerfile ë¥¼ í†µí•œ ë¹Œë“œ í™˜ê²½ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345678910111213$ lltotal 104drwxr-xr-x 2 root root 4096 May 28 09:05 ./drwxr-xr-x 6 root root 4096 May 26 09:56 ../-rw-r--r-- 1 root root 71 May 26 01:52 create_pwd_hash.py-rw-r--r-- 1 root root 8160 May 26 08:10 Dockerfile-rw-r--r-- 1 root root 965 May 26 01:52 fix-permissions-rw-r--r-- 1 root root 33023 May 28 09:05 history.py-rw-r--r-- 1 root root 1877 May 26 09:54 jupyter_notebook_config.py-rw-r--r-- 1 root root 949 May 28 09:04 log_history.py-rwxr-xr-x 1 root root 524 May 26 01:52 start-notebook.sh*-rwxr-xr-x 1 root root 6302 May 26 01:52 start.sh*-rwxr-xr-x 1 root root 1181 May 26 01:52 start-singleuser.sh* íŒŒì¼ ëª©ë¡ ì¤‘ ìƒˆë¡œ ì¶”ê°€í•œ ê²ƒì€ log_history.pyì™€ history.pyì´ë‹¤. ì¶”í›„ì— Dockerfile ì»¤ìŠ¤í…€í™” í•œ ê²°ê³¼ë¥¼ ì¶”ê°€í•  ì˜ˆì •ì´ë‹¤. log_history.pyìƒì†Œí•  ê²ƒì´ë‹¤. ë§ë‹¤. ì™œëƒí•˜ë©´ íŒŒì¼ ë„¤ì´ë°ì€ ë‚´ê°€ ìƒê°í•œ ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤. ê³ ê°ì‚¬ ìš”ê±´ì€ ê°„ë‹¨í•˜ë‹¤. Jupyter Notebook ì„ ì´ìš©í•´ ë¶„ì„ê°€ê°€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì˜€ì„ ë•Œ, ì½”ë“œ ì´ë ¥ì„ ë‚¨ê¸°ëŠ” logê°€ í•„ìš”í–ˆë‹¤. ë¬¼ë¡  python ë¡œê·¸ì˜ ê²½ìš° python ì„ ì‹¤í–‰í•œ ë””ë ‰í† ë¦¬ì—ì„œ .python_history ê°€ ì‘ì„±ë˜ì§€ë§Œ, ì´ë†ˆì˜ Jupyter Notebook ì€ ì–´ë””ì—ë‹¤ ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ”ì§€ íŒŒì•…ì´ ì–´ë ¤ì› ë‹¤. But, Jupyter Notebook ê³¼ IPython ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ë©´ ì‰½ê²Œ í’€ë¦°ë‹¤. êµ¬ê¸€ë§ í•˜ë©´ ì‰½ê²Œ ì°¨ì´ì ì„ ì‚´í•„ ìˆ˜ ìˆê² ì§€ë§Œ, ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´ ì°¨ì´ê°€ ìˆëŠ” ê²ƒ ë³´ë‹¤ í¬í•¨ê´€ê³„ë¥¼ ê°€ì§„ë‹¤. ì¦‰, Jupyter Notebook ì€ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ”ë° ê·¸ ì¤‘ IPython ì´ íŒŒì´ì¬ ì–¸ì–´ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ë‹¤. ë‹¤ì‹œ ë§í•´ Jupyter Notebookì€ IPython ì„ í¬í•¨í•œë‹¤. ì„œë¡ ì´ ê¸¸ì—ˆë‹¤. ê²°êµ­ Jupyter POD ë¥¼ ê¸°ë™í•˜ë©´ $HOME ë””ë ‰í† ë¦¬ì— .ipython í´ë”ê°€ ìƒì„±ëœë‹¤. êµ¬ì¡°ë¥¼ ì‚´í”¼ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345678910111213root@jupyter-3:~/.ipython# tree ..â”œâ”€â”€ extensionsâ”œâ”€â”€ nbextensionsâ””â”€â”€ profile_default â”œâ”€â”€ db â”œâ”€â”€ history.sqlite â”œâ”€â”€ jupyter.log â”œâ”€â”€ log â”œâ”€â”€ pid â”œâ”€â”€ security â””â”€â”€ startup â””â”€â”€ README ìš°ë¦¬ê°€ ì£¼ì˜ìˆê²Œ ë³¼ ë””ë ‰í† ë¦¬ëŠ” startup í´ë”ë‹¤. ì´ë¦„ì—ì„œ ë³´ì´ë“¯, startup í´ë”ì˜ README ë¥¼ ì—´ì–´ë³´ë©´ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. Notebook ì„ ì‹¤í–‰í•˜ê¸° ì „ í™˜ê²½ êµ¬ì„±ì„ ë„ì™€ì£¼ëŠ” ê³µê°„ì´ë‹¤. ì´ í´ë”ì— ë‹¤ìŒê³¼ ê°™ì´ log_history.py ë¥¼ ì‘ì„±í•œë‹¤. 1234567891011121314151617181920212223242526import atexitimport osimport datetimeip = get_ipython()LIMIT = 100000 # limit the size of the historydef save_history(): \"\"\"save the IPython history to a plaintext file\"\"\" histfile = os.path.join(ip.profile_dir.location, \"jupyter.log\") print(\"[INFO] Saving plaintext history to %s\" % histfile) lines = [] lines.extend('[&#123;0&#125;]\\n&#123;1&#125;'.format(record[2][1], record[2][0]) + '\\n' for record in ip.history_manager.get_range()) # get previous lines # this is only necessary because we truncate the history, # otherwise we chould just open with mode='a' if os.path.exists(histfile): with open(histfile, 'a') as f: #lines = f.readlines() f.writelines(lines) else: with open(histfile, 'w') as f: f.writelines(lines)# do the save at exitatexit.register(save_history) ì½”ë“œë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´ log íŒŒì¼ì´ ìˆë‹¤ë©´ íŒŒì¼ì„ ìˆ˜ì •ëª¨ë“œë¡œ ì—´ì–´ Notebook ì•ˆì—ì„œ ì‹¤í–‰í•œ Python ì‹¤í–‰ ì´ë ¥ì„ ì¶”ê°€í•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ ì²˜ìŒìœ¼ë¡œ ìƒì„±í•œ ë¡œê·¸ë¥¼ ì¶”ê°€í•œë‹¤. ì—¬ê¸°ì„œ ì£¼ì˜ê¹Šê²Œ ë³¼ ê³³ì€ history_manager ì˜¤ë¸Œì íŠ¸ì´ë‹¤. Jupyter Notebook ì˜ History ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ë¡œ ë‹¤ìŒ ì±•í„°ì—ì„œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³  ìˆ˜ì •í•œ ë¶€ë¶„ì„ ì„¤ëª…í•˜ê² ë‹¤. Customize IPython/core/history.pypython ì„¤ì¹˜ ë””ë ‰í† ë¦¬ ë‚´ site-package ì—ëŠ” IPython ì´ ì¡´ì¬í•  ê²ƒì´ë‹¤. $PY_PKG_DIR/IPython/core ì— history.py ë¥¼ ìˆ˜ì •í•  ê²ƒì´ë‹¤. ìˆ˜ì •ì´ ì™œ í•„ìš”í•œê°€? ê¸°ë³¸ì ìœ¼ë¡œ Jupyter Notebook ì€ sqlite3 DBì— history ë¥¼ ë‚¨ê¸°ì§€ë§Œ Timestamp ëŠ” ì—†ë‹¤. ì´ë¥¼ ìœ„í•´ ìˆ˜ì •í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— history.py ë¥¼ ì—´ì–´ def store_inputs í•¨ìˆ˜ë¥¼ ì°¾ì•„ë³¸ë‹¤. ê·¸ ë‹¤ìŒì€ ì‰½ë‹¤, í•œ ì¤„ë§Œ ì¶”ê°€í•˜ë©´ ëœë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253def store_inputs(self, line_num, source, source_raw=None): \"\"\"Store source and raw input in history and create input cache variables ``_i*``. Parameters ---------- line_num : int The prompt number of this input. source : str Python input. source_raw : str, optional If given, this is the raw input without any IPython transformations applied to it. If not given, ``source`` is used. \"\"\" if source_raw is None: source_raw = source source = source.rstrip('\\n') source_raw = source_raw.rstrip('\\n') # do not store exit/quit commands if self._exit_re.match(source_raw.strip()): return self.input_hist_parsed.append(source) ############# ###append self.input_hist_raw.append([source_raw, datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')]) ###append-end ############# with self.db_input_cache_lock: self.db_input_cache.append((line_num, source, source_raw)) # Trigger to flush cache and write to DB. if len(self.db_input_cache) &gt;= self.db_cache_size: self.save_flag.set() # update the auto _i variables self._iii = self._ii self._ii = self._i self._i = self._i00 self._i00 = source_raw # hackish access to user namespace to create _i1,_i2... dynamically new_i = '_i%s' % line_num to_main = &#123;'_i': self._i, '_ii': self._ii, '_iii': self._iii, new_i : self._i00 &#125; if self.shell is not None: self.shell.push(to_main, interactive=False) ì´ í•¨ìˆ˜ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´, Jupyter Notebook ì—ì„œ ë°œìƒí•œ python history input ì„ sqlite3 DB ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë‹¤. ì¶”ê°€ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.self.input_hist_raw.append([source_raw, datetime.datetime.now().strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)]) ì´ í•¨ìˆ˜ë¥¼ ì¶”ì í•œ ê³¼ì •ì€ history_manager.get_range() ê°€ generator í˜•íƒœë¡œ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì— yield ê²€ìƒ‰ì„ í•´ë³´ë‹ˆ ë‹´ë‹¹ í•¨ìˆ˜ëŠ” _get_range_session ì„ì„ í™•ì¸í–ˆë‹¤. ì²« ì¤„ input_hist_raw ê°€ history ì˜ raw data ë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì„ í™•ì¸í•˜ê³  input_hist_raw ê²€ìƒ‰í•˜ì—¬ store_inputs í•¨ìˆ˜ë¥¼ trace í•˜ì˜€ë‹¤. Resultê°„ë‹¨í•œ Notebook ì„ ìƒì„±í•˜ê³  log íŒŒì¼ì„ í™•ì¸í•´ë³¸ë‹¤. log ê²½ë¡œëŠ” $HOME/.ipython/profile-default ê²½ë¡œì´ë‹¤. (log_history.py ì—ì„œ ìˆ˜ì • ê°€ëŠ¥) 1234567891011121314151617181920212223242526272829303132$ cat jupyter.log[2020-05-28 08:43:46]print(1)[2020-05-28 08:43:47]def sum(a, b): # 3ê³¼ 5ê°€ ê°ê° ë§¤ê°œë³€ìˆ˜ aì™€ bì— í• ë‹¹ëœë‹¤. result = a + b # ë³€ìˆ˜ resultì—ëŠ” ë§¤ê°œë³€ìˆ˜ aì™€ bì˜ í•©ì´ í• ë‹¹ë˜ë¯€ë¡œ ì´ ê²½ìš°ì—ëŠ” 3ê³¼ 5ì˜ í•©ì¸ 8ì´ í• ë‹¹ëœë‹¤. return result # 8ì„ í•¨ìˆ˜ ë°”ê¹¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤.[2020-05-28 08:43:47]sum(10,20)[2020-05-28 08:43:47]print(2)[2020-05-28 08:43:47]def say_hello(func): # 1 def wrapper2(*args, **kwargs): # 8 print('Hello') # 11 return func(*args, **kwargs) # 12 return wrapper2 # 9def say_hi(func): # 2 def wrapper1(*args, **kwargs): # 5 print('Hi') # 13 return func(*args, **kwargs) # 14 return wrapper1 # 6@say_hello # 7@say_hi # 4def introduce(name): # 3 print(f'My name is &#123;name&#125;!') # 15introduce('Jaejun') # 10 ì¶”ê°€ì ìœ¼ë¡œ ê³ ë ¤í•  ì‚¬í•­ì´ ìˆë‹¤. log íŒŒì¼ ê´€ë¦¬ì¸ë° ìµœëŒ€ í¬ê¸°ë¥¼ ì§€ì •í•´ì„œ ìš©ëŸ‰ì´ ì»¤ì§€ë©´ ì´ì „ History ë¥¼ ì‚­ì œí•˜ëŠ” ë°©ì•ˆì„ ë§ˆë ¨í•˜ê³  ìˆë‹¤. ì¡°ë§Œê°„ Dockerfile ë„ ì™„ì„±ë˜ë©´ ì¶”ê°€í•  ì˜ˆì •ì´ë‹¤. Reference https://anaconda.org/conda-forge/python-json-logger https://velog.io/@log327 https://stackoverflow.com/questions/16858724/how-to-log-ipython-history-to-text-file made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Hadoop] CDH(ClouDera Hadoop) Client ì„¤ì •","slug":"hadoop-client","date":"2020-05-14T15:00:00.000Z","updated":"2020-09-26T13:43:28.431Z","comments":true,"path":"hadoop-client/","link":"","permalink":"https://jx2lee.github.io/hadoop-client/","excerpt":"Python ì„ ì´ìš©í•´ CDH ì—°ë™í•˜ëŠ” ê³¼ì •ì—ì„œ Hadoop Client ì„¤ì • ë°©ë²•ì— ëŒ€í•´ ì •ë¦¬í•œë‹¤.","text":"Python ì„ ì´ìš©í•´ CDH ì—°ë™í•˜ëŠ” ê³¼ì •ì—ì„œ Hadoop Client ì„¤ì • ë°©ë²•ì— ëŒ€í•´ ì •ë¦¬í•œë‹¤. &#x2728; Contents: Bianry Download CDH Hadoop Config Client ì••ì¶• í•´ì œ Config ì ìš© /etc/hosts ì ìš© ENV Bianry Download wget ì„ ì´ìš©í•´ CDH hadoop 3 ë²„ì ¼ì„ ë‹¤ìš´ $ wget https://archive.apache.org/dist/hadoop/core/hadoop-3.0.0/hadoop-3.0.0.tar.gz CDH Hadoop Config CDH ì›¹ì—ì„œ hadoop config ì„ ë‹¤ìš´ë¡œë“œ core-site.xml hdfs-site.xml yarn-site.xml (Yarn êµ¬ì„± ì‹œ) Client ì••ì¶• í•´ì œ íŠ¹ì • directory ì— ì••ì¶• í•´ì œ $ tar -xvf hadoop-3.0.0.tar.gz &amp;&amp; mv hadoop-3.0.0 hadoop Config ì ìš© $HADOOP_HOME/etc/hadoop ì— ìœ„ì— ì¤€ë¹„í•œ CDH config ì„ copy &amp; paste $ cp *-site.xml $HADOOP_HOME/etc/hadoop /etc/hosts ì ìš© Client ì„œë²„ì˜ IP hostname ì— ë§ˆì°¬ê°€ì§€ë¡œ í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì •ë³´ë¥¼ ì‘ì„± example123456#/etc/hosts......192.168.179.181 chd1192.168.179.182 chd2192.168.179.183 chd3 $ touch /etc/hosts ë¡œ íŒŒì¼ ì ìš© ENV1234export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64export HADOOP_HOME=/home/jovyan/hadoopexport HADOOP_CMD=/home/jovyan/hadoop/bin/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$HADOOP_CMD made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Python] Jupyter Notebook ì„ ì´ìš©í•œ Hadoop ë° Database ì—°ë™","slug":"python-connection_test","date":"2020-05-14T15:00:00.000Z","updated":"2020-09-26T13:49:34.429Z","comments":true,"path":"python-connection_test/","link":"","permalink":"https://jx2lee.github.io/python-connection_test/","excerpt":"Python ì„ ì´ìš©í•œ Hadoop ë° Database ì—°ë™ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.","text":"Python ì„ ì´ìš©í•œ Hadoop ë° Database ì—°ë™ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. í™˜ê²½êµ¬ì„±: Hadoop Cluster (CDH 6.3.2) cdh1: 192.168.179.181 cdh2: 192.168.179.182 cdh3: 192.168.179.183 (master) Jupyter Notebook docker custom image (python version: 3.7) kubernetes deployment ë°°í¬ namespace: nps ì»¨í…Œì´ë„ˆ í™˜ê²½ : Ubuntu 18.04.4 LTS &#x2728; Contents: HDFS Hive HBase Impala Spark Sybase Oracle HDFSì„¤ì¹˜ íŒ¨í‚¤ì§€LinuxPython hdfs Requirement already satisfied: docopt in /opt/conda/lib/python3.8/site-packages (from hdfs) (0.6.2) Requirement already satisfied: six&gt;=1.9.0 in /opt/conda/lib/python3.8/site-packages (from hdfs) (1.14.0) Requirement already satisfied: requests&gt;=2.7.0 in /opt/conda/lib/python3.8/site-packages (from hdfs) (2.23.0) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.8/site-packages (from - requests&gt;=2.7.0-&gt;hdfs) (1.25.9) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (2.9) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (2020.4.5.1) Code123456789101112131415161718192021222324252627282930313233343536373839import pandas as pdfrom hdfs import InsecureClient# Connectionclient_hdfs = InsecureClient('http://192.168.179.183:9870', user='hdfs')## Createcreate_df = pd.DataFrame([1000, 2000, 3000, 4000])with client_hdfs.write('/tmp/t2.csv', encoding = 'utf-8') as writer: create_df.to_csv(writer)print(client_hdfs.list('/tmp'))## Readclient_hdfs.list('/tmp')with client_hdfs.read('/tmp/test.csv', encoding = 'utf-8') as reader: df = pd.read_csv(reader) print(df)## Updatewith client_hdfs.read('/tmp/t2.csv', encoding = 'utf-8') as reader: df = pd.read_csv(reader)df.loc[4] = [4,5000]client_hdfs.delete('/tmp/t2.csv')with client_hdfs.write('/tmp/t2.csv', encoding = 'utf-8') as writer: df.to_csv(writer) print(df)## Deleteclient_hdfs.delete('/tmp/t2.csv')'t2.csv' in client_hdfs.list('/tmp') Ref https://pypi.org/project/hdfs/ https://hdfscli.readthedocs.io/en/latest/api.html Hiveì„¤ì¹˜ íŒ¨í‚¤ì§€Linux libsasl2-dev libsasl2-modules Python pyhive Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from pyhive) (0.18.2) Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from pyhive) (2.8.1) Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil-&gt;pyhive) (1.14.0) thrift sasl thrift_sasl Requirement already satisfied: thrift&gt;=0.10.0 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (0.13.0) Requirement already satisfied: sasl&gt;=0.2.1 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (0.2.1) Requirement already satisfied: six&gt;=1.13.0 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (1.14.0) Code12345678910111213141516171819202122232425262728293031323334import pyhive.hive as hiveconn = hive.Connection(host='cdh3', port=10000, username='root', password='tmaxtmax', database='default', auth='CUSTOM')# Createcur = conn.cursor()sql = \"CREATE TABLE `default`.`create_test` ( `field_1` bigint , `field_2` string , `field_3` string , `field_4` string , `field_5` string , `field_6` bigint , `field_7` string , `field_8` double , `field_9` string , `field_10` string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '|' COLLECTION ITEMS TERMINATED BY '' MAP KEYS TERMINATED BY '' STORED AS TextFile\"cur.execute(sql)cur = conn.cursor()cur.execute('select * from create_test')res = cur.fetchall()print(res)# Readcur.execute('select count(*) from create_test')res = cur.fetchall()print(res)# Updatecur.execute('alter table create_test rename to create_test_rev')cur.execute('describe create_test_rev')res = cur.fetchall()print(res)# Deletecur.execute('drop table create_test_rev')cur.execute('show tables')res = cur.fetchall()print(res) Ref https://sungwookkang.com/m/1367 HBase Hbase ì„œë²„ ë‚´ Thrift ê°€ ë™ì‘í•˜ê³  ìˆì–´ì•¼í•¨ í´ëŸ¬ìŠ¤í„° ë‚´ ì•„ë¬´ ë…¸ë“œì—ì„œ $ hbase thrift &amp; ëª…ë ¹ì–´ë¡œ thrift ì‹¤í–‰ backgroud êµ¬ë™ ì„¤ì¹˜ íŒ¨í‚¤ì§€LinuxPython happybase Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from happybase) (1.14.0) Requirement already satisfied: thriftpy2&gt;=0.4 in /opt/conda/lib/python3.8/site-packages (from happybase) (0.4.11) Requirement already satisfied: ply&lt;4.0,&gt;=3.4 in /opt/conda/lib/python3.8/site-packages (from thriftpy2&gt;=0.4-&gt;happybase) (3.11) Code1234567891011121314151617181920212223242526272829import happybase# Connectionconn = happybase.Connection('192.168.179.183', 9090, autoconnect=True)## Create conn.create_table('test',&#123;'cf':&#123;&#125;&#125;)conn.tables()## Readtbl = conn.table('test')for key, data in tbl.scan(): print(key, data)## Updatetable = conn.table('test')table.put('row-key',&#123;'cf:col1':'value1','cf:col2':'value2'&#125;)row = dict(table.row('row-key'))print(row)## Deleteconn.delete_table('test', disable=True)conn.tables() Ref https://creatorw.tistory.com/entry/Hbase%EC%99%80-python-%EC%97%B0%EA%B2%B0-%ED%95%98%EA%B8%B0%EA%B8%B0 Impala connection ì‹œ host ëŠ” ë§ˆìŠ¤í„°ë¡œ ì‘ì„±í•˜ë‹ˆ connection ì´ ë˜ì§€ ì•ŠìŒ ë§ˆìŠ¤í„° ì™¸ ë…¸ë“œ ipë¡œ host ì„¤ì • í•„ìš” ì„¤ì¹˜ íŒ¨í‚¤ì§€LinuxPython impyla==0.15a1 *(ê¼­ 0.15a1 ë²„ì ¼ ì„¤ì¹˜ í•„ìš”) Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (1.14.0) Requirement already satisfied: bitarray in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (1.2.1) Requirement already satisfied: thrift&gt;=0.9.3 in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (0.13.0) Requirement already satisfied: thriftpy2==0.4.0; python_version &gt;= â€œ3.0â€ in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) ( - 0.4.0) Requirement already satisfied: ply&lt;4.0,&gt;=3.4 in /opt/conda/lib/python3.8/site-packages (from thriftpy2==0.4.0; python_version &gt;= - â€œ3.0â€-&gt;impyla==0.15a1) (3.11) Code1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from impala.dbapi import connect# Connectionconn = connect(host='192.168.179.181', port=21050)cursor = conn.cursor()cursor.get_databases()drop = \"DROP TABLE IF EXISTS default.tab;\"create = \"\"\"CREATE EXTERNAL TABLE default.tab(id INT,col_1 BOOLEAN,col_2 DOUBLE,col_3 TIMESTAMP)ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\"\"\"## Createcursor.execute(create)cursor.execute('select count(*) from default.tab')res = cursor.fetchall()print(res)## Readcursor.execute('select * from tab')res = cursor.fetchall()print(res)## Updatecursor.execute('alter table default.tab rename to default.tab_rev')cursor.execute('describe default.tab_rev')res = cursor.fetchall()print(res)## Deletecursor.execute('drop table default.tab_rev')cursor.execute('show tables')res = cursor.fetchall()print(res) Ref https://euriion.com/?p=411856 https://m.blog.naver.com/PostView.nhn?blogId=hancury&amp;logNo=220755129588&amp;proxyReferer=https:%2F%2Fwww.google.com%2F Spark python 3.8 íŒ¨í‚¤ì§€ ë¯¸ì§€ì› (pyspark) python 3.7 í™˜ê²½ì—ì„œë§Œ ì§„í–‰ ì»¨í…Œì´ë„ˆ ë‚´ hadoop client ë° spark ì„¤ì¹˜ í•„ìš” hadoop: $ wget https://archive.apache.org/dist/hadoop/core/hadoop-3.0.0/hadoop-3.0.0.tar.gz cdh í´ë¼ì´ì–¸íŠ¸ êµ¬ì„±íŒŒì¼ ì¤‘ core-site.xml, hdfs-site.xml, yarn-site.xml ì„ $HADOOP_HOME/etc/hadoop ìœ¼ë¡œ copy&amp;paste spark: spark-2.4.0-bin-hadoop2.7.tgz .bashrc12345678export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64export HADOOP_HOME=/home/jovyan/hadoopexport HADOOP_CMD=/home/jovyan/hadoop/bin/hadoopexport HADOOP_CONF_DIR=/home/jovyan/hadoop/etc/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$HADOOP_CMDexport SPARK_HOME=/home/jovyan/sparkexport PATH=$PATH:$SPARK_HOME/bin CDH spark êµ¬ì„± master: yarn deploy mode: client ì„¤ì¹˜ íŒ¨í‚¤ì§€Linux default-jdk Python pyspark Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.8/site-packages (from pyspark) (0.10.7) Ref https://www.sicara.ai/blog/2017-05-02-get-started-pyspark-jupyter-notebook-3-minutes https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark_ipython.html https://github.com/mike-wendt/cloudera-jupyter-notebook-spark ìœ„ì™€ ê°™ì€ í™˜ê²½ì—ì„œ Spark ì—°ë™ì€ ì‚¬ì‹¤ ì–´ë µë‹¤. ì™œëƒí•˜ë©´ CDH ë‚´ Yarn ì—ì„œ ì»¨í…Œì´ë„ˆ í˜¸ìŠ¤íŠ¸ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´ëŠ” CDH Yarn config ë¥¼ ìˆ˜ì •í•´ì„œ, ì»¨í…Œì´ë„ˆ í˜¸ìŠ¤íŠ¸ëª…ì„ ë°”ë¼ë³¼ ìˆ˜ ìˆê²Œë” ë³€ê²½í•˜ë©´ yarn-client ëª¨ë“œë¡œ ì—°ë™ì´ ê°€ëŠ¥í•˜ë‹¤. ì•„ë‹ˆë©´ Livy ë¼ëŠ” íŒ¨í‚¤ì§€ë¥¼ CDH í´ëŸ¬ìŠ¤í„°ì— ì„¤ì¹˜í•˜ì—¬ API ë¡œ ì—°ë™í•˜ëŠ” ë°©ë²•ì´ ì¡´ì¬í•œë‹¤. (êµ¬ê¸€ë§ ì¶”ì²œ) Sybase jar file jconn3.jar (jdk ë²„ì ¼ë³„ë¡œ ìƒì´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ jconn4.jar ì¤€ë¹„ í•„ìš”) ì„¤ì¹˜ íŒ¨í‚¤ì§€Linux default-jdk Python jpype1==0.6.3 Jaydebeapi Code12345678910111213141516171819202122232425262728293031import jpypeimport jaydebeapi# Connectionconn = jaydebeapi.connect('com.sybase.jdbc3.jdbc.SybDriver', 'jdbc:sybase:Tds:192.168.179.169:2638', &#123;'user': 'DBA', 'password': 'sql'&#125; ,['/home/jovyan/jconn3.jar'])c1 = conn.cursor()## Createc1.execute('create table aa(a int)')c1.execute('select * from aa')print(c1.fetchall())## Readc1.execute('select * from aa')print(c1.fetchall())## Updatec1.execute('insert into aa (a) values (1000)')c1.execute('select * from aa')print(c1.fetchall())## Deletec1.execute('drop table aa')c1.execute('select * from aa')print(c1.fetchall()) Ref https://stackoverflow.com/questions/3319788/what-is-the-best-way-to-connect-to-a-sybase-database-from-python Oracle jar file ojdbc6.jar ì„¤ì¹˜ íŒ¨í‚¤ì§€Linux default-jdk Python jpype1==0.6.3 Jaydebeapi Code1234567891011121314151617181920212223242526272829303132import jpypeimport jaydebeapi# Connection#jpype.startJVM(jpype.getDefaultJVMPath(), classpath='/home/jovyan/ojdbc6.jar', convertStrings=True)conn = jaydebeapi.connect('oracle.jdbc.driver.OracleDriver', 'jdbc:oracle:thin:scott/tiger@192.168.179.167:1521:ORCL1', jars='/home/jovyan/ojdbc6.jar')c1 = conn.cursor()## Createc1.execute('create table bb(a number)')c1.execute('select * from bb')res = c1.fetchone()print(res)## Readc1.execute('select * from emp')res = c1.fetchone()print(res)## Updatec1.execute('insert into bb values (1000)')c1.execute('select * from bb')print(c1.fetchall())## Deletec1.execute('drop table scott.bb') Ref https://m.blog.naver.com/PostView.nhn?blogId=axzswq&amp;logNo=221533592504&amp;proxyReferer=https:%2F%2Fwww.google.com%2F http://blog.naver.com/PostView.nhn?blogId=delfood&amp;logNo=221666021769&amp;categoryNo=33&amp;parentCategoryNo=0&amp;viewDate=&amp;currentPage=1&amp;postListTopCurrentPage=1&amp;from=search made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[]},{"title":"[Cloud] Kubeflow ","slug":"cloud-kubeflow_katib","date":"2020-05-03T15:00:00.000Z","updated":"2020-10-29T14:38:28.109Z","comments":true,"path":"cloud-kubeflow_katib/","link":"","permalink":"https://jx2lee.github.io/cloud-kubeflow_katib/","excerpt":"Kubeflow ì±…ì„ ê³µë¶€í•˜ë©° ë‚´ìš©ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤. ì´ë²ˆ íŒŒíŠ¸ëŠ” Katib ì´ë‹¤.","text":"Kubeflow ì±…ì„ ê³µë¶€í•˜ë©° ë‚´ìš©ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤. ì´ë²ˆ íŒŒíŠ¸ëŠ” Katib ì´ë‹¤. KatibKubeflow ì„¤ì¹˜ ì‹œ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë¡œ, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì™€ ë‰´ëŸ´ ì•„í‚¤í…ì²˜ íƒìƒ‰(NAS)ìœ¼ë¡œ êµ¬ì„±í•œë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì™€ ë‰´ëŸ´ ì•„í‚¤í…ì²˜ íƒìƒ‰(NAS)ì— ëŒ€í•œ ê°œë…ì€ ì´ë²ˆ ê¸€ì—ì„œ ë‹¤ë£¨ì§€ ì•ŠëŠ”ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¸ê³  https://jx2lee.github.io/2019/07/02/ml-introduction_to_grid_search/ Hyperparameters in Machine /Deep Learning ë‰´ëŸ´ ì•„í‚¤í…ì³ íƒìƒ‰(NAS) AutoMLì„ ì´ìš©í•œ Architecture Search ì†Œê°œ ë° NASNet ë…¼ë¬¸ ë¦¬ë·° Network Architecture Search - Samsung Software Membership ArchitectureKatib ì€ í¬ê²Œ 4ê°€ì§€ ê°œë…ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œë‹¤. Experiment : í•˜ë‚˜ì˜ ì‹¤í–‰ë‹¨ìœ„ë¡œ Job ê°œë…ìœ¼ë¡œ ìƒê°í•˜ë©´ ëœë‹¤. K8s ì»¤ìŠ¤í…€ ë¦¬ì†ŒìŠ¤ë¡œ Trial ë¥¼ ì‹¤í–‰í•˜ëŠ” ì—­í• ì„ í•˜ë©° Experiment ëŠ” 5ê°œ ì˜ì—­ìœ¼ë¡œ ë‚˜ë‰œë‹¤. Trial Count : ì‹¤í–‰ íšŸìˆ˜ (ë³‘ë ¬) Trial Template : Trial íŒŒë“œ í…œí”Œë¦¿ Objective : ëª©í‘œ ìˆ˜ì¹˜ (ìµœê³³ê°’ ë˜ëŠ” ìµœì†Ÿê°’ ì„¤ì •) Search Parameter : íƒìƒ‰í•˜ê³ ì í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì˜ range Search Algorithm : íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜ Trial : ìµœì í™” ê³¼ì •ì˜ ë°˜ë³µ ë‹¨ìœ„. Experimentì˜ Trial Count ê°’ ë§Œí¼ Trialì„ ìƒì„±í•˜ê³  ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰. í•˜ë‚˜ì˜ Trial ì—ì„œ í•˜ë‚˜ì˜ worker jobì„ ì‹¤í–‰, Trial ë„ K8s ì»¤ìŠ¤í…€ ë¦¬ì†ŒìŠ¤ Suggestion : Search Algorithm ìœ¼ë¡œ ìƒì„±í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì˜ ëª¨ìŒ. í•˜ë‚˜ì˜ Experiment ì—ì„œ í•˜ë‚˜ì˜ Suggestion ì„ ìƒì„± Worker job : íŒŒë¼ë¯¸í„°ì™€ Suggestion ê°’ì„ ì´ìš©í•´ Trial, ê°ê°ì˜ ê°’ì„ í‰ê°€í•˜ê³  ê³„ì‚¬í•˜ëŠ” í”„ë¡œì„¸ìŠ¤. ì‹¤ì œë¡œ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©° K8s Job ê³¼ TFJob, PyTorch ì„ ì‚¬ìš© Experiment exampleMNIST ì˜ˆì œ í…œí”Œë¦¿ì„ í•¨ê»˜ ë³´ë©° ìœ„ì—ì„œ ì„¤ëª…í•œ êµ¬ì¡°ì™€ ë¹„êµí•˜ë©° ì‚´í´ë³¸ë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455apiVersion: \"kubeflow.org/v1alpha3\"kind: Experimentmetadata: namespace: kubeflow labels: controller-tools.k8s.io: \"1.0\" name: handson-experiment-1spec: parallelTrialCount: 5 # ë³‘ë ¬ë¡œ ì‹¤í–‰í•  Trial ìˆ˜ë¡œ, ë¦¬ì†ŒìŠ¤ í—ˆìš©í•œë„ê¹Œì§€ ë™ì‹œì— 5ê°œ Trial ì„ ì‹¤í–‰í•œë‹¤. maxTrialCount: 30 # ìµœëŒ€ë¡œ ì‹¤í–‰í•  Trial ìˆ˜ë¡œ ì´ 30ê°œ. parallelTrialCount ê°€ 5 ì´ë¯€ë¡œ ë³‘ë ¬ë¡œ 5ê°œ Trial ì„ ì‹¤í–‰í•˜ê³  6ë²ˆ ë°˜ë³µ maxFailedTrialCount: 3 # ì‹¤íŒ¨ í•œë„ ìˆ˜ë¡œ Trial ì´ 3ë²ˆ ì‹¤íŒ¨í•˜ë©´ Experiment ë¥¼ ì¤‘ì§€í•œë‹¤. objective: # ìˆ˜ì§‘ ëŒ€ìƒì˜ ë©”íŠ¸ë¦­ ì„¤ì • ë‹¨ê³„ type: maximize # ìµœëŒ“ê°’ ë˜ëŠ” ìµœì†Ÿê°’ ì„¤ì • (ë³¸ ì˜ˆì œëŠ” maximize, ìµœëŒ“ê°’) goal: 0.99 # ëª©í‘œ ìˆ˜ì¹˜ ì„¤ì • objectiveMetricName: validation-accuracy # ìˆ˜ì§‘í•  ë©”íŠ¸ë¦­ name, validation-accuracy ë¡œ ì„¤ì • additionalMetricNames: # ì´ì™¸ ìˆ˜ì§‘í•  ë©”íŠ¸ë¦­ì„ ì •ì˜ (accuracy, loss, validation-loss 3ê°œë¥¼ ì¶”ê°€ ìˆ˜ì§‘í•  ì˜ˆì •) - accuracy - loss - Validation-loss algorithm: # Search Algorithm ì„¤ì • (ê·¸ë¦¬ë“œ, ëœë¤, í•˜ì´í¼ë°´ë“œ, ë² ì´ì§€ì•ˆìµœì í™” ì„ íƒ ê°€ëŠ¥) algorithmName: random trialTemplate: # Trial í…œí”Œë¦¿ ì •ì˜ goTemplate: rawTemplate: |- apiVersion: batch/v1 kind: Job metadata: name: &#123;&#123;.Trial&#125;&#125; namespace: &#123;&#123;.NameSpace&#125;&#125; spec: template: spec: containers: - name: &#123;&#123;.Trial&#125;&#125; image: brightfly/katib-job:handson command: - \"python\" - \"/app/katib_keras_mnist.py\" &#123;&#123;- with .HyperParameters&#125;&#125; # ì„¤ì • íŒŒë¼ë¯¸í„°ì˜ iteration êµ¬ë¬¸. .Name=.Value í˜•íƒœë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ &#123;&#123;- range .&#125;&#125; - \"&#123;&#123;.Name&#125;&#125;=&#123;&#123;.Value&#125;&#125;\" &#123;&#123;- end&#125;&#125; &#123;&#123;- end&#125;&#125; restartPolicy: Never parameters: # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë ¥ê°’ìœ¼ë¡œ learning rate ì™€ dropout ì„¤ì • - name: --learning_rate parameterType: double feasibleSpace: # ê° í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ range ì„¤ì • min: \"0.01\" max: \"0.03\" - name: --dropout_rate parameterType: double feasibleSpace: min: \"0.1\" max: \"0.9\" ë³¸ í…œí”Œë¦¿ìœ¼ë¡œ Experiment ë¥¼ ì‹¤í–‰í•˜ë©´ python /app/katib_keras_mnist.py -learning_rate=0.012--dropout_rate=0.381 ì™€ ê°™ì´ ì‹¤í–‰í•œë‹¤. Katib ComponentKatib ì„ êµ¬ì„±í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë¡œëŠ” ì´ 4ê°œê°€ ì¡´ì¬í•œë‹¤. ê° ì»´í¬ë„ŒíŠ¸ëŠ” kubectl ë¡œ ì¡°íšŒ ê°€ëŠ¥í•˜ë©° K8sì˜ Deployment ë¡œ ê´€ë¦¬í•œë‹¤. katib-manager : GRPC API server katib-db : Katib ì˜ ë°±ì—”ë“œ ì €ì¥ì†Œ, mysql katib-ui : Katib UI katib-controller : katib CRDì˜ ì»¨íŠ¸ë¡¤ëŸ¬ Katib UIWeb UIë¥¼ ì œê³µí•˜ëŠ”ë° í¬ê²Œ Hyperparameter Tuning ê³¼ NAS 2ê°œ ë©”ë‰´ê°€ ì¡´ì¬í•œë‹¤. Hyperparameter Tuning ì—ì„œëŠ” ì§ì ‘ YAML ì„ ì‘ì„±í•˜ê±°ë‚˜ ë§ˆìš°ìŠ¤ì™€ í‚¤ë³´ë“œë¡œ ê°’ì„ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” í˜ì´ì§€ë¥¼ ì œê³µí•œë‹¤. Katib Command-line interfaceUI ì™¸ì— ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ”ë°, kfctl ë˜ëŠ” kubectl ì„ ì´ìš©í•´ Experiment ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ë‹¨, Experiment ë¦¬ì†ŒìŠ¤ ê¶Œí•œì´ ì¡´ì¬í•´ì•¼í•œë‹¤. kubectl apply -f mnist_experiment_random.yaml 123456789[root@master my-kubeflow]# kubectl get pod -n kubeflowNAME READY STATUS RESTARTS AGEadmission-webhook-bootstrap-stateful-set-0 1/1 Running 1 26dadmission-webhook-deployment-68c6dd4cc5-sb6hq 1/1 Running 0 6d23happlication-controller-stateful-set-0 1/1 Running 1 26dargo-ui-78bf45b698-r5zhr 1/1 Running 0 26dcentraldashboard-6957f8bcbc-6nktd 1/1 Running 1 26dhandson-experiment-1-random-57698b477b-dzmwm 1/1 Running 0 98s... mnist_experimnet_random.yaml : (https://github.com/mojokb/handson-kubeflow/blob/master/katib/mnist_experiment_random.yaml) Reference ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì´ ì²˜ìŒì´ë¼ë©´! ì¿ ë¸Œí”Œë¡œìš°! Kubeflow.org made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubeflow","slug":"Kubeflow","permalink":"https://jx2lee.github.io/tags/Kubeflow/"}]},{"title":"[Cloud] Kubeflow ","slug":"cloud-kubeflow_fairing","date":"2020-04-27T15:00:00.000Z","updated":"2020-10-29T14:38:26.422Z","comments":true,"path":"cloud-kubeflow_fairing/","link":"","permalink":"https://jx2lee.github.io/cloud-kubeflow_fairing/","excerpt":"Kubeflow ì±…ì„ ê³µë¶€í•˜ë©° ë‚´ìš©ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤. ì´ë²ˆ íŒŒíŠ¸ëŠ” Faring ì´ë‹¤.","text":"Kubeflow ì±…ì„ ê³µë¶€í•˜ë©° ë‚´ìš©ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤. ì´ë²ˆ íŒŒíŠ¸ëŠ” Faring ì´ë‹¤. FairingKubeflow í™˜ê²½ì—ì„œ ML ëª¨ë¸ì„ ì†ì‰½ê²Œ í•™ìŠµ-ë°°í¬í•  ìˆ˜ ìˆëŠ” Python Package Architecture work flow python ìœ¼ë¡œ ì‘ì„±í•œ íŒŒì¼ì„ ë„ì»¤ ì´ë¯¸ì§€ë¡œ ë¹Œë“œ ë¹Œë“œëœ ì´ë¯¸ì§€ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ push ë°°í¬ ë¦¬ì†ŒìŠ¤ì— ë”°ë¼ k8s Job, TFJob, KFServing ë“±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ k8s API ì„œë²„ ìš”ì²­ ìœ„ work flow ëŠ” preprocessor, builder, deployer êµ¬ì¡°ë¡œ ì„¤ê³„ preprocessor : Python íŒŒì¼ì„ ë„ì»¤ ì´ë¯¸ì§€ë¡œ ë¹Œë“œí•  ìˆ˜ ìˆê²Œ íŒ¨í‚¤ì§€í™” builder : íŒ¨í‚¤ì§€ëœ íŒŒì¼ì„ ë„ì»¤ ì´ë¯¸ì§€í™” deployer : ìƒì„±í•œ ì´ë¯¸ì§€ ë°°í¬ Fairing ì€ Kubeflow ì„¤ì¹˜ í›„ ìƒì„±í•œ ë…¸íŠ¸ë¶ ì´ë¯¸ì§€ì—ëŠ” default ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ë”°ë¡œ ì„¤ì¹˜ë¥¼ í•˜ì§€ ì•Šì•„ë„ í…ŒìŠ¤íŠ¸ê°€ ê°€ëŠ¥í•˜ë‹¤. Faring ì˜ˆì œFairing ì˜ˆì œëŠ” Kubeflow ë…¸íŠ¸ë¶ ì„œë²„ì—ì„œ ì§„í–‰í•œë‹¤. ì•ì„œ ì†Œê°œí–ˆë“¯ì´ Fairing ì€ K8s ë¦¬ì†ŒìŠ¤ë¥¼ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— docker registry ì™€ kubeflow ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•˜ë‹¤. í…ŒìŠ¤íŠ¸ ê²°ê³¼, private docker registry ì— fairing ì´ë¯¸ì§€ë¥¼ push/pull í•  ë•Œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì¥ì•  í•´ê²°ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•„ docker hub ì˜ ê³µê°œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•  ì˜ˆì •ì´ë©°, ì±… ìˆœì„œì— ë”°ë¼ ì§„í–‰í•œë‹¤. fairing_config.ipynb1234567891011121314151617181920# in Jupyter Notebookimport kubeflow.fairing as fairingdocker_registry = \"jaejunlee\"fairing.config.set_builder( 'append', base_image='gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0', image_name='fairing-test', registry=docker_registry, push=True)fairing.config.set_deployer('job')def train(): hostname = tf.constant(os.environ['HOSTNAME']) sess = tf.Session() print('Hostname : ', sess.run(hostname).decode('utf-8'))remote_train = fairing.config.fn(train)remote_train() ìœ„ ì˜ˆì œëŠ” HOSTNAME í™˜ê²½ë³€ìˆ˜ë¥¼ ì¶œë ¥í•œë‹¤. gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0 ê¸°ë³¸ ì´ë¯¸ì§€ì— ìœ„ ì¶œë ¥í•¨ìˆ˜ë¥¼ ì…íŒ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ jaejunlee public registry ì— í‘¸ì‰¬í•˜ê³  fairing-job ì´ë€ ì´ë¦„ì˜ k8s job ì´ k8s ì— ì‹¤í–‰ì„ ìš”ì²­í•œë‹¤. ì‰½ê²Œ ë§í•´, ê¸°ë³¸ ì´ë¯¸ì§€ ìœ„ì— ë‹´ì•„ fairing ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  k8s ë¥¼ ì´ìš©í•´ ì •ì˜í•œ í•¨ìˆ˜ë¥¼ k8s ì—ì„œ ì‹¤í–‰í•œë‹¤. hub.docker.io ì— ì ‘ì†í•˜ì—¬ í™•ì¸í•˜ë©´ í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•  ë•Œ ë§ˆë‹¤ ì´ë¯¸ì§€ë¥¼ push í•œë‹¤. (set_builder ë¶€ë¶„ push=True ë¡œ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì´ë‹¤.) ì½”ë“œë¥¼ í†µí•´ Config í´ë˜ìŠ¤ëŠ” preprocessor, builder, deployer ì— ëŒ€ì‘í•˜ëŠ” setterë“¤ì„ ê°€ì§€ê³  ìˆë‹¤. ê°ê°ì˜ default ê°’ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. preprocessor : Notebook í™˜ê²½ì€ â€œnotebookâ€, else â€œpythonâ€ builder : â€œappendâ€ deployâ€ : job Fairing êµ¬ì¡° 3ê°œë¥¼ ì‚´í´ë³´ë„ë¡ í•œë‹¤. Preprocessor in Fairingpreprocessor ëŠ” ë„ì»¤ ì´ë¯¸ì§€ë¡œ íŒ¨í‚¤ì§€í™” í•  ëŒ€ìƒì„ ì„¤ì •í•˜ëŠ”ë°, íƒ€ì…ì€ ì´ 4ê°œì´ë‹¤. python : íŒŒì´ì¬ file íŒ¨í‚¤ì§€í™” ë„ì»¤ ì´ë¯¸ì§€ ë‚´ app/{íŒŒì¼ëª…}.py ë¡œ cmd ìƒì„± example123456789101112131415161718192021222324#!/usr/bin/env pythonimport os, timedef train(): print(\"Training...\") import tensorflow as tf x = tf.constant([1,2,3,4,5,6], shape=[2,3]) print(x) time.sleep(1)if __name__ == '__main__': if os.getenv('FAIRING_RUNTIME', None) is not None: # if else êµ¬ì¡°ë¥¼ í†µí•´ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ë©´ \bFAIRING_RUNTIME ë³€ìˆ˜ê°€ \b1 ë¡œ ë³€í™˜ëœë‹¤. ì¦‰, ì´ë¯¸ì§€ ìƒì„±í›„ì—ëŠ” train() ë§Œ ì‘ì—… train() else: from kubeflow import fairing DOCKER_REGISTRY = 'jaejunlee' file_name = os.path.basename(__file__) print(\"Executing &#123;&#125; remotely.\".format(file_name)) fairing.config.set_preprocessor('python', executable=file_name, input_files=[file_name]) fairing.config.set_builder( 'append', base_image='gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0', registry=DOCKER_REGISTRY, push=True) fairing.config.run() 123456789101112131415161718192021222324252627$ chmod +x fairing_preprocessor_python.py$ ./fairing_preprocessor_python.py[I 200428 09:36:11 config:134] Using preprocessor: &lt;kubeflow.fairing.preprocessors.base.BasePreProcessor object at 0x7f8b2fc1e278&gt;[I 200428 09:36:11 config:136] Using builder: &lt;kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f8b2fc1e2b0&gt;[I 200428 09:36:11 config:138] Using deployer: &lt;kubeflow.fairing.deployers.job.job.Job object at 0x7f8b2fc1e9b0&gt;[W 200428 09:36:11 append:50] Building image using Append builder...[I 200428 09:36:11 base:107] Creating docker context: /tmp/fairing_context_jvkk0mqm[I 200428 09:36:11 docker_creds_:234] Loading Docker credentials for repository 'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'[W 200428 09:36:13 append:54] Image successfully built in 1.9876068960002158s.[W 200428 09:36:13 append:94] Pushing image jaejunlee/fairing-job:13B00B9B...[I 200428 09:36:13 docker_creds_:234] Loading Docker credentials for repository 'jaejunlee/fairing-job:13B00B9B'[W 200428 09:36:15 append:81] Uploading jaejunlee/fairing-job:13B00B9B[I 200428 09:36:16 docker_session_:280] Layer sha256:823f4685c03b26a545ca41dcdca1e782ad5e52cf85bac03113edaa6aebdca1b3 exists, skipping......sha256:19f71f3a178549ee1bacd534f061e4b465d85c3378ecddb4dc716f1283aff2a8 pushed.[I 200428 09:36:22 docker_session_:334] Finished upload of: jaejunlee/fairing-job:13B00B9B[W 200428 09:36:22 append:99] Pushed image jaejunlee/fairing-job:13B00B9B in 9.045510983996792s.[W 200428 09:36:22 job:101] The job fairing-job-gm8hb launched.[W 200428 09:36:22 manager:296] Waiting for fairing-job-gm8hb-87z5h to start...[W 200428 09:36:22 manager:296] Waiting for fairing-job-gm8hb-87z5h to start...[W 200428 09:36:22 manager:296] Waiting for fairing-job-gm8hb-87z5h to start...[W 200428 09:36:23 manager:296] Waiting for fairing-job-gm8hb-87z5h to start...[I 200428 09:36:29 manager:302] Pod started running TrueTraining...Tensor(\"Const:0\", shape=(2, 3), dtype=int32)[W 200428 09:36:31 job:173] Cleaning up job fairing-job-gm8hb... notebook : jupyter notebook ë‚´ìš©ì„ íŒŒì´ì¬ file ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì´ì¬ file ì„ íŒ¨í‚¤ì§€í™” example1234567891011121314# jupyter notebook# fairing_preprocessor_notebook.ipynbimport os, timedef train(): print(&quot;Training...&quot;) import tensorflow as tf x &#x3D; tf.constant([1,2,3,4,5,6], shape&#x3D;[2,3]) print(x) time.sleep(1)if __name__ &#x3D;&#x3D; &#39;__main__&#39;:train() 1234567891011121314#!/usr/bin/env python# fairing_preprocessor_notebook.pyimport osfrom kubeflow import fairingDOCKER_REGISTRY = 'jaejunlee'file_name = os.path.basename(__file__)print(\"Executing &#123;&#125; remotely.\".format(file_name))fairing.config.set_preprocessor('notebook', notebook_file='fairing_preprocessor_notebook.ipynb')fairing.config.set_builder( 'append', base_image='gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0', registry=DOCKER_REGISTRY, push=True)fairing.config.run() 12345678910111213141516171819202122232425262728$ chmod +x fairing_preprocessor_notebook.py$ ./fairing_preprocessor_notebook.py[I 200428 09:44:27 config:134] Using preprocessor: &lt;kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7fd480eb0908&gt;[I 200428 09:44:27 config:136] Using builder: &lt;kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7fd480eb0860&gt;[I 200428 09:44:27 config:138] Using deployer: &lt;kubeflow.fairing.deployers.job.job.Job object at 0x7fd4809d6240&gt;[W 200428 09:44:27 append:50] Building image using Append builder...[I 200428 09:44:27 base:107] Creating docker context: /tmp/fairing_context_b254bkb_[I 200428 09:44:27 converted_notebook:127] Converting fairing_preprocessor_notebook.ipynb to fairing_preprocessor_notebook.py[I 200428 09:44:27 docker_creds_:234] Loading Docker credentials for repository 'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'[W 200428 09:44:29 append:54] Image successfully built in 1.9862057870050194s.[W 200428 09:44:29 append:94] Pushing image jaejunlee/fairing-job:7FCC2CF6...[I 200428 09:44:29 docker_creds_:234] Loading Docker credentials for repository 'jaejunlee/fairing-job:7FCC2CF6'[W 200428 09:44:31 append:81] Uploading jaejunlee/fairing-job:7FCC2CF6[I 200428 09:44:31 docker_session_:280] Layer sha256:380fe9d3ba2fe8c69d05cc9038b72aa9ec669cd0d51b0e61f312edb13586d5a8 pushed.......[I 200428 09:44:38 docker_session_:334] Finished upload of: jaejunlee/fairing-job:7FCC2CF6[W 200428 09:44:38 append:99] Pushed image jaejunlee/fairing-job:7FCC2CF6 in 9.018262255005538s.[W 200428 09:44:38 job:101] The job fairing-job-bbpjs launched.[W 200428 09:44:38 manager:296] Waiting for fairing-job-bbpjs-5jq22 to start...[W 200428 09:44:38 manager:296] Waiting for fairing-job-bbpjs-5jq22 to start...[W 200428 09:44:38 manager:296] Waiting for fairing-job-bbpjs-5jq22 to start...[W 200428 09:44:39 manager:296] Waiting for fairing-job-bbpjs-5jq22 to start...[I 200428 09:44:44 manager:302] Pod started running TrueTraining...Tensor(\"Const:0\", shape=(2, 3), dtype=int32)[W 200428 09:44:47 job:173] Cleaning up job fairing-job-bbpjs... full_notebook : jupyter notebook íŒ¨í‚¤ì§€í™” í•˜ëŠ”ë°, ìˆ˜í–‰ í›„ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë…¸íŠ¸ë¶ íŒŒì¼ë¡œ ìƒì„± function : ë‹¨ì¼ í•¨ìˆ˜ íŒ¨í‚¤ì§€í™” Builder in FairingBuilder ëŠ” preprocessor ê°€ ìƒì„±í•œ íŒ¨í‚¤ì§€ë¥¼ ë„ì»¤ ì´ë¯¸ì§€í™” í•œë‹¤. ë¹Œë“œ íƒ€ì… append : docker client ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  íŒŒì´ì„  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ëŠ” ë°©ì‹ self-signed ë¡œ ì¸ì¦ëœ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” ì‚¬ìš© ë¶ˆê°€ .local ë¡œ ì„¤ì •í•œ ì£¼ì†ŒëŠ” í—ˆìš© ê°€ëŠ¥ (kubeflow ìš© ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì¶•ì‹œ) ë¡œê·¸ì¸ì´ í•„ìš”í•œ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ì¦‰ docker hub ë¥¼ ì´ìš©í•˜ë ¤ë©´ ë…¸íŠ¸ë¶ ì»¨í…Œì´ë„ˆ ë‚´ .docker/config.json íŒŒì¼ì„ ìˆ˜ì •í•´ì•¼í•œë‹¤. ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì€, ë„ì»¤ ì„œë²„ì—ì„œ docker loging ì„ í†µí•´ ìƒì„±í•œ config.json íŒŒì¼ì„ ë…¸íŠ¸ë¶ ì»¨í…Œì´ë„ˆ ~/.docker/config.json ìœ¼ë¡œ ë³µì‚¬í•œë‹¤. cluster : êµ¬ê¸€ ì»¨í…Œì´ë„ˆ íˆ´ì¸ Kaniko ë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ëŠ” ë°©ì‹ docker : ë„ì»¤ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ëŠ” ë°©ì‹ í•´ë‹¹ í™˜ê²½ì´ ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì´ ì¡´ì¬í•´ì•¼í•¨ format 123456DOCKER_REGISTRY='&#123;ì´ë¯¸ì§€ë¥¼ push/pull ì£¼ì†Œ&#125;'fairing.config.set_builder( '&#123;build type&#125;', base_image='&#123;python ì„ ì‹¤í–‰í•œ ê¸°ë³¸ ì´ë¯¸ì§€ ëª…&#125;:&#123;íƒœê·¸&#125;', registry=DOCKER_REGISTRY, push=True) Deployer in FairingDeployer ëŠ” builder ë¡œ ìƒì„±í•œ ì´ë¯¸ì§€ë¥¼ ë°°í¬í•œë‹¤. format 1234fairing.config.set_deployer('job', namespace=?, pod_spec_mutators=? ) ë°°í¬í˜•íƒœ : job, tfjob, pytorchjob, serving, kfserving, gcpjob, gcpservingë“± namespace : ë°°í¬ê°€ ì‹¤í–‰í•  namespace pod_spec_mutators : ë°°í¬ pod ì˜ spec ì •ì˜ ì´ë ‡ê²Œ ê°ê° ì •ì˜í•œ Preprocessor, Builder, Deployer ë¥¼ í†µí•´ Config.run ìœ¼ë¡œ Fairing ì„ ì‹¤í–‰í•œë‹¤. ì‹¤í–‰ ìˆœì„œëŠ” ì„¤ëª…í•œ íë¦„ëŒ€ë¡œ preprocessor ë¡œ íŒ¨í‚¤ì§€í™” í•  ëŒ€ìƒì„ ì„ íƒí•˜ê³ , Builder ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë©° Deployer ë¡œ ë°°í¬í•œë‹¤. Reference ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì´ ì²˜ìŒì´ë¼ë©´! ì¿ ë¸Œí”Œë¡œìš°! made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubeflow","slug":"Kubeflow","permalink":"https://jx2lee.github.io/tags/Kubeflow/"}]},{"title":"[Shell] k8s Pod ë‚´ alias ì ìš© ìŠ¤í¬ë¦½íŠ¸","slug":"shell-append_alias_to_pod","date":"2020-04-23T15:00:00.000Z","updated":"2020-05-07T08:31:47.888Z","comments":true,"path":"shell-append_alias_to_pod/","link":"","permalink":"https://jx2lee.github.io/shell-append_alias_to_pod/","excerpt":"ì‚¬ë‚´ í´ë¼ìš°ë“œ ì œí’ˆì„ ì´ìš©í•´ ì—…ë¬´ë¥¼ ë³´ë˜ ì¤‘, ê³„ì†ë˜ëŠ” íŒ¨ì¹˜ ì‘ì—…ìœ¼ë¡œ ë§¤ë²ˆ ìƒì„±í•˜ëŠ” ì»¨í…Œì´ë„ˆì˜ alias ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì íŒ¨ì¹˜ ì´í›„ ìƒˆë¡œ ìƒì„±í•˜ëŠ” íŒŒë“œë¥¼ ê²€ìƒ‰í•˜ê³  .bashrc ì— alias ë¥¼ ì¶”ê°€í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. Update Note 2020.05.07 : ìŠ¤í¬ë¦½íŠ¸ ê°œì„  (exec, alias ë‘ ê°œ í•¨ìˆ˜ë¡œ ë¶„ë¦¬)","text":"ì‚¬ë‚´ í´ë¼ìš°ë“œ ì œí’ˆì„ ì´ìš©í•´ ì—…ë¬´ë¥¼ ë³´ë˜ ì¤‘, ê³„ì†ë˜ëŠ” íŒ¨ì¹˜ ì‘ì—…ìœ¼ë¡œ ë§¤ë²ˆ ìƒì„±í•˜ëŠ” ì»¨í…Œì´ë„ˆì˜ alias ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì íŒ¨ì¹˜ ì´í›„ ìƒˆë¡œ ìƒì„±í•˜ëŠ” íŒŒë“œë¥¼ ê²€ìƒ‰í•˜ê³  .bashrc ì— alias ë¥¼ ì¶”ê°€í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. Update Note 2020.05.07 : ìŠ¤í¬ë¦½íŠ¸ ê°œì„  (exec, alias ë‘ ê°œ í•¨ìˆ˜ë¡œ ë¶„ë¦¬) ë¬¸ì œ ë°œìƒíŒ¨ì¹˜ê°€ ì§„í–‰ë˜ë©´ í•´ë‹¹ íŒŒë“œì˜ ì´ë¯¸ì§€ë¥¼ êµì²´í•´ì•¼ í•œë‹¤. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ ê¸°ì¡´ íŒŒë“œë¥¼ ì‚­ì œí•˜ê³  êµì²´ëœ ì´ë¯¸ì§€ë¡œ íŒŒë“œë¥¼ ì¬ìƒì„±í•˜ëŠ”ë°, ê·¸ëŸ¼ ê¸°ì¡´ íŒŒë“œì—ì„œ ì‘ì—…ì„ í•˜ë˜ alias ë“¤ì´ ì‚¬ë¼ì§„ë‹¤. (ë‹¹ì—°íˆ ì»¨í…Œì´ë„ˆê°€ ì¬ê¸°ë™í•˜ë©´ì„œ .bashrc ì´ˆê¸°í™”) ê¸°ì¡´ ì‚¬ìš©í•˜ëŠ” alias 1234567891011alias dasboot='startDomainAdminServer -u jeus -p jeus'alias dasdown='stopServer -host localhost:9736 -u jeus -p jeus'alias hdstart='startManagedServer -server hyperdata -u jeus -p jeus'alias hdstop='stopServer -host localhost:19736 -u jeus -p jeus'alias pastart='startManagedServer -server ProAuth -u jeus -p jeus'alias pastop='stopServer -host localhost:29736 -u jeus -p jeus'alias polog='tail -100f /hyperdata/proobject7/logs/ProObject.log'alias slog='tail -100f /db/tibero6/instance/tibero/log/slog/sys.log' Script ì„¤ê³„ ë°©ì•ˆìš°ì„  ê³ ë ¤í•  ì ì€ êµì²´í•œ ì´ë¯¸ì§€ë¡œ ê¸°ë™í•œ íŒŒë“œë¥¼ ì°¾ì•„ì•¼ í•œë‹¤. ì´ëŠ” grep ê³¼ awk ë¥¼ ì´ìš©í•´ íŒŒë“œ ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ íŒŒë“œ ì´ë¦„ì„ ê²€ìƒ‰í•˜ê³  kubectl exec ìœ¼ë¡œ .bashrc ì— alias ë¥¼ ì¶”ê°€í•œë‹¤. ë‹¹ì—°íˆ ì¶”ê°€ë§Œ í•œë‹¤ê³  ì ìš©ì´ ì•ˆë˜ë¯€ë¡œ ë§ˆì§€ë§‰ì— source ~/.bashrc ëª…ë ¹ì–´ë¥¼ íŒŒë“œì— ë„˜ê²¨ì£¼ê³  ì ‘ì†í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì„¤ê³„ë¥¼ í•˜ì˜€ë‹¤. ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. íŒŒë“œ ì´ë¦„ ê²€ìƒ‰ alias ë¥¼ .bashrc ì— ì¶”ê°€ bash ì ìš©ì„ ìœ„í•œ source ëª…ë ¹ì–´ ì „ë‹¬ íŒŒë“œ ì ‘ê·¼ ì‚¬ë‚´ í´ë¼ìš°ë“œì—ì„œëŠ” namespace ê°€ default ë¡œ ì •ì˜ë˜ì–´ ìˆë‹¤. ì´ëŠ” ë°”ë€Œì§€ ì•Šê¸° ë•Œë¬¸ì— ìŠ¤í¬ë¦½íŠ¸ ì•ˆì— default ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. Script12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/sh# script for managing hd container# jaejun.lee.1991@gmail.comnamespace=$(kubectl get namespace | grep hpcd | awk '&#123;print $1&#125;')pod=$(kubectl describe pod -n hpcd-510fdc58 | grep -B 20 hyperdata8.3_hd | grep \"Name: hpcd\" | awk '&#123;print $2&#125;')function hd_container_exec() &#123; echo \"[INFO] exec $pod in $namespace\" | grep \"[INFO]\" --color kubectl exec -ti -n $namespace $pod -- bash&#125;function append_alias() &#123; echo \"[INFO] append alias to $pod\" | grep \"[INFO]\" --color kubectl exec -n $namespace $pod -- bash -c 'echo alias dasboot=\"\\\"startDomainAdminServer -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias dasdown=\"\\\"stopServer -host localhost:9736 -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias pastart=\"\\\"startManagedServer -server ProAuth -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias pastop=\"\\\"stopServer -host localhost:29736 -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias hdstart=\"\\\"startManagedServer -server hyperdata -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias hdstop=\"\\\"stopServer -host localhost:19736 -u jeus -p jeus\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias polog=\"\\\"tail -f /hyperdata/proobject7/logs/ProObject.log\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'echo alias slog=\"\\\"tail -f /db/tibero6/instance/tibero/log/slog/sys.log\"\\\" &gt;&gt; ~/.bashrc' kubectl exec -n $namespace $pod -- bash -c 'source ~/.bashrc'&#125;function main() &#123; case \"$&#123;1:-&#125;\" in exec) hd_container_exec ;; alias) append_alias ;; *) set +x echo \"usage:\" &gt;&amp;2 echo \" $0 exec\" &gt;&amp;2 echo \" $0 alias\" &gt;&amp;2 ;; esac&#125;main $1 6ë²ˆì§¸ ì¤„ : alias ë¥¼ ì ìš©í•  íŒŒë“œ ì´ë¦„ì„ ê²€ìƒ‰ 9ë²ˆì§¸ ì¤„ ~ 29ë²ˆì§¸ ì¤„ : source ~/.bashrc ì´ì „ : alias ë¥¼ .bashrc ì— ì¶”ê°€ 30ë²ˆì§¸ ì¤„ : .bashrc ì ìš© 31ë²ˆì§¸ ì¤„ : íŒŒë“œ ì ‘ê·¼ hd_container_exec : íŠ¹ì • ì»¨í…Œì´ë„ˆ(hd) ë¡œ ì ‘ê·¼í•˜ëŠ” í•¨ìˆ˜ append_alias : íŠ¹ì • ì»¨í…Œì´ë„ˆ(hd) ë‚´ .bashrc íŒŒì¼ì— alias ë¥¼ ì¶”ê°€í•˜ê³  ì ìš©í•˜ëŠ” í•¨ìˆ˜ main : exec or alias ì¸ìë¥¼ ë°›ëŠ” ë©”ì¸ í•¨ìˆ˜ made by jaejun.lee","categories":[{"name":"Shell","slug":"Shell","permalink":"https://jx2lee.github.io/categories/Shell/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Shell] ë‘ docker registry ê°„ ì´ë¯¸ì§€ ìµœì‹ í™”","slug":"shell-image_updater","date":"2020-04-08T15:00:00.000Z","updated":"2020-04-23T08:18:01.866Z","comments":true,"path":"shell-image_updater/","link":"","permalink":"https://jx2lee.github.io/shell-image_updater/","excerpt":"ìµœê·¼ë“¤ì–´ ì´ë¯¸ì§€ íŒ¨ì¹˜ê°€ ìì£¼ ì´ë£¨ì–´ì§€ë©´ì„œ, ì´ë¯¸ì§€ë¥¼ ì¼ì¼ì´ í’€(pull)í•˜ê³  ìš¸íŒ€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— í‘¸ì‰¬(push)í•˜ëŠ” ì‘ì—…ì´ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ì˜€ë‹¤. ìµœì‹ í™”ê°€ ì´ë£¨ì–´ì§€ëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ daemon / insecure-registry ì— ë“±ë¡í•´ ì‚¬ìš©í•´ë„ ë˜ì§€ë§Œ ìŠ¤í¬ë¦½íŠ¸ ì§œëŠ” ì—°ìŠµë„ í•  ê²¸ ì´ë¯¸ì§€ ìµœì‹ í™” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ê³  ì´ë¥¼ ì†Œê°œí•˜ê³ ì í•œë‹¤.","text":"ìµœê·¼ë“¤ì–´ ì´ë¯¸ì§€ íŒ¨ì¹˜ê°€ ìì£¼ ì´ë£¨ì–´ì§€ë©´ì„œ, ì´ë¯¸ì§€ë¥¼ ì¼ì¼ì´ í’€(pull)í•˜ê³  ìš¸íŒ€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— í‘¸ì‰¬(push)í•˜ëŠ” ì‘ì—…ì´ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ì˜€ë‹¤. ìµœì‹ í™”ê°€ ì´ë£¨ì–´ì§€ëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ daemon / insecure-registry ì— ë“±ë¡í•´ ì‚¬ìš©í•´ë„ ë˜ì§€ë§Œ ìŠ¤í¬ë¦½íŠ¸ ì§œëŠ” ì—°ìŠµë„ í•  ê²¸ ì´ë¯¸ì§€ ìµœì‹ í™” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ê³  ì´ë¥¼ ì†Œê°œí•˜ê³ ì í•œë‹¤. ìƒí™©ê°„ë‹¨íˆ AíŒ€, BíŒ€(ë‚´ê°€ ì†í•œ)ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. AíŒ€ : ì´ë¯¸ì§€ë¥¼ ìµœì‹ í™” í•˜ë©° ì´ë¯¸ì§€ íƒœê·¸ëŠ” ë‚ ì§œ_v?ìœ¼ë¡œ ì„¤ì •í•œë‹¤. ìµœì‹  ì´ë¯¸ì§€ëŠ” a ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•œë‹¤. BíŒ€ : í…ŒìŠ¤íŠ¸ ì‘ì—…ì„ ë§ˆì¹œ ìµœì‹  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ íŒ¨ì¹˜í•˜ê³  ì´ë¥¼ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ í•œë‹¤. b ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì´ìš©í•œë‹¤. ì‚¬ì‹¤ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¼ì¼ì´ ì´ë¯¸ì§€ íƒœê·¸ë¥¼ í™•ì¸í•˜ë©° pull&amp;push í•´ë„ ëœë‹¤. docker pull a/ì´ë¯¸ì§€:íƒœê·¸, docker tag a/ì´ë¯¸ì§€:íƒœê·¸ b/ì´ë¯¸ì§€:íƒœê·¸, docker push b/ì´ë¯¸ì§€:íƒœê·¸.. í•˜ë‚˜ì˜ ì œí’ˆì„ ì •ìƒê¸°ë™í•˜ë ¤ë©´ 4ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë‹ˆ êµ‰ì¥íˆ ë¶ˆí¸í•˜ì˜€ë‹¤. ì´ë¯¸ì§€ ìµœì í™”ê°€ ì•ˆë˜ì–´ì„œ ê·¸ëŸ°ì§€ í•œ ì´ë¯¸ì§€ì˜ pull&amp;push ê°€ 2ë¶„ì •ë„ ê±¸ë¦¬ëŠ” ê²½ìš°ë„ ì¡´ì¬í•œë‹¤. ì´ë¥¼ íƒ€íŒŒí•˜ê³ ì ê°„ë‹¨í•œ ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ ëª¨ë‘ update í•˜ë˜ê°€, í•œ ì´ë¯¸ì§€ë§Œ update í•˜ê²Œë” ë§Œë“¤ì—ˆë‹¤. Usageì»¨í”¼ê·¸ íŒŒì¼ í•˜ë‚˜ì™€ ì‰˜ ìŠ¤í¬ë¦½íŠ¸ í•˜ë‚˜ê°€ ì¡´ì¬í•œë‹¤. ì»¨í”¼ê·¸ íŒŒì¼(registry.config)ì€ pull í•˜ê¸° ìœ„í•œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì£¼ì†Œì™€ push í•˜ê¸° ìœ„í•œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì£¼ì†Œë¥¼ ì‘ì„±í•œë‹¤. ì´ ì¤‘ í•˜ë‚˜ë¼ë„ ì‘ì„±í•˜ì§€ ì•Šìœ¼ë©´ ERRORê°€ ë°œìƒí•œë‹¤. ê°„ë‹¨íˆ ì‚´í´ë³´ì. 1234â¯ ./updateImage.shusage: ./updateImage.sh all ./updateImage.sh img &#123;image_name&#125; ì‰˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” í¬ê²Œ all ê³¼ imgê°€ ìˆë‹¤. registry.config ë¥¼ ëª¨ë‘ ì‘ì„±í–ˆë‹¤ëŠ” ê°€ì •í•˜ì— ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ë³¸ë‹¤. all : ì´ 4ê°œì˜ ìµœì‹  ì´ë¯¸ì§€ë¥¼ pull&amp;push 12345â¯ ./updateImage.sh all[PULL REGISTRY] 192.xxx.xxx.xxx[PUSH REGISTRY] 192.yyy.yyy.yyy...... img : 4ê°œ ì¤‘ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ pull&amp;push 123456â¯ ./updateImage.sh img[PULL REGISTRY] 192.xxx.xxx.xxx[PUSH REGISTRY] 192.yyy.yyy.yyyEnter the image name : ???...... image name ì„ ì‘ì„±í•˜ë©´ ê·¸ ì´ë¯¸ì§€ì˜ ìµœì‹  íƒœê·¸ë¥¼ ì°¾ê³  ì´ë¥¼ pull&amp;push í•œë‹¤. ìµœì‚¬ ì œí’ˆëª…ì´ í˜¹ì‹œë‚˜ ë…¸ì¶œë˜ë©´ ì•ˆë ê¹Œ ì‹¶ì–´ ìˆ˜í–‰ ê²°ê³¼ëŠ” ì‘ì„±í•˜ì§€ ì•Šì•˜ë”°. ScriptìŠ¤í¬ë¦½íŠ¸ëŠ” ë‚´ ê¹ƒí—™ì— ì˜¬ë ¤ë‘ì—ˆì§€ë§Œ í•˜ê¸°ì—ë„ ìˆë‹¤. ë‚œ ì°©í•œ í¸ì´ë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#!/bin/bash# Thu, 08.04.2020# jaejun.lee.1991@gmail.com#includebase_dir=$(dirname \"$0\"). $&#123;base_dir&#125;/registry.configfunction check_env()&#123; if [ -z $&#123;pull_registry&#125; ] || [ -z $&#123;push_registry&#125; ]; then echo \"[ERROR] You must set registry variables in registry.config!\" | grep \"[ERROR]\" --color exit 1 else echo \"[PULL REGISTRY] $&#123;pull_registry&#125;\" | grep \"[PULL REGISTRY]\" --color echo \"[PUSH REGISTRY] $&#123;push_registry&#125;\" | grep \"[PUSH REGISTRY]\" --color fi&#125;function check_img() &#123; image_pattern='hyperdata8.3_' echo -n \"Enter the image name : \" read name if [[ $&#123;name&#125; == *$&#123;image_pattern&#125;* ]];then echo \"Update $name image..\" else echo \"[ERROR] you must enter the image on hyperdata8.3_&#123;tb, hl, efa, hd&#125;!\" | grep \"[ERROR]\" --color exit 1 fi&#125;function update_all()&#123; image_list=( \"hyperdata8.3_hd\" \"hyperdata8.3_tb\" \"hyperdata8.3_hl\" \"hyperdata8.3_eda\" ) for image in $&#123;image_list[@]&#125;;do version=$(curl -X GET $&#123;pull_registry&#125;/v2/$&#123;image&#125;/tags/list | jq -r '.tags | .[-1]') docker pull $&#123;pull_registry&#125;/$&#123;image&#125;:$&#123;version&#125; docker tag $&#123;pull_registry&#125;/$&#123;image&#125;:$&#123;version&#125; $&#123;push_registry&#125;/$&#123;image&#125;:$&#123;version&#125; docker push $&#123;push_registry&#125;/$&#123;image&#125;:$&#123;version&#125; done&#125;function update_once()&#123; version=$(curl -X GET $&#123;pull_registry&#125;/v2/$&#123;name&#125;/tags/list | jq -r '.tags | .[-1]') docker pull $&#123;pull_registry&#125;/$&#123;name&#125;:$&#123;version&#125; docker tag $&#123;pull_registry&#125;/$&#123;name&#125;:$&#123;version&#125; $&#123;push_registry&#125;/$&#123;name&#125;:$&#123;version&#125; docker push $&#123;push_registry&#125;/$&#123;name&#125;:$&#123;version&#125;&#125;function main() &#123; case \"$&#123;1:-&#125;\" in all) check_env update_all ;; img) check_env check_img update_once ;; *) set +x echo \"usage:\" &gt;&amp;2 echo \" $0 all\" &gt;&amp;2 echo \" $0 img hyperdata8.3_hd\" &gt;&amp;2 ;; esac&#125;main $1 made by jaejun.lee","categories":[{"name":"Shell","slug":"Shell","permalink":"https://jx2lee.github.io/categories/Shell/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] Metallb for Kubernetes ì„¤ì¹˜","slug":"cloud-install_metallb","date":"2020-04-05T15:00:00.000Z","updated":"2020-04-23T08:18:41.677Z","comments":true,"path":"cloud-install_metallb/","link":"","permalink":"https://jx2lee.github.io/cloud-install_metallb/","excerpt":"Kubernetes ì— ë¡œë“œë°¸ëŸ°ì„œ ìƒì„±ì„ ìœ„í•´ ì„¤ì¹˜í•œ Metallb ì„¤ì¹˜ ê³¼ì •ì„ ë‹¤ë¤„ë³¸ë‹¤. ì„œë¹„ìŠ¤ë¥¼ íŠ¹ì • IP ë¡œ ë…¸ì¶œí•˜ê¸° ìœ„í•´ Metallb config ì„¤ì •ê³¼ ì„œë¹„ìŠ¤ë¡œ ë…¸ì¶œí•˜ëŠ” ë‹¨ê³„ë¡œ ì„¤ëª…í•œë‹¤.","text":"Kubernetes ì— ë¡œë“œë°¸ëŸ°ì„œ ìƒì„±ì„ ìœ„í•´ ì„¤ì¹˜í•œ Metallb ì„¤ì¹˜ ê³¼ì •ì„ ë‹¤ë¤„ë³¸ë‹¤. ì„œë¹„ìŠ¤ë¥¼ íŠ¹ì • IP ë¡œ ë…¸ì¶œí•˜ê¸° ìœ„í•´ Metallb config ì„¤ì •ê³¼ ì„œë¹„ìŠ¤ë¡œ ë…¸ì¶œí•˜ëŠ” ë‹¨ê³„ë¡œ ì„¤ëª…í•œë‹¤. Metallb ë€MetalLBëŠ” í‘œì¤€ ë¼ìš°íŒ… í”„ë¡œí† ì½œì„ ì‚¬ìš©í•˜ì—¬ ë² ì–´ ë©”íƒˆ (ê¹¡í†µ) Kubernetes í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ë¡œë“œ ë°¸ëŸ°ì„œ êµ¬í˜„ ì´ë¼ê³  í•œë‹¤. í‘œì¤€ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ì™€ í†µí•©ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ LB êµ¬í˜„ì„ ì œê³µí•˜ì—¬ ë² ì–´ ë©”íƒˆ í´ëŸ¬ìŠ¤í„°ì˜ ì™¸ë¶€ ì„œë¹„ìŠ¤ë„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. í”„ë¼ì´ë¹— í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ë²¤ë”ì‚¬ë¥¼ ì´ìš©í•˜ì§€ ì•ŠëŠ” kubernetes ìš´ì˜ì˜ ê²½ìš°, ê³µìœ  IP ë§Œ ì¡´ì¬í•œë‹¤ë©´ ì´ë¥¼ ë¡œë“œë°¸ëŸ°ì„œë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì¥ì ì´ ìˆë‹¤. Metallb ì„¤ì¹˜github ì˜ ê³µì‹ ë°°í¬ ì•¼ë¯ˆì„ íŠ¹ì • ë””ë ‰í† ë¦¬ (ex. metallb) ì— ë‹¤ìš´ë°›ì•„ ë°°í¬í•œë‹¤. 123mkdir -p /data/jlee/metallbwget -O metallb.yaml https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yamlkubectl apply -f metallb.yaml ì´í›„ ìƒì„±í•˜ëŠ” metallb-system ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— íŒŒë“œë¥¼ ì •ìƒ ë°°í¬í•˜ì˜€ëŠ”ì§€ í™•ì¸í•œë‹¤. 1234567root@k8s-node2:/data/jlee# kubectl get pods -n metallb-systemNAME READY STATUS RESTARTS AGEcontroller-547d466688-25w69 1/1 Running 0 2d21hspeaker-dfhwc 1/1 Running 0 2d21hspeaker-kpc2n 1/1 Running 0 2d21hspeaker-lfjv9 1/1 Running 0 2d21hspeaker-p9qlt 1/1 Running 0 2d21h Metallb Configmap ë°°í¬ë¡œë“œë°¸ëŸ°ì„œ ìƒì„±ì— ëŒ€í•œ ì»¨í”¼ê·¸ ë§µ ì•¼ë¯ˆì„ ìƒì„±í•˜ê³  ë°°í¬í•œë‹¤. ì´ë¦„ì€ metallb-Configmap.yaml ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. 12345678910111213root@k8s-node2:/data/jlee/metallb# cat metallb-ConfigMap.yamlapiVersion: v1kind: ConfigMapmetadata: namespace: metallb-system name: configdata: config: | address-pools: - name: my-ip-space protocol: layer2 addresses: - 192.168.179.184-192.168.179.195 adresses ë¶€ë¶„ì€ ë¡œë“œë°¸ëŸ°ì„œë¡œ ì‚¬ìš©í•  IP ëŒ€ì—­ëŒ€ë¥¼ ì„¤ì •í•œë‹¤. ë‚˜ì˜ ê²½ìš°, 184-195 ê¹Œì§€ ì—¬ìœ  IP ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— range ë¥¼ ì¶”ê°€í•˜ì˜€ë‹¤. ë§Œì•½ í•˜ë‚˜ì˜ IP ë¡œ ì„¤ì •í•  ê²½ìš° IP í•˜ë‚˜ë§Œ ì‘ì„±í•œë‹¤. ì •ìƒ ë°°í¬í•˜ì˜€ëŠ”ì§€ configmap ì„ ì¶œë ¥í•œë‹¤.1234567891011121314151617181920212223242526root@k8s-node2:/data/jlee/metallb# kubectl get configmap -n metallb-system -o yamlapiVersion: v1items:- apiVersion: v1 data: config: | address-pools: - name: my-ip-space protocol: layer2 addresses: - 192.168.179.184-192.168.179.195 kind: ConfigMap metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;\"apiVersion\":\"v1\",\"data\":&#123;\"config\":\"address-pools:\\n- name: my-ip-space\\n protocol: layer2\\n addresses:\\n - 192.168.179.184-192.168.179.195\\n\"&#125;,\"kind\":\"ConfigMap\",\"metadata\":&#123;\"annotations\":&#123;&#125;,\"name\":\"config\",\"namespace\":\"metallb-system\"&#125;&#125; creationTimestamp: \"2020-04-03T09:56:44Z\" name: config namespace: metallb-system resourceVersion: \"13110630\" selfLink: /api/v1/namespaces/metallb-system/configmaps/config uid: 49765aca-9364-48c2-9f9a-4fa2304651e8kind: Listmetadata: resourceVersion: \"\" selfLink: \"\" ì„œë¹„ìŠ¤ ë°°í¬ í›„ í™•ì¸4ê°œ íŒŒë“œ í†µì‹ ì„ ìœ„í•œ ì„œë¹„ìŠ¤ ì•¼ë¯ˆ íŒŒì¼ì— type ì„ ë¡œë“œë°¸ëŸ°ì„œë¡œ ì„¤ì •í•˜ê³  ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•œë‹¤. loadbalancer.yaml 12345678910apiVersion: v1kind: Service....spec: ... ... ... type: LoadBalancer loadBalancerIP: 192.168.179.184 # ì´ ë¶€ë¶„ ìˆ˜ì • í•„ìš” loadBalancerIP ê°’ì„ ìœ„ metallb-Configmap.yaml ë‚´ IP ë²”ìœ„ì— í¬í•¨í•œ í•˜ë‚˜ë¡œ ì‚¬ìš©í•œë‹¤. ì´í›„ ë°°í¬í•œ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ë©´ EXTERNA-IP ì— IP ê°€ í‘œì‹œë  ê²ƒì´ë‹¤. ë°˜ë“œì‹œ ip ê°’ì€ configmap ip range ì•ˆì—ì„œ ì‚¬ìš©í•´ì•¼í•œë‹¤. kubectl get svc12NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhyper-lb LoadBalancer 10.96.25.50 192.168.179.184 20:31010/TCP,21:31020/TCP,22:31030/TCP,23:31040/TCP,80:31060/TCP,8080:31080/TCP,9736:31085/TCP,8629:31090/TCP,8630:31100/TCP,28080:31160/TCP,1883:31190/TCP,2883:31200/TCP 6h42m Reference https://metallb.universe.tf https://ssup2.github.io/record/Kubernetes_MetalLB_ì„¤ì¹˜_Ubuntu_18.04/ made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] kubectl ëª…ë ¹ì–´ ìˆ˜í–‰ ì‹œ ì‹¤í–‰ì†ë„ ì €í•˜ ë¬¸ì œ","slug":"cloud-kubectl_hang","date":"2020-03-30T15:00:00.000Z","updated":"2020-04-02T09:04:40.977Z","comments":true,"path":"cloud-kubectl_hang/","link":"","permalink":"https://jx2lee.github.io/cloud-kubectl_hang/","excerpt":"ë„ì»¤ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í•˜ë˜ ë„ì¤‘, k8s í´ëŸ¬ìŠ¤í„°ì—ì„œ kubectl ëª…ë ¹ì–´ê°€ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì›ì¸ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.","text":"ë„ì»¤ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í•˜ë˜ ë„ì¤‘, k8s í´ëŸ¬ìŠ¤í„°ì—ì„œ kubectl ëª…ë ¹ì–´ê°€ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ì›ì¸ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. ë¬¸ì œ ë°œìƒkubectl ë¥¼ ì‚¬ìš©í•˜ë©´ ê²°ê³¼ëŠ” ë‚˜ì˜¤ì§€ë§Œ ì—„ì²­ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. time kubectl get nodes ë¥¼ ìˆ˜í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. 12345678910NAME STATUS ROLES AGE VERSIONk8s-master Ready master 14d v1.15.3k8s-node1 Ready master 14d v1.15.3k8s-node2 Ready master 14d v1.15.3k8s-node3 Ready &lt;none&gt; 14d v1.15.3k8s-node4 Ready &lt;none&gt; 14d v1.15.3real 2m1.032suser 2m0.089ssys 2m0.041s ì›ì¸ íŒŒì•… kube-system ì˜ íŒŒë“œ ìƒíƒœ 12345678910111213141516171819202122232425262728root@k8s-master:/data# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcalico-kube-controllers-56cd854695-hvnkl 1/1 Running 0 7dcalico-node-4f2bt 1/1 Running 0 7dcalico-node-bhk4z 1/1 Running 0 7dcalico-node-kmvm9 1/1 Running 0 7dcalico-node-q928k 1/1 Running 0 7dcalico-node-snf8z 0/1 Evicted 0 90mcoredns-5c98db65d4-7665n 1/1 Running 35 10dcoredns-5c98db65d4-7hpxb 1/1 Running 34 10detcd-k8s-master 1/1 Running 3 14detcd-k8s-node1 1/1 Running 0 14detcd-k8s-node2 1/1 Running 0 14dkube-apiserver-k8s-master 1/1 Running 3 5d23hkube-apiserver-k8s-node1 1/1 Running 0 5d23hkube-apiserver-k8s-node2 1/1 Running 0 5d23hkube-controller-manager-k8s-master 1/1 Running 3 14dkube-controller-manager-k8s-node1 1/1 Running 7 14dkube-controller-manager-k8s-node2 1/1 Running 8 14dkube-proxy-4dhqc 1/1 Running 0 14dkube-proxy-9v87c 1/1 Running 0 14dkube-proxy-pfrwf 1/1 Running 0 14dkube-proxy-tsdb6 0/1 Evicted 0 91mkube-proxy-vsk6r 1/1 Running 0 14dkube-scheduler-k8s-master 1/1 Running 2 14dkube-scheduler-k8s-node1 1/1 Running 6 14dkube-scheduler-k8s-node2 1/1 Running 8 14dtiller-deploy-758bcdc94f-c92cw 1/1 Running 0 14d Evcited ëœ ìº˜ë¦¬ì½” ë…¸ë“œ íŒŒë“œê°€ ë³´ì¸ë‹¤. ë¶„ëª… k8s-master ë…¸ë“œì—ì„œ ë°œìƒí•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. (ë¯¸ë¦¬ ìº¡ì³ë¥¼ ë– ë†“ì§€ ëª»í•´ -o wide ì˜µì…˜ì„ ì¤€ ê²°ê³¼ëŠ” ì—†ë‹¤) calico-node-snf8z íŒŒë“œë¥¼ describe í•´ë³´ì. calico-node-snf8z ìº˜ë¦¬ì½” íŒŒë“œ 12345678910111213141516root@k8s-master:/data# kd pod -n kube-system calico-node-snf8zName: calico-node-snf8zNamespace: kube-systemPriority: 2000001000Priority Class Name: system-node-criticalNode: k8s-master/Start Time: Tue, 31 Mar 2020 14:14:44 +0900Labels: controller-revision-hash=5744776c47 k8s-app=calico-node pod-template-generation=1Annotations: scheduler.alpha.kubernetes.io/critical-pod:Status: FailedReason: EvictedMessage: The node was low on resource: ephemeral-storage....... The node was low on resource: ephemeral-storage. ë©”ì„¸ì§€ê°€ ëˆˆì— ëˆë‹¤. êµ¬ê¸€ë§ì„ í†µí•´ ì•Œì•„ë³¸ ê²°ê³¼, í•´ë‹¹ íŒŒë“œê°€ ë°°í¬ëœ ë…¸ë“œ ìš©ëŸ‰ì´ ë¶€ì¡±í•˜ë‹¤ ëŠë¼ë©´ íŒŒë“œë¥¼ ë„ìš°ì§€ ëª»í•˜ê³  Evicted ìƒíƒœë¡œ ë³€í•œë‹¤ê³  í•œë‹¤. ìƒíƒœë¥¼ ë³´ì•„í•˜ë‹ˆ docker root directory ê°€ /var/lib ê°€ default ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ì´ë¯¸ì§€ ë“± ë°ì´í„°ê°€ ë§ì´ ìŒ“ì´ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. (ë£¨íŠ¸ ì „ì²´ ë””ë ‰í† ë¦¬ì˜ ì•½ 80% ì´ìƒì„ ì°¨ì§€í•˜ê³  ìˆì—ˆë‹¤. ì´ëŠ” full ë‚˜ì§€ ì•Šì•„ë„ kubernetest ê°€ ì„¤ì •í•œ ì ì • ìš©ëŸ‰(?)ì—ì„œë§Œ íŒŒë“œë¥¼ ë„ìš°ê²Œë” ì„¤ê³„ëœ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤-ë‡Œí”¼ì…œ) ì´ë¥¼ í•´ê²°í•˜ê³ ì docker root directory ë¥¼ ë³€ê²½í•˜ì˜€ë‹¤. ì°¸ê³  ì´í›„ Evicted ëœ ìº˜ë¦¬ì½” ë…¸ë“œ íŒŒë“œë¥¼ ì¬ê¸°ë™í•˜ì˜€ë‹¤. 1docker restart 7feda4bd2162 ê²°ê³¼í•´ë‹¹ ì»¨í…Œì´ë„ˆë¥¼ ì¬ì‹œì‘í•˜ê³  kube-system íŒŒë“œ ìƒíƒœë¥¼ í™•ì¸í•œ ê²°ê³¼, ëª¨ë‘ ì •ìƒ ì‘ë™í•˜ê³  ìˆìœ¼ë©° kubectl ëª…ë ¹ì–´ ì‹¤í–‰ë„ ì´ì „ì²˜ëŸ¼ ë¹ ë¥´ê²Œ ë³µêµ¬ë˜ì—ˆë‹¤. ì´ë¥¼ í†µí•´ kubectl ëª…ë ¹ì–´ì–´ê°€ ëŠë ¤ì§„ ì´ìœ ëŠ” *â€ë…¸ë“œ ìš©ëŸ‰ ë° ë…¸ë“œ ê°„ í†µì‹ ì¼ ìˆ˜ë„ ìˆë‹¤â€* ë¼ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤. ì´ì™¸ì—ë„ ë§ì€ ë¶€ë¶„ì—ì„œ ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆëŠ”ë° ê·¸ë•Œë§ˆë‹¤ ê¸€ì— ì¶”ê°€í•  ì˜ˆì •ì´ë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839root@k8s-master:/data# kgpo -n kube-systemNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScalico-kube-controllers-56cd854695-hvnkl 1/1 Running 0 7d 10.244.169.130 k8s-node2 &lt;none&gt; &lt;none&gt;calico-node-2wvj8 1/1 Running 0 54s 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;calico-node-4f2bt 1/1 Running 0 7d 192.168.179.176 k8s-node4 &lt;none&gt; &lt;none&gt;calico-node-bhk4z 1/1 Running 0 7d 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;calico-node-kmvm9 1/1 Running 0 7d 192.168.179.175 k8s-node3 &lt;none&gt; &lt;none&gt;calico-node-q928k 1/1 Running 0 7d 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;coredns-5c98db65d4-7665n 1/1 Running 35 10d 10.244.36.71 k8s-node1 &lt;none&gt; &lt;none&gt;coredns-5c98db65d4-7hpxb 1/1 Running 34 10d 10.244.169.148 k8s-node2 &lt;none&gt; &lt;none&gt;etcd-k8s-master 1/1 Running 3 14d 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;etcd-k8s-node1 1/1 Running 0 14d 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;etcd-k8s-node2 1/1 Running 0 14d 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;kube-apiserver-k8s-master 1/1 Running 3 5d23h 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;kube-apiserver-k8s-node1 1/1 Running 0 5d23h 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;kube-apiserver-k8s-node2 1/1 Running 0 5d23h 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;kube-controller-manager-k8s-master 1/1 Running 3 14d 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;kube-controller-manager-k8s-node1 1/1 Running 7 14d 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;kube-controller-manager-k8s-node2 1/1 Running 8 14d 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;kube-proxy-4dhqc 1/1 Running 0 14d 192.168.179.175 k8s-node3 &lt;none&gt; &lt;none&gt;kube-proxy-8qtnp 1/1 Running 0 54s 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;kube-proxy-9v87c 1/1 Running 0 14d 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;kube-proxy-pfrwf 1/1 Running 0 14d 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;kube-proxy-vsk6r 1/1 Running 0 14d 192.168.179.176 k8s-node4 &lt;none&gt; &lt;none&gt;kube-scheduler-k8s-master 1/1 Running 2 14d 192.168.179.172 k8s-master &lt;none&gt; &lt;none&gt;kube-scheduler-k8s-node1 1/1 Running 6 14d 192.168.179.173 k8s-node1 &lt;none&gt; &lt;none&gt;kube-scheduler-k8s-node2 1/1 Running 8 14d 192.168.179.174 k8s-node2 &lt;none&gt; &lt;none&gt;tiller-deploy-758bcdc94f-c92cw 1/1 Running 0 14d 10.244.122.75 k8s-node4 &lt;none&gt; &lt;none&gt;root@k8s-node2:/data# time kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master Ready master 14d v1.15.3k8s-node1 Ready master 14d v1.15.3k8s-node2 Ready master 14d v1.15.3k8s-node3 Ready &lt;none&gt; 14d v1.15.3k8s-node4 Ready &lt;none&gt; 14d v1.15.3real 0m1.032suser 0m0.089ssys 0m0.041s 2020.03.31 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] Kubeflow íì‡„ë§ ì„¤ì¹˜ ì¤‘ Namespace ìƒì„± í™”ë©´ì´ ë‚˜ì˜¤ì§€ ì•ŠëŠ” ë¬¸ì œ","slug":"cloud-kubeflow_error","date":"2020-03-29T15:00:00.000Z","updated":"2020-06-24T03:29:13.139Z","comments":true,"path":"cloud-kubeflow_error/","link":"","permalink":"https://jx2lee.github.io/cloud-kubeflow_error/","excerpt":"Kubeflow ë¥¼ íì‡„ í™˜ê²½ì—ì„œ ì„¤ì¹˜í•˜ë˜ ì¤‘ Namespace ìƒì„±í™”ë©´ì´ ë‚˜ì˜¤ì§€ ì•Šê³  ì‹¬ì§€ì–´ ì„ íƒí•  ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ë¬¸ì œì˜ ì›ì¸ì„ íŒŒì•…í•˜ê³  í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Update Note 2020.05.19 : Image list ë³€ê²½ 2020.06.24 : Image List ë³€ê²½ (kfserving-system ì— í•„ìš”í•œ ì´ë¯¸ì§€ ì¶”ê°€)","text":"Kubeflow ë¥¼ íì‡„ í™˜ê²½ì—ì„œ ì„¤ì¹˜í•˜ë˜ ì¤‘ Namespace ìƒì„±í™”ë©´ì´ ë‚˜ì˜¤ì§€ ì•Šê³  ì‹¬ì§€ì–´ ì„ íƒí•  ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤. ë¬¸ì œì˜ ì›ì¸ì„ íŒŒì•…í•˜ê³  í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Update Note 2020.05.19 : Image list ë³€ê²½ 2020.06.24 : Image List ë³€ê²½ (kfserving-system ì— í•„ìš”í•œ ì´ë¯¸ì§€ ì¶”ê°€) ë¬¸ì œ UI ì ‘ì† í›„ namespace ìƒì„±ì´ ë˜ì§€ ì•ŠìŒ .cache í´ë” ì‚­ì œ í›„ ì¬ ë°°í¬í•´ë„ ê³„ì†ë˜ëŠ” ë¬¸ì œ ë°œìƒ kubectl get pod -n kubeflow123456789101112131415161718192021222324252627282930313233NAME READY STATUS RESTARTS AGEadmission-webhook-bootstrap-stateful-set-0 1/1 Running 0 15madmission-webhook-deployment-68c6dd4cc5-sgtn6 1/1 Running 0 14mapplication-controller-stateful-set-0 1/1 Running 0 15margo-ui-78bf45b698-2vhm9 1/1 Running 0 15mcentraldashboard-fd9549bd5-nv68z 1/1 Running 0 15mjupyter-web-app-deployment-7797778d74-5lq9d 1/1 Running 0 15mkatib-controller-55545cb4c8-8xdtn 1/1 Running 1 15mkatib-db-d99f776cd-zww8n 0/1 Running 1 15mkatib-manager-67d9689545-9j6cf 0/1 CrashLoopBackOff 6 15mkatib-ui-889499864-fd4hc 1/1 Running 0 15mmetacontroller-0 1/1 Running 0 15mmetadata-db-68df96445c-br8vt 1/1 Running 0 15mmetadata-deployment-865fddd777-dpkbv 1/1 Running 0 15mmetadata-envoy-deployment-68f64489cc-ts88j 1/1 Running 0 15mmetadata-grpc-deployment-7f5d6c8ccb-j99d2 1/1 Running 1 15mmetadata-ui-84c76df48f-4sxdq 1/1 Running 0 15mminio-75d8cbbb5c-2dsgt 1/1 Running 0 15mml-pipeline-7f6548ff8-74lh6 0/1 ImagePullBackOff 0 15mml-pipeline-ml-pipeline-visualizationserver-559c875d6b-9mth7 0/1 ImagePullBackOff 0 15mml-pipeline-persistenceagent-796c6c4c75-l8vx2 0/1 ImagePullBackOff 0 15mml-pipeline-scheduledworkflow-f86df57bd-87j5p 0/1 ImagePullBackOff 0 15mml-pipeline-ui-fb8b6778f-zgx59 1/1 Running 0 15mml-pipeline-viewer-controller-deployment-78bdcc54fc-pf8lb 1/1 Running 0 15mmysql-6c5ddbd98b-pkqqr 1/1 Running 0 15mnotebook-controller-deployment-7694b76c89-fb6g5 1/1 Running 0 15mprofiles-deployment-5c48f8d6d8-kxfx5 1/2 CrashLoopBackOff 7 15mpytorch-operator-dfb77d487-92dqx 1/1 Running 0 15mseldon-operator-controller-manager-0 1/1 Running 1 15mspartakus-volunteer-74f96589f9-g2xd5 1/1 Running 0 15mtensorboard-6867797f97-kqxsc 1/1 Running 0 15mtf-job-operator-58d7d7d976-jhpk4 1/1 Running 0 15mworkflow-controller-66dd745699-9bqcx 1/1 Running 0 15m logprofiles-deployment managerk logs -n kubeflow profiles-deployment-5c48f8d6d8-kxfx5 -c manager 123456789101112flag provided but not defined: -workload-identityUsage of /manager: -kubeconfig string Paths to a kubeconfig. Only required if out-of-cluster. -master string The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster. -metrics-addr string The address the metric endpoint binds to. (default \":8080\") -userid-header string Key of request header containing user id (default \"x-goog-authenticated-user-email\") -userid-prefix string Request header user id common prefix (default \"accounts.google.com:\") profiles-deployment kfamk logs -n kubeflow profiles-deployment-5c48f8d6d8-kxfx5 -c kfam 1time=\"2020-03-26T06:02:16Z\" level=info msg=\"Server started\" centraldashboard pod logs123456789101112131415161718192021222324252627282930313233343536373839Initializing Kubernetes configurationUnable to fetch Nodes &#123; kind: 'Status', apiVersion: 'v1', metadata: &#123;&#125;, status: 'Failure', message: 'nodes is forbidden: User \"system:serviceaccount:kubeflow:centraldashboard\" cannot list resource \"nodes\" in API group \"\" at the cluster scope', reason: 'Forbidden', details: &#123; kind: 'nodes' &#125;, code: 403 &#125;Unable to fetch Application information: &#123; kind: 'Status', apiVersion: 'v1', metadata: &#123;&#125;, status: 'Failure', message: 'applications.app.k8s.io is forbidden: User \"system:serviceaccount:kubeflow:centraldashboard\" cannot list resource \"applications\" in API group \"app.k8s.io\" in the namespace \"kubeflow\"',Using Profiles service at http://profiles-kfam.kubeflow:8081/kfam reason: 'Forbidden', details: &#123; group: 'app.k8s.io', kind: 'applications' &#125;, code: 403 &#125;Unable to fetch Nodes &#123; kind: 'Status', apiVersion: 'v1', metadata: &#123;&#125;, status: 'Failure', message: 'nodes is forbidden: User \"system:serviceaccount:kubeflow:centraldashboard\" cannot list resource \"nodes\" in API group \"\" at the cluster scope', reason: 'Forbidden', details: &#123; kind: 'nodes' &#125;, code: 403 &#125;\"other\" is not a supported platform for MetricsServer listening on port http://localhost:8082 (in production mode)Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object]Unable to contact Profile Controller [object Object] Unable to contact Profile Controller [object Object] centraldashboard ì—ì„œ profile controller ìš”ì²­ì„ ë°›ì§€ ëª»í•˜ëŠ” ìƒí™© ê° íŒŒë“œì— ì ‘ì†í•˜ì—¬ (centraldashboard, profile controller-manager) í•‘ì„ ë•Œë ¤ë´¤ëŠ”ë° ëª¨ë‘ í†µì‹ ì´ ì›í™œí•˜ì˜€ìŒ í•´ê²° ë°©ì•ˆ ì—„ì²­ë‚˜ê²Œ ë§ì€ ë°©ë²•ì„ ì‹œë„í–ˆë‹¤. kfctl verion, ê°ì¢… ì´ë¯¸ì§€ ë³€ê²½ ë“±.. ì‹œí–‰ì°©ì˜¤ ëì— centraldashobard ì™€ profile-deployment íŒŒë“œì— ìƒì„±í•œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë²„ì ¼ ë¬¸ì œì˜€ë‹¤. gcr.io/kubeflow-images-public/centraldashboard:latest gcr.io/kubeflow-images-public/profile-controller:v20191024-v0.7.0-rc.5-12-g956569ba-e3b0c4 gcr.io/kubeflow-images-public/kfam@sha256:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0 digest ë¡œ ì´ë£¨ì–´ì§„ ì´ë¯¸ì§€ëŠ” pull ì´í›„ì— tag ë¥¼ ìƒì„±í•˜ì—¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— push í•˜ì˜€ë‹¤. (ex. gcr.io/kubeflow-images-public/kfam:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0) ìµœì¢…ì ìœ¼ë¡œ kubeflow 0.7.1 ë²„ì ¼ì— ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475argoproj/argoui:v2.3.0argoproj/workflow-controller:v2.3.0docker.io/istio/citadel:1.1.6docker.io/istio/galley:1.1.6docker.io/istio/kubectl:1.1.6docker.io/istio/mixer:1.1.6docker.io/istio/pilot:1.1.6docker.io/istio/proxy_init:1.1.6docker.io/istio/proxyv2:1.1.6docker.io/istio/sidecar_injector:1.1.6docker.io/jaegertracing/all-in-one:1.9docker.io/kiali/kiali:v0.16docker.io/prom/prometheus:v2.3.1docker.io/seldonio/seldon-core-operator:0.4.1gcr.io/google_containers/spartakus-amd64:v1.1.0gcr.io/kfserving/alibi-explainer:0.2.2gcr.io/kfserving/kfserving-controller:0.2.2gcr.io/kfserving/logger:0.2.2gcr.io/kfserving/pytorchserver:0.2.2gcr.io/kfserving/sklearnserver:0.2.2gcr.io/kfserving/storage-initializer:0.2.2 gcr.io/kfserving/xgbserver:0.2.2gcr.io/kubebuilder/kube-rbac-proxy:v0.4.0gcr.io/kubeflow-images-public/admission-webhook:v20190520-v0-139-gcee39dbc-dirty-0d8f4cgcr.io/kubeflow-images-public/ingress-setup:latestgcr.io/kubeflow-images-public/jupyter-web-app:9419d4dgcr.io/kubeflow-images-public/katib/v1alpha3/katib-controller:v0.7.0gcr.io/kubeflow-images-public/katib/v1alpha3/katib-manager:v0.7.0gcr.io/kubeflow-images-public/katib/v1alpha3/katib-ui:v0.7.0gcr.io/kubeflow-images-public/kubernetes-sigs/application:1.0-betagcr.io/kubeflow-images-public/metadata-frontend:v0.1.8gcr.io/kubeflow-images-public/metadata:v0.1.11gcr.io/kubeflow-images-public/pytorch-operator:v0.7.0gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v-base-ef41372-1177829795472347138gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-gpu:v0.7.0gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-cpu:v0.7.0gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-gpu:v0.7.0gcr.io/kubeflow-images-public/tf_operator:kubeflow-tf-operator-postsubmit-v1-5adee6f-6109-a25cgcr.io/ml-pipeline/api-server:0.1.31gcr.io/ml-pipeline/envoy:metadata-grpcgcr.io/ml-pipeline/frontend:0.1.31gcr.io/ml-pipeline/persistenceagent:0.1.31gcr.io/ml-pipeline/scheduledworkflow:0.1.31gcr.io/ml-pipeline/viewer-crd-controller:0.1.31gcr.io/ml-pipeline/visualization-server:0.1.27gcr.io/tfx-oss-public/ml_metadata_store_server:0.15.1grafana/grafana:6.0.2mcr.microsoft.com/onnxruntime/server:v0.5.1metacontroller/metacontroller:v0.3.0minio/minio:RELEASE.2018-02-09T22-40-05Zmysql:5.6mysql:8mysql:8.0.3nvcr.io/nvidia/tensorrtserver:19.05-py3tensorflow/serving:1.11.0tensorflow/serving:1.11.0-gputensorflow/serving:1.12.0tensorflow/serving:1.12.0-gputensorflow/serving:1.13.0tensorflow/serving:1.13.0-gputensorflow/serving:1.14.0tensorflow/serving:1.14.0-gputensorflow/tensorflow:1.8.0gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:88d864eb3c47881cf7ac058479d1c735cc3cf4f07a11aad0621cd36dcd9ae3c6gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa@sha256:a7801c3cf4edecfa51b7bd2068f97941f6714f7922cb4806245377c2b336b723gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:aeaacec4feedee309293ac21da13e71a05a2ad84b1d5fcc01ffecfa6cfbb2870gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:3b096e55fa907cff53d37dadc5d20c29cea9bb18ed9e921a588fee17beb937dfgcr.io/knative-releases/knative.dev/serving/cmd/networking/istio@sha256:057c999bccfe32e9889616b571dc8d389c742ff66f0b5516bad651f05459b7bcgcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:e0654305370cf3bbbd0f56f97789c92cf5215f752b70902eba5d5fc0e88c5acagcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:c2076674618933df53e90cf9ddd17f5ddbad513b8c95e955e45e37be7ca9e0e8gcr.io/kubeflow-images-public/centraldashboard@sha256:4299297b8390599854aa8f77e9eb717db684b32ca9a94a0ab0e73f3f73e5d8b5gcr.io/kubeflow-images-public/kfam@sha256:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0gcr.io/kubeflow-images-public/notebook-controller@sha256:6490f737000bd1d2520ac4b8cbde2b09749cdb291b1967ddda95d05131db49dbgcr.io/kubeflow-images-public/profile-controller@sha256:e601b2226e534a4f8e0722cfc44ae4a919a90265c4c6c9e7a7a55fcb57032f25 tar íŒŒì¼ë¡œ ìš©ëŸ‰ì„ ê³„ì‚°í•œ ê²°ê³¼ ì•½ 30G(no gzip option) ì¶”ê°€ë¡œ ë°œìƒí•œ ë¬¸ì œ Kubeflow ë°°í¬ ì „ istio-system ì™€ knative-serving ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì—¬ ë°°í¬í•  ë•Œ ì—ëŸ¬ê°€ ë°œìƒ í•´ê²° ë°©ì•ˆ ë°°í¬ ì „ istio-system / knative-serving ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì‚­ì œ í›„ ì¬ ë°°í¬ Ref https://github.com/kubeflow/kubeflow/issues/3859 https://github.com/kubeflow/kubeflow/issues/4788 https://github.com/kubeflow/kubeflow/issues/4718 https://github.com/kubeflow/kubeflow/issues/3900 https://stackoverflow.com/questions/54203646/kubernetes-how-to-increase-ephemeral-storage https://www.kangwoo.kr/2020/02/18/pcì—-kubeflow-ì„¤ì¹˜í•˜ê¸°-3ë¶€-kubeflow-ì„¤ì¹˜í•˜ê¸°/ 2020.03.30 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] Docker private registry ì„¤ì •","slug":"cloud-docker_registry","date":"2020-03-17T15:00:00.000Z","updated":"2020-09-26T13:34:58.520Z","comments":true,"path":"cloud-docker_registry/","link":"","permalink":"https://jx2lee.github.io/cloud-docker_registry/","excerpt":"docker private registry ë¥¼ ìƒì„±í•˜ê³ , tar íŒŒì¼ë¡œ ë³€í™˜í•œ ì´ë¯¸ì§€ë¥¼ load ë° registry ì— push í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. ì‚¬ì´íŠ¸ì— ë‚˜ê°€ê²Œ ë˜ë©´ íì‡„ë§ì¸ ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì¸ë°, ì´ëŸ´ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ì„œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ë“¤ì—¬ docker image ë¥¼ tarë¡œ ë³€í™˜í•˜ê³  registry ì— push í•˜ëŠ” ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. Update Note 2020.03.30 : docker run ì‹œ mount ë°©ë²•(-v ì˜µì…˜) ë° docker image pull / push ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ 2020.04.13 : docker run ì‹œ restart argument ì¶”ê°€","text":"docker private registry ë¥¼ ìƒì„±í•˜ê³ , tar íŒŒì¼ë¡œ ë³€í™˜í•œ ì´ë¯¸ì§€ë¥¼ load ë° registry ì— push í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. ì‚¬ì´íŠ¸ì— ë‚˜ê°€ê²Œ ë˜ë©´ íì‡„ë§ì¸ ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì¸ë°, ì´ëŸ´ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ì„œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ë“¤ì—¬ docker image ë¥¼ tarë¡œ ë³€í™˜í•˜ê³  registry ì— push í•˜ëŠ” ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. Update Note 2020.03.30 : docker run ì‹œ mount ë°©ë²•(-v ì˜µì…˜) ë° docker image pull / push ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ 2020.04.13 : docker run ì‹œ restart argument ì¶”ê°€ Private registry ìƒì„±registry ì´ë¯¸ì§€ë¥¼ Pull í•˜ê³  container ë¥¼ ê¸°ë™í•œë‹¤.12docker pull registrydocker run -dit --name bips-registry --restart=always -p 5000:5000 -v /data/registry:/var/lib/registry registry:latest -v í”Œë˜ê·¸ë¥¼ ì´ìš©í•´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥ì†Œë¥¼ /data/registry ë§ˆìš´íŠ¸ ì‹œì¼œ ì»¨í…Œì´ë„ˆë¥¼ ë™ì‘í•œë‹¤. ì´ëŠ” ì´ë¯¸ì§€ê°€ ë§ì•„ì§ˆ ê²½ìš° ìš©ëŸ‰ì´ í° ë””ë°”ì´ìŠ¤ì— ì§ì ‘ ì„¤ì •í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. --restart=alyways ì¸ìë¥¼ ì¶”ê°€í•˜ì—¬ ë„ì»¤ ë°ëª¬ ì¬ì‹œì‘ ì‹œ ê¸°ë™í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤. Image pushtar íŒŒì¼ë¡œ ë¬¶ì€ ì´ë¯¸ì§€ë¥¼ docker load -i {tar_name} ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ registry ì— push í•œë‹¤. ì›ë˜ ì´ë¯¸ì§€ : 192.168.17.131:5000/ubuntu_t6:2020303_v2 íƒœê·¸ ë³€ê²½ í›„ ì´ë¯¸ì§€ : 92.168.179.185:5000/ubuntu_t6:2020303_v2 12docker tag 192.168.17.131:5000/ubuntu_t6:2020303_v2 192.168.179.185:5000/ubuntu_t6:2020303_v2docker push 192.168.179.185:5000/ubuntu_t6:2020303_v2 Image í™•ì¸registry ì— í•´ë‹¹ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ëŠ”ì§€ curl ëª…ë ¹ì–´ë¡œ í™•ì¸í•œë‹¤.1234root@k8s-master:~# curl -X GET 192.168.179.185:5000/v2/_catalog&#123;\"repositories\":[\"dfa-module\",\"hd8.3_rel\",\"hl_r172919\",\"ubuntu_t6\"]&#125;root@k8s-master:~# curl -X GET 192.168.179.185:5000/v2/ubuntu_t6/tags/list&#123;\"name\":\"ubuntu_t6\",\"tags\":[\"2020303_v2\"]&#125; ì˜~ ë“±ë¡ë˜ì—ˆë‹¤! Docker Image Pull &amp; Push ìŠ¤í¬ë¦½íŠ¸íì‡„ë§ í™˜ê²½ì—ì„œ docker hub ì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ìƒí™©ì´ ë°œìƒí•˜ì˜€ë‹¤. ì´ë¥¼ ìœ„í•´ íì‡„ë§ì´ ì•„ë‹Œ í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ë¥¼ pull í•˜ê³ , ì´ë¥¼ íì‡„ë§ í™˜ê²½ì—ì„œ íŠ¹ì • registry (private docker registry) ì— push í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. ê¸°ëŠ¥ pull : docker hub ì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ tars ë””ë ‰í† ë¦¬ì— ì €ì¥í•œë‹¤. push : tars ë””ë ‰í† ë¦¬ì— tar ì´ë¯¸ì§€ë¥¼ íŠ¹ì • registry ì— push í•œë‹¤. 1234â¯ ./imageLoaderusage: ./imageLoader pull ./imageLoader push &#123;registry_endpoint&#125; ì´ë¯¸ì§€:íƒœê·¸ ë¡œ ì´ë£¨ì–´ì§„ .imageList ê°€ ì„ í–‰ìœ¼ë¡œ ì¤€ë¹„í•´ì•¼ í•œë‹¤. ë˜í•œ, .imageListHash ëŠ” íƒœê·¸ëª…ì´ ì•„ë‹Œ í•´ì‰¬ê°’ìœ¼ë¡œ ë˜ì–´ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë°›ì„ ë•Œ ì‚¬ìš©í•œë‹¤. ë§Œì•½ ë‘˜ ì¤‘ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì„ íƒì— ë”°ë¼ ì‚­ì œí•˜ê³  í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ì— ì£¼ì„ì„ ì„¤ì •í•œë‹¤. ì²« ë²ˆì§¸ pull/push í•˜ëŠ” ë¶€ë¶„ì´ ì´ë¯¸ì§€:íƒœê·¸, ë‘ ë²ˆì§¸ê°€ ì´ë¯¸ì§€@í•´ì‰¬ ë³¸ì¸ì€ Kubeflow ë¥¼ íì‡„ë§ í™˜ê²½ì—ì„œ ì„¤ì¹˜í•  ì´ìŠˆê°€ ìƒê²¨ í•„ìš”í•œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ .imageList / .imageListHash ì— ì‘ì„±í•˜ì˜€ë‹¤. ì°¸ê³ ë¡œ Kubeflow íì‡„ë§ ì„¤ì¹˜ ì‹œ ì´ë¯¸ì§€ ë²„ì ¼ ë•Œë¬¸ì— ì• ë¥¼ ë§ì´ ë¨¹ì—ˆë‹¤.. github ì— ì˜¬ë ¤ë‘ì—ˆë‹¤. í—ˆì ‘í•œ ìŠ¤í¬ë¦½íŠ¸ ì´ì§€ë§Œ, í˜„ ì§ì¥ì—ì„œëŠ” í¸í•˜ê²Œ(?) ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ ê³µìœ í•œë‹¤. ë§ì€ ë³„ ë¶€íƒë“œë¦½ë‹ˆë‹¤. 2020.03.18 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] Orphaned pod found ì—ëŸ¬ í•´ê²°","slug":"cloud_orphaned_pod_error","date":"2020-03-11T15:00:00.000Z","updated":"2020-09-24T14:34:50.011Z","comments":true,"path":"cloud_orphaned_pod_error/","link":"","permalink":"https://jx2lee.github.io/cloud_orphaned_pod_error/","excerpt":"ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” kubelet log ì— Orphaned pod found , but volume subpaths are still present on disk ë¡œê·¸ê°€ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.","text":"ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” kubelet log ì— Orphaned pod found , but volume subpaths are still present on disk ë¡œê·¸ê°€ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. Kubelet logjournalctl -f | grep kubelet 1Mar 12 01:31:04 k8s-node2 kubelet[19210]: E0312 01:31:04.964272 19210 kubelet_volumes.go:154] Orphaned pod \"1a2f73f1-77a2-4053-975f-57a89fdba1db\" found, but volume subpaths are still present on disk : There were a total of 1 errors similar to this. Turn up verbosity to see them. ë¬¸ì œ ì›ì¸í•´ë‹¹ ë…¸ë“œë¥¼ ì¬ë¶€íŒ…í–ˆì„ ë•Œ ê¸°ì¡´ì— ë‚¨ì•„ìˆë˜ íŒŒë“œ ì •ë³´ë¡œ ì¸í•˜ì—¬ ì—ëŸ¬ê°€ ë°œìƒí•œ ê²ƒ ê°™ë‹¤. ì‚¬ë¼ì§„ íŒŒë“œì˜ ì •ë³´ì— volume subpath ë„ ì‚­ì œë˜ì§€ ì•Šì€ ê²ƒì´ë‹¤. ë¬¸ì œ í•´ê²°ì˜ì™¸ë¡œ ê°„ë‹¨í•˜ë‹¤. í•´ë‹¹ pod ì •ë³´ë¥¼ ì‚­ì œí•˜ë©´ ë˜ëŠ”ë°, ë³¸ì¸ í™˜ê²½ìœ¼ë¡œëŠ” /var/lib/kubelet/pods/ ì— íŒŒë“œ UUID í´ë”ë¥¼ ì‚­ì œí•˜ë©´ ëœë‹¤. ì´í›„ kubelet ì„ ì¬ê¸°ë™í•˜ë©´ ìœ„ ë¡œê·¸ê°€ ì‚­ì œë¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ì™¸ ë¬¸ì œë“¤ì˜¤ëŠ˜ ìˆì—ˆë˜ ë‹¤ì–‘í•œ ì—ëŸ¬ë“¤ì„ í•œ ë²ˆ ì •ë¦¬í–ˆë‹¤ (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ì¸í•´ file stroage ë¥¼ ë°°í¬í•˜ëŠ” ë¬¸ì œëŠ” ë” íŒŒì•…í•´ë³¸ í›„ í¬ìŠ¤íŒ… í•  ì˜ˆì •ì´ë‹¤). kubelet ë¡œê·¸ì— Unable to read config path â€œ/etc/kubernetes/manifestsâ€: path does not exist, ignoring ë©”ì„¸ì§€ ë°œìƒ /etc/kubernets/path ì— manifests í´ë”ë¥¼ ìƒì„±í•˜ì—¬ í•´ê²° ë…¸ë“œì— node.kubernetes.io/unreachable:NoSchedule Taint ê°€ ê±¸ë ¤ìˆëŠ” ê²½ìš° í•´ë‹¹ ë…¸ë“œê°€ Not Ready ì¸ ìƒíƒœ ì´ëŸ° ê²½ìš°ì—ëŠ” ëŒ€ê²Œ ë…¸ë“œê°€ ì¬ë¶€íŒ… í›„ ìŠ¤ì™‘ ë©”ëª¨ë¦¬ê°€ ì¼œì ¸ ìˆì„ í™•ë¥ ì´ ë†’ë‹¤. free ëª…ë ¹ì–´ë¥¼ í†µí•´ í™•ì¸í•œ ë‹¤ìŒ swap off ì´í›„ kubelet ì„ ì¬ê¸°ë™ í•œë‹¤. 2020.03.12 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] R docker ì»¨í…Œì´ë„ˆì—ì„œ Hadoop HDFS ì—°ë™","slug":"cloud-r_hadoop_connection","date":"2020-02-19T15:00:00.000Z","updated":"2020-04-10T02:58:19.324Z","comments":true,"path":"cloud-r_hadoop_connection/","link":"","permalink":"https://jx2lee.github.io/cloud-r_hadoop_connection/","excerpt":"ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” R Container ì—ì„œ Hadoop HDFS ë°ì´í„°ë¥¼ ì—°ë™í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤.","text":"ë³¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” R Container ì—ì„œ Hadoop HDFS ë°ì´í„°ë¥¼ ì—°ë™í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. R Container ê¸°ë™R container image ë¥¼ ì´ìš©í•´ ì»¨í…Œì´ë„ˆë¥¼ ê¸°ë™í•œë‹¤. docker run -d -p 8787:8787 -e PASSWORD=tmaxtmax rocker_with_java:latest 1234root@k8s-master:~# docker rename competent_dubinsky r-hadoop-testroot@k8s-master:/app# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESaa91a42054dc rocker_with_java:latest \"/init\" 23 minutes ago Up 23 minutes 0.0.0.0:8787-&gt;8787/tcp r-hadoop-test http://{NODE_IP}:8787 ë¡œ ì ‘ì†í•˜ì—¬ rstudio/tmaxtmax ì…ë ¥í•˜ì—¬ Rstduio í™”ë©´ìœ¼ë¡œ ì´ë™í•œë‹¤. rocker_with_java image ëŠ” rocker-rstudio ì´ë¯¸ì§€ ë³´ë‹¤ ìƒìœ„ ì´ë¯¸ì§€ì¸ rocker/tidyverse ë¥¼ ì‚¬ìš©í•œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë‹¤. ì°¸ê³  R Container í™˜ê²½ì„¤ì •Hadoop ì—°ë™ì„ ìœ„í•œ Hadoop client ì™€ java ë¥¼ ì„¤ì¹˜í•œë‹¤. ë¡œì»¬ì— ìˆëŠ” hadoop client ì™€ java tar íŒŒì¼ë“¤ì„ R container ë¡œ ì˜®ê¸´ë‹¤. docker cp hadoop-client.tar r-hadoop-test:/root docker cp jdk.tar r-hadoop-test:/root R containerë¡œ ì ‘ì†í•˜ì—¬ hadoop client ë¥¼ ì„¤ì¹˜í•œë‹¤ docker exec -it r-hadoop-test /bin/bash ëª…ë ¹ì–´ ì´í›„ hadoop client ì„¤ì¹˜ ì„¤ì¹˜ í™•ì¸ 1234567891011rstudio@4935816e695d:~$ java -versionjava version \"1.8.0_241\"Java(TM) SE Runtime Environment (build 1.8.0_241-b07)Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)rstudio@aa91a42054dc:~$ hdfs versionHadoop 2.10.0Subversion ssh://git.corp.linkedin.com:29418/hadoop/hadoop.git -r e2f1f118e465e787d8567dfa6e2f3b72a0eb9194Compiled by jhung on 2019-10-22T19:10ZCompiled with protoc 2.5.0From source with checksum 7b2d8877c5ce8c9a2cca5c7e81aa4026This command was run using /app/hadoop/2.10.0/share/hadoop/common/hadoop-common-2.10.0.jar Hadoop ì—°ë™ì„ ìœ„í•œ R package ì„¤ì¹˜Hadoop ì—°ë™ì„ ìœ„í•œ R íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤. R Studio ì—ì„œ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ ì´ìš©í•´ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤. HADOOP_CMDì™€ JAVA_HOME ì€ ê° í™˜ê²½ì— ë§ëŠ” PATH ë¡œ ë³€ê²½í•˜ì—¬ ìˆ˜í–‰í•œë‹¤. 12345678library(devtools)library(rJava)install_github(c(\"RevolutionAnalytics/rmr2/pkg\", \"RevolutionAnalytics/plyrmr2/pkg\"))Sys.setenv(HADOOP_CMD=\"/app/hadoop/2.10.0/bin/hadoop\")Sys.setenv(JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\")install_github(\"RevolutionAnalytics/rhdfs/pkg\") Packeges ê´€ë¦¬ í™”ë©´ì— ì„¤ì¹˜ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. R - Hadoop ì—°ë™R í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê³  HDFS ì— ì ‘ê·¼í•˜ì—¬ ëª©ë¡ê³¼ ë°ì´í„° ì¼ë¶€ë¥¼ í™•ì¸í•œë‹¤. rhdfs / rmr2 íŒ¨í‚¤ì§€ë¥¼ í™œì„±í™” ì‹œí‚¤ê³  hdfs ê°ì²´ë¥¼ ì´ˆê¸°í™”í•œë‹¤. 1234library(rmr2)library(rhdfs)hdfs.init() hdfs.ls / hdfs.cat í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë””ë ‰í† ë¦¬ ëª©ë¡ê³¼ ë°ì´í„° ì¼ë¶€ë¥¼ í™•ì¸í•œë‹¤. 1234567hdfs.ls(\"/user/spark\")hdfs.cat(\"/user/spark/test.csv\")&gt; hdfs.ls(\"/user/spark\") permission owner group size modtime file1 drwxr-xr-x spark supergroup 0 2020-02-19 05:02 /user/spark/.sparkStaging2 -rw-r--r-- rstudio supergroup 970491 2020-02-19 09:52 /user/spark/test.csv (ì°¸ê³ ) R - Hadoop ì—°ë™ (REST API ë°©ì‹)ì´ì „ì˜ ë°©ë²•ì€ R container ì— hadoop client ë¥¼ ì´ìš©í•´ ì—°ë™í•˜ì˜€ë‹¤. ë˜ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œì¨ hadoop ì—ì„œ ì œê³µí•˜ëŠ” REST API ë¥¼ ì´ìš©í•´ Rê³¼ ì—°ë™í•˜ëŠ” ë°©ë²•ì´ë‹¤. R package httr ì„ ì„¤ì¹˜í•œë‹¤. install.packages(&quot;httr&quot;) hadoop URI ë³€ìˆ˜ë¥¼ ìƒì„±í•œë‹¤. í˜•íƒœëŠ” http://namenodedns:port/webhdfs/v1/user/username/myfile.csv?user.name=MYUSERNAME&amp;op=OPEN ìœ¼ë¡œ hadoop ì„¤ì •ì— ë§ê²Œë” ë³€ê²½í•œë‹¤. 123456hdfsUri=\"http://192.168.179.178:50070/webhdfs/v1\"fileUri=\"/user/spark/test.csv\"readParameter=\"?user.name=\"usernameParameter=\"spark&amp;\"optionnalParameters=\"op=OPEN\"uri &lt;- paste0(hdfsUri, fileUri, readParameter, usernameParameter, optionnalParameters) URI í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìƒë‹¨ ë¶€ë¶„ (head) ì„ í™•ì¸í•œë‹¤. 12data = read.csv(uri)head(data)) Reference https://github.com/RevolutionAnalytics/RHadoop/wiki/Installing-RHadoop-on-RHEL https://niceguy1575.tistory.com/40 https://hub.docker.com/r/rocker/tidyverse https://github.com/gadenbuie/docker-tidyverse-rjava/blob/master/Dockerfile https://wikidocs.net/52630 2020.02.20 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] Elasticsearch ë°°í¬ on K8s","slug":"cloud-deploy_es","date":"2020-02-06T15:00:00.000Z","updated":"2020-09-24T14:35:37.607Z","comments":true,"path":"cloud-deploy_es/","link":"","permalink":"https://jx2lee.github.io/cloud-deploy_es/","excerpt":"toy projectë¥¼ ìœ„í•´ esë¥¼ êµ¬ì¶•í•˜ë ¤ë˜ ì°°ë‚˜, ì‚¬ë‚´ì— K8s clusterë¥¼ êµ¬ì¶•í•˜ì˜€ë‹¤. í´ë¼ìš°ë“œ ê³µë¶€ ê²¸ Elasticsearchì™€ kibanaë¥¼ K8sì— ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤","text":"toy projectë¥¼ ìœ„í•´ esë¥¼ êµ¬ì¶•í•˜ë ¤ë˜ ì°°ë‚˜, ì‚¬ë‚´ì— K8s clusterë¥¼ êµ¬ì¶•í•˜ì˜€ë‹¤. í´ë¼ìš°ë“œ ê³µë¶€ ê²¸ Elasticsearchì™€ kibanaë¥¼ K8sì— ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤ Elasticsearch ë°°í¬í•˜ê¸°3-nodeë¡œ êµ¬ì„±ëœ elasticsearch í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•œë‹¤. í•œ ê°œì˜ ë…¸ë“œë¡œë§Œ êµ¬ì„±ë  ê²½ìš° ì¥ì• ê°€ ë°œìƒí•˜ë©´ ê³ ê°€ìš©ì„±ì„ í™•ë³´í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì´ì™€ ê°™ì´ 3ê°œ ë…¸ë“œë¡œ êµ¬ì„±ëœ í´ëŸ¬ìŠ¤íŠ¸ë¥¼ ë°°í¬í•¨ìœ¼ë¡œì¨ split-brainì„ í”¼í•˜ê³ ì í•œë‹¤.Namespace ìƒì„±elastic_ns.yamlì„ ì‘ì„±í•˜ê³  namespaceë¥¼ ìƒì„±í•œë‹¤ kubectl create -f elastic_ns.yaml elastic_ns.yaml 1234kind: NamespaceapiVersion: v1metadata: name: elasticsearch Service ìƒì„±elastic_svc.yamlì„ ì‘ì„±í•˜ê³  serviceë¥¼ ìƒì„±í•œë‹¤ kubectl create -f elastic_svc.yaml elastic_svc.yaml 12345678910111213141516kind: ServiceapiVersion: v1metadata: name: elastic-svc namespace: elastic labels: app: elasticsearchspec: type: NodePort selector: app: elasticsearch ports: - port: 9200 name: rest - port: 9300 name: inter-node kubectl get service -n {namespace-name}ìœ¼ë¡œ ì„œë¹„ìŠ¤ ìƒì„±ì„ í™•ì¸í•œë‹¤ 123root@k8s-master:~/jlee/elastic# kg svc -n elasticNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelastic-svc NodePort 10.96.42.114 &lt;none&gt; 9200:30117/TCP,9300:30395/TCP 56m ê¸°ì¡´ ì‚¬ì´íŠ¸ì—ì„œ ì†Œê°œí•œ serviceì™€ëŠ” ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ ì‘ì„±í•˜ì˜€ë‹¤. í´ëŸ¬ìŠ¤í„°ì— ë°°ë³´ëœ es nodeì— ì ‘ì†í•˜ê¸° ìœ„í•´ì„œëŠ” serviceì˜ íƒ€ì…ì„ NodePortë¡œ ì„¤ì •í•˜ì˜€ë‹¤. NodePortë¡œ ì„¤ì •í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´í›„ì— curl í•˜ëŠ” ëª…ë ¹ì´ connected refused ë  ê²ƒì´ë‹¤, K8s Service ì •ë¦¬ê°€ í•„ìš”! StatefulSet ìƒì„±elastic_statefulset.yamlì„ ì‘ì„±í•˜ê³  StatefulSetì„ ìƒì„±í•œë‹¤ StatefulSetì´ë€, ìƒíƒœë¥¼ ê°€ì§€ê³  ìˆëŠ” Podë“¤ì„ ê´€ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ ìˆœì„œë¥¼ ì§€ì •í•˜ì—¬ Podë¥¼ ì‹¤í–‰í•˜ê³  volumeì„ ì§€ì •í•˜ì—¬ Podê°€ ë‚´ë ¤ê°€ë„ ì •ë³´ë¥¼ ìƒì§€ ì•Šê²Œ í•œë‹¤ kubectl create -f elastic_statefulset.yaml elastic_statefulset.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677apiVersion: apps/v1kind: StatefulSetmetadata: name: es-cluster namespace: elastic # namepsace name for elasticsearchspec: serviceName: elasticsearch # service name for elasticsearch replicas: 3 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: docker.elastic.co/elasticsearch/elasticsearch:7.5.2 resources: limits: cpu: 1000m requests: cpu: 100m ports: - containerPort: 9200 name: rest protocol: TCP - containerPort: 9300 name: inter-node protocol: TCP volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data env: - name: cluster.name value: k8s-elastic - name: node.name valueFrom: fieldRef: fieldPath: metadata.name - name: discovery.seed_hosts value: \"es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch\" # hostname for each container - name: cluster.initial_master_nodes value: \"es-cluster-0,es-cluster-1,es-cluster-2\" # node name in es-cluster - name: ES_JAVA_OPTS value: \"-Xms512m -Xmx512m\" initContainers: - name: fix-permissions image: busybox command: [\"sh\", \"-c\", \"chown -R 1000:1000 /usr/share/elasticsearch/data\"] securityContext: privileged: true volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data - name: increase-vm-max-map image: busybox command: [\"sysctl\", \"-w\", \"vm.max_map_count=262144\"] securityContext: privileged: true - name: increase-fd-ulimit image: busybox command: [\"sh\", \"-c\", \"ulimit -n 65536\"] securityContext: privileged: true volumeClaimTemplates: - metadata: name: data labels: app: elasticsearch spec: accessModes: [ \"ReadWriteOnce\" ] storageClassName: rook-ceph-block # your storageclass resources: requests: storage: 10Gi kubectl get pods -n elasticìœ¼ë¡œ ìƒì„±í•œ íŒŒë“œë¥¼ í™•ì¸í•œë‹¤. 12345root@k8s-master:~/jlee/elastic# kgpo -n elasticNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 159mes-cluster-1 1/1 Running 0 158mes-cluster-2 1/1 Running 0 158m Check Statusì •ìƒì ìœ¼ë¡œ ES ë…¸ë“œê°€ ë°°í¬ë˜ì—ˆëŠ”ì§€ kubectl get svc -n elasticì„ í†µí•´ í™•ì¸ëœ í¬íŠ¸ë¡œ (9200ì— í¬íŠ¸í¬ì›Œë”© ëœ í¬íŠ¸ í™•ì¸) curl ëª…ë ¹ì„ ìˆ˜í–‰í•œë‹¤. curl http://{ip}:{port} 123456789101112131415161718root@k8s-master:~/jlee/elastic# curl http://192.168.179.172:30117&#123; \"name\" : \"es-cluster-2\", \"cluster_name\" : \"k8s-elastic\", \"cluster_uuid\" : \"GqGwbyKYSfGZoEcqFumVzw\", \"version\" : &#123; \"number\" : \"7.2.0\", \"build_flavor\" : \"default\", \"build_type\" : \"docker\", \"build_hash\" : \"508c38a\", \"build_date\" : \"2019-06-20T15:54:18.811730Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.0.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; Kibana ë°°í¬í•˜ê¸°Kibana ë°°í¬ì— ê²½ìš° Serviceì™€ Deploymentê°€ ëª…ì‹œëœ yaml íŒŒì¼ì„ ìƒì„±í•˜ê³  ë°°í¬í•˜ë©´ ëœë‹¤. ìœ„ì™€ ê°™ì€ ì„œë¹„ìŠ¤ ë°©ì‹ì¸ NodePortë¡œ ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•˜ê³  í¬íŠ¸ë²ˆí˜¸ 5601ë§Œ ëª…ì‹œí•´ì£¼ë©´ ë…¸ë“œí¬íŠ¸ í˜•ì‹ì˜ ì„œë¹„ìŠ¤ê°€ í¬íŠ¸ í¬ì›Œë”©ì„ ìˆ˜í–‰í•˜ì—¬ ì›¹ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆë‹¤.kubectl create -f kibana.yaml kibana.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: v1kind: Servicemetadata: name: kibana namespace: elastic labels: app: kibanaspec: type: NodePort ports: - port: 5601 selector: app: kibana---apiVersion: apps/v1kind: Deploymentmetadata: name: kibana namespace: elastic labels: app: kibanaspec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: docker.elastic.co/kibana/kibana:7.2.0 resources: limits: cpu: 1000m requests: cpu: 100m env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 ports: - containerPort: 5601 Check Statusì •ìƒì ìœ¼ë¡œ Kibana ê°€ ë°°í¬ë˜ì—ˆëŠ”ì§€ kubectl get svc -n elasticì„ í†µí•´ í™•ì¸ëœ í¬íŠ¸ë¡œ (9200ì— í¬íŠ¸í¬ì›Œë”© ëœ í¬íŠ¸ í™•ì¸) curl ëª…ë ¹ì„ ìˆ˜í–‰í•œë‹¤. curl http://{ip}:{port} Reference How To Set Up an Elasticsearch, Fluentd and Kibana (EFK) Logging Stack on Kubernetes Elasticsearchì™€ Kibana, filebeat ë¥¼ í™œìš©í•œ ì¿ ë²„ë„¤í‹°ìŠ¤ ë¡œê¹… ì•„í‚¤í…ì³ 2020.02.06 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] rook-cephì„ ì´ìš©í•œ Ceph cluster êµ¬ì„±","slug":"cloud-install_rook_ceph","date":"2020-02-05T15:00:00.000Z","updated":"2020-03-30T15:06:23.567Z","comments":true,"path":"cloud-install_rook_ceph/","link":"","permalink":"https://jx2lee.github.io/cloud-install_rook_ceph/","excerpt":"K8s í´ëŸ¬ìŠ¤í„° ë‚´ rook-cephì„ ì´ìš©í•œ Ceph clusterë¥¼ êµ¬ì„±í•œë‹¤. Update Note 2020.03.30 : yaml íŒŒì¼ì´ í¬í•¨ëœ github ì£¼ì†Œ ì¶”ê°€","text":"K8s í´ëŸ¬ìŠ¤í„° ë‚´ rook-cephì„ ì´ìš©í•œ Ceph clusterë¥¼ êµ¬ì„±í•œë‹¤. Update Note 2020.03.30 : yaml íŒŒì¼ì´ í¬í•¨ëœ github ì£¼ì†Œ ì¶”ê°€ Architecture rook-cephì€ Ceph í´ëŸ¬ìŠ¤í„° ë° ë‹¤ë¥¸ componentë“¤ì„ CRD(Custom Resource Definition)ìœ¼ë¡œ ê´€ë¦¬í•˜ë©° CRDì˜ ë³€ê²½ì‚¬í•­ì„ Rook Operatorë¥¼ ì´ìš©í•´ ì¼ê´„ ì ìš©í•  ìˆ˜ ìˆë‹¤ ì„¤ì¹˜ ìˆœì„œì•„ë˜ ìˆœì„œì™€ ê°™ì´ ì„¤ì¹˜ë¥¼ ì§„í–‰ íŠ¹ì • ìœ„ì¹˜ì— git repositoryë¥¼ clone í•œë‹¤. ì´í›„ common.yaml, operator.yaml ì„ ì´ìš©í•´ rook-cephì—ì„œ ì œê³µí•˜ëŠ” CRDì™€ operatorë¥¼ ìƒì„±í•œë‹¤. 123git clone https://github.com/rook/rook.gitcd /rook/cluster/example/kubenetes/cephfskubectl apply -f common.yamlkubectl apply -f operator.yaml ceph_config_override.yaml ê³¼ cluster.yaml ì„ ì´ìš©í•´ configmapì„ ìƒì„±í•˜ê³  clusterë¥¼ êµ¬ì„±í•œë‹¤. 12kubectl apply -f ceph_config_override.yamlkubectl apply -f cluster.yaml ceph_config_override.yaml 12345678910apiVersion: v1kind: ConfigMapmetadata: name: rook-config-override namespace: rook-cephdata: config: | [global] mon osd down out interval = &#123;osd_down_out_interval&#125; mon clock drift allowed = 0.2 cluster.yaml 12345678910111213141516171819202122232425262728293031323334353637apiVersion: ceph.rook.io/v1kind: CephClustermetadata: name: rook-ceph namespace: rook-cephspec: cephVersion: image: ceph/ceph:v14.2.4-20190917 allowUnsupported: true dataDirHostPath: /var/lib/rook skipUpgradeChecks: false mon: count: 1 # Recommendation: Use odd numbers (ex. 3, 5) dashboard: enabled: true ssl: true monitoring: enabled: false # Require Prometheus to be pre-installed rulesNamespace: rook-ceph network: hostNetwork: false rbdMirroring: workers: 0 mgr: modules: # The pg_autoscaler is only available on nautilus or newer. remove this if testing mimic. - name: pg_autoscaler enabled: true storage: useAllNodes: true # Apply ceph-osd to all nodes. useAllDevices: false deviceFilter: config: journalSizeMB: \"1024\" # This value can be removed for environments with normal sized disks (20 GB or larger) osdsPerDevice: \"1\" # This value can be overridden at the node or device level directories: - path: /var/lib/rook toolbox.yaml ì„ ì´ìš©í•´ ceph í´ëŸ¬ìŠ¤í„° ì´ìš©ì„ ìœ„í•œ clientë¥¼ ì„¤ì¹˜í•œë‹¤ kubectl apply -f toolbox.yaml block_pool.yaml ê³¼ file_system.yamlì„ ì´ìš©í•´ block / file storage ë°°í¬ ì¤€ë¹„ 12kubectl apply -f block_pool.yamlkubectl apply -f file_system.yaml block_pool.yaml 123456789apiVersion: ceph.rook.io/v1kind: CephBlockPoolmetadata: name: replicapool namespace: rook-cephspec: failureDomain: host replicated: size: 2 file_system.yaml 12345678910111213141516171819apiVersion: ceph.rook.io/v1kind: CephFilesystemmetadata: name: myfs namespace: rook-cephspec: metadataPool: # failureDomain - values are possible for 'osd' and 'host' failureDomain: host # ceph-osd must exist equal or more than replicated size replicated: size: 2 dataPools: # failureDomain - values are possible for 'osd' and 'host' - failureDomain: host # ceph-osd must exist equal or more than replicated size replicated: size: 2 metadataServer: activeCount: 1 activeStandby: true ë§ˆì§€ë§‰ìœ¼ë¡œ block_sc.yaml ê³¼ file_sc.yamlì„ ì´ìš©í•´ ê° block / file storageclassë¥¼ ìƒì„±í•œë‹¤ 12kubectl apply -f block_sc.yamlkubectl apply -f file_sc.yaml block_sc.yaml 1234567891011121314151617181920212223242526272829apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: rook-ceph-blockprovisioner: rook-ceph.rbd.csi.ceph.comparameters: # clusterID is the namespace where the rook cluster is running # If you change this namespace, also change the namespace below where the secret namespaces are defined clusterID: rook-ceph # Ceph pool into which the RBD image shall be created pool: replicapool # RBD image format. Defaults to \"2\". imageFormat: \"2\" # RBD image features. Available for imageFormat: \"2\". CSI RBD currently supports only `layering` feature. imageFeatures: layering # The secrets contain Ceph admin credentials. These are generated automatically by the operator # in the same namespace as the cluster. csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph # Specify the filesystem type of the volume. If not specified, csi-provisioner # will set default as `ext4`. csi.storage.k8s.io/fstype: ext4# uncomment the following to use rbd-nbd as mounter on supported nodes file_sc.yaml 1234567891011121314151617181920212223242526272829303132333435apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: csi-cephfs-scprovisioner: rook-ceph.cephfs.csi.ceph.comparameters: # clusterID is the namespace where operator is deployed. clusterID: rook-ceph # CephFS filesystem name into which the volume shall be created fsName: myfs # Ceph pool into which the volume shall be created # Required for provisionVolume: \"true\" pool: myfs-data0 # Root path of an existing CephFS volume # Required for provisionVolume: \"false\" # rootPath: /absolute/path # The secrets contain Ceph admin credentials. These are generated automatically by the operator # in the same namespace as the cluster. csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph # (optional) The driver can use either ceph-fuse (fuse) or ceph kernel client (kernel) # If omitted, default volume mounter will be used - this is determined by probing for ceph-fuse # or by setting the default mounter explicitly via --volumemounter command-line argument. # mounter: kernelreclaimPolicy: DeletemountOptions: # uncomment the following line for debugging #- debug ìœ„ ë‹¨ê³„ë¥¼ ê±°ì¹˜ê³  ë‚œ ë’¤ rook-ceph namespaceì˜ podì™€ storageclass ë¥¼ í™•ì¸í•œë‹¤ kubectl get pods -n rook-ceph 12345678910111213141516171819202122232425262728293031323334root@k8s-master:~/jlee/rook-ceph-master# kubectl get pods -n rook-cephNAME READY STATUS RESTARTS AGEcsi-cephfsplugin-7kz7v 3/3 Running 0 4d19hcsi-cephfsplugin-9rt7t 3/3 Running 0 4d19hcsi-cephfsplugin-dnggh 3/3 Running 0 4d19hcsi-cephfsplugin-provisioner-974b566d9-7k2rb 4/4 Running 0 4d19hcsi-cephfsplugin-provisioner-974b566d9-kxg2f 4/4 Running 0 4d19hcsi-cephfsplugin-xzt9b 3/3 Running 0 4d19hcsi-rbdplugin-2npvg 3/3 Running 0 4d19hcsi-rbdplugin-drzkp 3/3 Running 0 4d19hcsi-rbdplugin-hhsm5 3/3 Running 0 4d19hcsi-rbdplugin-provisioner-579c546f5-qprb8 5/5 Running 0 4d19hcsi-rbdplugin-provisioner-579c546f5-svhlw 5/5 Running 0 4d19hcsi-rbdplugin-qhsw6 3/3 Running 0 4d19hrook-ceph-mds-myfs-a-58ddc89fc8-s4f44 1/1 Running 0 4d19hrook-ceph-mds-myfs-b-85dc7c7cf4-x68lk 1/1 Running 0 4d19hrook-ceph-mgr-a-69df8d6794-glbjb 1/1 Running 0 4d19hrook-ceph-mon-a-7b9cb64846-zfbwf 1/1 Running 0 4d19hrook-ceph-mon-b-7fc7c8fbb4-75j9j 1/1 Running 0 4d19hrook-ceph-mon-c-6c59c89fbc-rn8nv 1/1 Running 0 4d19hrook-ceph-operator-7985c4b57d-8qtht 1/1 Running 0 4d19hrook-ceph-osd-0-55888686c-pf6wn 1/1 Running 0 4d19hrook-ceph-osd-1-f56d885d4-tnrmv 1/1 Running 0 4d19hrook-ceph-osd-2-68f99d999f-zlrl4 1/1 Running 0 4d19hrook-ceph-osd-3-7545f4df9b-ng4tf 1/1 Running 0 4d19hrook-ceph-osd-prepare-k8s-node1-msfs9 0/1 Completed 0 4d19hrook-ceph-osd-prepare-k8s-node2-z858m 0/1 Completed 0 4d19hrook-ceph-osd-prepare-k8s-node3-lwh4c 0/1 Completed 0 4d19hrook-ceph-osd-prepare-k8s-node4-w8rfw 0/1 Completed 0 4d19hrook-ceph-tools-8648fbb998-5q7v2 1/1 Running 0 4d19hrook-discover-85fzl 1/1 Running 0 4d19hrook-discover-djj97 1/1 Running 0 4d19hrook-discover-p7cwx 1/1 Running 0 4d19hrook-discover-zvn5f 1/1 Running 0 4d19h kubectl get storageclass 1234root@k8s-master:~# kubectl get storageclassNAME PROVISIONER AGEcsi-cephfs-sc rook-ceph.cephfs.csi.ceph.com 16hrook-ceph-block rook-ceph.rbd.csi.ceph.com 16h ìœ„ ì–¸ê¸‰í•œ yaml íŒŒì¼ì€ github ì— ì˜¬ë ¤ ë‘ì—ˆë‹¤. https://github.com/jaejuning/rook-ceph-deploy Ceph cluster ìƒíƒœ í™•ì¸ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆë‹¤ë©´ êµ¬ì¶•í•œ ceph clusterê°€ ì •ìƒ êµ¬ë™ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì—¬ì•¼ í•œë‹¤. toolbox pod ë¥¼ í†µí•´ pod ë„¤ì„ì„ í™•ì¸í•œë‹¤kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot; 123root@k8s-master:~# kubectl -n rook-ceph get pod -l \"app=rook-ceph-tools\"NAME READY STATUS RESTARTS AGErook-ceph-tools-8648fbb998-dzbbd 1/1 Running 0 15h í™•ì¸ëœ pod ë„¤ì„ì„ í†µí•´ exec ëª…ë ¹ì–´ë¡œ í•´ë‹¹ ì»¨í…Œì´ë„ˆë¡œ ì ‘ì† kubectl exec -it -n rook-ceph [ìœ„ ê²°ê³¼ë¡œ ë‚˜ì˜¨ pod NAME] -- /bin/bash Ceph cluster ìƒíƒœ í™•ì¸ceph -s 12345678910111213141516[root@k8s-node3 /] ceph -s cluster: id: 9d3a534e-797f-4659-af8d-4bfb5f60f76c health: HEALTH_OK services: mon: 1 daemons, quorum a (age 16h) mgr: a(active, since 15h) mds: myfs:1 &#123;0=myfs-a=up:active&#125; 1 up:standby-replay osd: 2 osds: 2 up (since 15h), 2 in (since 15h) data: pools: 3 pools, 24 pgs objects: 537 objects, 1.4 GiB usage: 53 GiB used, 45 GiB / 98 GiB avail pgs: 24 active+clean Ceph cluster disk í™•ì¸ceph df 1234567891011[root@k8s-node3 /] ceph dfRAW STORAGE: CLASS SIZE AVAIL USED RAW USED %RAW USED ssd 98 GiB 45 GiB 53 GiB 53 GiB 53.87 TOTAL 98 GiB 45 GiB 53 GiB 53 GiB 53.87 POOLS: POOL ID STORED OBJECTS USED %USED MAX AVAIL replicapool 1 1.4 GiB 509 1.4 GiB 3.50 19 GiB myfs-metadata 2 2.2 KiB 28 2.2 KiB 0 19 GiB myfs-data0 3 0 B 0 0 B 0 19 GiB RBD image ì‚¬ìš©ëŸ‰rbd du -p replicapoll 12345678NAME PROVISIONED USED csi-vol-22712573-4815-11ea-9f90-aea9eb69a9f1 10 GiB 344 MiB csi-vol-6d1536b2-47fc-11ea-9f90-aea9eb69a9f1 10 GiB 300 MiB csi-vol-d38c964b-4814-11ea-9f90-aea9eb69a9f1 10 GiB 404 MiB csi-vol-d4745340-4814-11ea-9f90-aea9eb69a9f1 10 GiB 396 MiB csi-vol-d4937470-4814-11ea-9f90-aea9eb69a9f1 20 GiB 244 MiB csi-vol-d4a291d9-4814-11ea-9f90-aea9eb69a9f1 20 GiB 400 MiB &lt;TOTAL&gt; 80 GiB 2.0 GiB reclaimPolicyë¥¼ Retainìœ¼ë¡œ ì„¤ì •í•  ê²½ìš°, pvë¥¼ ì§€ì›Œë„ RBD imageê°€ ceph clusterì— ë‚¨ê²Œ ë˜ëŠ”ë°, ì´ ê²½ìš°ì—ëŠ” rbd ls, rbd rm ë“±ì„ í†µí•´ rbd ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê³  ì‚­ì œí•´ì•¼ í•œë‹¤. Troubleshootingë‚´ ê²½ìš° í´ëŸ¬ìŠ¤í„°ì˜ í•œ ë…¸ë“œì—ì„œ csi-rbdplugin podê°€ ìƒì„±ë˜ì§€ ì•Šê³  CrashLoopBack ì´ ê±¸ë¦¬ëŠ” í˜„ìƒì´ ë°œìƒí•˜ì˜€ë‹¤. ë…¸ë“œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•˜ì—¬ ìš°íšŒí•˜ëŠ” ë°©ì•ˆìœ¼ë¡œ í•´ë‹¹ ë…¸ë“œì— íŒŒë“œê°€ ì„¤ì •ë˜ì§€ ì•Šê²Œ taint ì¡°ê±´ì„ ì¶”ê°€í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤. kubectl taint nodes {csi-rbdplugin podë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ëŠ” ë…¸ë“œ} key=value:NoSchedule- ì´í›„ì— rook-ceph clusterë¥¼ ì¬ êµ¬ì¶•í•˜ë©´ csi-rbdpluginì´ ì •ìƒ ì‘ë™í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 2020.02.06 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] Terminating Stateì— ë¹ ì§„ Namespace ì‚­ì œ","slug":"cloud-delete_ns_at_terminating_state","date":"2020-02-03T15:00:00.000Z","updated":"2020-09-24T14:34:59.240Z","comments":true,"path":"cloud-delete_ns_at_terminating_state/","link":"","permalink":"https://jx2lee.github.io/cloud-delete_ns_at_terminating_state/","excerpt":"K8s namespaceë¥¼ ì‚­ì œí•˜ë‹¤ë³´ë©´ stateê°€ Terminatingì´ë©´ì„œ get namespace ê²°ê³¼ì— ê³„ì† ë‚¨ì•„ìˆëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤. Updata Note 2020.03.13 : Advanced ì¶”ê°€ (shell script)","text":"K8s namespaceë¥¼ ì‚­ì œí•˜ë‹¤ë³´ë©´ stateê°€ Terminatingì´ë©´ì„œ get namespace ê²°ê³¼ì— ê³„ì† ë‚¨ì•„ìˆëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤. Updata Note 2020.03.13 : Advanced ì¶”ê°€ (shell script) ë¬¸ì œ ë°œìƒrook-ceph ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•˜ë‹¤ ì‚­ì œí•˜ë©´ì„œ ì•„ë˜ì™€ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ë‹¤ 123456789$ kubectl get nsNAME STATUS AGEdefault Active 2d21histio-system Active 6h40mknative-serving Active 6h40mkube-node-lease Active 2d21hkube-public Active 2d21hkube-system Active 2d21hrook-ceph Terminating 16m Terminating ì¤‘ì¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í•œ ë²ˆ ë” ì§€ìš°ëŠ” ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤. 1Error from server (Conflict): Operation cannot be fulfilled on namespaces \"rook-ceph\": The system is ensuring all content is removed from this namespace. Upon completion, this namespace will automatically be purged by the system. ë¬¸ì œ í•´ê²°í•´ë‹¹ Namespaceì˜ yaml íŒŒì¼ì„ ì‚´í´ë³´ë©´, .spec/finalizers ë¶€ë¶„ì— Kubernetesë¼ ëª…ì‹œë˜ì–´ ìˆë‹¤. ì´ë¥¼ ë¹ˆ ê³µë°±ìœ¼ë¡œ ë°”ê¾¸ê³  ì ìš©í•˜ëŠ” ìˆœì„œë¡œ ì§„í–‰í•œë‹¤. jq íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  (apt get install jq) ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•œë‹¤.kubectl get namespace $NAMESPACE -o json |jq &#39;.spec = {&quot;finalizers&quot;:[]}&#39; &gt; temp.json ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•œ ë””ë ‰í† ë¦¬ì— temp.jsonì´ ìƒì„±ë˜ëŠ”ë°, ì´ë¥¼ yaml íŒŒì¼ë¡œ ì ìš©í•  ê²ƒì´ë‹¤. ì´ë•Œ í•„ìš”í•œ Ip/portë¥¼ ì•„ë˜ ëª…ë ¹ì–´ë¡œ í™•ì¸í•œë‹¤.kubectl proxy &amp; curl ëª…ë ¹ì–´ë¡œ ìˆ˜ì •ì‚¬í•­ì„ ë°˜ì˜í•œë‹¤.curl -k -H &quot;Content-Type: application/json&quot; -X PUT --data-binary @temp.json http://127.0.0.1:8001/api/v1/namespaces/{Namespace-name}/finalize 12345678$ kubectl get namespacesNAME STATUS AGEdefault Active 2d21histio-system Active 6h43mknative-serving Active 6h43mkube-node-lease Active 2d21hkube-public Active 2d21hkube-system Active 2d21h (Advanced) Shell scriptì´ëŸ° ì—ëŸ¬ê°€ ë°œìƒí•  ë•Œë§ˆë‹¤ ì¼ì¼ì´ ì°¾ê¸° ê·€ì°®ì•„ì„œ ì‰˜ ìŠ¤í¬ë¦½íŠ¸ ê³µë¶€ë„ í•  ê²¸ deleteNS.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ êµ¬í˜„í•˜ì˜€ë‹¤. 123456789#! /bin/bash# delete namespacesNS=$1kubectl get namespace $NS -o json |jq '.spec = &#123;\"finalizers\":[]&#125;' &gt; temp.jsonkubectl proxy &amp;curl -k -H \"Content-Type: application/json\" -X PUT --data-binary @temp.json http://127.0.0.1:8001/api/v1/namespaces/$NS/finalizekill %1 &amp;&amp; rm tmp.json # proxy process ë¥¼ ë‹¤ìš´í•˜ê³  tmp.json íŒŒì¼ì„ ì‚­ì œ Reference Delete Namespace Stuck At Terminating State, https://nasermirzaei89.net/2019/01/27/delete-namespace-stuck-at-terminating-state/ 2020.02.04 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] K8s cluster node ì¶”ê°€ ë° ì‚­ì œ","slug":"cloud-manage_node","date":"2020-01-28T15:00:00.000Z","updated":"2020-03-30T15:06:23.543Z","comments":true,"path":"cloud-manage_node/","link":"","permalink":"https://jx2lee.github.io/cloud-manage_node/","excerpt":"K8s í´ëŸ¬ìŠ¤í„°ì— ë…¸ë“œë¥¼ ì¶”ê°€ ë° ì‚­ì œí•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Update Node 2020.03.10 : kubectl drain ì„¤ëª… ì¶”ê°€","text":"K8s í´ëŸ¬ìŠ¤í„°ì— ë…¸ë“œë¥¼ ì¶”ê°€ ë° ì‚­ì œí•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Update Node 2020.03.10 : kubectl drain ì„¤ëª… ì¶”ê°€ ìƒíƒœ í™•ì¸kubectl get nodesë¡œ ë…¸ë“œ ìƒíƒœë¥¼ í™•ì¸í•œë‹¤ 12345678root@k8s-master:~# kubectl get nodesNAME STATUS ROLES AGE VERSIONai.bips NotReady &lt;none&gt; 11m v1.15.3bigdata-svr Ready &lt;none&gt; 8m24s v1.15.3k8s-master Ready master 6d17h v1.15.3k8s-node1 Ready master 6d17h v1.15.3k8s-node2 Ready master 6d17h v1.15.3k8s-node3 Ready &lt;none&gt; 4m14s v1.15.3 k8s-node3 ë…¸ë“œë¥¼ ì‚­ì œí•˜ê³  ì¶”ê°€í•´ë³´ë„ë¡ í•˜ì Delete (k8s-master) &amp; Reset (k8s-node3)ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ k8s-node3ë¥¼ delete í•œë‹¤ 12$ kubectl delete node k8s-node3node \"k8s-node3\" deleted kubectl delete ë§ê³  kubectl drain {node_name} ì„ ìˆ˜í–‰í•˜ë©´ ì´ë¯¸ ë„ì›Œì ¸ìˆëŠ” í•´ë‹¹ ë…¸ë“œì˜ íŒŒë“œë“¤ì„ í´ëŸ¬ìŠ¤í„° ë‚´ ë‹¤ë¥¸ ë…¸ë“œë¡œ ì´ë™ì‹œí‚¤ëŠ” ëª…ë ¹ì´ë‹¤. delete ë³´ë‹¤ drainì„ ìˆ˜í–‰í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì œì™¸ì‹œí‚¤ëŠ” ê²ƒì´ ê´€ë¦¬ì— ë” ìš©ì´í•  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ì´í›„, ì‚­ì œí•œ ë…¸ë“œì—ì„œ kubeadmì„ í†µí•´ reset í•œë‹¤. resetì„ í•˜ê²Œë˜ë©´ ì´í›„ ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ k8s-node3ê°€ ì‚­ì œë˜ì—ˆìŒì„ í™•ì¸í•œë‹¤ kubeadm reset reset í•˜ì§€ ì•Šìœ¼ë©´ ì´ì „ ì •ë³´ê°€ ë‚¨ì•„ìˆì–´ ì¶”í›„ì— join ìˆ˜í–‰ ì‹œ error ë°œìƒ In master node,kubeadm init ì„ í†µí•´ ìƒì„±ëœ í† í°ì„ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ 3ê°œ ë§ˆìŠ¤í„° ì¤‘ í•œ ëŒ€ ë…¸ë“œì—ì„œ token ì„ í™•ì¸í•œë‹¤ kubeadm token list 12345TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS4e3bad.gzp017frj86g4ngi 23h 2020-01-30T01:53:56Z authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-tokeneo7vb4.3ck3l5ja3ry78bef &lt;invalid&gt; 2020-01-23T08:03:36Z authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-tokenm8470a.r8fo1tbwmdhb39eo 22h 2020-01-30T00:58:34Z authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-tokensds92v.mk937ek75jygtrlo &lt;invalid&gt; 2020-01-22T10:03:36Z &lt;none&gt; Proxy for managing TTL for the kubeadm-certs secret &lt;none&gt; EXPIERS : invalid í•˜ì§€ ì•ŠëŠ” í† í°ì´ ì—†ëŠ” ê²½ìš°, kubeadm token create(or generate)ë¡œ í† í°ì„ ì„¤ì •í•œë‹¤. ë§Œì•½ expired ë˜ì§€ ì•Šì•˜ë‹¤ë©´, join ëª…ë ì–´ì˜ í† í°ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ ì´í›„ hash ê°’ì´ í•„ìš”í•˜ë¯€ë¡œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ í†µí•´ hash ê°’ì„ í™•ì¸í•œë‹¤ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39; In k8s-node3,k8s-node3ì—ì„œ ìœ„ master ë…¸ë“œë¥¼ í†µí•´ í™•ì¸í•œ ê°’ìœ¼ë¡œ join ì„ ìˆ˜í–‰í•œë‹¤ 12345678$ kubeadm join 192.168.179.171:6443 --token 4e3bad.gzp017frj86g4ngi \\ --discovery-token-ca-cert-hash sha256:b141f77ea7c5749767bd7a1dfc54f256ef374969b08f660f1c131453ebed7091......This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details. IPëŠ” ë§ˆìŠ¤í„° IP(ì£¼ì˜ : ì‚¼ì¤‘í™”ë¥¼ ì§„í–‰í•˜ì˜€ìœ¼ë¯€ë¡œ, 3ê°œ ë§ˆìŠ¤í„° í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” VIPë¡œ ì‘ì„±) portëŠ” 6443 ì¶”ê°€ë¥¼ ì™„ë£Œí•˜ì˜€ë‹¤. ì´í›„ì— master ë…¸ë“œì—ì„œ kubectl get nodes ë¥¼ í•˜ë©´ í•˜ê¸° ì¶œë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤ 123456NAME STATUS ROLES AGE VERSIONbigdata-svr Ready &lt;none&gt; 23m v1.15.3k8s-master Ready master 6d18h v1.15.3k8s-node1 Ready master 6d18h v1.15.3k8s-node2 Ready master 6d18h v1.15.3k8s-node3 Ready &lt;none&gt; 3m16s v1.15.3 # Check! SummaryK8s clusterì— ë…¸ë“œë¥¼ ì¶”ê°€í•˜ê³  ì‚­ì œí•˜ëŠ” ê³¼ì •ì„ ë‹¤ë¤˜ë‹¤. ë…¸ë“œë¥¼ ì‚­ì œí•˜ê³  ì‚­ì œí•œ ë…¸ë“œì—ì„œ ë¦¬ì…‹ì„ ì§„í–‰í•œ ë‹¤ìŒ, ë§ˆìŠ¤í„°ì—ì„œì˜ token ë° hash valueë¥¼ ì¶”ê°€ ë…¸ë“œì— joinì— ì´ìš©í•˜ì˜€ë‹¤ ë…¸ë“œ ì‚­ì œ kubectl delete node {node-name} ë…¸ë“œ ë¦¬ì…‹ kubeadm reset cluster token í™•ì¸ kubadm token list, expired ëœ í† í° ë°œê²¬ ì‹œ kubeadm token createë¡œ ìƒˆ í† í° ìƒì„± hashê°’ í™•ì¸ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39; 2020.01.29 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Shell] .DS_Store ì‚­ì œ script","slug":"shell-delete_ds_store","date":"2020-01-26T15:00:00.000Z","updated":"2020-04-01T14:18:05.613Z","comments":true,"path":"shell-delete_ds_store/","link":"","permalink":"https://jx2lee.github.io/shell-delete_ds_store/","excerpt":"Mac Finderë¡œ íŒŒì¼ì„ íƒìƒ‰í•˜ë‹¤ ë³´ë©´ .DS_Store ì´ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ëœë‹¤. ì„±ê°€ì‹œë‹¤! gitì„ ì‚¬ìš©í•  ë•Œí•­ìƒ .gitignoreë¡œ ëª…ì‹œë¥¼ í•´ì•¼ë˜ë©°, ëª¨ë“  í´ë”ì— ì ìš©í•˜ê³  push í•œ ê²½í—˜ì´ ìˆì„ê±°ë‹¤. ì‰˜ ê³µë¶€í•˜ë©´ì„œ ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œ ì‘ì„±í•´ë³¸ë‹¤. Update Note 2020.04.01 : ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • (ë³€ìˆ˜ ì…ë ¥ ë° usage)","text":"Mac Finderë¡œ íŒŒì¼ì„ íƒìƒ‰í•˜ë‹¤ ë³´ë©´ .DS_Store ì´ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ëœë‹¤. ì„±ê°€ì‹œë‹¤! gitì„ ì‚¬ìš©í•  ë•Œí•­ìƒ .gitignoreë¡œ ëª…ì‹œë¥¼ í•´ì•¼ë˜ë©°, ëª¨ë“  í´ë”ì— ì ìš©í•˜ê³  push í•œ ê²½í—˜ì´ ìˆì„ê±°ë‹¤. ì‰˜ ê³µë¶€í•˜ë©´ì„œ ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œ ì‘ì„±í•´ë³¸ë‹¤. Update Note 2020.04.01 : ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • (ë³€ìˆ˜ ì…ë ¥ ë° usage) .DS_Store?DS_STORE íŒŒì¼ì´ë€ Desktop Services Storeì˜ ì•½ìë¡œ ì• í”Œì—ì„œ ì •ì˜í•œ íŒŒì¼ í¬ë§·ì´ë‹¤. ì• í”Œì˜ ë§¥ OS X ì‹œìŠ¤í…œì´ í´ë”ì— ì ‘ê·¼í•  ë•Œ ìƒê¸°ëŠ” í•´ë‹¹ í´ë”ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì¼ì´ë‹¤. ìœˆë„ìš°ì˜ thumb.db íŒŒì¼ê³¼ ë¹„ìŠ·í•˜ë‹¤. ë¶„ì„í•´ë³´ë©´ í•´ë‹¹ ë””ë ‰í† ë¦¬ í¬ê¸°, ì•„ì´ì½˜ì˜ ìœ„ì¹˜, í´ë”ì˜ ë°°ê²½ì— ëŒ€í•œ ì •ë³´ë“¤ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ë§¥ OS í™˜ê²½ì—ì„œë§Œ ìƒì„± ë° ì‚¬ìš©ë˜ì§€ë§Œ,íŒŒì¼ì„ ê³µìœ í•˜ëŠ” ê³¼ì •ì—ì„œ ì´ íŒŒì¼ë„ ê°™ì´ ê³µìœ ë˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì¶œì²˜ Shell scriptê°„ë‹¨í•œ í•œ ì¤„ ì§œë¦¬ ëª…ë ¹ìœ¼ë¡œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¶€í„° ì‚­ì œí•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ë‚˜ëŠ” ì´ê²Œ ê·€ì°®ì•˜ë‹¤. ê·¸ë¦¬ê³  Finderë¡œëŠ” / ë””ë ‰í† ë¦¬ê¹Œì§€ ê°ˆ ì¼ì´ ì—†ê³ , /Users/jj ì•„ë˜ í•˜ìœ„ ë””ë ‰í† ë¦¬ì— ìƒì„±ë˜ëŠ” DS_Store íŒŒì¼ì´ ê±°ìŠ¬ë ¸ë‹¤. hackerrank shell ë¬¸ì œë¥¼ í‘¸ëŠ” ë””ë ‰í† ë¦¬ì— rm-ds-store.sh íŒŒì¼ì„ ìƒì„±í•˜ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤ sudoì™€ findë¡œ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. ì‰˜ ì‹¤í–‰ ì‹œ stdinìœ¼ë¡œ íŒ¨ìŠ¤ì›Œë“œ ì…ë ¥ê°’ì„ ë°›ì•„ sudo ëª…ë ì„ ì‹¤í–‰í•˜ê³ , ì‚­ì œë˜ëŠ” ë‚´ì—­ì„ print í•œë‹¤. ë‚´ìš©ì€ í•˜ê¸°ì™€ ê°™ë‹¤ 12345678910111213#!/bin/bash# delete all .DS_Store file from path# Wed, 01.04.2020if [ \"$#\" -ne 1 ]; then echo \"usage : $0 &#123;path&#125;\" echo \"example : $0 /Users/jj\" exit 0fipath=$1sudo --stdin find $&#123;path&#125; -name \".DS_Store\" -print -deleteecho \".DS_Store clear in $&#123;path&#125; !\" Result./rm-ds-store.sh ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ Usage ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì •ë¦¬í•˜ê³ ì í•˜ëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì‚½ì…í•˜ë©´ ëœë‹¤. 123456789~/shell/customâ¯ ./rm-ds-store.shusage : ./rm-ds-store.sh &#123;path&#125;example : ./rm-ds-store.sh /Users/jj~/shell/customâ¯ ./rm-ds-store.sh /Users/jjPassword:.DS_Store clear in /Users/jj..! ì‚­ì œëœ ìœ„ì¹˜ê°€ í”„ë¦°íŠ¸í•˜ë©° ë™ì‹œì— ì‚­ì œí•˜ì—¬ ì™„ë£Œë¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì›ë˜ëŠ” / í•˜ìœ„ ë””ë ‰í† ë¦¬ ëª¨ë‘ ê²€ì‚¬í•˜ì˜€ì§€ë§Œ êµ³ì´ ê²€ì‚¬í•  í•„ìš”ê°€ ì—†ì—ˆë‹¤ (ì´ìœ ëŠ” .DS_Store ì˜ ì •ì˜ë¥¼ ìƒê°í•˜ë©´ ëœë‹¤). ì‰˜ ìŠ¤í¬ë¦½íŠ¸ ê³µë¶€í•˜ë©´ì„œ ì‹¤ì œë¡œ ì¨ë³¼ ìˆ˜ ìˆëŠ” toy project ì˜€ê³  ë” í™œìš©í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ê³ ë¯¼í•´ì•¼ê² ë‹¤. ì¸ìê°’ì´ ì—†ìœ¼ë©´ Usage ë¥¼ ì¶œë ¥í•˜ê³  ì›í•˜ëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ëª¨ë‘ ê²€ìƒ‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¡œ ìˆ˜ì •í•˜ì˜€ë‹¤. ì¡°ê¸ˆì”© ë” í™œìš©í•  ë°©ì•ˆì„ ìƒê°í•˜ë©´ì„œ ìˆ˜ì •í•  ê³„íšì´ë‹¤. Reference .DS_STORE íŒŒì¼ì´ë€, https://chp747.tistory.com/54 2020.01.27 made by jaejun.lee","categories":[{"name":"Shell","slug":"Shell","permalink":"https://jx2lee.github.io/categories/Shell/"}],"tags":[]},{"title":"[Cloud] Kubeflow ì„¤ì¹˜","slug":"cloud-install_kubeflow","date":"2020-01-22T15:00:00.000Z","updated":"2020-03-30T15:06:23.561Z","comments":true,"path":"cloud-install_kubeflow/","link":"","permalink":"https://jx2lee.github.io/cloud-install_kubeflow/","excerpt":"K8s cluster ìœ„ Kubeflowë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. K8s cluster êµ¬ì¶•ì€ í¬ìŠ¤íŠ¸ ì°¸ê³  Update Note 2020.02.25 : Trouble Shooting ì¶”ê°€ 2020.03.13 : Kubeflow ì‚­ì œ ì¶”ê°€, kfctl ë²„ì ¼ ëª…ì‹œ 2020.03.18 : Dashboard UI ìˆ˜ì •","text":"K8s cluster ìœ„ Kubeflowë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. K8s cluster êµ¬ì¶•ì€ í¬ìŠ¤íŠ¸ ì°¸ê³  Update Note 2020.02.25 : Trouble Shooting ì¶”ê°€ 2020.03.13 : Kubeflow ì‚­ì œ ì¶”ê°€, kfctl ë²„ì ¼ ëª…ì‹œ 2020.03.18 : Dashboard UI ìˆ˜ì • K8s í™˜ê²½Storageclass default ì„¤ì • í™•ì¸storage class name default ì„¤ì •ì„ ìœ„í•´ ì•„ë˜ ì»¤ë§¨ë“œë¼ì¸ì„ ìˆ˜í–‰ kubectl patch storageclass [storage class ëª…] -p &#39;{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}&#39; 1234$ kubectl get sc #sc : storageclassNAME PROVISIONER AGEcsi-cephfs-sc rook-ceph.cephfs.csi.ceph.com 16hrook-ceph-block (default) rook-ceph.rbd.csi.ceph.com 16h Kubeflow ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´https://github.com/kubeflow/kubeflow/releasesì—ì„œ ìµœì‹  kfctl ë°”ì´ë„ˆë¦¬ë¥¼ ë‹¤ìš´ë°›ì•„ ì••ì¶•ì„ í•´ì œí•œë‹¤. ë³¸ì¸ì€ v1.0.1-0-gf3edb9b ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. Kubeflow í™˜ê²½ ì„¤ì •.bashrc12345export KF_NAME=my-kubeflowexport BASE_DIR=/root/kubeflowexport KF_DIR=$&#123;BASE_DIR&#125;/$&#123;KF_NAME&#125;export CONFIG_FILE=$&#123;KF_DIR&#125;/kfctl_k8s_istio.0.7.0.yamlexport CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.0.yaml\" kfctl_k8s_istio.0.7.0.yamlwget -O kfctl_k8s_istio.0.7.0.yaml $CONFIG_URI Kubeflow deployBinary ì´ë™123cd $&#123;BASE_DIR&#125;chmod 755 kfctlmv kfctl /usr/bin ì„¤ì¹˜12cd $KF_DIRkfctl apply -V -f $&#123;CONFIG_FILE&#125; Access Kubeflow UIhttp://{NODE_IP}:31380ë¡œ ì ‘ì†í•œë‹¤ Masterê°€ ë§ì€ ê²½ìš°ì— centraldashboard pod ë¥¼ í™•ì¸í•˜ì—¬, í•´ë‹¹ host ipë¥¼ ì‚¬ìš©í•˜ë©´ ì ‘ì†ì´ ê°€ëŠ¥í•˜ë‹¤ (Master, Worker IPë¡œ ì ‘ì†ì´ ëª¨ë‘ ê°€ëŠ¥) Service ë¥¼ NodePort ë¡œ ì„¤ì •í•˜ì˜€ê¸°ë•Œë¬¸ì— í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ë…¸ë“œì˜ IPë¡œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë‹¤. Truuble ShootingArtifacts ë˜ëŠ” Executions íƒ­ì—ì„œ error mysql_query failed errno 2006í•´ë‹¹ íƒ­ìœ¼ë¡œ ì´ë™í•˜ë©´ mysql_query failed ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì´ë•Œì—ëŠ” metadata-grpc-deployment pod ë¥¼ ì¬ì‹œì‘ í•˜ë©´ ëœë‹¤. kubectl get pod {pod_name} -n kubeflow -o yaml | kubectl replace --force -f- Kubeflow ì‚­ì œKubeflow ë¥¼ ì‚­ì œí•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ kfctl delete ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•œë‹¤. 12cd $&#123;KF_DIR&#125;kfctl delete -f $&#123;CONFIG_FILE&#125; ëª…ë ¹ì–´ ìˆ˜í–‰ í›„ kubectl get all -n kubeflow ë¡œ ëª¨ë“  ë‚´ìš©ì´ ì‚­ì œë˜ì—ˆëŠ”-f ì§€ í™•ì¸í•œë‹¤. 12 root@k8s-master:~/kubeflow/my-kubeflow# kubectl get all -n kubeflowNo resources found. 2020.01.23 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] K8s cluster êµ¬ì¶•","slug":"cloud-install_k8s","date":"2020-01-21T15:00:00.000Z","updated":"2020-09-26T13:39:01.939Z","comments":true,"path":"cloud-install_k8s/","link":"","permalink":"https://jx2lee.github.io/cloud-install_k8s/","excerpt":"K8s clusterëŠ” Master 3ëŒ€(k8s-master/k8s-node1/k8s-node2) / Worker 2ëŒ€(k8s-node3/k8s-node4)ë¡œ êµ¬ì„±í•œë‹¤. k8sëŠ” 1.15.3 version ì´ë©° ì„œë²„ëŠ” ubuntu 18.04 ì´ë‹¤. Update Note 2020.02.25 : kubeadm init ì‹œ --upload-certs ì˜µì…˜ ë¶€ê°€ ì„¤ëª… 2020.03.12 : Calico CNI ì„¤ì • ì¶”ê°€ 2020.03.17 : Trouble shooting ì¶”ê°€ - Calico node not working 2020.06.04 : Taint NoSchedule ë³€ê²½ (/ to =) 2020.09.26 : VIP í¬íŠ¸ ì¶”ê°€ ì„¤ëª…","text":"K8s clusterëŠ” Master 3ëŒ€(k8s-master/k8s-node1/k8s-node2) / Worker 2ëŒ€(k8s-node3/k8s-node4)ë¡œ êµ¬ì„±í•œë‹¤. k8sëŠ” 1.15.3 version ì´ë©° ì„œë²„ëŠ” ubuntu 18.04 ì´ë‹¤. Update Note 2020.02.25 : kubeadm init ì‹œ --upload-certs ì˜µì…˜ ë¶€ê°€ ì„¤ëª… 2020.03.12 : Calico CNI ì„¤ì • ì¶”ê°€ 2020.03.17 : Trouble shooting ì¶”ê°€ - Calico node not working 2020.06.04 : Taint NoSchedule ë³€ê²½ (/ to =) 2020.09.26 : VIP í¬íŠ¸ ì¶”ê°€ ì„¤ëª… ê³µí†µëª¨ë“  ë…¸ë“œì— ê³µí†µìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤. 123456789apt-get install -y apt-transport-https curlapt-get updatecurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # Docker ê³µì‹ GPG keysudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"apt-get install -y docker-ce 1.15.3 ë²„ì ¼ì— ë§ëŠ” kubelet / kubeadm / kubectl ë¥¼ ì„¤ì¹˜í•œë‹¤. 1234curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -echo deb http://apt.kubernetes.io/ kubernetes-xenial main &gt; /etc/apt/sources.list.d/kubernetes.listapt-get updateapt-get install -y kubeadm=1.15.3-00 kubelet=1.15.3-00 kubectl=1.15.3-00 KubernetsëŠ” swapë¥¼ offì‹œì¼œì•¼ ì‘ë™í•˜ë¯€ë¡œ swap ë©”ëª¨ë¦¬ë¥¼ ëˆë‹¤. 1234freeswapoff -avi /etc/fstab# ì¬ë¶€íŒ…ì‹œ ìë™ìœ¼ë¡œ swapoff í•˜ë ¤ë©´ ìœ„ íŒŒì¼ì—ì„œ swap ë¶€ë¶„ ì£¼ì„ ì²˜ë¦¬ ë°©í™”ë²½ì„ ë‚´ë ¤ì¤€ë‹¤ (ubnut : ufw) 12systemctl stop ufw systemctl disable ufw /etc/docker/daemon.json ì˜ íŒŒì¼ì„ ìˆ˜ì •í•˜ê³  ë„ì»¤ ë°ëª¬ì„ ì¬ì‹¤í–‰í•œë‹¤ 1234567891011cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123;\"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\",\"log-opts\": &#123;\"max-size\": \"100m\" &#125;,\"storage-driver\": \"overlay2\", \"insecure-registries\": [\"192.168.179.185:5000\"]&#125;EOFsystemctl daemon-reloadsystemctl restart docker insecure-registries ëŠ” VIP(virtual ip)ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ë°, ì‚¼ì¤‘í™” í–ˆì„ ë•Œ ë§ˆìŠ¤í„° ê°„ í†µì‹ ì„ ìœ„í•œ ip. ë’¤ì— í¬íŠ¸ 5000ì€ í›„ì— ë§ˆìŠ¤í„° ë¶€ë¶„ì— ì„¤ì¹˜í•  keepalived ì—ì„œ ì‚¬ìš©í•œë‹¤ VIP Port: kubernetes API Server í†µì‹ ì— ì‚¬ìš©í•˜ëŠ” default port ìœ„ ì»¤ë§¨ë“œ ë¼ì¸ì„ ì •ë¦¬í•œ scriptëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ 5ê°œ ë…¸ë“œì—ì„œ ëª¨ë‘ ì‹¤í–‰í•œë‹¤ 1234567891011121314151617181920212223242526272829303132333435#!/bin/bash# install basic package &amp; docker-ce &amp; k8s utilsapt-get install -y apt-transport-https curlapt-get updatecurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # Docker ê³µì‹ GPG keysudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"apt-get install -y docker-cecurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -echo deb http://apt.kubernetes.io/ kubernetes-xenial main &gt; /etc/apt/sources.list.d/kubernetes.listapt-get updateapt-get install -y kubeadm=1.15.3-00 kubelet=1.15.3-00 kubectl=1.15.3-00freeswapoff -aufw disableufw statuscat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123;\"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\",\"log-opts\": &#123;\"max-size\": \"100m\" &#125;,\"storage-driver\": \"overlay2\", \"insecure-registries\": [\"192.168.179.185:5000\"]&#125;EOFsystemctl daemon-reload &amp;&amp; echo \"restart docker-daemon\"systemctl restart docker &amp;&amp; echo \"restart docker\" Master NodeKeepalived ì„¤ì¹˜12apt-get install -y keepalivedvi /etc/keepalived/keepalived.conf keepalived.conf 123456789101112131415vrrp_instance VI_1 &#123; state BACKUP interface enp0s8 virtual_router_id 50 priority 100 # ì´í›„ ë§ˆìŠ¤í„°ë¶€í„° 1ì”© ê°ì†Œí•˜ì—¬ ìˆ˜ì • advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass $ place secure password here. &#125; virtual_ipaddress &#123; 192.168.179.185 &#125;&#125; interface : ifconfig -aë¡œ í™•ì¸ priority : master ë§ˆë‹¤ ë‹¤ë¥¸ ê°’ ì„¤ì • priority ê°’ì´ ë†’ìœ¼ë©´ ìµœìš°ì„ ì ìœ¼ë¡œ master ì—­í•  ìˆ˜í–‰ 100, 99, 98 ë¡œ ì„¤ì • virtual_ipaddress : ì•ì „ì— docker daemonì˜ vip ì£¼ì†Œ ê¸°ì… VIP ì´ì–´ë„ ì•„ë¬´ ipë‚˜ ì‚¬ìš©í•˜ë©´ í˜¹ì—¬ë‚˜ ì¶©ëŒì´ ì¼ì–´ë‚ ê¹Œë´ í• ë‹¹ë°›ì€ ip ì‚¬ìš© keepalived ì„œë¹„ìŠ¤ ì¬ì‹œì‘ í›„ ìƒíƒœ($ ip addr)ë¥¼ í™•ì¸í•œë‹¤ $ systemctl restart keepalived &amp;&amp; systemctl status keepalived 123456783: enp6s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 64:e5:99:fa:52:c1 brd ff:ff:ff:ff:ff:ff inet 192.168.179.172/24 brd 192.168.179.255 scope global enp6s0 valid_lft forever preferred_lft forever inet 192.168.179.185/32 scope global enp6s0 valid_lft forever preferred_lft forever inet6 fe80::66e5:99ff:fefa:52c1/64 scope link valid_lft forever preferred_lft forever VIPë¡œ ì„¤ì •í•œ 192.168.179.171 ì´ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸ // í•˜ë‚˜ì˜ masterì—ë§Œ ë³´ì„ (ë‚˜ë¨¸ì§€ëŠ” stand by) K8s ì„¤ì¹˜kubeadm-config.yaml 12345678910apiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: \"v1.15.3\"controlPlaneEndpoint: \"192.168.179.185:6443\"networking: serviceSubnet: \"10.96.0.0/16\" podSubnet: \"10.244.0.0/16\"apiServer: extraArgs: advertise-address: \"192.168.179.185â€ ìœ„ Yaml íŒŒì¼ì€ ì²« ë²ˆì§¸ masterì—ì„œë§Œ ì‘ì„± í›„ init ì„ ìˆ˜í–‰í•œë‹¤. v1.15.3ìœ¼ë¡œ ì‘ì„±í•œë‹¤. controlPlaneEndpointì™€ advertise-address ëŠ” VIPì´ê³  í¬íŠ¸ë¡œ 6443ìœ¼ë¡œ ì§€ì • Yaml íŒŒì¼ì„ ì´ìš©í•´ í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•œë‹¤. $ kubeadm init --config=kubeadm-config.yaml --upload-certs 1234567891011121314151617181920212223242526Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of the control-plane node running the following command on each as root: kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \\ --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 \\ --control-plane --certificate-key 553c75881e6825bf9e5f3887b2100de4a3d979777a313b70281c5bbe5ddeef80Please note that the certificate-key gives access to cluster sensitive data, keep it secret!As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward.Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \\ --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 *â€“upload-certs ì˜µì…˜ì€ Master ì´ì¤‘í™” ì‹œ \bkey ì¸ì¦ì„ init ëª…ë ¹ê³¼ ìˆ˜í–‰í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. \bì´ ì˜µì…˜ì„ ì£¼ì§€ ì•Šìœ¼ë©´ ì´ì¤‘í™” ëŒ€ìƒ Master ì— key ì¸ì¦ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤.* ì„œë²„ ì£¼ì†Œ ë° ì¸ì¦ì„œë¥¼ ë³µì‚¬í•˜ëŠ” ë‹¨ê³„ë¡œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•œë‹¤. 123mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get pods --all-namespaces ëª…ë ¹ì–´ë¡œ ì•„ë˜ì™€ ê°™ì€ íŒŒë“œê°€ ìƒì„±ë˜ê¸° ê¸°ë‹¤ë¦°ë‹¤. 123456789root@k8s-master:~# kgpo --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-5c98db65d4-9fpzf 0/1 Pending 0 3m2skube-system coredns-5c98db65d4-vn8d5 0/1 Pending 0 3m2skube-system etcd-k8s-master 1/1 Running 0 119skube-system kube-apiserver-k8s-master 1/1 Running 0 2m14skube-system kube-controller-manager-k8s-master 1/1 Running 0 2m21skube-system kube-proxy-c4cnn 1/1 Running 0 3m1skube-system kube-scheduler-k8s-master 1/1 Running 0 2m7s coredns ëŠ” CNIë¥¼ ì„¤ì¹˜í•´ì•¼ Running ìƒíƒœê°€ ëœë‹¤. calico yamlì„ ë‹¤ìš´ë°›ì•„ CALICO_IPV4POOL_CIDR ê°’ì„ 10.244.0.0/16 ìœ¼ë¡œ ë³€ê²½í•œ í›„ CNI ë¥¼ ì„¤ì¹˜í•œë‹¤. $ kubectl apply -f kube-calico.yaml CALICO_IPV4POOL_CIDR ê°’ì„ 10.244.0.0/16 ìœ¼ë¡œ ë³€ê²½ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•œ í›„ ë°°í¬í•œë‹¤. \bí´ëŸ¬ìŠ¤í„° êµ¬ì„±í•œ ë…¸ë“œ IP ëŒ€ì—­ê³¼ ê°™ìœ¼ë©´ ì¶©ëŒì´ ì¼ì–´ë‚œë‹¤ê³  í•œë‹¤. 1234567891011root@k8s-master:~# kgpo --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-56cd854695-65j42 1/1 Running 0 89skube-system calico-node-ptq8x 1/1 Running 0 89skube-system coredns-5c98db65d4-9fpzf 1/1 Running 0 7m29skube-system coredns-5c98db65d4-vn8d5 1/1 Running 0 7m29skube-system etcd-k8s-master 1/1 Running 0 6m26skube-system kube-apiserver-k8s-master 1/1 Running 0 6m41skube-system kube-controller-manager-k8s-master 1/1 Running 0 6m48skube-system kube-proxy-c4cnn 1/1 Running 0 7m28skube-system kube-scheduler-k8s-master 1/1 Running 0 6m34s kubeadm init ì‹œ ìƒì„±ëœ ì»¤ë§¨ë“œë¥¼ ë‹¤ë¥¸ ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ Join í•œë‹¤. 123kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \\ --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 \\ --control-plane --certificate-key 553c75881e6825bf9e5f3887b2100de4a3d979777a313b70281c5bbe5ddeef80 ì„œë²„ ì£¼ì†Œ ë° ì¸ì¦ì„œë¥¼ ë³µì‚¬í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•œë‹¤. 123mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config Worker Nodekubeadm init ì‹œ ë‚˜ì˜¨ í† í°ê³¼ í•´ì‰¬ê°’ìœ¼ë¡œ ê° ì›Œì»¤ ë…¸ë“œì—ì„œ Join í•œë‹¤. 12kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \\ --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 ì„¤ì¹˜ í™•ì¸Kubectl get nodeskubectl get nodes -o widemaster nodeì—ì„œ í™•ì¸í•˜ë©´ í´ëŸ¬ìŠ¤í„°ì— í¬í•¨ëœ ë…¸ë“œë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤ 123456NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEk8s-master Ready master 44m v1.15.3 192.168.179.172 &lt;none&gt; Ubuntu 18.04.4 LTS 5.3.0-28-generic docker://19.3.8k8s-node1 Ready master 41m v1.15.3 192.168.179.173 &lt;none&gt; Ubuntu 18.04.3 LTS 4.15.0-88-generic docker://19.3.6k8s-node2 Ready master 40m v1.15.3 192.168.179.174 &lt;none&gt; Ubuntu 18.04.3 LTS 4.15.0-88-generic docker://19.3.6k8s-node3 Ready &lt;none&gt; 40m v1.15.3 192.168.179.175 &lt;none&gt; Ubuntu 18.04.3 LTS 4.15.0-88-generic docker://19.3.8k8s-node4 Ready &lt;none&gt; 40m v1.15.3 192.168.179.176 &lt;none&gt; Ubuntu 18.04.3 LTS 4.15.0-88-generic docker://19.3.8 (ì„ íƒì‚¬í•­) Master nodeì—ë„ pod ë°°í¬ê°€ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë³€í™˜masterì— Podë¥¼ ë°°í¬í•  ìˆ˜ ìˆëŠ” ìƒíƒœë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ taint ì¡°ê±´ì„ í•´ì œí•œë‹¤. kubectl taint nodes {node-name} node-role.kubernetes.io=master:NoSchedule- ë§Œì•½ ë…¸ë“œë¥¼ ë¦¬ìŠ¤ì¼€ì¥´ ë˜ì§€ ì•Šê²Œ ë³µêµ¬í•˜ë ¤ë©´ kubectl taint nodes {node-name} node-role.kubernetes.io/master:NoSchedule Trouble-Shootingcalico node ê°€ Running ìƒíƒœì´ì§€ë§Œ Unhealthy ë¬¸ì œhttps://github.com/projectcalico/calico/issues/2904 ë¬¸ì œì™€ ê°™ë‹¤. calico-node ê°€ í´ëŸ¬ìŠ¤í„° ë‚´ ë…¸ë“œ ìˆ˜ë§Œí¼ ê¸°ë™í•˜ì§€ë§Œ 0/1 Running ìƒíƒœì˜€ë‹¤. ë¬¸ì œê°€ ìˆëŠ” íŒŒë“œë¥¼ describe í•´ë³¸ ê²°ê³¼ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789101112131415161718192021222324252627282930313233343536Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Pulled 45m kubelet, k8s-master Container image \"calico/cni:v3.9.5\" already present on machine Normal Created 45m kubelet, k8s-master Created container upgrade-ipam Normal Started 45m kubelet, k8s-master Started container upgrade-ipam Normal Scheduled 45m default-scheduler Successfully assigned kube-system/calico-node-v5rgk to k8s-master Normal Started 45m kubelet, k8s-master Started container install-cni Normal Pulled 45m kubelet, k8s-master Container image \"calico/cni:v3.9.5\" already present on machine Normal Created 45m kubelet, k8s-master Created container install-cni Normal Started 45m kubelet, k8s-master Started container flexvol-driver Normal Pulled 45m kubelet, k8s-master Container image \"calico/pod2daemon-flexvol:v3.9.5\" already present on machine Normal Created 45m kubelet, k8s-master Created container flexvol-driver Normal Pulled 45m kubelet, k8s-master Container image \"calico/node:v3.9.5\" already present on machine Normal Created 45m kubelet, k8s-master Created container calico-node Normal Started 45m kubelet, k8s-master Started container calico-node Warning Unhealthy 30m (x34 over 45m) kubelet, k8s-master Readiness probe failed: calico/node is not ready: felix is not ready: readiness probe reporting 503 Warning Unhealthy 25m (x76 over 45m) kubelet, k8s-master Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused Warning Unhealthy 15m (x116 over 45m) kubelet, k8s-master Liveness probe failed: calico/node is not ready: Felix is not live: Get http://localhost:9099/liveness: dial tcp 127.0.0.1:9099: connect: connection refused Warning FailedMount 12m kubelet, k8s-master MountVolume.SetUp failed for volume \"calico-node-token-9j8gt\" : couldn't propagate object cache: timed out waiting for the condition Normal SandboxChanged 12m kubelet, k8s-master Pod sandbox changed, it will be killed and re-created. Normal Pulled 12m kubelet, k8s-master Container image \"calico/cni:v3.9.5\" already present on machine Normal Started 12m kubelet, k8s-master Started container upgrade-ipam Normal Created 12m kubelet, k8s-master Created container upgrade-ipam Normal Started 12m (x2 over 12m) kubelet, k8s-master Started container install-cni Normal Pulled 12m (x2 over 12m) kubelet, k8s-master Container image \"calico/cni:v3.9.5\" already present on machine Normal Created 12m (x2 over 12m) kubelet, k8s-master Created container install-cni Normal Started 12m kubelet, k8s-master Started container flexvol-driver Normal Pulled 12m kubelet, k8s-master Container image \"calico/pod2daemon-flexvol:v3.9.5\" already present on machine Normal Created 12m kubelet, k8s-master Created container flexvol-driver Normal Pulled 12m kubelet, k8s-master Container image \"calico/node:v3.9.5\" already present on machine Normal Created 12m kubelet, k8s-master Created container calico-node Normal Started 12m kubelet, k8s-master Started container calico-node Warning Unhealthy 11m (x2 over 12m) kubelet, k8s-master Readiness probe failed: calico/node is not ready: felix is not ready: readiness probe reporting 503 Warning Unhealthy 7m34s (x19 over 12m) kubelet, k8s-master Liveness probe failed: calico/node is not ready: Felix is not live: Get http://localhost:9099/liveness: dial tcp 127.0.0.1:9099: connect: connection refused Warning Unhealthy 2m30s (x38 over 12m) kubelet, k8s-master Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused ë„ˆë¬´ ê¸¸ì–´ Event ë¶€ë¶„ë§Œ ì‘ì„±í•˜ì˜€ë‹¤. ì¢€ ë” deep í•œ ë¡œê·¸ë¥¼ ì°¾ê³ ì í•´ë‹¹ íŒŒë“œ log ë¥¼ ì°¾ì•„ë³¸ ê²°ê³¼ ë‹¤ìŒê³¼ ê°™ë‹¤. 12342019-10-03 04:34:38.296 [WARNING][16449] int_dataplane.go 781: failed to wipe the XDP state error=failed to load BPF program (/tmp/felix-bpf-824808941): stat /sys/fs/bpf/calico/xdp/prefilter_v1_calico_tmp_A: no such file or directorylibbpf: Error in bpf_object__probe_name():Operation not permitted(1). Couldn't load basic 'r0 = 0' BPF program.libbpf: failed to load object '/tmp/felix-bpf-824808941'Error: failed to load object file ìœ„ ê¹ƒí—™ ì´ìŠˆ ë§í¬ë¥¼ í™•ì¸í•´ë³´ë©´ OS ì»¤ë„ë‹¨ì—ì„œ BPF ê´€ë ¨ ì˜¤ë¸Œì íŠ¸ë¥¼ ì½ì–´ë“œë¦¬ì§€ ëª»í•œ ìƒíƒœì˜€ë‹¤. ì´ìŠˆ ë‚´ìš©ë“¤ì„ ì‚´í´ë³´ë‹ˆ OS secure boot í•œ ê²½ìš° ìƒê¸¸ ìˆ˜ ìˆë‹¤í•˜ë©° $ mokutil --disable-validation ëª…ë ¹ì–´ë¡œ ì•ˆì „ ëª¨ë“œë¡œ ë¶€íŒ…í•˜ì§€ ëª»í•˜ê²Œ ì„¤ì •í•˜ê³  ì¬ë¶€íŒ… í•˜ì˜€ë‹¤. ì¬ë¶€íŒ… ì‹œ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•œ íŒ¨ìŠ¤ì›Œë“œë¡œ secure-mode boot ì„ disabled ë¡œ ì„¤ì •í•˜ê³  ì¬ë¶€íŒ… í•˜ë‹ˆ calico node ê°€ ë¬¸ì œì—†ì´ ê¸°ë™ë¨ì„ í™•ì¸í•˜ì˜€ë‹¤. 2020.01.22 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Cloud] Kubeflow overview","slug":"cloud-introduction_to_kubeflow","date":"2020-01-12T15:00:00.000Z","updated":"2020-04-10T02:58:26.204Z","comments":true,"path":"cloud-introduction_to_kubeflow/","link":"","permalink":"https://jx2lee.github.io/cloud-introduction_to_kubeflow/","excerpt":"Kubeflow ëŠ” Kubernetes ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ML toolkit ì´ì, ML íŒŒì´í”„ ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ì‹¤í—˜í•˜ëŠ” data scientistë¥¼ ìœ„í•œ í”Œë«í¼ì´ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ì‹œìŠ¤í…œ ê°œë°œ, í…ŒìŠ¤íŠ¸ ë° í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ í™˜ê²½ì— ë°°í¬í•˜ë ¤ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ ë° ìš´ì˜ íŒ€ì„ ìœ„í•œ ê²ƒì´ë‹¤. í¬ìŠ¤íŠ¸ëŠ” Conceptual overview, ML workflow, Kuberflow Components, interface, example ìˆœì„œë¡œ ì‘ì„±í•˜ì˜€ë‹¤. kubeflow 0.7.0 version ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ë‹¤","text":"Kubeflow ëŠ” Kubernetes ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ML toolkit ì´ì, ML íŒŒì´í”„ ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ì‹¤í—˜í•˜ëŠ” data scientistë¥¼ ìœ„í•œ í”Œë«í¼ì´ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ì‹œìŠ¤í…œ ê°œë°œ, í…ŒìŠ¤íŠ¸ ë° í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ í™˜ê²½ì— ë°°í¬í•˜ë ¤ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ ë° ìš´ì˜ íŒ€ì„ ìœ„í•œ ê²ƒì´ë‹¤. í¬ìŠ¤íŠ¸ëŠ” Conceptual overview, ML workflow, Kuberflow Components, interface, example ìˆœì„œë¡œ ì‘ì„±í•˜ì˜€ë‹¤. kubeflow 0.7.0 version ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ë‹¤ Conceptual overviewKubernetes ìœ„ ML ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œë¥¼ ë°°ì¹˜í•œ ê·¸ë¦¼ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. KubeflowëŠ” ML ì‹œìŠ¤í…œì„ ë°°í¬, í™•ì¥ ë° ê´€ë¦¬í•˜ê¸° ìœ„í•œ í”Œë«í¼ìœ¼ë¡œ Kubernetes ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±í•œë‹¤. Kubeflow interface ë¥¼ í†µí•´ ML toolsì„ ì§€ì •í•  ìˆ˜ ìˆê³  í´ë¼ìš°ë“œ ë¿ ì•„ë‹ˆë¼ on-premise ì— ë™ì¼í•œ worflowë¥¼ ë°°í¬í•  ìˆ˜ ìˆì–´ íŠ¹ì • í”Œë«í¼ì— ì¢…ì†ë˜ì§€ ì•ŠëŠ”ë‹¤. ê° êµ¬ì„± ìš”ì†Œë“¤ì´ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ëŠ” ë’¤ kubeflow Componentsì—ì„œ ì‚´í´ë³¸ë‹¤. ML workflowë§ì€ ì‚¬ëŒë“¤ì˜ ì„ ì…ê²¬ ì¤‘ í•˜ë‚˜ê°€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œì´ ML ì‹œìŠ¤í…œì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•  ê²ƒì´ë¼ ìƒê°í•œë‹¤. í•˜ì§€ë§Œ, ì‹¤ì œ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ì‹œê°„ ë³´ë‹¤ ë°ì´í„° íƒìƒ‰ë¶€í„° ë°ì´í„° ë¶„ì„, ê·¸ë¦¬ê³  ê°œë°œëœ ëª¨ë¸ì„ ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµí•˜ë©° íŠœë‹í•˜ëŠ” ì‹œê°„ì´ í›¨ì”¬ ê¸¸ë‹¤. ì¦‰, ML ì‹œìŠ¤í…œ ê°œë°œì€ ë°˜ë³µì ì¸ í”„ë¡œì„¸ìŠ¤ë¡œ, workflowì˜ ê° ë‹¨ê³„ë¥¼ í‰ê°€í•˜ê³  ìµœê³ ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ë‚¼ ìˆ˜ ìˆê²Œ ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ë³€ê²½ ì‚¬í•­ì„ ì ìš©í•´ì•¼ í•œë‹¤. ì•„ë˜ëŠ” ì‹¤í—˜ ë° ìƒì‚°(ì‹¤ì œ ë°°í¬) ê´€ì ì—ì„œì˜ workflowë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ê° ë‹¨ê³„ë³„ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. Experimental phase : ì‹¤í—˜ ë‹¨ê³„ Identify problem and collect and analyse data : ML ì‹œìŠ¤í…œìœ¼ë¡œ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë¥¼ ì‹ë³„í•˜ê³  í•™ìŠµ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•œë‹¤ Choose an ML algorithm and code your model : ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ML Framework ë° ì•Œê³ ë¦¬ì¦˜ì„ ì„ ë³„í•˜ê³  ëª¨ë¸ ì´ˆê¸° ë²„ì ¼ì„ ì½”ë”©í•œë‹¤ Experiment with data and model training : ì•ì„œ ì¤€ë¹„ëœ ë°ì´í„°ì™€ ëª¨ë¸ ì½”ë“œë¥¼ í†µí•´ í•™ìŠµì„ ì§„í–‰í•œë‹¤ Tune the model hyperparameters : ëª¨ë¸ ê²°ê³¼ì— ì˜í–¥ì„ ì£¼ëŠ” hyperparameterë¥¼ ì¡°ì •í•˜ë©° í•™ìŠµì„ ë°˜ë³µì ìœ¼ë¡œ ì§„í–‰í•œë‹¤ (ì´í›„ì—ëŠ” ë°˜ë³µì ì¸ parameter íŠœë‹ê³¼ í•™ìŠµì„ ì§„í–‰í•œë‹¤) Production phase : ìƒì‚° ë‹¨ê³„(ë°°í¬ ë‹¨ê³„) Transform data : í•™ìŠµê³¼ ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ë³€í™˜í•œë‹¤. ì´ë•Œ, ëª¨ë¸ ì •í•©ì„±ì„ ìœ„í•´ ìœ„ ì‹¤í—˜ ë‹¨ê³„ì—ì„œ ì§„í–‰í•œ ë°ì´í„°ì™€ ê°™ì€ í˜•íƒœë¡œ ë³€í™˜í•´ì•¼ í•¨ì„ ì£¼ì˜í•œë‹¤ Train model : ëª¨ë¸ì„ í•™ìŠµí•œë‹¤ Serve the model for online/batch prediction : ì˜¨ë¼ì¸ ë˜ëŠ” ë°°ì¹˜ ëª¨ë“œë¥¼ ìœ„í•œ ëª¨ë¸ì„ ì œê³µí•œë‹¤ Monitor the modelâ€™s performance : ëª¨ë¸ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•œë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì„ ìˆ˜ì •í•˜ê³  ì¬ í•™ìŠµì„ ì§„í–‰í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì—¬ê°„ë‹¤ Kubeflow components in the ML workflowìœ„ì— ì„¤ëª…í•œ ML workflowì— Kubeflow ì»´í¬ë„ŒíŠ¸ë¥¼ ëŒ€ì…í•œ ê·¸ë¦¼ì´ë‹¤. ê° ì»´í¬ë„ŒíŠ¸ë“¤ì„ experiment/production ë³„ ë‚˜ëˆ„ì–´ ì„¤ëª…í•œë‹¤. Experiment Pytorch / scikit-learn / Tensorflow / XGBoost : ML ì•Œê³ ë¦¬ì¦˜ì„ ì œê³µí•˜ëŠ” íŒ¨í‚¤ì§€. ê°€ì¥ ìœ ëª…í•œ Tensorflow ë¶€í„° ì†ì‰½ê²Œ ML ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” scikit-learn ê¹Œì§€, í˜„ì¬ ì§„í–‰í˜•ìœ¼ë¡œ ë‹¤ì–‘í•œ ML ì•Œê³ ë¦¬ì¦˜ íŒ¨í‚¤ì§€ë¥¼ ì§€ì›í•˜ê³  ìˆë‹¤. Jupyter notebook / Fairing / pipelines Jupyter notebook : web ê¸°ë°˜ íŒŒì´ì„  ì¸í„°í”„ë¦¬í„°ë¡œ, ì¸í„°ë ‰í‹°ë¸Œí•œ í™˜ê²½ì„ ì œê³µí•˜ë©° ë°ì´í„° ë¶„ì„ì— ë§ì´ ì‚¬ìš©í•˜ëŠ” tool Fairing : Kubeflowì—ì„œ ML ëª¨ë¸ì„ ì‰½ê²Œ í•™ìŠµí•˜ê³  ë°°í¬í•  ìˆ˜ ìˆëŠ” Python íŒ¨í‚¤ì§€ pipelines : Kubeflowì˜ pipelineì€ ML workflowì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ì„¤ëª…í•˜ëŠ” ê°œë…ì´ë‹¤. í—·ê°ˆë¦´ ìˆ˜ ìˆê² ì§€ë§Œ, ML workflowì˜ ëª¨ë“  ê³¼ì •ì„ ë‹´ì€ ê²ƒìœ¼ë¡œ ì¸ì§€í•˜ê³  workflowë¥¼ ì‹¤í–‰í•˜ëŠ”ë° í•„ìš”í•œ ì…ë ¥ê°’ &amp; êµ¬ì„± ìš”ì†Œì˜ ëª¨ë“  ì…ì¶œë ¥ì— ëŒ€í•œ ì •ì˜ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤ (ê³µì‹ Docì—ëŠ” pipelineì„ Kubeflow ì•ˆì˜ í”Œë«í¼ì´ë¼ í‘œí˜„í•œë‹¤). pipelineì€ ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ í¬í•¨í•˜ê³  ìˆë‹¤. ML workflowì„ ì¶”ì í•˜ê³  ê´€ë¦¬í•˜ëŠ” UI ë‹¤ì¤‘ ML workflow scheduling ML workflowë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•˜ê¸° ìœ„í•œ SDK (python) SDKë¥¼ ì´ìš©í•´ ML systemê³¼ ì—°ê²°í•˜ëŠ” Notebook [ì°¸ê³  - pipeline architecture] Katib : ML ëª¨ë¸ì˜ Hyper parameter ë° ì•„í‚¤í…ì³ë¥¼ ìë™ìœ¼ë¡œ íŠœë‹í•˜ëŠ” kubeflowì˜ ì»´í¬ë„ŒíŠ¸ (Hyperparameterë€, ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ì œì–´í•˜ëŠ” ë³€ìˆ˜ë¡œ learning rate / neural networkì˜ layer ìˆ˜ / layer ë‚´ node ìˆ˜ ë“±ì´ ìˆë‹¤) Prodiction Chainer / MPI MXNet / PyTorch / TFJob Chainer : CUDA(GPU), ë‹¤ì–‘í•œ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì³ë¥¼ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ MPI : ? MXNet / Pytorch / TFJob : ì˜¤í”ˆì†ŒìŠ¤ ë”¥ëŸ¬ë‹ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë ˆì„ì›Œí¬ë¡œ Deep Neural Networkë¥¼ í•™ìŠµ ë° ë°°í¬ KFServing / NVDIA TensorRT / PyTorch / TFServing / Seldon : í•™ìŠµëœ ëª¨ë¸ì„ ì‹¤ì œ ë°°í¬í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë¡œ, í¬ê²Œ KFServing ê³¼ Seldon ì„ ì´ìš©í•´ í”„ë ˆì„ì›Œí¬ë¥¼ ë°°í¬. ê° ì»´í¬ë„ŒíŠ¸ë“¤ì— ëŒ€í•œ ë‚´ìš©ì€ ë°©ëŒ€í•˜ì—¬ ê³µì‹ Doc ì°¸ì¡° Metadata / TensorBoard Metadata : ëª¨ë¸, ëª¨ë¸ ì‹¤í–‰, ë°ì´í„° ì…‹ ë“± ê¸°íƒ€ Artifactì— ëŒ€í•œ ì •ë³´ë¥¼ ì˜ë¯¸í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ (Artifactë€, ML workflow êµ¬ì„± ìš”ì†Œì˜ input / outputì„ í˜•ì„±í•˜ëŠ” file ë˜ëŠ” ì˜¤ë¸Œì íŠ¸) TensorBoard : Tensorflowê°€ í¬í•¨í•˜ëŠ” graph visualization tool #Kubeflow interface KubeflowëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì™€ ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ëª¨ë‘ ì œê³µí•œë‹¤. User interface ë°°í¬ëœ ì»´í¬ë„ŒíŠ¸ì— ì•¡ì„¸ìŠ¤í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€ì‹œ ë³´ë“œë¥¼ ì œê³µí•œë‹¤. (ì°¸ê³ ) Command line interface Kfctl ì€ Kubeflowë¥¼ ì„¤ì¹˜ ë° êµ¬ì„±í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Kubeflow CLI. (ì°¸ê³ ) ê³µì‹ ë„íë¨¼íŠ¸ë¥¼ ì°¸ê³ í•´ ì „ì²´ì ì¸ ê°œë…ì„ ì‚´í´ë³´ì•˜ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ëŠ” Kubernetes í´ëŸ¬ìŠ¤í„°ì— Kubeflowë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. Reference Kubeflow org, https://www.kubeflow.org/docs/about/kubeflow/ ì¿ ë²„ë„¤í‹°ìŠ¤ ê¸°ë°˜ì˜ End2End ë¨¸ì‹ ëŸ¬ë‹ í”Œë«í¼ Kubeflow #1 - ì†Œê°œ, https://bcho.tistory.com/1301 2020.01.13 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Database] Install ElasticSearch using Docker","slug":"cloud-install_elasticsearch","date":"2020-01-07T15:00:00.000Z","updated":"2020-09-26T13:36:15.963Z","comments":true,"path":"cloud-install_elasticsearch/","link":"","permalink":"https://jx2lee.github.io/cloud-install_elasticsearch/","excerpt":"ë°ì´í„° ë§ˆíŠ¸ë¥¼ êµ¬ì¶•í•˜ê³  ì´ë¥¼ ì‹œê°í™”í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶• pilotì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ElasticSearchë¥¼ ì„¤ì¹˜í•˜ê³ ì í•œë‹¤. ë‹¨ì¼ ì„œë²„ì— ì‹±ê¸€ ë…¸ë“œë¡œ êµ¬ì¶•í•˜ê³  binary ì„¤ì¹˜ë¥¼ í•˜ë ¤ê³  í–ˆì§€ë§Œ ìš”ì¦˜ ì¶”ì„¸ì— ë§ê²Œ(?) Container ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•í•˜ê³ ì Dockerë¥¼ ì´ìš©í•œë‹¤. Updata Note 2020.05.10 : Elasticsearch ìš©ì–´ ì •ë¦¬","text":"ë°ì´í„° ë§ˆíŠ¸ë¥¼ êµ¬ì¶•í•˜ê³  ì´ë¥¼ ì‹œê°í™”í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶• pilotì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ElasticSearchë¥¼ ì„¤ì¹˜í•˜ê³ ì í•œë‹¤. ë‹¨ì¼ ì„œë²„ì— ì‹±ê¸€ ë…¸ë“œë¡œ êµ¬ì¶•í•˜ê³  binary ì„¤ì¹˜ë¥¼ í•˜ë ¤ê³  í–ˆì§€ë§Œ ìš”ì¦˜ ì¶”ì„¸ì— ë§ê²Œ(?) Container ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•í•˜ê³ ì Dockerë¥¼ ì´ìš©í•œë‹¤. Updata Note 2020.05.10 : Elasticsearch ìš©ì–´ ì •ë¦¬ Elasticsearch ìš©ì–´Indexelasticsearch ë‚´ ë°ì´ã…“ ì €ì¥ì†Œë¡œ RDBMS ì˜ ë°ì´í„°ë² ì´ìŠ¤ì™€ ìœ ì‚¬ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œ Document í¬ê´„ì ì¸ ì˜ë¯¸ì˜ ìƒ‰ì¸ ë˜ëŠ” ìƒ‰ì¸ íŒŒì¼ (ë²”ìš©ì ì¸ ì˜ë¯¸ë¡œ ì‚¬ìš©) indice: elasticsearch ë‚´ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìƒ‰ì¸ ë˜ëŠ” ìƒ‰ì¸ íŒŒì¼ ShardLucene ì„ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰ì˜ ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë˜ëŠ” ì¸ë±ìŠ¤ ë¶„ì‚° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°œë… í° í¬ê¸°ì˜ ì¸ë±ìŠ¤ -&gt; ì—¬ëŸ¬ ê°œ ì‘ì€ ì¸ë±ìŠ¤ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥í•˜ëŠ” ê²ƒì„ ì˜ë¯¸ ë‹¨ì¼ ë…¸ë“œì—ì„œëŠ” ì €ì¥ì†Œ ì„œëŠ¥ì— ëŒ€í•œ í•œê³„ë¥¼ í•´ê²°, í´ëŸ¬ìŠ¤í„°ì—ì„œëŠ” ë¶„ì‚° ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ë©° ë¹ ë¥¸ ê²°ê³¼ ìƒì„± Primary Shard:ìƒ‰ì¸ ì‹œ ê°€ì¥ ë¨¼ì € ìƒì„±ë˜ëŠ” ì¸ë±ìŠ¤ë¡œ ë³µì œì˜ ê¸°ë³¸ ì†ŒìŠ¤ Replica Shard:ë ˆí”Œë¦¬ì¹´ ì„¤ì •ê°’ì— ë”°ë¼ Primary Shard ì„ ë³µì œí•˜ì—¬ ìƒì„±í•œ ìƒ¤ë“œë¥¼ ì¼ì»«ìŒ Replicaë‹¨ì–´ ëœ»ëŒ€ë¡œ ë³µì œë³¸ìœ¼ë¡œ, ì¥ì•  ë°œìƒ ì‹œ ì§€ì†ì„± ë³´ì¥ê³¼ ê²€ìƒ‰ íš¨ìœ¨ì„±ì„ ìœ„í•´ ì‚¬ìš© ë¶„ì‚°ëœ ë‹¤ë¥¸ ë…¸ë“œì— Shard ì™€ ê°™ì€ ë°ì´í„°ë¥¼ ë³µì œ (ë³µì œëœ Shard ë¥¼ Replica ë¼ ìƒê°í•˜ì) ìƒì„± ì ˆì°¨ Primary Shard ìƒ‰ì¸ ê° ë…¸ë“œì—ì„œ async í•˜ê²Œ Shard ë³µì œ ê²€ìƒ‰ ì„±ëŠ¥ ì €í•˜ ìµœì†Œí™” Documentelasticsearch ì—ì„œ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ë°ì´í„° ë‹¨ìœ„ í•˜ë‚˜ì˜ item ë˜ëŠ” article RDBMS ì˜ í…Œì´ë¸” ë‚´ í•˜ë‚˜ì˜ row ì— í•´ë‹¹ Type ì€ RDBMS í…Œì´ë¸” Field ëŠ” RDBMS í…Œì´ë¸”ì˜ í•˜ë‚˜ì˜ column Nodeelasticsearch ë¥¼ êµ¬ì„±í•˜ëŠ” í•˜ë‚˜ì˜ ì„œë²„ ë˜ëŠ” ë°ëª¬ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘ ê°€ëŠ¥í•œ ì„œë²„ Clusterstandalone í•˜ê²Œ ë™ì‘í•˜ëŠ” ì—¬ëŸ¬ ë…¸ë“œë¥¼ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ ë°ì´í„°ì˜ ë¶„ì‚°ê³¼ ê³µìœ ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì„±í•œ ê²ƒ pull Docker-Image for ElasticSearchElasticSearch docker imageë¥¼ ì„œë²„ë¡œ ê°€ì ¸ì˜¤ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. í˜„ì¬ í¬ìŠ¤íŒ… ê¸°ì¤€ ìµœì‹  ë²„ì ¼ì€ 7.5.1 ì´ë‹¤. 12345678910111213$ docker pull docker.elastic.co/elasticsearch/elasticsearch:7.5.1Trying to pull repository docker.elastic.co/elasticsearch/elasticsearch ... 7.5.1: Pulling from docker.elastic.co/elasticsearch/elasticsearchc808caf183b6: Pull complete 05ff3f896999: Pull complete 82fb7fb0a94e: Pull complete c4d0024708f4: Pull complete 136650a16cfe: Pull complete 968db096c092: Pull complete 42547e91692f: Pull complete Digest: sha256:b0960105e830085acbb1f9c8001f58626506ce118f33816ea5d38c772bfc7e6cStatus: Downloaded newer image for docker.elastic.co/elasticsearch/elasticsearch:7.5.1 Run single-node clusterdocker run -i -t -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.5.1 docker container ì‹¤í–‰ ì‹œ ì™¸ë¶€ ì ‘ê·¼ì„ í—ˆìš©í•˜ê¸° ìœ„í•´ì„œ -p ì¸ìë¥¼ ì¶”ê°€í•˜ì—¬ port forwarding í•˜ê²Œë” ì„¤ì •í•œë‹¤. ë˜í•œ, ì¸í„°ë ‰í‹°ë¸Œí•œ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ -i -p ì¸ìë¥¼ ì¶”ê°€í•˜ì˜€ë‹¤. Checkcurl ì„ ì´ìš©í•´ elasticsearch ê°€ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•œë‹¤. 123456789101112131415161718$ curl -XGET [ì„¤ì¹˜í•œ ì„œë²„ ip]:9200&#123; \"name\" : \"294fb8043230\", \"cluster_name\" : \"docker-cluster\", \"cluster_uuid\" : \"UOT6i7eIRjuan8ot89zNHw\", \"version\" : &#123; \"number\" : \"7.5.1\", \"build_flavor\" : \"default\", \"build_type\" : \"docker\", \"build_hash\" : \"3ae9ac9a93c95bd0cdc054951cf95d88e1e18d96\", \"build_date\" : \"2019-12-16T22:57:37.835892Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.3.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" &#125;, \"tagline\" : \"You Know, for Search\" ì„¤ì¹˜ë¥¼ ì™„ë£Œí•˜ì˜€ë‹¤. Reference elasticsearch ì„¤ì¹˜ (ë„ì»¤), https://velog.io/@pa324/elasticsearch-ì„¤ì¹˜-ë„ì»¤-2bk2h3gh7d elasticsearch document, https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 2020.01.08 made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[BI] Superset ì„¤ì¹˜","slug":"bi-install_superset","date":"2020-01-06T15:00:00.000Z","updated":"2020-09-14T14:02:47.615Z","comments":true,"path":"bi-install_superset/","link":"","permalink":"https://jx2lee.github.io/bi-install_superset/","excerpt":"Supersetì€ Web ê¸°ë°˜ BI íˆ´ë¡œì¨ Pythonìœ¼ë¡œ ê°œë°œë˜ì—ˆê³  ìˆ˜ì§‘-ì €ì¥-ì²˜ë¦¬ë¥¼ ê±°ì¹œ ë°ì´í„°ë¥¼ ë§ˆíŠ¸ì—ì„œ ì¶”ì¶œí•˜ì—¬ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤. ì œê³µ ê¸°ëŠ¥ìœ¼ë¡œëŠ” EDA, Dashboard ìƒì„± ë° ê³µìœ , ë³´ì•ˆ, ê¶Œí•œê³¼ ë‹¤ì–‘í•œ ì†ŒìŠ¤ ì—°ê²°ì„ ì§€ì›í•œë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ëŠ” Supersetì„ ì„¤ì¹˜í•´ë³¸ë‹¤.","text":"Supersetì€ Web ê¸°ë°˜ BI íˆ´ë¡œì¨ Pythonìœ¼ë¡œ ê°œë°œë˜ì—ˆê³  ìˆ˜ì§‘-ì €ì¥-ì²˜ë¦¬ë¥¼ ê±°ì¹œ ë°ì´í„°ë¥¼ ë§ˆíŠ¸ì—ì„œ ì¶”ì¶œí•˜ì—¬ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤. ì œê³µ ê¸°ëŠ¥ìœ¼ë¡œëŠ” EDA, Dashboard ìƒì„± ë° ê³µìœ , ë³´ì•ˆ, ê¶Œí•œê³¼ ë‹¤ì–‘í•œ ì†ŒìŠ¤ ì—°ê²°ì„ ì§€ì›í•œë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ëŠ” Supersetì„ ì„¤ì¹˜í•´ë³¸ë‹¤. InstallVirtualenvWrapperpython ê°€ìƒí™˜ê²½ì„ ê´€ë¦¬í•˜ëŠ” VirtualenvWrapperì„ ì„¤ì¹˜í•˜ê³  superset í™˜ê²½ì„ ì…‹íŒ…í•œë‹¤. 12$ mkvirtualenv superset$ workon superset Install Superset and Initializationvirtualenv í™˜ê²½ì—ì„œ pip ëª…ë ¹ì–´ë¥¼ ì´ìš©í•´ ì„¤ì¹˜í•œë‹¤. 1$ pip install apache-superset supersetì˜ databaseë¥¼ ì´ˆê¸°í™” í•˜ê³  admin userë¥¼ ìƒì„±í•œë‹¤ 1234567891011$ superset db upgrade$ flask fab create-adminUsername [admin]: flask fab create-adminUser first name [admin]: adminUser last name [user]:Email [admin@fab.org]:Password:Repeat for confirmation:2020-01-07 10:51:24,272:INFO:root:Configured event logger of type &lt;class 'superset.utils.log.DBEventLogger'&gt;Recognized Database Authentications.Admin User flask fab create-admin created. ì´í›„ í…ŒìŠ¤íŠ¸ í•  ë°ì´í„°ë¥¼ importí•œë‹¤. ì´í›„ ê¶Œí•œ/í—ˆê°€ë“±ì„ ì´ˆê¸°í™”í•˜ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ UI í™”ë©´ì„ ë„ìš´ë‹¤. 123$ superset load_examples$ superset init$ superset run -p 8088 --with-threads --reload --debugger Troubleshootingì„¤ì¹˜ ì¤‘ ë°œìƒí•œ ì—ëŸ¬ë¥¼ ì‚´í´ë³¸ë‹¤. install error : python-geohash12345678910111213141516171819202122232425ERROR: Command errored out with exit status 1: command: /home/supset/.virtualenvs/superset/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-oy48mkll/install-record.txt --single-version-externally-managed --compile --install-headers /home/supset/.virtualenvs/superset/include/site/python3.6/python-geohash cwd: /tmp/pip-install-onzf3pi1/python-geohash/ Complete output (19 lines): running install running build running build_py creating build creating build/lib.linux-x86_64-3.6 copying geohash.py -&gt; build/lib.linux-x86_64-3.6 copying quadtree.py -&gt; build/lib.linux-x86_64-3.6 copying jpgrid.py -&gt; build/lib.linux-x86_64-3.6 copying jpiarea.py -&gt; build/lib.linux-x86_64-3.6 running build_ext building '_geohash' extension creating build/temp.linux-x86_64-3.6 creating build/temp.linux-x86_64-3.6/src gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DPYTHON_MODULE=1 -I/usr/include/python3.6m -c src/geohash.cpp -o build/temp.linux-x86_64-3.6/src/geohash.o src/geohash.cpp:538:20: fatal error: Python.h: No such file or directory #include &lt;Python.h&gt; ^ compilation terminated. error: command 'gcc' failed with exit status 1 ----------------------------------------ERROR: Command errored out with exit status 1: /home/supset/.virtualenvs/superset/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-oy48mkll/install-record.txt --single-version-externally-managed --compile --install-headers /home/supset/.virtualenvs/superset/include/site/python3.6/python-geohash Check the logs for full command output. python-geohash package ì„¤ì¹˜ ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ëŠ” ì„¤ì¹˜ ì‹œ í•„ìš”í•œ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ê°€ ë¯¸ì„¤ì¹˜ë˜ì–´ ë°œìƒí•œ ì—ëŸ¬ë¡œ, sudo yum install gcc gcc-c++ python3-devel cyrus-sasl-devel ì„ í†µí•´ í•´ê²°í•  ìˆ˜ ìˆë‹¤. í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œ í™˜ê²½ ì„¤ì •ì´ ê¼­ í•„ìš”í•˜ë‹ˆ ê³µì‹ documentsë¥¼ ì°¸ê³ í•˜ì. Reference Superset Document, https://superset.incubator.apache.org/installation.html 2020.01.07 made by jaejun.lee","categories":[{"name":"BI","slug":"BI","permalink":"https://jx2lee.github.io/categories/BI/"}],"tags":[]},{"title":"[Python] í° ìˆ˜ ë§Œë“¤ê¸°","slug":"programmers-large_number","date":"2019-12-16T15:00:00.000Z","updated":"2020-03-30T15:06:23.536Z","comments":true,"path":"programmers-large_number/","link":"","permalink":"https://jx2lee.github.io/programmers-large_number/","excerpt":"ì£¼ì–´ì§„ ìˆ«ìì—ì„œ íŠ¹ì • ê°¯ìˆ˜ì˜ ìˆ«ìë§Œìœ¼ë¡œ ê°€ì¥ í° ìˆ˜ë¥¼ ë§Œë“œëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤","text":"ì£¼ì–´ì§„ ìˆ«ìì—ì„œ íŠ¹ì • ê°¯ìˆ˜ì˜ ìˆ«ìë§Œìœ¼ë¡œ ê°€ì¥ í° ìˆ˜ë¥¼ ë§Œë“œëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ ë¬¸ì œ ì„¤ëª…ì–´ë–¤ ìˆ«ìì—ì„œ kê°œì˜ ìˆ˜ë¥¼ ì œê±°í–ˆì„ ë•Œ ì–»ì„ ìˆ˜ ìˆëŠ” ê°€ì¥ í° ìˆ«ìë¥¼ êµ¬í•˜ë ¤ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìˆ«ì 1924ì—ì„œ ìˆ˜ ë‘ ê°œë¥¼ ì œê±°í•˜ë©´ [19, 12, 14, 92, 94, 24] ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì¤‘ ê°€ì¥ í° ìˆ«ìëŠ” 94 ì…ë‹ˆë‹¤. ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ìˆ«ì numberì™€ ì œê±°í•  ìˆ˜ì˜ ê°œìˆ˜ kê°€ solution í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤. numberì—ì„œ k ê°œì˜ ìˆ˜ë¥¼ ì œê±°í–ˆì„ ë•Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìˆ˜ ì¤‘ ê°€ì¥ í° ìˆ«ìë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”. ì œí•œ ì¡°ê±´numberëŠ” 1ìë¦¬ ì´ìƒ, 1,000,000ìë¦¬ ì´í•˜ì¸ ìˆ«ìì…ë‹ˆë‹¤. këŠ” 1 ì´ìƒ numberì˜ ìë¦¿ìˆ˜ ë¯¸ë§Œì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ number k return 1924 2 94 1231234 3 3234 4177252841 4 775841 ë¬¸ì œ í’€ì´íƒìš•ë²•ìœ¼ë¡œ í’€ ìˆ˜ ìˆëŠ” ë¬¸ì œë¡œ, ìš°ì„  collected ë¼ëŠ” ê²°ê³¼ë¬¼ ì €ì¥ Listë¥¼ ì„ ì–¸í•œë‹¤. numberì˜ ìˆ«ìë¥¼ forë¬¸ìœ¼ë¡œ ëŒë©´ì„œ collected ê¸¸ì´ &gt; 0 / collectedì˜ ë§ˆì§€ë§‰ ìˆ«ì ë¹„êµ / k &gt; 0 ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´, ì›ì†Œ í•˜ë‚˜ë¥¼ ë¹¼ì£¼ê³  kë¥¼ ì°¨ê°í•œë‹¤. ì´í›„ kê°€ 0ì´ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ê±¸ ë°©ì§€í•˜ê³ ì index iì´ìƒ ë§Œí¼ì˜ numberë¥¼ ë‹´ëŠ”ë‹¤. forë¬¸ì˜ ë§ˆì§€ë§‰ìœ¼ë¡œ ì¡°ê±´ì— ì•ˆê±¸ë¦¬ëŠ” numì€ collectedì— ë‹´ëŠ”ë‹¤. ì´í›„ kê°€ ìŒìˆ˜ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ -k ê¹Œì§€ sliceë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¬¼ì´ ë‹´ê¸´ collected Listë¥¼ joiní•˜ì—¬ ìˆ«ìë¡œ ë³€í™˜í•œë‹¤. Code1234567891011121314151617def solution(number, k): collected = [] for i, num in enumerate(number): while len(collected) &gt; 0 and collected[-1] &lt; num and k &gt; 0: collected.pop() k -= 1 if k == 0: collected += list(number[i:]) break collected.append(num) collected = collected[:-k] if k &gt; 0 else collected answer = ''.join(collected) return answer 2019.12.17 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[SQL] ì´ë™í‰ê·  - Moving Average","slug":"sql-moving_average","date":"2019-12-15T15:00:00.000Z","updated":"2020-03-30T15:06:23.587Z","comments":true,"path":"sql-moving_average/","link":"","permalink":"https://jx2lee.github.io/sql-moving_average/","excerpt":"ëª¨ ê¸°ì—… ì½”ë”©í…ŒìŠ¤íŠ¸ì— ë‚˜ì˜¨ ì´ë™ í‰ê· , Moving Average ë¥¼ SQLë¡œ í’€ì–´ë³¸ë‹¤","text":"ëª¨ ê¸°ì—… ì½”ë”©í…ŒìŠ¤íŠ¸ì— ë‚˜ì˜¨ ì´ë™ í‰ê· , Moving Average ë¥¼ SQLë¡œ í’€ì–´ë³¸ë‹¤ ì½”ë”©í…ŒìŠ¤íŠ¸ë¥¼ Hackerrank í”Œë«í¼ì„ ì´ìš©í–ˆë˜í„°ë¼ ë¬¸ì œ ë³µì›ì„ í•  ìˆ˜ ì—†ì—ˆë‹¤. ì´ì— (https://www.sqlteam.com/articles/calculating-running-totals) ì—ì„œ ì œê³µí•œ create database scriptë¥¼ í™œìš©í•´ ìƒì„±í•œ ë°ì´í„°ë¡œ ì´ë™ í‰ê· ì„ êµ¬í•´ë³´ê³ ì í•œë‹¤. ì‚¬ìš©í•œ ì¿¼ë¦¬ì™€ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. 12345678910111213141516delimiter //CREATE PROCEDURE insert_row()BEGIN DECLARE DayCount smallint default 5; DECLARE Sales bigint default 10; WHILE DayCount &lt;= 5000 DO INSERT INTO Sales values (DayCount, Sales); SET DayCount = DayCount + 1; SET Sales = Sales + 15; END WHILE;END//delimiter; 12345678mysql root@localhost:practice&gt; select count(*) from Sales; +----------+| count(*) |+----------+| 5000 |+----------+1 row in setTime: 0.010s ì´ë™í‰ê·  êµ¬í•˜ê¸°ìŠ¤ì¹¼ë¼ ì„œë¸Œì¿¼ë¦¬ë¥¼ ì´ìš©í•´ ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤. average í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í‰ê·  Sales ê°’ì„ êµ¬í•˜ëŠ”ë°, ìŠ¤ì¹¼ë¼ ì„œë¸Œì¿¼ë¦¬ ë‚´ ì„œë¸Œì¿¼ë¦¬(Count ì ˆ)ë¥¼ ì‘ì„±í•˜ì—¬ countê°€ 1ê³¼ 3ì‚¬ì´ì— ìˆì„ë•Œ í‰ê· ì„ êµ¬í•˜ëŠ” ì¹¼ëŸ¼(MvAvg)ì„ ì¡°íšŒí•˜ì˜€ë‹¤. ë¬¸ì œë¥¼ í’€ë‹¤ë³´ë‹ˆ SQL ì‹¤í–‰ìˆœì„œë‚˜ ê³„íš ë“±ì— ëŒ€í•œ ì§€ì‹ì´ ë¶€ì¡±í•œ ê²ƒ ê°™ë‹¤. ì±…ì„ í•œ ê¶Œ êµ¬ë¹„í•˜ì—¬ ê³µë¶€í•˜ëŠ”ê²Œ ì¢‹ì„ ë“¯ í•˜ë‹¤. Code123456789101112131415select DayCount, Sales, (select avg(Sales) as moving_average from Sales b where (select count(*) from Sales c where DayCount between b.DayCount and a.DayCount ) between 1 and 3 ) as MvAvg from Sales a; 2019.12.16 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jx2lee.github.io/tags/MySQL/"}]},{"title":"[Hadoop] Install Spark","slug":"hadoop-install_spark","date":"2019-12-12T15:00:00.000Z","updated":"2020-05-15T05:25:12.601Z","comments":true,"path":"hadoop-install_spark/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_spark/","excerpt":"Sparkë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. binaryë¥¼ ë‹¤ìš´ë°›ì•„ í’€ê³  configë¥¼ ìˆ˜ì •í•˜ë©´ ì‰½ê²Œ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ì´ í¬ìŠ¤íŠ¸ì—ëŠ” standalone ëª¨ë“œë¡œ sparkë¥¼ ì‹¤í–‰í•œë‹¤","text":"Sparkë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. binaryë¥¼ ë‹¤ìš´ë°›ì•„ í’€ê³  configë¥¼ ìˆ˜ì •í•˜ë©´ ì‰½ê²Œ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ì´ í¬ìŠ¤íŠ¸ì—ëŠ” standalone ëª¨ë“œë¡œ sparkë¥¼ ì‹¤í–‰í•œë‹¤ PreliminariesHadoop Versionhadoop version ëª…ë ¹ì–´ë¥¼ í†µí•´ Hadoopì˜ ë²„ì ¼ì„ ì²´í¬í•œë‹¤. ì´ ë§ì¸ ì¦‰ìŠ¨, Hadoop Clientê°€ Sparkë¥¼ ì‚¬ìš©í•  ê³„ì •ì— ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤. 123456Hadoop 2.9.2Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704Compiled by ajisaka on 2018-11-13T12:42ZCompiled with protoc 2.5.0From source with checksum 3a9939967262218aa556c684d107985This command was run using /app/hadoop/2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar Hadoop ClientëŠ” ì„¤ì¹˜ê°€ í•„ìš”ì—†ê³  ì´ë¯¸ êµ¬ì¶•ëœ í•˜ë‘¡ í´ëŸ¬ìŠ¤í„°ì—ì„œ hadoop ë°”ì´ë„ˆë¦¬ë§Œ ê°€ì ¸ì™€ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤. ì¦‰, ë‹¤ë¥¸ ì„œë²„ì—ì„œ í•˜ë‘¡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œë”ë§Œ ì„¤ì •í•´ë†“ì. Download binarySpark Documentsë¡œ ì ‘ì†í•˜ì—¬ binaryë¥¼ ë‹¤ìš´ë¡œë“œ í•œë‹¤. 1234567[root@node2 app]# wget http://mirror.apache-kr.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz--2019-12-10 17:41:49-- http://mirror.apache-kr.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgzResolving mirror.apache-kr.org (mirror.apache-kr.org)... 1.201.139.179Connecting to mirror.apache-kr.org (mirror.apache-kr.org)|1.201.139.179|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 230091034 (219M) [application/x-gzip]Saving to: â€˜spark-2.4.4-bin-hadoop2.7.tgzâ€™ Spark ìœ ì €ë¥¼ ìƒì„±í•˜ê³  Spark Home ë””ë ‰í† ë¦¬ì— ë‹¤ìš´ë°›ì€ binaryë¥¼ í’€ì–´ì¤€ë‹¤. Set config~/.bash_profileJAVA, HADOOP í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê³  SPARK í™˜ê²½ë³€ìˆ˜ë¥¼ ìƒˆë¡œ ì‘ì„±í•˜ê³  update í•œë‹¤. 1234567891011#JAVA ENVexport JAVA_HOME=/app/java/jdk1.8.0_181export PATH=$PATH:$JAVA_HOME/bin#SPARK ENVSPARK_HOME=/app/sparkexport PATH=$PATH:$SPARK_HOME/bin#HADOOP ENVexport HADOOP_HOME=/app/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin Run$SPARK_HOME/bin í´ë”ì— pyparkë¥¼ ì‹¤í–‰í•œë‹¤. * 1234567891011121314[spark@node2 bin]$ ./pyspark Python 3.6.8 (default, Aug 7 2019, 17:28:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 2.4.4 /_/Using Python version 3.6.8 (default, Aug 7 2019 17:28:10)SparkSession available as 'spark'.&gt;&gt;&gt; ê°„ë‹¨í•œ RDDë¥¼ ìƒì„±í•˜ì—¬ README.md ì— í¬í•¨í•œ ë¼ì¸ì„ ì„¸ë³´ë„ë¡ í•œë‹¤. 123&gt;&gt;&gt; lines &#x3D; sc.textFile(&#39;README.md&#39;)&gt;&gt;&gt; lines.count()105 sc.textFileë¡œ ê²½ë¡œë¥¼ ë¬´ì‹œí•˜ê²Œë˜ë©´ ìë™ìœ¼ë¡œ hdfs ê²½ë¡œë¥¼ ì½ì–´ë“¤ì¸ë‹¤. ë§Œì•½ì— ë¡œì»¬ íŒŒì¼ì„ ì½ê³  ì‹¶ë‹¤ë©´, file://[file path]/[file name]ìœ¼ë¡œ ì‘ì„±í•˜ë©´ ë¡œì»¬ íŒŒì¼ì„ ì½ì–´ë“¤ì¸ë‹¤. Reference Spark Documents made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://jx2lee.github.io/tags/Spark/"}]},{"title":"[Python] ë‹¤ë¦¬ë¥¼ ì§€ë‚˜ëŠ” íŠ¸ëŸ­","slug":"programmers-truck","date":"2019-12-02T15:00:00.000Z","updated":"2020-03-30T15:06:23.540Z","comments":true,"path":"programmers-truck/","link":"","permalink":"https://jx2lee.github.io/programmers-truck/","excerpt":"ìµœëŒ€ ìš©ëŸ‰ì„ ê°€ì§„ ë‹¤ë¦¬ë¥¼ íŠ¸ëŸ­ì´ ëª¨ë‘ ì§€ë‚˜ëŠ” ì‹œê°„ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.","text":"ìµœëŒ€ ìš©ëŸ‰ì„ ê°€ì§„ ë‹¤ë¦¬ë¥¼ íŠ¸ëŸ­ì´ ëª¨ë‘ ì§€ë‚˜ëŠ” ì‹œê°„ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë¬¸ì œ ì„¤ëª…íŠ¸ëŸ­ ì—¬ëŸ¬ ëŒ€ê°€ ê°•ì„ ê°€ë¡œì§€ë¥´ëŠ” ì¼ ì°¨ì„  ë‹¤ë¦¬ë¥¼ ì •í•´ì§„ ìˆœìœ¼ë¡œ ê±´ë„ˆë ¤ í•©ë‹ˆë‹¤. ëª¨ë“  íŠ¸ëŸ­ì´ ë‹¤ë¦¬ë¥¼ ê±´ë„ˆë ¤ë©´ ìµœì†Œ ëª‡ ì´ˆê°€ ê±¸ë¦¬ëŠ”ì§€ ì•Œì•„ë‚´ì•¼ í•©ë‹ˆë‹¤. íŠ¸ëŸ­ì€ 1ì´ˆì— 1ë§Œí¼ ì›€ì§ì´ë©°, ë‹¤ë¦¬ ê¸¸ì´ëŠ” bridge_lengthì´ê³  ë‹¤ë¦¬ëŠ” ë¬´ê²Œ weightê¹Œì§€ ê²¬ë”¥ë‹ˆë‹¤.â€» íŠ¸ëŸ­ì´ ë‹¤ë¦¬ì— ì™„ì „íˆ ì˜¤ë¥´ì§€ ì•Šì€ ê²½ìš°, ì´ íŠ¸ëŸ­ì˜ ë¬´ê²ŒëŠ” ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸¸ì´ê°€ 2ì´ê³  10kg ë¬´ê²Œë¥¼ ê²¬ë””ëŠ” ë‹¤ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤. ë¬´ê²Œê°€ [7, 4, 5, 6]kgì¸ íŠ¸ëŸ­ì´ ìˆœì„œëŒ€ë¡œ ìµœë‹¨ ì‹œê°„ ì•ˆì— ë‹¤ë¦¬ë¥¼ ê±´ë„ˆë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê±´ë„ˆì•¼ í•©ë‹ˆë‹¤. ê²½ê³¼ ì‹œê°„ ë‹¤ë¦¬ë¥¼ ì§€ë‚œ íŠ¸ëŸ­ ë‹¤ë¦¬ë¥¼ ê±´ë„ˆëŠ” íŠ¸ëŸ­ ëŒ€ê¸° íŠ¸ëŸ­ 0 [] [] [7,4,5,6] 1~2 [] [7] [4,5,6] 3 [7] [4] [5,6] 4 [7] [4,5] [6] 5 [7,4] [5] [6] 6~7 [7,4,5] [6] [] 8 [7,4,5,6] [] [] ë”°ë¼ì„œ, ëª¨ë“  íŠ¸ëŸ­ì´ ë‹¤ë¦¬ë¥¼ ì§€ë‚˜ë ¤ë©´ ìµœì†Œ 8ì´ˆê°€ ê±¸ë¦½ë‹ˆë‹¤. solution í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë‹¤ë¦¬ ê¸¸ì´ bridge_length, ë‹¤ë¦¬ê°€ ê²¬ë”œ ìˆ˜ ìˆëŠ” ë¬´ê²Œ weight, íŠ¸ëŸ­ë³„ ë¬´ê²Œ truck_weightsê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. ì´ë•Œ ëª¨ë“  íŠ¸ëŸ­ì´ ë‹¤ë¦¬ë¥¼ ê±´ë„ˆë ¤ë©´ ìµœì†Œ ëª‡ ì´ˆê°€ ê±¸ë¦¬ëŠ”ì§€ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”. ì œí•œ ì¡°ê±´ bridge_lengthëŠ” 1 ì´ìƒ 10,000 ì´í•˜ì…ë‹ˆë‹¤. weightëŠ” 1 ì´ìƒ 10,000 ì´í•˜ì…ë‹ˆë‹¤. truck_weightsì˜ ê¸¸ì´ëŠ” 1 ì´ìƒ 10,000 ì´í•˜ì…ë‹ˆë‹¤. ëª¨ë“  íŠ¸ëŸ­ì˜ ë¬´ê²ŒëŠ” 1 ì´ìƒ weight ì´í•˜ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ bridge_length weight truck_weights return 2 10 [7,4,5,6] 8 100 100 [10] 101 100 100 [10,10,10,10,10,10,10,10,10,10] 110 ë¬¸ì œ í’€ì´ë°°ì—´ì„ listë¡œ í’€ë©´ í•˜ë‚˜ì˜ ì¼€ì´ìŠ¤ê°€ ì‹œê°„ì´ˆê³¼ê°€ ë°œìƒí•œë‹¤. popì™€ append ì‹œ indexë¥¼ ì¬ë°°ì—´í•˜ë¯€ë¡œ ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´, collections íŒ¨í‚¤ì§€ì˜ deque ë°°ì—´ì„ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•˜ì˜€ë‹¤. queue ë³€ìˆ˜ëŠ” ë‹¤ë¦¬ë¥¼ ì§€ë‚˜ê°€ê³  ìˆëŠ” íŠ¸ëŸ­ë“¤ì„ ë‚˜íƒ€ë‚¸ë‹¤. truck_weights ì˜ ëª¨ë“  íŠ¸ëŸ­ë“¤ì„ í•˜ë‚˜ì”© ë½‘ì•„ while ë¬¸ì„ ì‹¤í–‰í•œë‹¤. queue ë°°ì—´ ê¸¸ì´ê°€ bridge_lengthì™€ ê°™ë‹¤ë©´ queueì—ì„œ popì„ ì‹¤í–‰í•˜ê³ , ë§Œì•½ ì„ íƒëœ íŠ¸ëŸ­ì˜ ë¬´ê²Œë¥¼ ë”í•´ë„ ë²„í‹¸ ìˆ˜ ìˆë‹¤ë©´ (sum(queue) + truck &lt;= weight) queueì— íŠ¸ëŸ­ì„ ì¶”ê°€í•˜ê³  whileë¬¸ì„ ë¹ ì ¸ë‚˜ì˜¨ë‹¤. ë§Œì•½ ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ queueì— 0ì„ ì™¼ìª½ì— ì¶”ê°€í•˜ê³  ì‹œê°„ì„ +1 í•œë‹¤. ìœ„ë¥¼ ë°˜ë³µí•˜ê³  ë§ˆì§€ë§‰ì— ë“¤ì–´ê°„ íŠ¸ëŸ­ì˜ ì†Œìš”ì‹œê°„ì„ êµ¬í•˜ê¸° ìœ„í•´ bridge_lengthë¥¼ ë”í•˜ê³  ë¬¸ì œë¥¼ ë§ˆë¬´ë¦¬í•œë‹¤. Code1234567891011121314151617181920212223from collections import dequedef solution(bridge_length, weight, truck_weights): answer = 0 queue = deque([]) truck_weights = deque(truck_weights) for truck in truck_weights: while truck: if len(queue) == bridge_length: queue.pop() if sum(queue) + truck &lt;= weight: queue.appendleft(truck) truck = 0 answer += 1 else: queue.appendleft(0) answer += 1 answer += bridge_length return answer Python ì˜ List íƒ€ì…ì˜ ê²½ìš° pop(0)ì„ ìˆ˜í–‰í•  ë•Œ ì¸ë±ìŠ¤ë¥¼ ì¬ë°°ì—´í•˜ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤. ì¦‰, queueë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œëŠ” Listë³´ë‹¤ Collections íŒ¨í‚¤ì§€ì˜ dequeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì‹œê°„ì´ˆê³¼ë¥¼ í”¼í•  ìˆ˜ ìˆë‹¤ 2019.12.03 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Hadoop] Tibero ê³„ì •ì˜ ëª¨ë“  tableì„ HDFSë¡œ ì €ì¥","slug":"hadoop-tables_to_hdfs_using_sqoop","date":"2019-11-26T15:00:00.000Z","updated":"2020-03-30T15:06:23.546Z","comments":true,"path":"hadoop-tables_to_hdfs_using_sqoop/","link":"","permalink":"https://jx2lee.github.io/hadoop-tables_to_hdfs_using_sqoop/","excerpt":"Sqoopì„ ì´ìš©í•´ RDB íŠ¹ì • ê³„ì •ì˜ ëª¨ë“  Tableì„ Import í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤","text":"Sqoopì„ ì´ìš©í•´ RDB íŠ¹ì • ê³„ì •ì˜ ëª¨ë“  Tableì„ Import í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤ Tiberoì˜ ERP ê³„ì •ì˜ ëª¨ë“  Tableì„ HDFSë¡œ ì €ì¥í•˜ê³  ë™ì‹œì— Hive Tableë¡œ ìƒì„±í•œë‹¤. sqoop import-all-tablesì„ ì´ìš©í•˜ë©° íŠ¹ì • ìŠ¤í‚¤ë§ˆê°€ ì—†ëŠ” í…Œì´ë¸”ì€ ì œì™¸í•˜ì˜€ë‹¤. êµ¬ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345678sqoop import-all-tables \\--connect jdbc:tibero:thin:@[ip]:[port]:[DB SID] \\--driver com.tmax.tibero.jdbc.TbDriver \\--username [user] --password [passowrd] \\--warehouse-dir [hdfs dir] \\--hive-import --hive-overwrite --hive-database [metastore db name] \\--exclude-tables SM_GROUP,SM_GROUP_PERMISSION,SM_PERMISSION,SM_PROJECT_GROUP_AUTH,SM_ROLE,SM_USER,SM_USER_GROUP \\--m 1 â€“connect : ì ‘ì†í•  DB ì •ë³´ â€“driver : ì ‘ì†í•  DB Driver â€“username &amp; â€“password : ê³„ì • ID/Password â€“warehouse-dir : HDFS ìœ„ì¹˜ â€“hive-import â€“hive-overwrite â€“hive-database : HDFSë¡œ ì €ì¥í•¨ê³¼ ë™ì‹œì— Hive tableë¡œ import. hive-databaseëŠ” MetaStoreì˜ database â€“exclude-table : Import ì‹œ ì œì™¸í•  Table â€“m : number of mappers ì œì™¸í•  í…Œì´ë¸” ëª…ì„ ëª…ì‹œí•  ë–„ ì½¤ë§ˆ ì´í›„ì— ë¬´ì¡°ê±´ ë¶™ì—¬ì¤˜ì•¼ argumentë¥¼ ì¸ì‹í•œë‹¤ ìƒê°ë³´ë‹¤ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë ¸ë‹¤. ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì. 12$ beeline$ !connect jdbc:hive2://[ip]:[port] user password 1234567891011121314151617181920use tims;show tables;+-----------------------+| tab_name |+-----------------------+| aactv00t || aactv01t || aactv10t || aactv20t || aactv24t || aactv25t |......| satch00t_03 || sbms_common_code || sbms_document_data || sbms_error_log |+-----------------------+595 rows selected (0.183 seconds) 2019.11.27 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Python] ë¬¸ìì—´ ì••ì¶•","slug":"programmers-compress_char","date":"2019-11-25T15:00:00.000Z","updated":"2020-03-30T15:06:23.535Z","comments":true,"path":"programmers-compress_char/","link":"","permalink":"https://jx2lee.github.io/programmers-compress_char/","excerpt":"ì£¼ì–´ì§„ ë¬¸ìì—´ì„ ê°€ì¥ ì§§ê²Œ ì••ì¶•í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ (2020 ì¹´ì¹´ì˜¤ 1ì°¨ ì½”ë”©í…ŒìŠ¤íŠ¸)","text":"ì£¼ì–´ì§„ ë¬¸ìì—´ì„ ê°€ì¥ ì§§ê²Œ ì••ì¶•í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ (2020 ì¹´ì¹´ì˜¤ 1ì°¨ ì½”ë”©í…ŒìŠ¤íŠ¸) ë¬¸ì œë°ì´í„° ì²˜ë¦¬ ì „ë¬¸ê°€ê°€ ë˜ê³  ì‹¶ì€ â€œì–´í”¼ì¹˜â€ëŠ” ë¬¸ìì—´ì„ ì••ì¶•í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ê³µë¶€ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœê·¼ì— ëŒ€ëŸ‰ì˜ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë¹„ì†ì‹¤ ì••ì¶• ë°©ë²•ì— ëŒ€í•´ ê³µë¶€ë¥¼ í•˜ê³  ìˆëŠ”ë°, ë¬¸ìì—´ì—ì„œ ê°™ì€ ê°’ì´ ì—°ì†í•´ì„œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ê·¸ ë¬¸ìì˜ ê°œìˆ˜ì™€ ë°˜ë³µë˜ëŠ” ê°’ìœ¼ë¡œ í‘œí˜„í•˜ì—¬ ë” ì§§ì€ ë¬¸ìì—´ë¡œ ì¤„ì—¬ì„œ í‘œí˜„í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤.ê°„ë‹¨í•œ ì˜ˆë¡œ â€œaabbacccâ€ì˜ ê²½ìš° â€œ2a2ba3câ€(ë¬¸ìê°€ ë°˜ë³µë˜ì§€ ì•Šì•„ í•œë²ˆë§Œ ë‚˜íƒ€ë‚œ ê²½ìš° 1ì€ ìƒëµí•¨)ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆëŠ”ë°, ì´ëŸ¬í•œ ë°©ì‹ì€ ë°˜ë³µë˜ëŠ” ë¬¸ìê°€ ì ì€ ê²½ìš° ì••ì¶•ë¥ ì´ ë‚®ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´, â€œabcabcdedeâ€ì™€ ê°™ì€ ë¬¸ìì—´ì€ ì „í˜€ ì••ì¶•ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. â€œì–´í”¼ì¹˜â€ëŠ” ì´ëŸ¬í•œ ë‹¨ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë¬¸ìì—´ì„ 1ê°œ ì´ìƒì˜ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì••ì¶•í•˜ì—¬ ë” ì§§ì€ ë¬¸ìì—´ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ”ì§€ ë°©ë²•ì„ ì°¾ì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤.ì˜ˆë¥¼ ë“¤ì–´, â€œababcdcdababcdcdâ€ì˜ ê²½ìš° ë¬¸ìë¥¼ 1ê°œ ë‹¨ìœ„ë¡œ ìë¥´ë©´ ì „í˜€ ì••ì¶•ë˜ì§€ ì•Šì§€ë§Œ, 2ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì••ì¶•í•œë‹¤ë©´ â€œ2ab2cd2ab2cdâ€ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ 8ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì••ì¶•í•œë‹¤ë©´ â€œ2ababcdcdâ€ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë•Œê°€ ê°€ì¥ ì§§ê²Œ ì••ì¶•í•˜ì—¬ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤.ë‹¤ë¥¸ ì˜ˆë¡œ, â€œabcabcdedeâ€ì™€ ê°™ì€ ê²½ìš°, ë¬¸ìë¥¼ 2ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì••ì¶•í•˜ë©´ â€œabcabc2deâ€ê°€ ë˜ì§€ë§Œ, 3ê°œ ë‹¨ìœ„ë¡œ ìë¥¸ë‹¤ë©´ â€œ2abcdedeâ€ê°€ ë˜ì–´ 3ê°œ ë‹¨ìœ„ê°€ ê°€ì¥ ì§§ì€ ì••ì¶• ë°©ë²•ì´ ë©ë‹ˆë‹¤. ì´ë•Œ 3ê°œ ë‹¨ìœ„ë¡œ ìë¥´ê³  ë§ˆì§€ë§‰ì— ë‚¨ëŠ” ë¬¸ìì—´ì€ ê·¸ëŒ€ë¡œ ë¶™ì—¬ì£¼ë©´ ë©ë‹ˆë‹¤.ì••ì¶•í•  ë¬¸ìì—´ sê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ìœ„ì— ì„¤ëª…í•œ ë°©ë²•ìœ¼ë¡œ 1ê°œ ì´ìƒ ë‹¨ìœ„ë¡œ ë¬¸ìì—´ì„ ì˜ë¼ ì••ì¶•í•˜ì—¬ í‘œí˜„í•œ ë¬¸ìì—´ ì¤‘ ê°€ì¥ ì§§ì€ ê²ƒì˜ ê¸¸ì´ë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ sì˜ ê¸¸ì´ëŠ” 1 ì´ìƒ 1,000 ì´í•˜ì…ë‹ˆë‹¤. sëŠ” ì•ŒíŒŒë²³ ì†Œë¬¸ìë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ123456 s result&quot;aabbaccc&quot; 7&quot;ababcdcdababcdcd&quot; 9&quot;abcabcdede&quot; 8&quot;abcabcabcabcdededededede&quot; 14&quot;xababcdcdababcdcd&quot; 17 ì…ì¶œë ¥ ì˜ˆì— ëŒ€í•œ ì„¤ëª… ì…ì¶œë ¥ ì˜ˆ #1 ë¬¸ìì—´ì„ 1ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ ì••ì¶•í–ˆì„ ë•Œ ê°€ì¥ ì§§ìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ #2 ë¬¸ìì—´ì„ 8ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ ì••ì¶•í–ˆì„ ë•Œ ê°€ì¥ ì§§ìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ #3 ë¬¸ìì—´ì„ 3ê°œ ë‹¨ìœ„ë¡œ ì˜ë¼ ì••ì¶•í–ˆì„ ë•Œ ê°€ì¥ ì§§ìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ #4 ë¬¸ìì—´ì„ 2ê°œ ë‹¨ìœ„ë¡œ ìë¥´ë©´ â€œabcabcabcabc6deâ€ ê°€ ë©ë‹ˆë‹¤. ë¬¸ìì—´ì„ 3ê°œ ë‹¨ìœ„ë¡œ ìë¥´ë©´ â€œ4abcdedededededeâ€ ê°€ ë©ë‹ˆë‹¤. ë¬¸ìì—´ì„ 4ê°œ ë‹¨ìœ„ë¡œ ìë¥´ë©´ â€œabcabcabcabc3dedeâ€ ê°€ ë©ë‹ˆë‹¤. ë¬¸ìì—´ì„ 6ê°œ ë‹¨ìœ„ë¡œ ìë¥¼ ê²½ìš° â€œ2abcabc2dededeâ€ê°€ ë˜ë©°, ì´ë•Œì˜ ê¸¸ì´ê°€ 14ë¡œ ê°€ì¥ ì§§ìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ #5 ë¬¸ìì—´ì€ ì œì¼ ì•ë¶€í„° ì •í•´ì§„ ê¸¸ì´ë§Œí¼ ì˜ë¼ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì£¼ì–´ì§„ ë¬¸ìì—´ì„ x / ababcdcd / ababcdcd ë¡œ ìë¥´ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥ í•©ë‹ˆë‹¤. ì´ ê²½ìš° ì–´ë–»ê²Œ ë¬¸ìì—´ì„ ì˜ë¼ë„ ì••ì¶•ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê°€ì¥ ì§§ì€ ê¸¸ì´ëŠ” ì´ ë©ë‹ˆë‹¤. ë¬¸ì œ í’€ì´ë”±íˆ ì‚¬ìš©í•œ ì•Œê³ ë¦¬ì¦˜ì€ ì—†ëŠ” ê²ƒ ê°™ë‹¤ (êµ³ì´ ì„ íƒí•˜ë©´ ë¸Œë£¨íŠ¸í¬ìŠ¤?). ë°˜ë³µí•˜ëŠ” ë¬¸ìì—´ ê¸¸ì´ì— ë”°ë¼ ëª¨ë“  ë¬¸ìì—´ì„ ì••ì¶•í•˜ê³ , ì´ì— ëŒ€í•œ ê¸¸ì´ë¥¼ res ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ìµœì†Ÿê°’ì„ ì¶œë ¥í•´ë‚¸ë‹¤. Code123456789101112131415161718192021222324252627def solution(s): result = '' cnt = 1 res = [] for n in range(1, len(s)+1): for i in range(0, len(s), n): if s[i:i+n] == s[i+n:i+2*n]: cnt += 1 else: if cnt &gt; 1: result += str(cnt) + s[i:i+n] else: result += s[i:i+n] cnt = 1 if i == len(s) - n: if cnt &gt; 1: result += str(cnt) + s[i+n:i+2*n] else: result += s[i+n:i+2*n] res.append(len(result)) result = '' cnt = 1 return min(res) 2019.11.26 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Python] ìë¬¼ì‡ ì™€ ì—´ì‡ ","slug":"programmers-unlock","date":"2019-11-25T15:00:00.000Z","updated":"2020-03-30T15:06:23.578Z","comments":true,"path":"programmers-unlock/","link":"","permalink":"https://jx2lee.github.io/programmers-unlock/","excerpt":"keyë¥¼ ì´ìš©í•´ ìë¬¼ì‡ ë¥¼ ì—¬ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ (2020 ì¹´ì¹´ì˜¤ 1ì°¨ ì½”ë”©í…ŒìŠ¤íŠ¸)","text":"keyë¥¼ ì´ìš©í•´ ìë¬¼ì‡ ë¥¼ ì—¬ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ (2020 ì¹´ì¹´ì˜¤ 1ì°¨ ì½”ë”©í…ŒìŠ¤íŠ¸) ë¬¸ì œ ì„¤ëª…ê³ ê³ í•™ìì¸ íŠœë¸ŒëŠ” ê³ ëŒ€ ìœ ì ì§€ì—ì„œ ë³´ë¬¼ê³¼ ìœ ì ì´ ê°€ë“í•  ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ë¹„ë°€ì˜ ë¬¸ì„ ë°œê²¬í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¬¸ì„ ì—´ë ¤ê³  ì‚´í´ë³´ë‹ˆ íŠ¹ì´í•œ í˜•íƒœì˜ ìë¬¼ì‡ ë¡œ ì ê²¨ ìˆì—ˆê³  ë¬¸ ì•ì—ëŠ” íŠ¹ì´í•œ í˜•íƒœì˜ ì—´ì‡ ì™€ í•¨ê»˜ ìë¬¼ì‡ ë¥¼ í‘¸ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•´ ì£¼ëŠ” ì¢…ì´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì ê²¨ìˆëŠ” ìë¬¼ì‡ ëŠ” ê²©ì í•œ ì¹¸ì˜ í¬ê¸°ê°€ 1 x 1ì¸ N x N í¬ê¸°ì˜ ì •ì‚¬ê° ê²©ì í˜•íƒœì´ê³  íŠ¹ì´í•œ ëª¨ì–‘ì˜ ì—´ì‡ ëŠ” M x M í¬ê¸°ì¸ ì •ì‚¬ê° ê²©ì í˜•íƒœë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìë¬¼ì‡ ì—ëŠ” í™ˆì´ íŒŒì—¬ ìˆê³  ì—´ì‡  ë˜í•œ í™ˆê³¼ ëŒê¸° ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤. ì—´ì‡ ëŠ” íšŒì „ê³¼ ì´ë™ì´ ê°€ëŠ¥í•˜ë©° ì—´ì‡ ì˜ ëŒê¸° ë¶€ë¶„ì„ ìë¬¼ì‡ ì˜ í™ˆ ë¶€ë¶„ì— ë”± ë§ê²Œ ì±„ìš°ë©´ ìë¬¼ì‡ ê°€ ì—´ë¦¬ê²Œ ë˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. ìë¬¼ì‡  ì˜ì—­ì„ ë²—ì–´ë‚œ ë¶€ë¶„ì— ìˆëŠ” ì—´ì‡ ì˜ í™ˆê³¼ ëŒê¸°ëŠ” ìë¬¼ì‡ ë¥¼ ì—¬ëŠ” ë° ì˜í–¥ì„ ì£¼ì§€ ì•Šì§€ë§Œ, ìë¬¼ì‡  ì˜ì—­ ë‚´ì—ì„œëŠ” ì—´ì‡ ì˜ ëŒê¸° ë¶€ë¶„ê³¼ ìë¬¼ì‡ ì˜ í™ˆ ë¶€ë¶„ì´ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•˜ë©° ì—´ì‡ ì˜ ëŒê¸°ì™€ ìë¬¼ì‡ ì˜ ëŒê¸°ê°€ ë§Œë‚˜ì„œëŠ” ì•ˆë©ë‹ˆë‹¤. ë˜í•œ ìë¬¼ì‡ ì˜ ëª¨ë“  í™ˆì„ ì±„ì›Œ ë¹„ì–´ìˆëŠ” ê³³ì´ ì—†ì–´ì•¼ ìë¬¼ì‡ ë¥¼ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—´ì‡ ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 2ì°¨ì› ë°°ì—´ keyì™€ ìë¬¼ì‡ ë¥¼ ë‚˜íƒ€ë‚´ëŠ” 2ì°¨ì› ë°°ì—´ lockì´ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ì—´ì‡ ë¡œ ìë¬¼ì‡ ë¥¼ ì—´ìˆ˜ ìˆìœ¼ë©´ trueë¥¼, ì—´ ìˆ˜ ì—†ìœ¼ë©´ falseë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ keyëŠ” M x M(3 â‰¤ M â‰¤ 20, Mì€ ìì—°ìˆ˜)í¬ê¸° 2ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. lockì€ N x N(3 â‰¤ N â‰¤ 20, Nì€ ìì—°ìˆ˜)í¬ê¸° 2ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. Mì€ í•­ìƒ N ì´í•˜ì…ë‹ˆë‹¤. keyì™€ lockì˜ ì›ì†ŒëŠ” 0 ë˜ëŠ” 1ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. 0ì€ í™ˆ ë¶€ë¶„, 1ì€ ëŒê¸° ë¶€ë¶„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ| key | lock | result || â€”â€“ | â€”â€” | â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” | â€”â€” || [[0, 0, 0], [1, 0, 0], [0, 1, 1]] | [[1, 1, 1], [1, 1, 0], [1, 0, 1]] | true | ì…ì¶œë ¥ ì˜ˆ ì„¤ëª… keyë¥¼ ì‹œê³„ ë°©í–¥ìœ¼ë¡œ 90ë„ íšŒì „í•˜ê³ , ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•œ ì¹¸, ì•„ë˜ë¡œ í•œ ì¹¸ ì´ë™í•˜ë©´ lockì˜ í™ˆ ë¶€ë¶„ì„ ì •í™•íˆ ëª¨ë‘ ì±„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¸ì œ í’€ì´í•œ ì¤„ë¡œ ë¬¸ì œë¥¼ í’€ì–´ë³´ë©´, lockì„ í™•ëŒ€í•˜ê³  keyë¥¼ í•˜ë‚˜ì”© ëŒ€ì…í•´ë³´ë©´ì„œ ëª¨ë“  ë¶€ë¶„ì´ 1ì¸ ê²½ìš°ë¥¼ ì°¾ìœ¼ë©´ ëœë‹¤. í¬ê²Œ ì„¸ ê°€ì§€ í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ì˜€ë‹¤. rotate_keyëŠ” ë§ê·¸ë˜ë„ ì…ë ¥í•œ key ë¥¼ ì‹œê³„ ë°©í–¥ 90ë„ë¡œ íšŒì „í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. ì…ë ¥ì€ keyì™€ keyì˜ ê¸¸ì´ 123456def rotate_key(key, M): res = [[0 * n for n in range(M)] for _ in range(M)] for y in range(M): for x in range(M): res[x][M - y - 1] = key[y][x] return res expand_lockì€ lockì„ keyì™€ ëŒ€ì¡°í•˜ê¸° ìœ„í•´ í™•ì¥í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. n+2 X (m-1) ë§Œí¼ í™•ì¥í•œë‹¤. Nì€ lockì˜ ê¸¸ì´, Mì€ ì—´ì‡ ì˜ ê¸¸ì´ 123456def expand_lock(lock, N, M, K): res = [[0 * i for i in range(K)] for _ in range(K)] for y in range(N): for x in range(N): res[y + M - 1][x + M - 1] = lock[y][x] return res is_openì€ í™•ì¥ëœ lockê³¼ keyë¥¼ ì´ìš©í•´ ê° êµ¬ë© valueë¥¼ ë”í•´ 1ì´ ì•„ë‹ˆë©´ ê²½ìš°ëŠ” False, 1ì¸ ê²½ìš°ì—ëŠ” Trueë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. ì´ í•¨ìˆ˜ëŠ” í™•ì¥ëœ lockì„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ë¶€í„° ëê¹Œì§€ keyë¥¼ forë¬¸ìœ¼ë¡œ ëŒë ¤ê°€ë©° í™•ì¸í•œë‹¤. 1234567891011def is_open(_y, _x, key, lock, N, M): _lock = copy.deepcopy(lock) for y in range(M): for x in range(M): _lock[_y + y][_x + x] += key[y][x] for y in range(N): for x in range(N): if _lock[y + M - 1][x + M - 1] != 1: return False return True ë§ˆì§€ë§‰ solutioní•¨ìˆ˜ëŠ” í•˜ë‚˜í•˜ë‚˜ í‚¤ë¥¼ ëŒë ¤ê°€ë©° ëª¨ë“  ê°’ë“¤ì´ 1ì¸ì§€ë¥¼ íŒë‹¨í•˜ê³ , ì•„ë‹ˆë©´ keyë¥¼ ëŒë ¤ê°€ë©° í™•ì¸í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. 1234567891011121314def solution(key, lock): n, m = len(lock), len(key) k = n + 2 * (m - 1) lock = expand_lock(lock, n, m, k) for y in range(k - m +1): for x in range(k - m +1): for _ in range(4): if is_open(y, x, key, lock, n, m): return True key = rotate_key(key, m) return False Code123456789101112131415161718192021222324252627282930313233343536373839404142import copydef rotate_key(key, M): res = [[0 * n for n in range(M)] for _ in range(M)] for y in range(M): for x in range(M): res[x][M - y - 1] = key[y][x] return resdef expand_lock(lock, N, M, K): res = [[0 * i for i in range(K)] for _ in range(K)] for y in range(N): for x in range(N): res[y + M - 1][x + M - 1] = lock[y][x] return resdef is_open(_y, _x, key, lock, N, M): _lock = copy.deepcopy(lock) for y in range(M): for x in range(M): _lock[_y + y][_x + x] += key[y][x] for y in range(N): for x in range(N): if _lock[y + M - 1][x + M - 1] != 1: return False return Truedef solution(key, lock): answer = True n, m = len(lock), len(key) k = n + 2 * (m - 1) lock = expand_lock(lock, n, m, k) for y in range(k - m +1): for x in range(k - m +1): for _ in range(4): if is_open(y, x, key, lock, n, m): return True key = rotate_key(key, m) return False 2019.11.26 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Database] MySQL ìœ ì € ê´€ë¦¬","slug":"database-manage_user_in_mysql","date":"2019-11-24T15:00:00.000Z","updated":"2020-03-30T15:06:23.568Z","comments":true,"path":"database-manage_user_in_mysql/","link":"","permalink":"https://jx2lee.github.io/database-manage_user_in_mysql/","excerpt":"MySQLì˜ ìœ ì €ë¥¼ ê´€ë¦¬í•´ë³¸ë‹¤","text":"MySQLì˜ ìœ ì €ë¥¼ ê´€ë¦¬í•´ë³¸ë‹¤ User tableMySQLì—ì„œ ê´€ë¦¬í•˜ëŠ” ìœ ì €ë¥¼ ì¡°íšŒí•´ë³´ì. ìš°ì„ , ê¸°ë³¸ì ìœ¼ë¡œ mysql databaseì— user í…Œì´ë¸”ì—ì„œ ê´€ë¦¬í•œë‹¤. mysql databaseë¥¼ ì„ íƒí•˜ê³  user tableì˜ host, userë¥¼ ì¡°íšŒí•´ë³´ì. 12345678910111213141516171819202122232425mysql&gt; show databases;+--------------------+| Database |+--------------------+| hive || information_schema || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)mysql&gt; use mysql;Database changedmysql&gt; select host, user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | hive || localhost | mysql.infoschema || localhost | mysql.session || localhost | mysql.sys || localhost | root |+-----------+------------------+5 rows in set (0.01 sec) Create User &amp; DatabaseUserSqoopë¥¼ ì´ìš©í•´ hdfs ë°ì´í„°ë¥¼ MySQL tableì„ ì €ì¥í•˜ê¸° ìœ„í•œ ê³„ì •ì„ ìƒì„±í•œë‹¤. (Sqoop exportë¥¼ ìœ„í•´ì„œëŠ” í•´ë‹¹ RDBì— í…Œì´ë¸”ì´ ì¡´ì¬í•´ì•¼í•œë‹¤. êµ³ì´ ì´ê´€í•˜ëŠ” ê²ƒ ê¹Œì§„ í•„ìš”ì—†ì„ ê²ƒ ê°™ì•„, ì´ë²ˆ í¬ìŠ¤íŒ…ì—ëŠ” ìœ ì €ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ë²•ë§Œ ë‹¤ë£¬ë‹¤) create user [user name]@[ip] identified by [password]; user name : ìƒì„±í•  ê³„ì •ëª… ip : ì ‘ì†ê°€ëŠ¥ ipë¡œ ë¡œì»¬ ê³„ì •ì—ì„œë§Œ ì ‘ì†ì„ í—ˆìš©í•  ê²ƒì´ë©´ localhost, ë³¸ì¸ê³¼ ê°™ì´ ëª¨ë“  ì™¸ë¶€ IPì—ì„œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ê²Œ í•˜ë ¤ë©´ % password : ìƒì„±í•  ê³„ì •ì˜ ë¹„ë°€ë²ˆí˜¸ ipì˜ ê²½ìš°, grant ëª…ë ¹ì–´ë¡œ ìˆ˜ì •ì´ ê°€ëŠ¥í•¨ 123456789101112131415mysql&gt; create user 'tims'@'%' identified by '****';Query OK, 0 rows affected (0.00 sec)mysql&gt; select host, user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | hive || % | tims || localhost | mysql.infoschema || localhost | mysql.session || localhost | mysql.sys || localhost | root |+-----------+------------------+6 rows in set (0.01 sec) Databaseìƒì„±í•œ timsê³„ì •ì—ì„œ ì‚¬ìš©í•  databaseë¥¼ ìƒì„±í•œë‹¤. create database [database name] database name : ìƒì„±í•  database ì´ë¦„ grank all privileges on [database name].[schema] to [user name]@[ip] database naem : ìƒì„±í•œ database ì´ë¦„ schema : ìƒì„±í•œ database ë‚´ ìŠ¤í‚¤ë§ˆ user name : ê¶Œí•œì„ ì¤„ ê³„ì •ëª… ip : ì ‘ì† ip 12345mysql&gt; create database tims;Query OK, 1 row affected (0.01 sec)mysql&gt; grant all privileges on tims.* to 'tims'@'%';Query OK, 0 rows affected (0.00 sec) í…ŒìŠ¤íŠ¸í•´ë³´ì. show tables ë¥¼ ì¹˜ê²Œë˜ë©´ ì•„ë¬´ í…Œì´ë¸”ì´ í‘œì‹œë˜ì§€ ì•Šì„ ê²ƒì´ë‹¤. (ë‹¹ì—°) 123456789101112131415161718192021222324252627[mysql@node2 ~]$ mysql -u tims -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 6820Server version: 8.0.18 Source distributionCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || tims |+--------------------+2 rows in set (0.00 sec)mysql&gt; use tims;Database changedmysql&gt; show tables;Empty set (0.00 sec) ERROR 1045 (28000): Access denied for user â€˜hiveâ€™@â€™localhostâ€™ (using password: NO) ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì´ë•ŒëŠ” í•´ë‹¹ ê³„ì •ìœ¼ë¡œ Login í•  ë•Œ -p opitonì„ ë¶™ì—¬ì¤€ë‹¤ 2019.11.25 made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jx2lee.github.io/tags/MySQL/"}]},{"title":"[Hadoop] Install Zeppelin and Connect to RDBMS & Hive","slug":"hadoop-install_zeppelin","date":"2019-11-17T15:00:00.000Z","updated":"2020-03-30T15:06:23.583Z","comments":true,"path":"hadoop-install_zeppelin/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_zeppelin/","excerpt":"Apache Zeppelinì„ ì„¤ì¹˜í•˜ê³  Tiberoì™€ Hiveì— ì—°ë™í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤","text":"Apache Zeppelinì„ ì„¤ì¹˜í•˜ê³  Tiberoì™€ Hiveì— ì—°ë™í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤ Install Apache ZeppelinZeppelin userë¥¼ ìƒì„±í•˜ê³  ì„¤ì¹˜íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œë‹¤. 123$ adduser zepp --gid 1000 # bigdata$ wget http://apache.mirror.cdnetworks.com/zeppelin/zeppelin-0.8.2/zeppelin-0.8.2-bin-all.tgz$ cd /app &amp;&amp; tar -xvzf zeppelin-0.8.2-bin-all.tgz $ZEPPELIN_HOME/conf/zeppelin-site.xml íŒŒì¼ì„ ìˆ˜ì •í•œë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;configuration&gt;&lt;property&gt; &lt;name&gt;zeppelin.server.addr&lt;/name&gt; &lt;value&gt;192.xxx.xxx.xx&lt;/value&gt; &lt;description&gt;Server binding address, Server IP&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.server.port&lt;/name&gt; &lt;value&gt;8001&lt;/value&gt; &lt;description&gt;Server port.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.server.ssl.port&lt;/name&gt; &lt;value&gt;8443&lt;/value&gt; &lt;description&gt;Server ssl port. (used when ssl property is set to true)&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.server.context.path&lt;/name&gt; &lt;value&gt;/&lt;/value&gt;&lt;property&gt; &lt;name&gt;zeppelin.server.context.path&lt;/name&gt; &lt;value&gt;/&lt;/value&gt; &lt;description&gt;Context Path of the Web Application&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.war.tempdir&lt;/name&gt; &lt;value&gt;webapps&lt;/value&gt; &lt;description&gt;Location of jetty temporary directory&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.notebook.dir&lt;/name&gt; &lt;value&gt;notebook&lt;/value&gt; &lt;description&gt;path or URI for notebook persist&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.notebook.homescreen&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;description&gt;id of notebook to be displayed in homescreen. ex) 2A94M5J1Z Empty value displays default home screen&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;zeppelin.notebook.homescreen.hide&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;hide homescreen notebook from list when this value set to true&lt;/description&gt;&lt;/property&gt; ì´ë¯¸ 8080í¬íŠ¸ê°€ ì‚¬ìš©ì¤‘ì´ë¯€ë¡œ portë¥¼ 8001ë¡œ ìˆ˜ì •í•˜ì˜€ë‹¤. zeppelin í´ë” ì´ìš© ê¶Œí•œì„ zeppì—ê²Œ ì£¼ê³  daemonì„ ì‹¤í–‰í•œë‹¤. 1234$ chown -R zepp:bigdata zeppelin/$ su - zepp$ bin/zeppelin-daemon.sh startZeppelin start [ OK ] http://localhost:8080 ìœ¼ë¡œ ì ‘ì†í•œë‹¤. ConnectionTibero ConnectionTiberoì™€ ì—°ë™í•˜ëŠ” ë°©ë²•ì€ ê°„ë‹¨í•˜ë‹¤. $ZEPPELIN_HOME/interpreter/jdbc ì•ˆì— tibero6-jdbc.jar íŒŒì¼ì„ ë³µì‚¬í•œë‹¤ $ cp tibero6-jdbc.jar $ZEPPELIN_HOME/interpreter/jdbc/tibero6-jdbc.jar ì´í›„ $ZEPPELIN/conf/interpreter.json ë‚´ jdbc ë¶€ë¶„ì— importí•  DB ì •ë³´ë¥¼ ì‘ì„±í•œë‹¤. 123456789101112131415161718192021222324\"jdbc\": &#123; \"id\": \"jdbc\", \"name\": \"jdbc\", \"group\": \"jdbc\", \"properties\": &#123; \"default.url\": &#123; \"name\": \"default.url\", \"value\": \"jdbc:tibero:thin:@192.168.xxx.xxx:xxxx:tibero\", \"type\": \"string\" &#125;, \"default.driver\": &#123; \"name\": \"default.driver\", \"value\": \"com.tmax.tibero.jdbc.TbDriver\", \"type\": \"string\" &#125;, \"default.password\": &#123; \"name\": \"default.password\", \"value\": \"xxxxx\", \"type\": \"password\" &#125;, \"default.user\": &#123; \"name\": \"default.user\", \"value\": \"xxx\", \"type\": \"string\" properties ì•ˆì— default.url, default.driver, default.password/user ë¥¼ í•´ë‹¹ DB ì •ë³´ë¥¼ ì‘ì„±í•œë‹¤. ë‚˜ë¨¸ì§€ëŠ” ì„¸ë¶€ì ì¸ ì‚¬í•­ì´ë¯€ë¡œ https://zeppelin.apache.org/docs/0.8.0/interpreter/jdbc.htmlë¥¼ í™•ì¸í•´ í•„ìš”í•˜ë©´ ìˆ˜ì •í•˜ë„ë¡ í•œë‹¤. Zeppelinì„ ì¬ì‹¤í–‰í•œë‹¤. Notebookì„ ìƒì„±í•˜ê³  %jdbc \\n select * from tabì„ ì‹¤í–‰í•˜ì—¬ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. 1234$ $ZEPPELIN_HOME/bin/zeppelin-daemon.sh restart%jdbcselect * from tab Hive ConnectionHiveì™€ì˜ ì—°ë™ë„ ë§ˆì°¬ê°€ì§€ë¡œ $ZEPPELIN/conf/interpreter.json ë‚´ interpreterSettings ë¶€ë¶„ì— Hive ì •ë³´ë¥¼ ì‘ì„±í•œë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344&#123; \"interpreterSettings\": &#123; \"hive\": &#123; \"id\": \"hive\", \"name\": \"hive\", \"group\": \"jdbc\", \"properties\": &#123; \"default.url\": &#123; \"name\": \"default.url\", \"value\": \"jdbc:hive2://localhost:10000/project\", \"type\": \"string\" &#125;, \"default.driver\": &#123; \"name\": \"default.driver\", \"value\": \"org.apache.hive.jdbc.HiveDriver\", \"type\": \"string\" &#125;,...... \"default.password\": &#123; \"name\": \"default.password\", \"value\": \"hive\", \"type\": \"password\" &#125;, \"default.user\": &#123; \"name\": \"default.user\", \"value\": \"hive\", \"type\": \"string\"...... \"dependencies\": [ &#123; \"groupArtifactVersion\": \"org.apache.hive:hive-jdbc:2.3.6\", \"local\": false &#125;, &#123; \"groupArtifactVersion\": \"org.apache.hadoop:hadoop-common:2.6.0\", \"local\": false, \"exclusions\": [] &#125; ], \"option\": &#123; \"remote\": true, \"port\": -1, templeteì„ ì´ìš©í•´ êµ³ì´ ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ì•Šì•„ë„ ëœë‹¤. Zeppelin ì›¹ì—ì„œ interpreterë¥¼ ìƒì„±í•œ í›„ default.driver, default.password, default.url, default.user, Dependencies 2ê°œë¥¼ ì‘ì„±í•œ í›„ ìƒì„±í•˜ë©´ ìë™ìœ¼ë¡œ interpreter.jsonì— ì¶”ê°€ëœë‹¤. ì£¼ì˜í•  ì ì€, HiveServer2 ë¡œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ìƒíƒœì„ì„ ì²´í¬í•´ì£¼ì–´ì•¼ í•œë‹¤. Zeppelinì„ ì¬ì‹¤í–‰í•œë‹¤. Notebookì„ ìƒì„±í•˜ê³  %jdbc \\n show tablesì„ ì‹¤í–‰í•˜ì—¬ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. 1234$ $ZEPPELIN_HOME/bin/zeppelin-daemon.sh restart%hiveshow tables Reference Zeppelin Documents, https://zeppelin.apache.org/docs/0.8.0/interpreter/hive.html#dependencies 2019.11.18 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Hadoop] Install Presto","slug":"hadoop-install_presto","date":"2019-11-11T15:00:00.000Z","updated":"2020-05-15T05:24:08.746Z","comments":true,"path":"hadoop-install_presto/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_presto/","excerpt":"Prestoë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤","text":"Prestoë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤ PreliminariesAdd user &amp; DownloadPresto userë¥¼ ìƒì„±í•˜ê³  hdclient ê·¸ë£¹ì— í¬í•¨í•œë‹¤. ì´í›„ ì„¤ì¹˜íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œë‹¤. 12$ adduser presto --gid 8630 # hdclient$ wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.228/presto-server-0.228.tar.gz .bash_profile.bash_profileì— Hadoop ë° Presto Envë¥¼ ì¶”ê°€í•œë‹¤. 123456789101112131415161718# Hadoop Envexport JAVA_HOME=/app/jdkexport HADOOP_HOME=/app/hadoopexport PATH=$PATH:$JAVA_HOME/bin:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbinexport HADOOP_PREFIX=/app/hadoopexport HADOOP_COMMON_HOME=$HADOOP_PREFIXexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopexport HADOOP_HDFS_HOME=$HADOOP_PREFIXexport HADOOP_MAPRED_HOME=$HADOOP_PREFIXexport HADOOP_YARN_HOME=$HADOOP_PREFIXexport YARN_CONF_DIR=$HADOOP_PREFIX/etc/hadoop# Presto Envexport PRESTO_HOME=/app/prestoexport PATH=$PATH:$JAVA_HOME/bin:$HIVE_HOME/bin Configuring Prestoì„¸ ê°œì˜ ì„¤ì •íŒŒì¼ì„ $PRESTO_HOME/etc í´ë”ì— ìƒì„±í•œë‹¤. /etc/node.properties123node.environment=productionnode.id=ffffffff-ffff-ffff-ffff-ffffffffffffnode.data-dir=/app/presto/data /etc/jvm.confing12345678-server-Xmx16G-XX:+UseG1GC-XX:G1HeapRegionSize=32M-XX:+UseGCOverheadLimit-XX:+ExplicitGCInvokesConcurrent-XX:+HeapDumpOnOutOfMemoryError-XX:+ExitOnOutOfMemoryError /etc/config.properties12345678coordinator=truenode-scheduler.include-coordinator=truehttp-server.http.port=8000query.max-memory=5GBquery.max-memory-per-node=1GBquery.max-total-memory-per-node=2GBdiscovery-server.enabled=truediscovery.uri=http://192.168.xxx.xxx:8000 http-server.htt.port : PrestoëŠ” ë‚´ë¶€ ë° ì™¸ë¶€ ëª¨ë“  í†µì‹ ì— HTTPë¥¼ ì‚¬ìš©í•˜ë©°, ë‚´ ê²½ìš° 8000ë²ˆ í¬íŠ¸ë¥¼ open, ì´ë¥¼ í†µí•´ í†µì‹  discovery.uri : Presto instanceëŠ” ì‹œì‘ ì‹œ Discovery serviceì— ë“±ë¡ë˜ëŠ” URIë¡œ Presto êµ¬ë™ ì„œë²„ì˜ IPì™€ port (ìœ„ì™€ ê°™ì€ ê²½ìš°ëŠ” 8000 port) ë¡œ ì‘ì„± /etc/catalog/hive.properties12connector.name=hive-hadoop2hive.metastore.uri=thrift://localhost:9083 Hive MetaStore ì˜ default portëŠ” *9083*** ìœ„ì— ìƒì„±í•œ íŒŒì¼ë“¤ì„ treeë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789$ tree ..â”œâ”€â”€ catalogâ”‚ â””â”€â”€ hive.propertiesâ”œâ”€â”€ config.propertiesâ”œâ”€â”€ jvm.configâ””â”€â”€ node.properties1 directory, 4 files Start Presto Server$PRESTO_HOME/bin í´ë”ì— launcher íŒŒì¼ì„ ì‹¤í–‰í•œë‹¤. 12345678$ ./launcher startStarted as 25072# $PRESTO_HOME/data/var/log/launcher.log2019-11-12T14:56:02.306+0900 INFO main io.airlift.log.Logging Logging to stderr2019-11-12T14:56:02.308+0900 INFO main Bootstrap Loading configuration2019-11-12T14:56:02.404+0900 INFO main Bootstrap Initializing logging2019-11-12T14:56:02.447+0900 INFO main io.airlift.log.Logging Logging to /app/presto/data/var/log/server.log2019-11-12T14:56:02.497+0900 INFO main io.airlift.log.Logging Disabling stderr output Presto CLI ì„ wgetì„ ì´ìš©í•´ ë‹¤ìš´ë¡œë“œ í•œë‹¤. ì´í›„ ì‹¤í–‰ê¶Œí•œì„ ì£¼ê³  CLI ë¥¼ ì‹¤í–‰í•œë‹¤. 123$ wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.228/presto-cli-0.228-executable.jar &amp;&amp; mv presto-cli-0.228-executable.jar presto$ chmod +x presto$ ./presto --server 192.168.154.156:8000 --catalog hive --schema project Presto CLI ëª…ë ¹ì–´ arguments server : discovery.uri catalog : Hive MetaStore schema : Hive metaStore ì¤‘ project db ** í…Œì´ë¸”ì„ ì¡°íšŒí•´ë³´ì. 123456789101112presto:project&gt; show tables; Table ---------- binvt00t bprjt00t ccomp00t iprsn00t (4 rows)Query 20191112_060524_00002_bgi94, FINISHED, 1 nodeSplits: 19 total, 19 done (100.00%)0:02 [4 rows, 100B] [1 rows/s, 43B/s] êµ¬ì¶• ì™„ë£Œ! Query ì†ë„ ë¹„êµí…Œì´ë¸”ì˜ row ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ì¿¼ë¦¬ë¬¸ì„ Prestoì™€ Hiveì—ì„œ ìˆ˜í–‰í•´ë³¸ë‹¤. Presto 123456789presto:project&gt; select count(*) from bprjt00t; _col0 ------- 65355 (1 row)Query 20191112_061041_00004_bgi94, FINISHED, 1 nodeSplits: 23 total, 23 done (100.00%)0:04 [65.4K rows, 9.29MB] [15.9K rows/s, 2.26MB/s] Hive 123456789101112131415161718192021222324252627hive&gt; select count(*) &gt; from bprjt00t;WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.Query ID = hive_20191112151209_8598d146-fed8-4b55-8a2b-e1ed186a82d0Total jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapreduce.job.reduces=&lt;number&gt;Starting Job = job_1567153359966_0111, Tracking URL = http://node5.dat:8088/proxy/application_1567153359966_0111/Kill Command = /app/hadoop/bin/hadoop job -kill job_1567153359966_0111Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 12019-11-12 15:12:19,615 Stage-1 map = 0%, reduce = 0%2019-11-12 15:12:23,860 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 4.1 sec2019-11-12 15:12:27,986 Stage-1 map = 100%, reduce = 100%, Cumulative CPU 5.98 secMapReduce Total cumulative CPU time: 5 seconds 980 msecEnded Job = job_1567153359966_0111MapReduce Jobs Launched: Stage-Stage-1: Map: 2 Reduce: 1 Cumulative CPU: 5.98 sec HDFS Read: 9754283 HDFS Write: 105 SUCCESSTotal MapReduce CPU Time Spent: 5 seconds 980 msecOK65355Time taken: 20.718 seconds, Fetched: 1 row(s) ëŒ€ëµ Prestoê°€ Hive ëŒ€ë¹„ ì¿¼ë¦¬ì†ë„ê°€ *20ë°° ê°€ëŸ‰ ë¹ ë¥´ë‹¤*** Reference Presto Documents A Single-node Installation of Presto and Simple Benchmarks made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Hadoop] Sqoopì„ ì´ìš©í•œ Table ì¡°íšŒ","slug":"hadoop-sqoop_example","date":"2019-11-06T15:00:00.000Z","updated":"2020-03-30T15:06:23.578Z","comments":true,"path":"hadoop-sqoop_example/","link":"","permalink":"https://jx2lee.github.io/hadoop-sqoop_example/","excerpt":"Tibero Tableì„ Sqoop ì„ ì´ìš©í•´ HDFSì— ì €ì¥í•¨ê³¼ ë™ì‹œì—, Hive ë¡œ ì¡°íšŒí•˜ëŠ” ì˜ˆì œë¥¼ ì‚´í´ë³¸ë‹¤.","text":"Tibero Tableì„ Sqoop ì„ ì´ìš©í•´ HDFSì— ì €ì¥í•¨ê³¼ ë™ì‹œì—, Hive ë¡œ ì¡°íšŒí•˜ëŠ” ì˜ˆì œë¥¼ ì‚´í´ë³¸ë‹¤. PreliminariesRDBMS TableBPRJT00T í…Œì´ë¸”ì„ í™•ì¸í•œë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839$ DESC BPRJT00T;COLUMN_NAME TYPE CONSTRAINT ---------------------------------------- ------------------ --------------------PRJT_CD VARCHAR(10) PRIMARY KEYPRJT_NM VARCHAR(1000) COMP_CD VARCHAR(10) CUST_CD VARCHAR(10) PRJT_ENV VARCHAR(3000) BUSI_AMT NUMBER(13) ATTACH_NO_ORG VARCHAR(20) IMPORTANT_CLS VARCHAR(1) NOT NULLMA_PRJT_CLS VARCHAR(1) NOT NULLREPORT_CLS VARCHAR(4) NOT NULLPRIORITY_CD VARCHAR(4) NOT NULLPRJT_STATUS VARCHAR(4) NOT NULLSALE_EMP VARCHAR(7) REMARK VARCHAR(4000) REG_EMP VARCHAR(7) REG_DATE VARCHAR(8) MOD_EMP VARCHAR(7) MOD_DATE VARCHAR(8) LOSS_PROD VARCHAR(200) CURRENCY_KIND VARCHAR(4) NOT NULLRECNTR_YN VARCHAR(1) NOT NULLRECNTR_STATUS VARCHAR(4) DIST_PATH VARCHAR(100) DISTRIB_YN VARCHAR(1) NOT NULLDISTRIB_PRJTCD VARCHAR(10) INDEX_NAME TYPE COLUMN_NAME -------------------------------- ------------------------ ----------------------BPRJT00T_IDX01 NORMAL SALE_EMPBPRJT00T_IDX02 NORMAL COMP_CDBPRJT00T_PK NORMAL PRJT_CD$ SELECT COUNT(*) FROM BPRJT00T; COUNT(*)---------- 56125 Sqoop evalSqoopì„ ì´ìš©í•´ í…Œì´ë¸” ì ‘ê·¼ì´ ê°€ëŠ¥í•œì§€ í™•ì¸í•œë‹¤. 123456$ sqoop eval \\-connect jdbc:tibero:thin:@[ip]:[port]:[DB SID]] \\-driver com.tmax.tibero.jdbc.TbDriver \\-username XXX -password XXX \\-e \"select * from BPRJT00T where rownum &lt; 10\"... ë³´ì•ˆìƒ ì¡°íšŒ ê²°ê³¼ëŠ” ìƒëµí•˜ì˜€ë‹¤ RDMBS to HDFSí™•ì¸ì´ ëë‚¬ë‹¤ë©´, ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ Sqoopìœ¼ë¡œ HDFSì— ì €ì¥í•˜ê³  ë™ì‹œì— Hiveë¡œ Import í•œë‹¤. 12345678910sqoop import \"-Dorg.apache.sqoop.splitter.allow_text_splitter=true\" \\--connect jdbc:tibero:thin:@[ip]:[port]:[DB SID] \\--driver com.tmax.tibero.jdbc.TbDriver \\--target-dir /project/BPRJT00T \\--username XXX --password XXX \\--table BPRJT00T \\--fields-terminated-by \",\" \\--hive-import \\--create-hive-table \\--hive-table project.BPRJT00T Hiveë¡œ Import í•˜ê¸° ìœ„í•´ì„œëŠ” ë¯¸ë¦¬ Databaseê°€ êµ¬ì„±ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤. (ë‚˜ì˜ ê²½ìš° DB Nameì€ project) 12345678...19/11/07 16:28:43 INFO hive.HiveImport: OK19/11/07 16:28:43 INFO hive.HiveImport: Time taken: 4.162 seconds19/11/07 16:28:44 INFO hive.HiveImport: Loading data to table project.bprjt00t19/11/07 16:28:44 INFO hive.HiveImport: OK19/11/07 16:28:44 INFO hive.HiveImport: Time taken: 0.611 seconds19/11/07 16:28:45 INFO hive.HiveImport: Hive import complete.19/11/07 16:28:45 INFO hive.HiveImport: Export directory is contains the _SUCCESS file only, removing the directory. Resultìš°ì„ , Hiveë¡œ Import í•œ í…Œì´ë¸”ì„ hdfs ëª…ë ì–´ë¡œ í™•ì¸í•œë‹¤. 123456$ hdfs dfs -ls /user/hive/warehouseFound 1 itemsdrwxrwxrwx - hive supergroup 0 2019-11-07 16:27 /user/hive/warehouse/project.db$ hdfs dfs -ls /user/hive/warehouse/project.db/Found 1 itemsdrwxrwxrwx - hive supergroup 0 2019-11-07 16:28 /user/hive/warehouse/project.db/bprjt00t ì˜ ë“¤ì–´ê°”ë‹¤. ê·¸ëŸ¼ Hive ì½˜ì†”ë¡œ ì ‘ì†í•˜ì—¬ BPRJT00T í…Œì´ë¸”ì„ ì¡°íšŒí•´ë³´ì. 1234567891011121314$ hiveSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Logging initialized using configuration in jar:file:/app/hive/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: trueHive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.hive&gt; $ use project;OKTime taken: 2.963 secondshive&gt; $ select * from bprjt00t limit 10;OK ì´ë˜í•œ, ì¡°íšŒê²°ê³¼ëŠ” ìƒëµ 2019.11.07 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Hadoop] Hive Import ì‹œ Could not initialize class org.apache.derby.jdbc.EmbeddedDriver ë¬¸ì œí•´ê²°","slug":"hadoop-sqoop_import_error","date":"2019-11-06T15:00:00.000Z","updated":"2020-03-30T15:06:23.585Z","comments":true,"path":"hadoop-sqoop_import_error/","link":"","permalink":"https://jx2lee.github.io/hadoop-sqoop_import_error/","excerpt":"Hive ì— RDMS í…Œì´ë¸”ì„ import í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•œ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤","text":"Hive ì— RDMS í…Œì´ë¸”ì„ import í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•œ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤ Statusì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ í†µí•´ Tibero í…Œì´ë¸” BPRJT00Të¥¼ Sqoopìœ¼ë¡œ ë•¡ê²¨ì˜¤ê³  Hiveë¡œ Import í•˜ê³ ì í–ˆë‹¤. 12345678910sqoop import \"-Dorg.apache.sqoop.splitter.allow_text_splitter=true\" \\--connect jdbc:tibero:thin:@192.168.154.xxx:xxxx:tibero \\--driver com.tmax.tibero.jdbc.TbDriver \\--target-dir /project/BPRJT00T \\--username ERP --password xxxx \\--table BPRJT00T \\--fields-terminated-by \",\" \\--hive-import \\--create-hive-table \\--hive-table project.BPRJT00T Error Message123Could not initialize class org.apache.derby.jdbc.EmbeddedDriver......... 12 more Solutionë¶„ëª… Hiveì˜ MetaStoreë¥¼ MySQLë¡œ ì„¤ì •í•˜ì˜€ëŠ”ë°(ì´ˆê¸°í™”ê¹Œì§€ ì™„ë£Œí•œ ìƒíƒœ) ìê¾¸ Derby Driverë¥¼ ëª»ì°¾ì•˜ë‹¤ëŠ” ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì´ëŠ”, hive-site.xmlì´ Hiveê°€ ì¸ì‹ì„ ëª»í•´ Default Databaseë¡œ Derbyë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ëŠ” .bash_profile ë˜ëŠ” .profile ë‚´ HADOOP_CLASSPATHë¥¼ ì¶”ê°€í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆë‹¤. ë§Œì•½ ë‚˜ì²˜ëŸ¼ MetaStoreë¥¼ MySQLì´ ì•„ë‹Œ Derbyë¡œ ì„¤ì •í–ˆëŠ”ë° ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´, $HIVE_HOME/lib ì•ˆì— connector íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ë‹¤ë©´ copy &amp; paste í•˜ì 123$ vi ~/.profileexport HADOOP_CLASSPATH=$HIVE_HOME/conf:$HIVE_HOME/lib$ . ~/.profile ì´í›„ Statusì—ì„œ ì‘ì„±í•œ ì»¤ë§¨ë“œë¥¼ ì‹¤í–‰í•˜ë©´ Hiveì— ë¯¸ë¦¬ ìƒì„±í•´ë†“ì€ Databaseì— í…Œì´ë¸”ì´ ìƒì„±í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 123$ hdfs dfs -ls /user/hive/warehouseFound 1 itemsdrwxrwxrwx - hive supergroup 0 2019-11-07 15:41 /user/hive/warehouse/project.db MySQL hive ìœ ì €ì˜ proejct DBì— bprjt00t í…Œì´ë¸”ì´ ë“¤ì–´ê°€ ìˆìŒì„ í™•ì¸ 2019.11.07 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Database] Install MySQL 8.0","slug":"database-install_mysql","date":"2019-11-05T15:00:00.000Z","updated":"2020-05-15T05:21:06.069Z","comments":true,"path":"database-install_mysql/","link":"","permalink":"https://jx2lee.github.io/database-install_mysql/","excerpt":"Hiveì˜ Meta Storeë¡œ MySQLë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„¤ì¹˜í•˜ê³ , ì´ë¥¼ ì •ë¦¬í•œë‹¤","text":"Hiveì˜ Meta Storeë¡œ MySQLë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„¤ì¹˜í•˜ê³ , ì´ë¥¼ ì •ë¦¬í•œë‹¤ Setting Environmentì„¤ì¹˜ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ versionì„ ë§ì¶°ì¤„ í•„ìš”ê°€ ìˆë‹¤. Version Up CMakeCMake ì´ í•˜ìœ„ versionì´ë¼ë©´ ì˜¬ë ¤ë³´ë„ë¡ í•œë‹¤. 12345$ tar -xvzf cmake-3.16.0-rc3.tar.gz$ cd cmake-3.16.0-rc3.tar.gz$ ./bootstrap$ make$ sudo make install Version up gccë§ˆì°¬ê°€ì§€ë¡œ gcc versionì´ í•˜ìœ„ ë²„ì ¼ì´ë©´ ì˜¬ë ¤ë³´ë„ë¡ í•œë‹¤. 123456789$ sudo yum install centos-release-scl$ sudo yum install devtoolset-7-gcc*$ scl enable devtoolset-7 bash$ which gcc$ gcc --versiongcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Makewgetì„ ì´ìš©í•´ binary íŒŒì¼ì„ ë‹¤ìš´ë°›ê³  CMakeì„ ì´ìš©í•´ ì„¤ì¹˜í•œë‹¤. 12345678910111213141516171819202122232425262728$ cd /app/$ wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.18.tar.gz$ tar xvfz mysql-8.0.18.tar.gz$ cd mysql-8.0.18$ cmake \\-DCMAKE_INSTALL_PREFIX=/app/mysql \\-DMYSQL_DATADIR=/home/mysql/data \\-DSYSCONFDIR=/app/mysql \\-DMYSQL_USER=mysql \\-DWITH_MYISAM_STORAGE_ENGINE=1 \\-DWITH_INNOBASE_STORAGE_ENGINE=1 \\-DWITH_PARTITION_STORAGE_ENGINE=1 \\-DWITH_FEDERATED_STORAGE_ENGINE=1 \\-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\-DWITH_MEMORY_STORAGE_ENGINE=1 \\-DWITH_READLINE=1 \\-DMYSQL_UNIX_ADDR=/app/mysql/mysql.sock \\-DMYSOL_TCP_PORT=3306 \\-DENABLED_LOCAL_INFILE=1 \\-DENABLE_DOWNLOADS=1 \\-DWITH_EXTRA_CHARSETS=all \\-DDEFAULT_CHARSET=utf8 \\-DDEFAULT_COLLATION=utf8_general_ci \\-DWITH_DEBUG=0 \\-DMYSQL_MAINTAINER_MODE=0 \\-DDOWNLOAD_BOOST=1 \\-DDOWNLOAD_BOOST=1 -DWITH_BOOST=/app/mysql-8.0.18$ make install Add Servcie123$ cp mysql.server /etc/rc.d/init.d/mysql$ ln -s /etc/rc.d/init.d/mysql /etc/rc.d/rc3.d/S97mysql $ vi /usr/lib/systemd/system/mysql.service /etc/my.cnf/etc ì— my.cnf config íŒŒì¼ì„ ìƒì„±í•œë‹¤. my.cnfëŠ” MySQLì˜ configë¥¼ ì„¤ì •í•˜ëŠ” íŒŒì¼ì´ë©°, ë³¸ ì„¤ì¹˜ì—ì„œëŠ” DB Engineìœ¼ë¡œ InnoDBë¥¼ ì‚¬ìš©í•œë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697[client]default-character-set &#x3D; utf8port &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sockdefault-character-set &#x3D; utf8 [mysqld]socket&#x3D;&#x2F;app&#x2F;mysql&#x2F;mysql.sockdatadir&#x3D;&#x2F;home&#x2F;mysql&#x2F;databasedir &#x3D; &#x2F;app&#x2F;mysql#user &#x3D; mysql#bind-address &#x3D; 0.0.0.0skip-external-lockingkey_buffer_size &#x3D; 384Mmax_allowed_packet &#x3D; 16Mtable_open_cache &#x3D; 2048sort_buffer_size &#x3D; 2Mread_buffer_size &#x3D; 2Mread_rnd_buffer_size &#x3D; 8Mmyisam_sort_buffer_size &#x3D; 64Mthread_cache_size &#x3D; 8 #dns queryskip-name-resolve #connectionmax_connections &#x3D; 1000max_connect_errors &#x3D; 1000wait_timeout&#x3D; 60 #slow-queries#slow_query_log &#x3D; &#x2F;home&#x2F;mysql_data&#x2F;slow-queries.log#long_query_time &#x3D; 3#log-slow-queries &#x3D; &#x2F;home&#x2F;mysql_data&#x2F;mysql-slow-queries.log ##timestampexplicit_defaults_for_timestampsymbolic-links&#x3D;0### loglog-error&#x3D;&#x2F;home&#x2F;mysql&#x2F;data&#x2F;mysqld.logpid-file&#x3D;&#x2F;home&#x2F;mysql&#x2F;mysqld.pid ###chractercharacter-set-client-handshake&#x3D;FALSEinit_connect &#x3D; SET collation_connection &#x3D; utf8_general_ciinit_connect &#x3D; SET NAMES utf8character-set-server &#x3D; utf8collation-server &#x3D; utf8_general_cisymbolic-links&#x3D;0##Password Policy#validate_password_policy&#x3D;LOW#validate_password_policy&#x3D;MEDIUM ### MyISAM Spectific options#default-storage-engine &#x3D; myisamkey_buffer_size &#x3D; 32Mbulk_insert_buffer_size &#x3D; 64Mmyisam_sort_buffer_size &#x3D; 128Mmyisam_max_sort_file_size &#x3D; 10Gmyisam_repair_threads &#x3D; 1 ### INNODB Spectific optionsdefault-storage-engine &#x3D; InnoDB#skip-innodb#innodb_additional_mem_pool_size &#x3D; 16Minnodb_buffer_pool_size &#x3D; 1024MBinnodb_data_file_path &#x3D; ibdata1:10M:autoextendinnodb_write_io_threads &#x3D; 8innodb_read_io_threads &#x3D; 8innodb_thread_concurrency &#x3D; 16innodb_flush_log_at_trx_commit &#x3D; 1innodb_log_buffer_size &#x3D; 8Minnodb_log_file_size &#x3D; 128Minnodb_log_files_in_group &#x3D; 3innodb_max_dirty_pages_pct &#x3D; 90innodb_lock_wait_timeout &#x3D; 120 [mysqldump]default-character-set &#x3D; utf8max_allowed_packet &#x3D; 512M [mysql]#no-auto-rehashdefault-character-set &#x3D; utf8 [myisamchk]key_buffer_size &#x3D; 512Msort_buffer_size &#x3D; 512Mread_buffer &#x3D; 8Mwrite_buffer &#x3D; 8M Initialize DatabaseDatabaseë¥¼ mysql userë¡œ ì´ˆê¸°í™” í•œë‹¤. 12345678910111213141516171819202122232425$ /app/mysql/bin/mysqld --initialize-insecure --basedir=/app/mysql --datadir=/home/mysql/data --user=mysql$ ll /home/mysql/data/total 448572-rw-r----- 1 mysql mysql 56 Nov 5 17:19 auto.cnf-rw------- 1 mysql mysql 1680 Nov 5 17:19 ca-key.pem-rw-r--r-- 1 mysql mysql 1112 Nov 5 17:19 ca.pem-rw-r--r-- 1 mysql mysql 1112 Nov 5 17:19 client-cert.pem-rw------- 1 mysql mysql 1676 Nov 5 17:19 client-key.pem-rw-r----- 1 mysql mysql 6100 Nov 5 17:19 ib_buffer_pool-rw-r----- 1 mysql mysql 10485760 Nov 5 17:19 ibdata1-rw-r----- 1 mysql mysql 134217728 Nov 5 17:19 ib_logfile0-rw-r----- 1 mysql mysql 134217728 Nov 5 17:19 ib_logfile1-rw-r----- 1 mysql mysql 134217728 Nov 5 17:19 ib_logfile2drwxr-x--- 2 mysql mysql 6 Nov 5 17:19 #innodb_tempdrwxr-x--- 2 mysql mysql 143 Nov 5 17:19 mysql-rw-r----- 1 mysql mysql 1301 Nov 5 17:19 mysqld.log-rw-r----- 1 mysql mysql 25165824 Nov 5 17:19 mysql.ibddrwxr-x--- 2 mysql mysql 8192 Nov 5 17:19 performance_schema-rw------- 1 mysql mysql 1680 Nov 5 17:19 private_key.pem-rw-r--r-- 1 mysql mysql 452 Nov 5 17:19 public_key.pem-rw-r--r-- 1 mysql mysql 1112 Nov 5 17:19 server-cert.pem-rw------- 1 mysql mysql 1676 Nov 5 17:19 server-key.pemdrwxr-x--- 2 mysql mysql 28 Nov 5 17:19 sys-rw-r----- 1 mysql mysql 10485760 Nov 5 17:19 undo_001-rw-r----- 1 mysql mysql 10485760 Nov 5 17:19 undo_002 Restart Service &amp; CheckingService ì¬ê¸°ë™ í›„ MySQLì´ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142$ systemctl stop mysql$ systemctl start mysql$ /app/mysql/bin/mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 8Server version: 8.0.18 Source distributionCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; mysql&gt; mysql&gt; mysql&gt; \\s--------------/app/mysql/bin/mysql Ver 8.0.18 for Linux on x86_64 (Source distribution)Connection id: 8Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server version: 8.0.18 Source distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: utf8Db characterset: utf8Client characterset: utf8Conn. characterset: utf8UNIX socket: /tmp/mysql.sockUptime: 17 min 25 secThreads: 2 Questions: 6 Slow queries: 0 Opens: 115 Flush tables: 3 Open tables: 35 Queries per second avg: 0.005-------------- MySQL ì‹œì‘ ì‹œ /tmp/mysql.sock ì´ ì—†ë‹¤ê³  failì´ ë‚  ìˆ˜ ìˆë‹¤. ì´ë•ŒëŠ” tmp í´ë”ì•ˆì— mysql.sockì´ ìˆëŠ” pathë¡œ ë§í¬ë¥¼ ìƒì„±í•˜ë©´ëœë‹¤. (ì´ˆê¸° ì„¤ì •ë¶€í„° /tmpì— ì•ˆë“¤ì–´ê°€ê²Œë” ì–´ë–»ê²Œ ì„¤ì •í•˜ì§€..? ì´ê±´ ë‚´ì¼í•˜ì!) Reference MYSQL 8.0 INSTALL ( mysql 8.0.17 ) / Centos 7 CentOS7ì—ì„œ Mysql 8.0 ì†ŒìŠ¤ ì„¤ì¹˜ MySQL Documents 2019.11.06 made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jx2lee.github.io/tags/MySQL/"}]},{"title":"[Hadoop] Install Hive","slug":"hadoop-install_hive","date":"2019-11-05T15:00:00.000Z","updated":"2020-05-15T05:23:03.960Z","comments":true,"path":"hadoop-install_hive/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_hive/","excerpt":"Hiveë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤","text":"Hiveë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³¸ë‹¤ PreliminariesAdd user &amp; groupHive userë¥¼ ìƒì„±í•œë‹¤. 123$ groupadd hdclient$ usermod -g hdclient sqoop $ adduser hive --gid 8630 # hdclient .bash_profile.bash_profileì— Hadoop ë° Hive ENVë¥¼ ì¶”ê°€í•œë‹¤. 123456789101112131415161718# Hadoopexport JAVA_HOME=/app/jdkexport HADOOP_HOME=/app/hadoopexport PATH=$PATH:$JAVA_HOME/bin:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbinexport HADOOP_PREFIX=/app/hadoopexport HADOOP_COMMON_HOME=$HADOOP_PREFIXexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopexport HADOOP_HDFS_HOME=$HADOOP_PREFIXexport HADOOP_MAPRED_HOME=$HADOOP_PREFIXexport HADOOP_YARN_HOME=$HADOOP_PREFIXexport YARN_CONF_DIR=$HADOOP_PREFIX/etc/hadoop# Hiveexport HIVE_HOME=/app/hiveexport PATH=$PATH:$JAVA_HOME/bin:$HIVE_HOME/bin Setting MySQL for Hive MetaStoreHive MetaStoreë¥¼ MySQLë¡œ ì‚¬ìš©í•˜ê¸°ìœ„í•´ ìƒˆë¡œìš´ databaseì™€ hive userë¥¼ ìƒì„±í•œë‹¤ 12345678910111213141516$ create database hive;$ create user hive@'%' identified by 'hive';$ grant all privileges on hive.* to hive@'%';$ use mysql;$ select host, user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | hive || localhost | mysql.infoschema || localhost | mysql.session || localhost | mysql.sys || localhost | root |+-----------+------------------+5 rows in set (0.00 sec) userë¥¼ ìƒì„±í•  ë•Œ ê³¨ë±…ì´ ë’¤ %ëŠ” ëª¨ë“  ì™¸ë¶€ ipì˜ ì ‘ê·¼ì„ í—ˆìš©í•œë‹¤ëŠ” ëœ»ì´ë‹¤. jdbc to $HIVE_HOME/lib/MySQL Driverë¥¼ í•´ë‹¹ PATHë¡œ ë³µì‚¬í•œë‹¤. $ cp tibero6-jdbc.jar /app/hive/lib/ Driver URL : https://dev.mysql.com/downloads/connector/j/8.0.html Hive Configurationshive-env.sh123$ cp $HIVE_HOME/conf/hive-env.sh.template $HIVE_HOME/conf/hive-env.sh`$ vi $HIVE_HOME/conf/hive-env.shHADOOP_HOME=/app/hadoop hive-site.xmlhive-site.xmlì„ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•œë‹¤. Hiveì˜ MetaStoreë¥¼ ì™¸ë¶€ ì„œë²„ì˜ MySQLë¥¼ ì´ìš©í•  ì˜ˆì •ì´ë‹¤. (Hive ì„¤ì¹˜ëœ ì„œë²„ì™€ ë³„ê°œì˜ ì„œë²„ì´ë‹¤. ë§Œì•½ ê°™ì€ ì„œë²„ë¼ë©´, javax.jdo.option.ConnectionURLì˜ ip:portê°’ì€ localhost:portë¡œ ì‘ì„±í•œë‹¤.) 1234567891011121314151617181920212223242526&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.metastore.local&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://ip:port/hive?serverTimezone=UTC&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.urls&lt;/name&gt; &lt;value&gt;thrift://node5.dat:10000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; javax.jdo.option.ConnectionURLì˜ port ë’¤ hiveëŠ” MetaStoreë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ MySQL DB nameì´ë‹¤. ë’¤ì— serverTimezone argë¥¼ ì¶”ê°€í•œ ì´ìœ ëŠ” ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ SchemaTool ì´ˆê¸°í™” ì‹œ ì—ëŸ¬ ë©”ì„¸ì§€ê°€ ëœ¬ë‹¤. ê²°êµ­ì—” ì‹œê°„ í˜•ì‹ì´ ë§ì§€ ì•Šì•„ ìƒê¸°ëŠ” ë¬¸ì œì´ë¯€ë¡œ argë¥¼ ì¶”ê°€í•œë‹¤ Create MetaStore Schemaschematool -initSchema -dbType mysql --verbose ì„ í†µí•´ Hiveì˜ MetaStoreë¥¼ ì´ˆê¸°í™” í•œë‹¤. 1234567891011121314151617181920212223242526272829$ schematool -initSchema -dbType mysql --verbose...beeline&gt; Initialization script completedschemaTool completed$ mysql -u hive -pmysql&gt; use hive;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+---------------------------+| Tables_in_hive |+---------------------------+| AUX_TABLE || BUCKETING_COLS || CDS || COLUMNS_V2 || COMPACTION_QUEUE || COMPLETED_COMPACTIONS |......| SERDE_PARAMS || TYPES || TYPE_FIELDS || VERSION || WRITE_SET |+---------------------------+57 rows in set (0.00 sec) Run HiveServer &amp; MetaStorehiveserver2ì™€ metastoreë¥¼ ê¸°ë™í•´ì£¼ë©´ ì™„ë£Œ. 1234567891011121314$ hive --service hiveserver2 &amp;SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.$ hive --service metastore &amp;SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Python] Mappers and Reducers","slug":"python-map_reduce","date":"2019-10-30T15:00:00.000Z","updated":"2020-03-30T15:06:23.551Z","comments":true,"path":"python-map_reduce/","link":"","permalink":"https://jx2lee.github.io/python-map_reduce/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Database ì¹´í…Œê³ ë¦¬ì˜ MapReduce ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Database ì¹´í…Œê³ ë¦¬ì˜ MapReduce ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ ë¬¸ì œMappers and Reducers Hereâ€™s a quick but comprehensive introduction to the idea of splitting tasks into a MapReduce model. The four important functions involved are: 1234Map (the mapper function) EmitIntermediate(the intermediate key,value pairs emitted by the mapper functions) Reduce (the reducer function) Emit (the final output, after summarization from the Reduce functions) We provide you with a single system, single thread version of a basic MapReduce implementation. Task Joins are The input is a number of lines with pairs of name of friends, in the form: 1[Friend1] [Friend2] The required output is to print the number of friends of each person, in the format shown. The code for the MapReduce class, parts related to IO etc. has already been provided. However, the mapper and reducer functions are incomplete. Your task is to fill up the mapper and reducer functions appropriately, such that the program works, and outputs the list of number of friends of each person , in lexicographical order. Also, this program outputs certain information to the error stream. This information has been logged to help beginners gain a better understanding of the the intermediate steps in a map-reduce process. Languages Supported Currently, we provide the base code in Python. Input Format A list of single space separated pairs of friend names. We have already written the input handling code to read in this data. Output Format Again, the output handling part has already been provided in the template code. The Key contains [Person name] and the value contains the number of friends, sorted in lexicographical order. The entities in this list, will naturally be confined to only those people provided in the input data. Sample Input 1234Joe SueSue PhiPhi JoePhi Alice Sample Output 1234&#123;&quot;key&quot;:&quot;Alice&quot;,&quot;value&quot;:&quot;1&quot;&#125;&#123;&quot;key&quot;:&quot;Joe&quot;,&quot;value&quot;:&quot;2&quot;&#125;&#123;&quot;key&quot;:&quot;Phi&quot;,&quot;value&quot;:&quot;3&quot;&#125;&#123;&quot;key&quot;:&quot;Sue&quot;,&quot;value&quot;:&quot;2&quot;&#125; Explanation We have computed the number of friends for each person via the Mapper and Reducer functions. í•´ê²°full code ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import sysfrom collections import OrderedDictclass MapReduce: def __init__(self): self.intermediate = OrderedDict() self.result = [] def emitIntermediate(self, key, value): self.intermediate.setdefault(key, []) self.intermediate[key].append(value) def emit(self, value): self.result.append(value) def execute(self, data, mapper, reducer): for record in data: mapper(record) for key in self.intermediate: reducer(key, self.intermediate[key]) self.result.sort() print(self.result) for item in self.result: print(\"&#123;\\\"key\\\":\\\"\" + item[0] + \"\\\",\\\"value\\\":\\\"\" + str(item[1]) + \"\\\"&#125;\")mapReducer = MapReduce()def mapper(record): # Start writing the Map code here words = record.split() mapReducer.emitIntermediate(words[0], words[1]) mapReducer.emitIntermediate(words[1], words[0]) print(mapReducer.intermediate)def reducer(key, list_of_values): # Start writing the Reduce code here mapReducer.emit((key, len(list_of_values))) print(mapReducer.result)if __name__ == \"__main__\": # inputData = ['Joe Sue', 'Sue Phi', 'Phi Joe', 'Phi Alice'] inputData = [] for line in sys.stdin: inputData.append(line) mapReducer.execute(inputData, mapper, reducer) ìš°ì„ , mapReduce classë¥¼ ì‚´í´ë³¸ë‹¤. Class : mapReduceclss mapReduceëŠ” init í•¨ìˆ˜ë¥¼ í¬í•¨ ì´ ì„¸ ê°œì˜ í•¨ìˆ˜ë¥¼ ê°–ëŠ”ë‹¤. Func : initinit`í•¨ìˆ˜ë¡œ ì¸í•´ intermediate, result ë³€ìˆ˜ë¥¼ ê°–ëŠ”ë‹¤. ì´ëŠ” ê°ê° key-valueë¡œ ì´ë£¨ì–´ì§„ dictionary (ë¬¸ì œì—ì„œ ì›í•˜ëŠ” ë‹¨ì–´ : ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ë¥¼ ì˜ë¯¸)ì™€ ë¬¸ì œ ì •ë‹µì— ë§ëŠ” í˜•ì‹ì˜ Return ê°’ì´ë‹¤. 123def __init__(self): self.intermediate = OrderedDict() self.result = [] Func : emitIntermediatekey-value ë¥¼ ì…ë ¥ë°›ì•„ dictionaryì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. 123def emitIntermediate(self, key, value): self.intermediate.setdefault(key, []) self.intermediate[key].append(value) Func : emitê° ë‹¨ì–´ì˜ ì¶œí˜„ íšŸìˆ˜ë¥¼ ì§‘ê³„í•œ í›„ ê²°ê³¼ê°’ì— ë‹´ëŠ” í•¨ìˆ˜ì´ë‹¤. 12def emit(self, value): self.result.append(value) Func : executeì…ë ¥ë°›ì€ ë°ì´í„°ë¥¼ ì½ì–´ë“¤ì—¬ ë‚˜ì¤‘ì— ìš°ë¦¬ê°€ ì‘ì„±í•´ì•¼í•  mapper / reducerí•¨ìˆ˜ë¥¼ ì´ìš©í•´ ìµœì¢… ê²°ê³¼ê°’ì„ ì•Œë§ëŠ” í˜•íƒœë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. 12345678910def execute(self, data, mapper, reducer): for record in data: mapper(record) for key in self.intermediate: reducer(key, self.intermediate[key]) self.result.sort() print(self.result) for item in self.result: print(\"&#123;\\\"key\\\":\\\"\" + item[0] + \"\\\",\\\"value\\\":\\\"\" + str(item[1]) + \"\\\"&#125;\") ì‹¤í–‰í•¨ìˆ˜(excutable fucntion)ë¼ ìƒê°í•˜ì Func : mapperì´ì œ mapper ë¥¼ ì‚´í´ë³¸ë‹¤. ì…ë ¥ë°›ì€ í•œ ë¬¸ì¥ì€ split í•¨ìˆ˜ë¥¼ í†µí•´ ë‘ ë‹¨ì–´ë¡œ ë‚˜ëˆ„ì–´ì£¼ê³ , ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ keyë¡œ ì¸ì‹í•˜ë©´ ì•ˆë˜ê¸° ë•Œë¬¸ì— mapReducer í´ë˜ìŠ¤ì—ì„œ ë§Œë“  emitIntermediate í•¨ìˆ˜ë¥¼ ë‘ ë²ˆ ìˆ˜í–‰í•œë‹¤. 123456def mapper(record): # Start writing the Map code here words = record.split() mapReducer.emitIntermediate(words[0], words[1]) mapReducer.emitIntermediate(words[1], words[0]) print(mapReducer.intermediate) ê³¼ì—° ì´ mapper í•¨ìˆ˜ê°€ ì–´ë–»ê²Œ ì‘ë™ë˜ëŠ”ì§€ ë¬¸ì œì—ì„œ ì œê³µí•œ test caseë¥¼ ë°”íƒ•ìœ¼ë¡œ print í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ëœë‹¤. ì¦‰, ê°™ì€ keyê°’ì„ ê°€ì§€ë©´ valueë¡œ append í•´ë‚˜ê°„ë‹¤. (valueê°’ìœ¼ë¡œ ê³„ì†í•´ì„œ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ëŠ”ë° ì´ëŠ” ë‚˜ì¤‘ì— reducer í•¨ìˆ˜ì—ì„œ ì§‘ê³„ë¥¼ í•  ë•Œ ì‚¬ìš©í•œë‹¤) 1234OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;])])OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;])])OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;, &#39;Phi&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;, &#39;Joe&#39;])])OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;, &#39;Phi&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;, &#39;Joe&#39;, &#39;Alice&#39;]), (&#39;Alice&#39;, [&#39;Phi&#39;])]) Func : reducerkey-valueë¡œ ì´ë£¨ì–´ì§„ dictionaryë¥¼ ì§‘ê³„í•´ì£¼ëŠ” reducer í•¨ìˆ˜ì´ë‹¤. mapReducer í´ë˜ìŠ¤ì˜ emití•¨ìˆ˜ë¥¼ í†µí•´ result ë³€ìˆ˜ì— ê²°ê³¼ê°’ì„ ì €ì¥í•œë‹¤. ì´ë•Œ, ìœ„ mapperí•¨ìˆ˜ë¥¼ í†µí•´ ê° keyì— ëŒ€í•œ valueë“¤ì˜ ê¸¸ì´ë¥¼ keyì™€ í•¨ê»˜ append í•œë‹¤. 1234def reducer(key, list_of_values): # Start writing the Reduce code here mapReducer.emit((key, len(list_of_values))) print(mapReducer.result) Main123456if __name__ == \"__main__\": # inputData = ['Joe Sue', 'Sue Phi', 'Phi Joe', 'Phi Alice'] inputData = [] for line in sys.stdin: inputData.append(line) mapReducer.execute(inputData, mapper, reducer) ì´ë ‡ê²Œ class ë° functionì„ ì§ì ‘ ì§œë³´ë©´ì„œ ì„¤ê³„í•˜ëŠ” ë‹¨ê³„ì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ë‹¤. Pythonì„ ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ì½”ë”©ì„ í•´ë³´ëŠ” ì—°ìŠµì„ í•´ì•¼ê² ë‹¤ ì°¸ê³  https://github.com/cielavenir/procon/blob/master/hackerrank/map-reduce-advanced-count-number-of-friends.py í•˜ë‘¡ ë§µë¦¬ë“€ìŠ¤(MapReduce) ì•Œì•„ë³´ì, https://jayzzz.tistory.com/44 2019.10.31 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] 15 Days of Learning","slug":"hackerrank-15_days_of_learning","date":"2019-10-29T15:00:00.000Z","updated":"2020-03-30T15:06:23.575Z","comments":true,"path":"hackerrank-15_days_of_learning/","link":"","permalink":"https://jx2lee.github.io/hackerrank-15_days_of_learning/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” 15 Days of Learning ë¥¼ SELECT sub queryì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” 15 Days of Learning ë¥¼ SELECT sub queryì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œJulia conducted a days of learning SQL contest. The start date of the contest was March 01, 2016 and the end date was March 15, 2016. Write a query to print total number of unique hackers who made at least submission each day (starting on the first day of the contest), and find the hacker_id and name of the hacker who made maximum number of submissions each day. If more than one such hacker has a maximum number of submissions, print the lowest hacker_id. The query should print this information for each day of the contest, sorted by the date. Input Format The following tables hold contest data: Hackers: The hacker_id is the id of the hacker, and name is the name of the hacker. Submissions: The submission_date is the date of the submission, submission_id is the id of the submission, hacker_id is the id of the hacker who made the submission, and score is the score of the submission. Sample Input For the following sample input, assume that the end date of the contest was March 06, 2016. Hackers Table: Submissions Table: Sample Output 1234562016-03-01 4 20703 Angela2016-03-02 2 79722 Michael2016-03-03 2 20703 Angela2016-03-04 2 20703 Angela2016-03-05 1 36396 Frank2016-03-06 1 20703 Angela Explanation On March 01, 2016 hackers , , , and made submissions. There are unique hackers who made at least one submission each day. As each hacker made one submission, is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is Angela. On March 02, 2016 hackers , , and made submissions. Now and were the only ones to submit every day, so there are unique hackers who made at least one submission each day. made submissions, and name of the hacker is Michael. On March 03, 2016 hackers , , and made submissions. Now and were the only ones, so there are unique hackers who made at least one submission each day. As each hacker made one submission so is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is Angela. On March 04, 2016 hackers , , , and made submissions. Now and only submitted each day, so there are unique hackers who made at least one submission each day. As each hacker made one submission so is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is Angela. On March 05, 2016 hackers , , and made submissions. Now only submitted each day, so there is only unique hacker who made at least one submission each day. made submissions and name of the hacker is Frank. On March 06, 2016 only made submission, so there is only unique hacker who made at least one submission each day. made submission and name of the hacker is Angela. ì ‘ê·¼Joinì„ ì´ìš©í•´ ë¬¸ì œë¥¼ í’€ë ¤ë‹¤ ì‹¤íŒ¨í•˜ì˜€ë‹¤. ì´ì— ì œê³µë˜ëŠ” Tableì´ 2ê°œì¸ ì ì„ í™œìš©í•˜ì—¬ SELECT ì ˆ ë‚´ Sub queryë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì ‘ê·¼í•˜ì˜€ë‹¤. ìš°ì„ , ìœ ì¼í•œ ì œì¶œ ë‚ ì§œ Tableë¡œ ë¶€í„° ì œì¶œ ë‚ ì§œê°€ ê°™ê³  ì œì¶œ ë§ˆê°ì¼ê¹Œì§€ ë‚ ì§œ ì°¨ì´ê°€ ê°™ì€ ìœ ì¼í•œ hacker_id ë¥¼ ì¡°íšŒí•˜ëŠ” SELECT ë¬¸ì„ ì‘ì„±í•œë‹¤. ì´ë•Œ, ìµœì¢… ê²°ê³¼ë¬¼ì€ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ groupí™” ì‹œí‚¨ë‹¤. 1234567891011select submission_date, (select count(distinct hacker_id) from submissions as s2 where s2.submission_date = s1.submission_date and (select count(distinct s3.submission_date) from submissions as s3 where s3.hacker_id = s2.hacker_id and s3.submission_date &lt; s1.submission_date) = datediff(s1.submission_date, '2016-03-01')),from (select distinct submission_date from submissions) as s1group by submission_date; ì´í›„, ì œì¶œì„ ê°€ì¥ ë§ì´ í•œ hackerì˜ idë¥¼ ì¡°íšŒí•œ id table ê³¼ id tableì„ ì´ìš©í•´ hacker ì´ë¦„ì„ ì¡°íšŒ í•˜ëŠ” SELECT Sub queryë¥¼ ì¶”ê°€í•œë‹¤. ì´ë•Œ, id tableì˜ ê²½ìš° ê°€ì¥ ë§ì´ ì œì¶œí•œ hackerë§Œ ë½‘ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì¤‘ë³µì„ í”¼í•˜ê³ ì LIMIT 1ì„ ì¶”ê°€í•œë‹¤. 12345678910111213141516171819select submission_date, (select count(distinct hacker_id) from submissions as s2 where s2.submission_date = s1.submission_date and (select count(distinct s3.submission_date) from submissions as s3 where s3.hacker_id = s2.hacker_id and s3.submission_date &lt; s1.submission_date) = datediff(s1.submission_date, '2016-03-01')), --append (select hacker_id from submissions as s2 where s2.submission_date = s1.submission_date group by hacker_id order by count(submission_id) desc, hacker_id limit 1) as id, (select name from hackers where hacker_id = id) --/appendfrom (select distinct submission_date from submissions) as s1group by submission_date; ë¬¸ì œ ì ‘ê·¼í•  ë•Œ Joinë§Œ ë°”ë¼ë³´ì§€ ì•Šê³  SELECT / FROM / WHERE ì ˆì—ì„œ Sub queryë¥¼ ì‘ì„±í•˜ëŠ” ì•ˆëª©ì„ í‚¤ì›Œë³´ì. (ë¬¼ë¡  hackerrankì˜ ë¬¸ì œëŠ” ëë‚¬ë‹¤..) í•´ê²°1234567891011121314151617select submission_date, (select count(distinct hacker_id) from submissions as s2 where s2.submission_date = s1.submission_date and (select count(distinct s3.submission_date) from submissions as s3 where s3.hacker_id = s2.hacker_id and s3.submission_date &lt; s1.submission_date) = datediff(s1.submission_date, '2016-03-01')), (select hacker_id from submissions as s2 where s2.submission_date = s1.submission_date group by hacker_id order by count(submission_id) desc, hacker_id limit 1) as id, (select name from hackers where hacker_id = id)from (select distinct submission_date from submissions) as s1group by submission_date; 2019.10.30 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Hadoop] Sqoop import ì‹œ JDBC-90401:Connection refused by the server Error ë°œìƒ","slug":"hadoop-sqoop_jdbc_error","date":"2019-10-29T15:00:00.000Z","updated":"2020-03-30T15:06:23.562Z","comments":true,"path":"hadoop-sqoop_jdbc_error/","link":"","permalink":"https://jx2lee.github.io/hadoop-sqoop_jdbc_error/","excerpt":"ìƒí™©Sqoopì„ ì´ìš©í•´ Tibero Tableì„ hdfs í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” import ê³¼ì •ì—ì„œ ERRORê°€ ë°œìƒí•˜ì˜€ë‹¤. ìƒí™©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´, ì •ë³´ì‹œìŠ¤í…œ ê°œë°œê¸° DB(Tibero) Tabelì„ íŒ€ ì„œë²„ì— êµ¬ì¶•í•œ Hadoop ì—(51, 52 : DataNode, 53 : NameNodeë¡œ ì´í•˜ ìˆ«ìë¡œ í‘œí˜„) ì €ì¥í•˜ê³ ì í–ˆë‹¤.","text":"ìƒí™©Sqoopì„ ì´ìš©í•´ Tibero Tableì„ hdfs í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” import ê³¼ì •ì—ì„œ ERRORê°€ ë°œìƒí•˜ì˜€ë‹¤. ìƒí™©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´, ì •ë³´ì‹œìŠ¤í…œ ê°œë°œê¸° DB(Tibero) Tabelì„ íŒ€ ì„œë²„ì— êµ¬ì¶•í•œ Hadoop ì—(51, 52 : DataNode, 53 : NameNodeë¡œ ì´í•˜ ìˆ«ìë¡œ í‘œí˜„) ì €ì¥í•˜ê³ ì í–ˆë‹¤.ì •ë³´ì‹œìŠ¤í…œì—ì„œ í—ˆìš©í•œ IPëŠ” ì´ 4ê°œì˜€ê³  ê·¸ ì¤‘ í•˜ë‚˜ì¸ 69(í¸í•˜ê²Œ ìˆ«ìë¡œ.. ëŒ€ì²´í•˜ê² ë‹¤)ì— Sqoopì„ ì„¤ì¹˜í•˜ì—¬ Hadoopì— ì €ì¥í•˜ë ¤ëŠ” ê³„íšì´ì—ˆë‹¤. ê°„ëµíˆ ê° ì„œë²„ì™€ í˜„í™©ì„ ë‚˜íƒ€ë‚´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. Hadoop 51, 52 : DataNode 53 : NameNode ì •ë³´ì‹œìŠ¤í…œ ê°œë°œê¸° DBì— ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•ŠìŒ Sqoop 69 ì •ë³´ì‹œìŠ¤í…œ ê°œë°œê¸° DBì— ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•ŠìŒ Sqoop import ëª…ë ¹ì–´ (sqoop import â€“connect jdbc:tibero:thin:@192.168.xx.xx:8629:tibero â€“driver com.tmax.tibero.jdbc.TbDriver â€“username xxxx â€“password xxxx â€“table PROJECT_INFO â€“delete-target-dir -m 1) ë¥¼ ë‚ ë¦¬ë©´ ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455sqoop@bips:/app/sqoop/sqoop$ sqoop import --connect jdbc:tibero:thin:@192.168.10.84:8629:tibero --driver com.tmax.tibero.jdbc.TbDriver --username tody -P --table PROJECT_INFO --delete-target-dir -m 1Warning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.Please set $HBASE_HOME to the root of your HBase installation.Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog jobs will fail.Please set $HCAT_HOME to the root of your HCatalog installation.Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.Please set $ACCUMULO_HOME to the root of your Accumulo installation.Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.19/10/30 09:32:49 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7Enter password: 19/10/30 09:33:01 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.19/10/30 09:33:01 INFO manager.SqlManager: Using default fetchSize of 100019/10/30 09:33:01 INFO tool.CodeGenTool: Beginning code generation19/10/30 09:33:01 ERROR manager.SqlManager: Error executing statement: java.sql.SQLException: JDBC-90401:Connection refused by the server. - Connection refused (Connection refused)java.sql.SQLException: JDBC-90401:Connection refused by the server. - Connection refused (Connection refused) at com.tmax.tibero.jdbc.err.TbError.makeSQLException(Unknown Source) at com.tmax.tibero.jdbc.err.TbError.newSQLException(Unknown Source) at com.tmax.tibero.jdbc.comm.TbStream.&lt;init&gt;(Unknown Source) at com.tmax.tibero.jdbc.comm.TbCommType4.createStream(Unknown Source) at com.tmax.tibero.jdbc.driver.TbConnection.openConnection(Unknown Source) at com.tmax.tibero.jdbc.TbDriver.connectInternal(Unknown Source) at com.tmax.tibero.jdbc.TbDriver.connect(Unknown Source) at java.sql.DriverManager.getConnection(DriverManager.java:664) at java.sql.DriverManager.getConnection(DriverManager.java:247) at org.apache.sqoop.manager.SqlManager.makeConnection(SqlManager.java:904) at org.apache.sqoop.manager.GenericJdbcManager.getConnection(GenericJdbcManager.java:59) at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:763) at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:786) at org.apache.sqoop.manager.SqlManager.getColumnInfoForRawQuery(SqlManager.java:289) at org.apache.sqoop.manager.SqlManager.getColumnTypesForRawQuery(SqlManager.java:260) at org.apache.sqoop.manager.SqlManager.getColumnTypes(SqlManager.java:246) at org.apache.sqoop.manager.ConnManager.getColumnTypes(ConnManager.java:327) at org.apache.sqoop.orm.ClassWriter.getColumnTypes(ClassWriter.java:1872) at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1671) at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:106) at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:501) at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628) at org.apache.sqoop.Sqoop.run(Sqoop.java:147) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76) at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243) at org.apache.sqoop.Sqoop.main(Sqoop.java:252)19/10/30 09:33:01 ERROR tool.ImportTool: Import failed: java.io.IOException: No columns to generate for ClassWriter at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1677) at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:106) at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:501) at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628) at org.apache.sqoop.Sqoop.run(Sqoop.java:147) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76) at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243) at org.apache.sqoop.Sqoop.main(Sqoop.java:252) í•´ê²°ê²°ë¡ ë¶€í„° ë§í•˜ë©´ í•´ê²°í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œì´ë‹¤. Hadoopì´ JDBCë¥¼ í†µí•´ ì •ë³´ì‹œìŠ¤í…œ ê°œë°œê¸° Tiberoì— ì ‘ê·¼í•´ì•¼ í•˜ëŠ”ë° Sqoopì´ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°–ëŠ”ë‹¤. ì°¸ê³  : https://t1.daumcdn.net/cfile/tistory/255AAE415527751E16 ì‚¬ì§„ì€ Sqoop 1ì˜ Architectureì´ì§€ë§Œ, ê²°êµ­ì— Sqoopì´ Hadoopì˜ Map Taskì—ê²Œ íƒœìŠ¤í¬ë¥¼ ë„˜ê¸°ë©´ Hadoopì´ Databaseì— ì ‘ê·¼í•˜ëŠ” í˜•íƒœì´ë‹¤. ì¦‰, ì •ë³´ì‹œìŠ¤í…œ DB ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•ŠëŠ” Hadoop í™˜ê²½ì—ì„œëŠ” Connectionì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ë•Œë¬¸ì— ìš°ë¦¬íŒ€ì´ ì›ë˜ ì‹œë„í•˜ë ¤ë˜ í–ˆë˜ HDFS í˜•íƒœë¡œ íŒŒì¼ì„ ë–¨êµ¬ê³  ì´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì„ ì•„ì˜ˆ ë‹¤ë¥¸ ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ê±°ë‚˜, ìš°íšŒ ë°©ì•ˆ ì„ ìƒê°í•´ì•¼ í•œë‹¤. ê²°ë¡ Connection ERROR í•´ê²° ë°©ì•ˆì€ Hadoopì´ Databaseì— ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ í™˜ê²½ì„ êµ¬ì„±í•´ì£¼ë©´ ëœë‹¤. í•˜ì§€ë§Œ, ìš°ë¦¬íŒ€ì˜ í”„ë¡œì íŠ¸ëŠ” ì´ë ‡ê²Œ í™˜ê²½ì„ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì‰½ì§€ ì•Šë‹¤. ì´ì—ëŒ€í•´ ë‹¤ìŒ ë‘ ê°€ì§€ ë°©ì•ˆì´ ìˆëŠ”ë° êµ¬ì²´ì ì´ì§€ ì•Šë‹¤. (ì–´ë– í•œ ë°©ë²•ì´ ë” íš¨ìœ¨ì ì¸ì§€ ë” ê³ ë¯¼í•´ë´ì•¼ê² ë‹¤) If using Hadoop, Hadoopì„ ì •ë³´ì‹œìŠ¤í…œ DBì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì— ì„¤ì¹˜ ì •ë³´ì‹œìŠ¤í…œ ìª½ì— ì ‘ê·¼ ê°€ëŠ¥í•œ IP ì¶”ê°€ ìš”ì²­ else, ìì‚¬ ì œí’ˆ ì‚¬ìš©.. ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•´ì„œëŠ” Hadoop systemì„ ì´ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ëŠ” ê°œì¸ì ì¸ ë°”ëŒì´ ìˆë‹¤. 2019.10.30 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Hadoop] Sqoop import/export with Tibero","slug":"hadoop-sqoop_with_tibero","date":"2019-10-29T15:00:00.000Z","updated":"2020-03-30T15:06:23.579Z","comments":true,"path":"hadoop-sqoop_with_tibero/","link":"","permalink":"https://jx2lee.github.io/hadoop-sqoop_with_tibero/","excerpt":"Sqoopì„ ì´ìš©í•´ Tibero tableì„ HDFSë¡œ ì €ì¥í•˜ê³  ì´ë¥¼ ë‹¤ì‹œ tableë¡œ ë³€í™˜í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•œë‹¤.","text":"Sqoopì„ ì´ìš©í•´ Tibero tableì„ HDFSë¡œ ì €ì¥í•˜ê³  ì´ë¥¼ ë‹¤ì‹œ tableë¡œ ë³€í™˜í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•œë‹¤. Create Test tableìš°ì„ , Importí•˜ë ¤ëŠ” tableì„ ìƒì„±í•œë‹¤. ì¤‘ìš”í•œ ê²ƒì€ exportí•˜ê¸° ìœ„í•œ tableë„ ìƒì„±í•´ì•¼ í•œë‹¤ëŠ” ì ì´ë‹¤. Import table : RECIPES Export table : RECIPES_EXP Import table1234567891011121314151617181920CREATE TABLE USERS(USERNO NUMBER,EMAIL VARCHAR2(255) NOT NULL,PWD VARCHAR2(100) NOT NULL,NAME VARCHAR2(100) NOT NULL,PNO VARCHAR2(100) NOT NULL,ADDRESS VARCHAR2(255));INSERT INTO recipes (recipe_id, recipe_name) VALUES (1,'Tacos');INSERT INTO recipes (recipe_id, recipe_name) VALUES (2,'Tomato Soup');INSERT INTO recipes (recipe_id, recipe_name) VALUES (3,'Grilled Cheese');-- checking tableSQL&gt; SELECT * FROM RECIPES; RECIPE_ID RECIPE_NAME ---------- ------------------------------ 3 Grilled Cheese 1 Tacos 2 Tomato Soup3 rows selected. Export table123456CREATE TABLE recipes_exp ( recipe_id INT NOT NULL, recipe_name VARCHAR(30) NOT NULL, PRIMARY KEY (recipe_id), UNIQUE (recipe_name)); Sqoop Importtableì´ ì¤€ë¹„ë˜ì—ˆë‹¤ë©´ Sqoopì„ ì´ìš©í•´ HDFS í˜•íƒœë¡œ Hadoopì— ì €ì¥í•´ë³¸ë‹¤. ëª…ë ¹ì–´ì™€ ìˆ˜í–‰ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. CMD12345sqoop import --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero \\--driver com.tmax.tibero.jdbc.TbDriver \\--username tibero --password [password] \\--table RECIPES \\--target-dir /t1/input Tibero ì ‘ì†ì„ ìœ„í•œ stringì€ ìœ„ì™€ ê°™ì´ ì‘ì„±í•˜ê³ , MySQL/PostgreSQLì˜ ê²½ìš° driverë¥¼ ì§€ì •í•˜ì§€ ì•Šì•„ë„ ë˜ì§€ë§Œ Oracle/TiberoëŠ” driverë¥¼ ì„¤ì •í•´ì•¼ í•œë‹¤. (MySQL/PostgreSQL : direct connect ì§€ì›ì´ë¼ê³  documentì— ëª…ì‹œ) Result1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980sqoop@bips:~$ sqoop import --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero \\&gt; --driver com.tmax.tibero.jdbc.TbDriver \\&gt; --username tibero --password tmax \\&gt; --table RECIPES \\&gt; --target-dir /t1/inputWarning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.Please set $HBASE_HOME to the root of your HBase installation.Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog jobs will fail.Please set $HCAT_HOME to the root of your HCatalog installation.Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.Please set $ACCUMULO_HOME to the root of your Accumulo installation.Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.19/10/30 10:09:24 INFO sqoop.Sqoop: Running Sqoop version: 1.4.719/10/30 10:09:24 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.19/10/30 10:09:24 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.19/10/30 10:09:24 INFO manager.SqlManager: Using default fetchSize of 100019/10/30 10:09:24 INFO tool.CodeGenTool: Beginning code generation19/10/30 10:09:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=019/10/30 10:09:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=019/10/30 10:09:25 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /app/hadoopNote: /tmp/sqoop-sqoop/compile/905c294a54718643bcf983498f8878ba/RECIPES.java uses or overrides a deprecated API.Note: Recompile with -Xlint:deprecation for details.19/10/30 10:09:26 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-sqoop/compile/905c294a54718643bcf983498f8878ba/RECIPES.jar19/10/30 10:09:26 INFO mapreduce.ImportJobBase: Beginning import of RECIPES19/10/30 10:09:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar19/10/30 10:09:26 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=019/10/30 10:09:27 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps19/10/30 10:09:27 INFO client.RMProxy: Connecting to ResourceManager at node5.dat/192.168.158.53:805019/10/30 10:09:31 INFO db.DBInputFormat: Using read commited transaction isolation19/10/30 10:09:31 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(RECIPE_ID), MAX(RECIPE_ID) FROM RECIPES19/10/30 10:09:31 INFO mapreduce.JobSubmitter: number of splits:419/10/30 10:09:31 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled19/10/30 10:09:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1567153359966_006919/10/30 10:09:31 INFO impl.YarnClientImpl: Submitted application application_1567153359966_006919/10/30 10:09:31 INFO mapreduce.Job: The url to track the job: http://node5.dat:8088/proxy/application_1567153359966_0069/19/10/30 10:09:31 INFO mapreduce.Job: Running job: job_1567153359966_006919/10/30 10:09:35 INFO mapreduce.Job: Job job_1567153359966_0069 running in uber mode : false19/10/30 10:09:35 INFO mapreduce.Job: map 0% reduce 0%19/10/30 10:09:39 INFO mapreduce.Job: map 50% reduce 0%19/10/30 10:09:40 INFO mapreduce.Job: map 100% reduce 0%19/10/30 10:09:41 INFO mapreduce.Job: Job job_1567153359966_0069 completed successfully19/10/30 10:09:41 INFO mapreduce.Job: Counters: 30 File System Counters FILE: Number of bytes read=0 FILE: Number of bytes written=830592 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 HDFS: Number of bytes read=447 HDFS: Number of bytes written=39 HDFS: Number of read operations=16 HDFS: Number of large read operations=0 HDFS: Number of write operations=8 Job Counters Launched map tasks=4 Other local map tasks=4 Total time spent by all maps in occupied slots (ms)=8334 Total time spent by all reduces in occupied slots (ms)=0 Total time spent by all map tasks (ms)=8334 Total vcore-milliseconds taken by all map tasks=8334 Total megabyte-milliseconds taken by all map tasks=8534016 Map-Reduce Framework Map input records=3 Map output records=3 Input split bytes=447 Spilled Records=0 Failed Shuffles=0 Merged Map outputs=0 GC time elapsed (ms)=162 CPU time spent (ms)=3530 Physical memory (bytes) snapshot=827170816 Virtual memory (bytes) snapshot=8600104960 Total committed heap usage (bytes)=585629696 File Input Format Counters Bytes Read=0 File Output Format Counters Bytes Written=3919/10/30 10:09:41 INFO mapreduce.ImportJobBase: Transferred 39 bytes in 14.9856 seconds (2.6025 bytes/sec)19/10/30 10:09:41 INFO mapreduce.ImportJobBase: Retrieved 3 records. Checkingì œëŒ€ë¡œ hadoopì— ì €ì¥ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ë³¸ë‹¤. hdfsëª…ë ¹ì–´ë¥¼ ì´ìš©í•´ íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œë‹¤. hdfs dfs -cat /t1/input/* or hdfs dfs -ls /t1/input 1234567891011sqoop@bips:~$ hdfs dfs -cat /t1/input/*1,Tacos2,Tomato Soup3,Grilled Cheesesqoop@bips:~$ hdfs dfs -ls /t1/inputFound 5 items-rw-r--r-- 2 sqoop supergroup 0 2019-10-30 10:09 /t1/input/_SUCCESS-rw-r--r-- 2 sqoop supergroup 8 2019-10-30 10:09 /t1/input/part-m-00000-rw-r--r-- 2 sqoop supergroup 0 2019-10-30 10:09 /t1/input/part-m-00001-rw-r--r-- 2 sqoop supergroup 14 2019-10-30 10:09 /t1/input/part-m-00002-rw-r--r-- 2 sqoop supergroup 17 2019-10-30 10:09 /t1/input/part-m-00003 Sqoop Exportì´ë²ˆì—” HDFSë¥¼ Tibero tableë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•œë‹¤. ëª…ë ¹ì–´ì™€ ìˆ˜í–‰ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. CMD12345sqoop export --connect jdbc:tibero:thin:@192.168.xxx.xx:xxx:tibero \\--driver com.tmax.tibero.jdbc.TbDriver \\--username tibero --password ?? \\--table RECIPES_EXP \\--export-dir /t1/input ìœ„ì—ì„œë„ ì–¸ê¸‰í–ˆë“¯ì´ export tableì´ Tiberoì— ì´ë¯¸ ì¡´ì¬í•´ì•¼ í•œë‹¤. Result12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485sqoop@bips:~$ sqoop export --connect jdbc:tibero:thin:@192.168.158.53:8729:tibero \\&gt; --driver com.tmax.tibero.jdbc.TbDriver \\&gt; --username tibero --password tmax \\&gt; --table RECIPES_EXP \\&gt; --export-dir /t1/inputWarning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.Please set $HBASE_HOME to the root of your HBase installation.Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog jobs will fail.Please set $HCAT_HOME to the root of your HCatalog installation.Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.Please set $ACCUMULO_HOME to the root of your Accumulo installation.Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.19/10/30 10:40:23 INFO sqoop.Sqoop: Running Sqoop version: 1.4.719/10/30 10:40:23 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.19/10/30 10:40:23 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.19/10/30 10:40:23 INFO manager.SqlManager: Using default fetchSize of 100019/10/30 10:40:23 INFO tool.CodeGenTool: Beginning code generation19/10/30 10:40:24 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=019/10/30 10:40:24 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=019/10/30 10:40:24 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /app/hadoopNote: /tmp/sqoop-sqoop/compile/bc292d345cc3a16972516454f904b6df/RECIPES_EXP.java uses or overrides a deprecated API.Note: Recompile with -Xlint:deprecation for details.19/10/30 10:40:25 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-sqoop/compile/bc292d345cc3a16972516454f904b6df/RECIPES_EXP.jar19/10/30 10:40:25 INFO mapreduce.ExportJobBase: Beginning export of RECIPES_EXP19/10/30 10:40:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar19/10/30 10:40:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=019/10/30 10:40:25 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative19/10/30 10:40:25 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative19/10/30 10:40:25 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps19/10/30 10:40:25 INFO client.RMProxy: Connecting to ResourceManager at node5.dat/192.168.158.53:805019/10/30 10:40:29 INFO input.FileInputFormat: Total input files to process : 419/10/30 10:40:29 INFO input.FileInputFormat: Total input files to process : 419/10/30 10:40:29 INFO mapreduce.JobSubmitter: number of splits:419/10/30 10:40:29 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative19/10/30 10:40:29 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled19/10/30 10:40:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1567153359966_007119/10/30 10:40:30 INFO impl.YarnClientImpl: Submitted application application_1567153359966_007119/10/30 10:40:30 INFO mapreduce.Job: The url to track the job: http://node5.dat:8088/proxy/application_1567153359966_0071/19/10/30 10:40:30 INFO mapreduce.Job: Running job: job_1567153359966_007119/10/30 10:40:35 INFO mapreduce.Job: Job job_1567153359966_0071 running in uber mode : false19/10/30 10:40:35 INFO mapreduce.Job: map 0% reduce 0%19/10/30 10:40:40 INFO mapreduce.Job: map 75% reduce 0%19/10/30 10:40:41 INFO mapreduce.Job: map 100% reduce 0%19/10/30 10:40:41 INFO mapreduce.Job: Job job_1567153359966_0071 completed successfully19/10/30 10:40:41 INFO mapreduce.Job: Counters: 31 File System Counters FILE: Number of bytes read=0 FILE: Number of bytes written=829388 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 HDFS: Number of bytes read=656 HDFS: Number of bytes written=0 HDFS: Number of read operations=22 HDFS: Number of large read operations=0 HDFS: Number of write operations=0 Job Counters Launched map tasks=4 Other local map tasks=1 Data-local map tasks=3 Total time spent by all maps in occupied slots (ms)=14227 Total time spent by all reduces in occupied slots (ms)=0 Total time spent by all map tasks (ms)=14227 Total vcore-milliseconds taken by all map tasks=14227 Total megabyte-milliseconds taken by all map tasks=14568448 Map-Reduce Framework Map input records=3 Map output records=3 Input split bytes=586 Spilled Records=0 Failed Shuffles=0 Merged Map outputs=0 GC time elapsed (ms)=425 CPU time spent (ms)=4140 Physical memory (bytes) snapshot=811102208 Virtual memory (bytes) snapshot=8589045760 Total committed heap usage (bytes)=606601216 File Input Format Counters Bytes Read=0 File Output Format Counters Bytes Written=019/10/30 10:40:41 INFO mapreduce.ExportJobBase: Transferred 656 bytes in 15.7366 seconds (41.6862 bytes/sec)19/10/30 10:40:41 INFO mapreduce.ExportJobBase: Exported 3 records.â€‹ 123456789101112131415161718192021222324252627282930## Checkingì œëŒ€ë¡œ í…Œì´ë¸”ë¡œ ë°ì´í„°ê°€ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•´ë³¸ë‹¤. &#96;Sqoop&#96;ì—ì„œ &#96;--query&#96; argumentë¥¼ ì£¼ì–´ &#96;RECIPES_EXP&#96;ë¥¼ ì¡°íšŒí•´ë³´ì&#96;sqoop eval --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero --driver com.tmax.tibero.jdbc.TbDriver --username tibero --password ?? --query &#39;SELECT * FROM RECIPES_EXP&#39;&#96;&#96;&#96;&#96;bashsqoop@bips:~$ sqoop eval --connect jdbc:tibero:thin:@192.168.158.53:8729:tibero \\&gt; --driver com.tmax.tibero.jdbc.TbDriver \\&gt; --username tibero --password tmax --query &#39;SELECT * FROM RECIPES_EXP&#39;Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;hbase does not exist! HBase imports will fail.Please set $HBASE_HOME to the root of your HBase installation.Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;hcatalog does not exist! HCatalog jobs will fail.Please set $HCAT_HOME to the root of your HCatalog installation.Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;accumulo does not exist! Accumulo imports will fail.Please set $ACCUMULO_HOME to the root of your Accumulo installation.Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;zookeeper does not exist! Accumulo imports will fail.Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.19&#x2F;10&#x2F;30 10:41:54 INFO sqoop.Sqoop: Running Sqoop version: 1.4.719&#x2F;10&#x2F;30 10:41:54 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.19&#x2F;10&#x2F;30 10:41:54 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.19&#x2F;10&#x2F;30 10:41:54 INFO manager.SqlManager: Using default fetchSize of 1000-----------------------------------------------| RECIPE_ID | RECIPE_NAME | -----------------------------------------------| 3 | Grilled Cheese | | 1 | Tacos | | 2 | Tomato Soup | ----------------------------------------------- export ê°€ ì •ìƒ ì‘ë™ëìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤ ì°¸ê³  í”Œë°ì¥êµ°ë‹˜ ë¸”ë¡œê·¸ : https://dlwjdcks5343.tistory.com/116 AndersonChoi ë‹˜ ë¸”ë¡œê·¸ : https://blog.voidmainvoid.net/175 Sqoop Documents : https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_free_form_query_imports 2019.10.30 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[{"name":"Tibero","slug":"Tibero","permalink":"https://jx2lee.github.io/tags/Tibero/"}]},{"title":"[SQL] Interviews","slug":"hackerrank-interviews","date":"2019-10-27T15:00:00.000Z","updated":"2020-03-30T15:06:23.520Z","comments":true,"path":"hackerrank-interviews/","link":"","permalink":"https://jx2lee.github.io/hackerrank-interviews/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Interviews ë¬¸ì œë¥¼ multiple join ë° group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Interviews ë¬¸ì œë¥¼ multiple join ë° group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œSamantha interviews many candidates from different colleges using coding challenges and contests. Write a query to print the contest_id, hacker_id, name, and the sums of total_submissions, total_accepted_submissions, total_views, and total_unique_views for each contest sorted by contest_id. Exclude the contest from the result if all four sums are . Note: A specific contest can be used to screen candidates at more than one college, but each college only holds screening contest. Input Format The following tables hold interview data: Contests: The contest_id is the id of the contest, hacker_id is the id of the hacker who created the contest, and name is the name of the hacker. Colleges: The college_id is the id of the college, and contest_id is the id of the contest that Samantha used to screen the candidates. Challenges: The challenge_id is the id of the challenge that belongs to one of the contests whose contest_id Samantha forgot, and college_id is the id of the college where the challenge was given to candidates. View_Stats: The challenge_id is the id of the challenge, total_views is the number of times the challenge was viewed by candidates, and total_unique_views is the number of times the challenge was viewed by unique candidates. Submission_Stats: The challenge_id is the id of the challenge, total_submissions is the number of submissions for the challenge, and total_accepted_submission is the number of submissions that achieved full scores. Sample Input Contests Table: Colleges Table: Challenges*Table: *View_Stats Table: Submission_Stats Table: Sample Output 12366406 17973 Rose 111 39 156 5666556 79153 Angela 0 0 11 1094828 80275 Frank 150 38 41 15 Explanation The contest is used in the college . In this college , challenges and are asked, so from the view and submission stats: Sum of total submissions Sum of total accepted submissions Sum of total views Sum of total unique views Similarly, we can find the sums for contests and . ì ‘ê·¼Join ìœ í˜• ì¤‘ Left Joinì„ í™œìš©í•˜ì—¬ í•´ê²°í•˜ì˜€ë‹¤. ë‹¤ìˆ˜ì˜ tableì„ íŠ¹ì • í‚¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Joiní•˜ëŠ” ê²ƒì´ ë‹¤ì†Œ í—·ê°ˆë¦´ ìˆ˜ ìˆì§€ë§Œ ì°¨ê·¼ì°¨ê·¼ Joiní•˜ë©´ ë¬¸ì œë¥¼ ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‹¤. ìš°ì„ , contests tableì„ ê¸°ì¤€ìœ¼ë¡œ colleges, challenges tableê³¼ Left Joinì„ ìˆ˜í–‰í•œë‹¤. ê° keyëŠ” contest_id ì™€ college_id ì´ë‹¤. 1234select a.contest_id, a.hacker_id, a.name,from contests as aleft join colleges as b on a.contest_id = b.contest_idleft join challenges as c on b.college_id = c.college_id; ë‹¤ìŒ total_viewsì™€ *total_unique_viewsë¥¼ êµ¬í•˜ê¸° ìœ„í•´ view_stats tableì„ *challenge_id ê¸°ì¤€ìœ¼ë¡œ group by í•œë‹¤. ì´í›„ ê²°ê³¼ í…Œì´ë¸”ê³¼ Left Joinì„ ìˆ˜í–‰í•œë‹¤. ë‹¨, keyëŠ” challenge_idì´ë‹¤. 123456789select a.contest_id, a.hacker_id, a.name, sum(total_views) as total_views, sum(total_unique_views) as total_unique_viewsfrom contests as aleft join colleges as b on a.contest_id = b.contest_idleft join challenges as c on b.college_id = c.college_idleft join ( select challenge_id, sum(total_views) as total_views, sum(total_unique_views) as total_unique_views from view_stats group by challenge_id ) as d on c.challenge_id = d.challenge_id; view_stats table Joinê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ submission_stats tableì„ ì •ì œí•œ í›„ Left Joinì„ ìˆ˜í–‰í•œë‹¤. 1234567891011121314select a.contest_id, a.hacker_id, a.name, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions, sum(total_views) as total_views, sum(total_unique_views) as total_unique_viewsfrom contests as aleft join colleges as b on a.contest_id = b.contest_idleft join challenges as c on b.college_id = c.college_idleft join ( select challenge_id, sum(total_views) as total_views, sum(total_unique_views) as total_unique_views from view_stats group by challenge_id ) as d on c.challenge_id = d.challenge_idleft join ( select challenge_id, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions from submission_stats group by challenge_id ) as e on c.challenge_id = e.challenge_id; ë§ˆì§€ë§‰ìœ¼ë¡œ contest_id, hacker_id, nameì„ ê¸°ì¤€ìœ¼ë¡œ group byë¥¼ ìˆ˜í–‰í•˜ê³ , ë¬¸ì œì˜ ì¡°ê±´ì¸ ë„¤ ê°€ì§€ summationì´ 0ë³´ë‹¤ í° ê²½ìš°ë§Œ ì¡°íšŒí•˜ëŠ” havingì„ ì¶”ê°€í•˜ì—¬ ì™„ì„±í•œë‹¤. 12345678910111213141516select a.contest_id, a.hacker_id, a.name, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions, sum(total_views) as total_views, sum(total_unique_views) as total_unique_viewsfrom contests as aleft join colleges as b on a.contest_id = b.contest_idleft join challenges as c on b.college_id = c.college_idleft join ( select challenge_id, sum(total_views) as total_views, sum(total_unique_views) as total_unique_views from view_stats group by challenge_id ) as d on c.challenge_id = d.challenge_idleft join ( select challenge_id, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions from submission_stats group by challenge_id ) as e on c.challenge_id = e.challenge_idgroup by a.contest_id, a.hacker_id, a.namehaving (total_submissions + total_accepted_submissions + total_views + total_unique_views) &gt; 0; í•´ê²°ì°¸ê³  12345678910111213141516select a.contest_id, a.hacker_id, a.name, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions, sum(total_views) as total_views, sum(total_unique_views) as total_unique_viewsfrom contests as aleft join colleges as b on a.contest_id = b.contest_idleft join challenges as c on b.college_id = c.college_idleft join ( select challenge_id, sum(total_views) as total_views, sum(total_unique_views) as total_unique_views from view_stats group by challenge_id ) as d on c.challenge_id = d.challenge_idleft join ( select challenge_id, sum(total_submissions) as total_submissions, sum(total_accepted_submissions) as total_accepted_submissions from submission_stats group by challenge_id ) as e on c.challenge_id = e.challenge_idgroup by a.contest_id, a.hacker_id, a.namehaving (total_submissions + total_accepted_submissions + total_views + total_unique_views) &gt; 0; 2019.10.28 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Hadoop] Install Hadoop using Docker","slug":"hadoop-install_hadoop_using_docker","date":"2019-10-24T15:00:00.000Z","updated":"2020-05-15T05:22:11.687Z","comments":true,"path":"hadoop-install_hadoop_using_docker/","link":"","permalink":"https://jx2lee.github.io/hadoop-install_hadoop_using_docker/","excerpt":"Hadoop í™˜ê²½ì„ êµ¬ì„±í•´ë³´ì!","text":"Hadoop í™˜ê²½ì„ êµ¬ì„±í•´ë³´ì! ë“œë””ì–´ ì—”ì§€ë‹ˆì–´ë¡œì¨ì˜ ëŠ¥ë ¥ì„ ë°°ì–‘í•  ìˆ˜ ìˆëŠ” í™˜ê²½ êµ¬ì„±ì´ë‹¤. ìš°ì„ , íšŒì‚¬ì—ì„œ ì§€ê¸‰ë°›ì€ ì„œë²„ë¡œ ì´ë¯¸ í•˜ë‘¡ í™˜ê²½ì´ êµ¬ì¶•ë˜ì–´ ìˆì§€ë§Œ, ê°œì¸ í• ë‹¹ë°›ì€ ì„œë²„ì—ì„œ Dockerë¥¼ ì´ìš©í•´ ì‹¤ìŠµ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³ ì í•œë‹¤. Docker Hub ì—ì„œ ìŠ¤íƒ€ê°€ ê°€ì¥ ë§ì€ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•  ê²ƒì´ë‹¤. Dockerë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì€ í˜¹ì—¬ë‚˜ ë‚˜ì¤‘ì—ë„ ì¨ë¨¹ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê²ƒì´ë‹¤. PLAN3ê°œì˜ DataNodeì™€ 1ê°œì˜ NameNodeë¡œ êµ¬ì„±ëœ í•˜ë‘¡ í™˜ê²½ì„ êµ¬ì¶•í•œë‹¤. ì—¬ëŸ¬ ê°œ ì„œë²„ë¥¼ ì—°ê²°í•˜ëŠ” êµ¬ì¡° ëŒ€ì‹ , ì‰½ê²Œ í™˜ê²½ì„ ë°”ê¾¸ê³  ì…ë§›ëŒ€ë¡œ ìˆ˜ì •ì´ ê°€ëŠ¥í•œ dockerë¥¼ ì´ìš©í•´ êµ¬ì„±í•œë‹¤. dockerë¥¼ ê³µë¶€í•´ë³´ìëŠ” ì˜ë¯¸ë„ ìˆê³  ìƒˆë¡­ê²Œ í™˜ê²½ì„ ì¬êµ¬ì„±í•  ë•Œ ìœ ìš©í•  ê²ƒ ê°™ë‹¤. ENVIRONMENThadoop í´ë”ë¥¼ ìƒì„±í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°–ëŠ”ë‹¤. 12345678910111213141516[kuber@node2 hadoop]$ tree ..â”œâ”€â”€ baseâ”‚ â”œâ”€â”€ core-site.xmlâ”‚ â””â”€â”€ Dockerfileâ”œâ”€â”€ data-nodeâ”‚ â”œâ”€â”€ Dockerfileâ”‚ â”œâ”€â”€ hdfs-site.xmlâ”‚ â””â”€â”€ install.shâ”œâ”€â”€ docker-compose.ymlâ””â”€â”€ name-node â”œâ”€â”€ Dockerfile â”œâ”€â”€ hdfs-site.xml â””â”€â”€ install.sh3 directories, 9 files hadoopì˜ ê¸°ë³¸ í™˜ê²½ì„ êµ¬ì„±í•˜ëŠ” baseì™€ ì´ë¥¼ í™œìš©í•´ name / data -node í´ë”ë¥¼ êµ¬ì„±í•˜ì˜€ê³ , Dockerfileì„ ì‘ì„±í•˜ì—¬ ì§ì ‘ imageë¥¼ buildí•˜ê³  docker-composeë¥¼ í™œìš©í•´ ë°°í¬í•œë‹¤. BASEê° componentì˜ ë°‘ë°”ë‹¹ì´ ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” ë‹¨ê³„ì´ë‹¤. ì´ëŠ” base í´ë”ì—ì„œ ìˆ˜í–‰í•˜ë©°, ê³ ë ¤ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. Hadoop ì„¤ì¹˜ë¥¼ ìœ„í•œ binary Java ì´ë¯¸ì§€ ë¹Œë“œë¥¼ ìœ„í•´ Dockerfile, core-site.xmlì„ ì‘ì„±í•´ë³´ë„ë¡ í•œë‹¤. DockerfileDockerfileì€ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ ì‘ì„±í•˜ì˜€ë‹¤. Dockerfile ì‘ì„±ì„ ë§ì´ í•´ë²„ë¦‡ í•´ì•¼ê² ë‹¤. ì°¸ê³ í•œ ë¸”ë¡œê·¸ì—ì„œ ì‚¬ìš©í•œ ë‚´ìš©ì„ ë³µì‚¬ ë¶™ì—¬ë„£ì§€ ì•Šê³  ì§ì ‘ ì‘ì„±í•˜ë‹ˆ ì–´ëŠì •ë„ íë¦„ì€ íŒŒì•…í•˜ì˜€ë‹¤ í™˜ê²½ë³€ìˆ˜ ì„¤ì • HADOOP_VERSION : hadoop versionì„ ì˜ë¯¸ HADOOP_URL : hadoop ì„¤ì¹˜ binary ë‹¤ìš´ì„ ìœ„í•œ url í™˜ê²½ë³€ìˆ˜ë¥¼ ì´ìš©í•´ download ë° ì••ì¶•í•´ì œ ë§í¬íŒŒì¼ ìƒì„± í˜¸ìŠ¤íŠ¸(in base directory) íŒŒì¼ì„ containerì— ì¶”ê°€ hadoop ì‹¤í–‰ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • HADOOP_PREFIX : hadoop root directory HADOOP_CONF_DIR : hadoop config directory JAVA_HOME : Java directory 1234567891011121314151617181920212223242526# ENV for installationENV HADOOP_VERSION=2.9.2ENV HADOOP_URL=http://mirror.apache-kr.org/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz## Download Hadoop on /app/hadoopRUN curl -fSL \"$HADOOP_URL\" -o /tmp/hadoop.tar.gz \\ &amp;&amp; tar -xvf /tmp/hadoop.tar.gz -C /opt/ \\ &amp;&amp; rm /tmp/hadoop.tar.gz# make directory &amp; symbolic linkRUN ln -s /opt/hadoop-$HADOOP_VERSION /opt/hadoop \\ &amp;&amp; mkdir /opt/hadoop/dfs \\ &amp;&amp; ln -s /opt/hadoop-$HADOOP_VERSION/etc/hadoop /etc/hadoop \\ &amp;&amp; rm -rf /opt/hadoop/share/doc# copy local-site.xml file to containerADD core-site.xml /etc/hadoop/# ENV for runENV HADOOP_PREFIX /opt/hadoopENV HADOOP_CONF_DIR /etc/hadoopENV PATH $HADOOP_PREFIX/bin/:$PATHENV JAVA_HOME /usr/lib/jvm/zulu-8-amd64 core-site.xmlcore-site.xmlì€ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•œë‹¤. 12345678&lt;connfiguration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://namenode:9000/&lt;/value&gt; &lt;description&gt;NameNode URI &lt;/description&gt; &lt;/property&gt; &lt;/connfiguration&gt; fs.defaultFS : NameNodeì˜ ìœ„ì¹˜ë¥¼ ì°¾ëŠ” ì„¤ì •ìœ¼ë¡œ ì½ê¸°/ì“°ê¸° ìš”ì²­ì„ í•  ë•Œ ì‚¬ìš©ë˜ëŠ” í•­ëª© URI hostname ì€ namenodeë¼ ì„¤ì •í•˜ì˜€ëŠ”ë°, NameNode containerì˜ host nameì„ ì§€ì •í•œ ê²ƒ connfiguration tag ëª…ì„ ì œëŒ€ë¡œ í™•ì¸í•˜ë„ë¡ í•˜ì. (ë‚´ ê²½ìš° connfiguration -&gt; configurationìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œ í›„ ì‹¤í–‰í•˜ì˜€ë”ë‹ˆ containerê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•Šì•˜ë‹¤) Build hadoop-base:2.9.2ì´ì œ Docker imageë¡œ ë¹Œë“œí•  ì°¨ë¡€ì´ë‹¤. base í´ë”ë¡œ ì ‘ê·¼ í›„ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ í†µí•´ buildë¥¼ ìˆ˜í–‰í•œë‹¤. 12[kuber@node2 hadoop]$ cd base/[kuber@node2 base]$ docker build -t hadoop-base:2.9.2 . NAMENODEbase imageë¥¼ ìƒì„±í•˜ì˜€ë‹¤ë©´, ì´ë¥¼ ì´ìš©í•´ NameNode Containerë¥¼ ë¹Œë“œí•˜ê¸° ìœ„í•œ í™˜ê²½ì„ êµ¬ì„±í•œë‹¤. ê³ ë ¤ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. NameNode ìš© hdfs-site.xml FsImage, EditLog ì €ì¥ì„ ìœ„í•œ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œ NameNodeì˜ ì²« êµ¬ë™ í™•ì¸ (ì²« êµ¬ë™ì´ ì•„ë‹ˆë¼ë©´ í¬ë§· í›„ êµ¬ë™ í•„ìš”) NameNode ì´ë¯¸ì§€ ë¹Œë“œë¥¼ ìœ„í•´ Dockerfile, hdfs-site.xml, install.shë¥¼ ì‘ì„±í•´ë³´ë„ë¡ í•œë‹¤. DockerfileDockerfileì€ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ ì‘ì„±í•˜ì˜€ë‹¤. ì´ì „ì— ë§Œë“  hadoop-base:2.9.2 imageë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤ Web UI ì‘ë‹µ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•œ HEALTHCHECK í˜¸ìŠ¤íŠ¸(in name-node directory) íŒŒì¼ì„ containerì— ì¶”ê°€ FSIMage, EditLog íŒŒì¼ ê²½ë¡œ ì—°ê²° í¬íŠ¸ ë…¸ì¶œ ëª…ë ¹ì–´ ë“±ë¡ 123456789101112131415161718192021FROM hadoop-base:2.9.2# CON NameNode Web UIHEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50070/ || exit 1# COPY hdfs-site.xmlADD hdfs-site.xml /etc/hadoop/# FSImage/EditLog path -&gt; volumeRUN mkdir /opt/hadoop/dfs/nameVOLUME /opt/hadoop/dfs/name# COPY shell scripADD install.sh /install.shRUN chmod a+x /install.sh# EXPOSE PortEXPOSE 50070 9000# ADD command line for runCMD [\"/install.sh\", \"opt/hadoop/dfs/name\"] hdfs-site.xmlhdfs-site.xmlì€ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•œë‹¤. 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.blocksize&lt;/name&gt; &lt;value&gt;10485760&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.use.datanode.hostname&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.servicerpc-bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.https-bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; dfs.namenode.name.dir : FSImage / EditLog íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ê²½ë¡œ dfs.blocksize : HDFS íŒŒì¼ ë¸”ë¡ì˜ í¬ê¸°ë¡œ ë³¸ í™˜ê²½ì—ì„œëŠ” 10MBë¡œ ì„¤ì •í•˜ì˜€ë‹¤(default : 128MB) (ê¸°íƒ€ í•­ëª©ë“¤ì€ ( https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/ ) í™•ì¸) install.sh install.shì€ NameNodeì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ í¬ë§· ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ì‰˜ ìŠ¤í¬ë¦½íŠ¸ì´ë‹¤. ë§Œì•½ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ í¬ë§·ë˜ì–´ ìˆë‹¤ë©´ NameNodeë¥¼ êµ¬ë™í•˜ê³ , í¬ë§·ë˜ì–´ìˆì§€ ì•Šë‹¤ë©´ í¬ë§·ì„ ì§„í–‰í•œ í›„ êµ¬ë™í•œë‹¤. 12345678910111213141516#! /bin/bash# SET namespace directoryNAME_DIR=$1echo $NAME_DIR# CHECK if dir is emptyif [ \"$(ls -A $NAME_DIR)\" ]; then echo \"NameNode is already formatted !!\"else echo \"Format NameNode..\" $HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR namenode -formatfi# RUN$HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR namenode Build hadoop-namenode:2.9.2ì´ì œ Docker imageë¡œ ë¹Œë“œí•  ì°¨ë¡€ì´ë‹¤. name-node í´ë”ë¡œ ì ‘ê·¼ í›„ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ í†µí•´ buildë¥¼ ìˆ˜í–‰í•œë‹¤. 12[kuber@node2 hadoop]$ cd name-node/[kuber@node2 name-node]$ docker build -t hadoop-namenode:2.9.2 . DATANODENameNode ì´ë¯¸ì§€ ìƒì„±ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, base imageë¥¼ ì´ìš©í•´ DataNode imageë¥¼ ìƒì„±í•´ë³¸ë‹¤. ê³ ë ¤ì‚¬í•­ì€ ì•„ë˜ì™€ ê°™ë‹¤. DataNode ìš© hdfs-site.xml íŒŒì¼ ë¸”ë¡ ì €ì¥ì„ ìœ„í•œ ê²½ë¡œ DataNode ì´ë¯¸ì§€ ë¹Œë“œë¥¼ ìœ„í•´ Dockerfile, hdfs-site.xml, install.shë¥¼ ì‘ì„±í•´ë³´ë„ë¡ í•œë‹¤. DockerfileDockerfileì€ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ ì‘ì„±í•˜ì˜€ë‹¤. ì´ì „ì— ë§Œë“  hadoop-base:2.9.2 imageë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤ Web UI ì‘ë‹µ ì—¬ë¶€ í™•ì¸ì„ ìœ„í•œ HEALTHCHECK host(in name-node directory) íŒŒì¼ì„ containerì— ì¶”ê°€ FSIMage, EditLog íŒŒì¼ ê²½ë¡œ ì—°ê²° port ë…¸ì¶œ cmd ë“±ë¡ 123456789101112131415161718FROM hadoop-base:2.9.2# CONN NameNode Web UIHEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || exit 1# RUN mkdir /opt/hadoop/dfs/dataVOLUME /opt/hadoop/dfs/data# COPY shell scripADD install.sh /install.shRUN chmod a+x /install.sh# EXPOSE PortEXPOSE 50075 50010# ADD command line for runCMD [\"/install.sh\"] hdfs-site.xmlhdfs-site.xml ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•œë‹¤. container ì— datanodeì˜ dir pathì™€ blocksizeë¥¼ ì§€ì •í•œë‹¤. 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.blocksize&lt;/name&gt; &lt;value&gt;10485760&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.use.datanode.hostname&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; install.shDataNodeì˜ install.sh ì€ ë³„ê±° ì—†ë‹¤. DataNodeë¥¼ êµ¬ë™í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ì‘ì„±í•œë‹¤. 123#! /bin/sh$HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR datanode Build hadoop-datanode:2.9.2ì´ì œ Docker imageë¡œ ë¹Œë“œí•  ì°¨ë¡€ì´ë‹¤. data-node í´ë”ë¡œ ì ‘ê·¼ í›„ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ í†µí•´ buildë¥¼ ìˆ˜í–‰í•œë‹¤. 12345678910[kuber@node2 hadoop]$ cd data-node/[kuber@node2 data-node]$ docker build -t hadoop-datanode:2.9.2 .Sending build context to Docker daemon 4.096 kBStep 1/8 : FROM hadoop-base:2.9.2 ---&gt; 765c9acb59fdStep 2/8 : HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || exit 1 ---&gt; Running in e2b20d7d5fd1......Successfully built 3f1372bf4fdb container êµ¬ë™ì„ ìœ„í•œ ì¤€ë¹„ê°€ ê±°ì˜ ëë‚˜ê°„ë‹¤ RUNë¹Œë“œëœ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜í•˜ë‚˜ ì‹¤í–‰(ex. docker run ~)í•´ë„ ë˜ì§€ë§Œ, docker composeë¼ëŠ” íˆ´ì„ ì´ìš©í•´ í•œêº¼ë²ˆì— ë°°í¬í•´ë³´ë„ë¡ í•œë‹¤. yml í˜•ì‹ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ NadeNodeì™€ DataNodeë¥¼ í•œ ë²ˆì— ë°°í¬í•  ê²ƒì´ë‹¤. Install docker-composedocker ì„¤ì¹˜ ì‹œ ìë™ìœ¼ë¡œ ì„¤ì¹˜ëœ ì¤„ ì•Œì•˜ëŠ”ë°, ì„¤ì¹˜ê°€ ì•ˆë˜ìˆì—ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ docker-composeë¥¼ ì„¤ì¹˜í•œë‹¤. 1234567[kuber@node2 hadoop]$ sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 617 0 617 0 0 1382 0 --:--:-- --:--:-- --:--:-- 1380100 15.4M 100 15.4M 0 0 2327k 0 0:00:06 0:00:06 --:--:-- 3535k[kuber@node2 hadoop]$ sudo chmod +x /usr/local/bin/docker-compose[kuber@node2 hadoop]$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose.ymldocker-compose.ymlì€ docker ì‹¤í–‰ ì˜µì…˜ë“¤ì„ ë¯¸ë¦¬ ì ì–´ë‘” íŒŒì¼ì´ë‹¤. services` ë¶€ë¶„ì€ ìš°ë¦¬ê°€ êµ¬ë™í•  NameNode ë° DataNodeì— ê´€ë ¨ëœ ì˜µì…˜ë“¤ì„ ì‘ì„±í•˜ê³ , ê³„íšì—ì„œ ì–¸ê¸‰í•œ ê²ƒì²˜ëŸ¼ DataNode 3ê°œ êµ¬ë™ì„ ìœ„í•´ 01/02/03ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•œë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748version: \"3.4\"x-datanode_base: &amp;datanode_base image: hadoop-datanode:2.9.2 networks: - bridgeservices: namenode: image: hadoop-namenode:2.9.2 container_name: namenode hostname: namenode ports: - \"50070:50070\" - \"9000:9000\" volumes: - namenode:/opt/hadoop/dfs/name - /tmp:/tmp networks: - bridge datanode01: &lt;&lt;: *datanode_base container_name: datanode01 hostname: datanode01 volumes: - datanode01:/opt/hadoop/dfs/data datanode02: &lt;&lt;: *datanode_base container_name: datanode02 hostname: datanode02 volumes: - datanode02:/opt/hadoop/dfs/data datanode03: &lt;&lt;: *datanode_base container_name: datanode03 hostname: datanode03 volumes: - datanode03:/opt/hadoop/dfs/datavolumes: namenode: datanode01: datanode02: datanode03:networks: bridge: versionì˜ ê²½ìš°, ìì‹ ì˜ ì„œë²„ì— ì„¤ì¹˜ëœ docker engine releaseì— ë”°ë¼ formatì´ ì •í•´ì ¸ìˆìœ¼ë¯€ë¡œ ì´ ë¬¸ì„œë¥¼ ì°¸ê³  Run Container using docker-composedocker-composeë¥¼ ì´ìš©í•´ ë°°í¬í•´ ë³´ë„ë¡ í•˜ì. ë³¼ë¥¨ì„ ìƒì„±í•˜ê³  NameNode / DataNodeê°€ êµ¬ë™ë˜ì—ˆë‹¤ëŠ” ë©”ì„¸ì§€ê°€ ë³´ì¼ ê²ƒì´ë‹¤. 12345678[kuber@node2 hadoop]$ docker-compose up -dCreating volume \"hadoop_datanode01\" with default driverCreating volume \"hadoop_datanode02\" with default driverCreating volume \"hadoop_datanode03\" with default drivernamenode is up-to-dateCreating datanode01 ... doneCreating datanode02 ... doneCreating datanode03 ... done Installation Checkë…¸ë“œë“¤ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ëŠ” ë‹¨ê³„ì´ë‹¤. êµ¬ë™ì„ í–ˆìœ¼ë©´ ì œëŒ€ë¡œ ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ”ê²Œ ì¤‘ìš”í•˜ê² ì£ ? ì•„ë˜ ìˆœì„œì™€ ê°™ì´ ì„¤ì¹˜ í™•ì¸ì„ ì§„í–‰í•œë‹¤. NameNode ì»¨í…Œì´ë„ˆì˜ hadoop client ì‹¤í–‰ í™•ì¸NameNodeì˜ ì»¨í…Œì´ë„ˆì— ì ‘ì†í•´ ì»¤ë§¨ë“œë¼ì¸ì„ í™•ì¸í•˜ëŠ” ëª…ë ¹ì–´(docker exec)ë¥¼ í†µí•´ í™•ì¸í•´ë³¸ë‹¤. ê·¸ëŸ¬ë©´ ì•„ë˜ì™€ ê°™ì´ Usageê°€ ì¶œë ¥ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 1234567891011121314151617181920[kuber@node2 hadoop]$ docker exec namenode /opt/hadoop/bin/hadoopUsage: hadoop [--config confdir] [COMMAND | CLASSNAME] CLASSNAME run the class named CLASSNAME or where COMMAND is one of: fs run a generic filesystem user client version print the version jar &lt;jar&gt; run a jar file note: please use \"yarn jar\" to launch YARN applications, not this command. checknative [-a|-h] check native hadoop and compression libraries availability distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive classpath prints the class path needed to get the Hadoop jar and the required libraries credential interact with credential providers daemonlog get/set the log level for each daemon trace view and modify Hadoop tracing settingsMost commands print help when invoked w/o parameters. ì´ì²˜ëŸ¼ ë§¤ ë²ˆ docker exec ëª…ë ¹ì–´ë¥¼ ì‘ì„±í•˜ëŠ” ê±´ ì •ë§ ê·€ì°®ì„ ê²ƒì´ë‹¤. aliasë¥¼ ë“±ë¡í•´ ê°„í¸í•˜ê²Œ ëª…ë ¹ì–´ë¥¼ ë‚ ë ¤ë³´ì. 12345678910111213141516171819202122232425[kuber@node2 hadoop]$ vi ~/.bash_profile # bash_profilealias hadoop=\"docker exec namenode /opt/hadoop/bin/hadoop\"#[kuber@node2 hadoop]$ source ~/.bash_profile [kuber@node2 hadoop]$ hadoopUsage: hadoop [--config confdir] [COMMAND | CLASSNAME] CLASSNAME run the class named CLASSNAME or where COMMAND is one of: fs run a generic filesystem user client version print the version jar &lt;jar&gt; run a jar file note: please use \"yarn jar\" to launch YARN applications, not this command. checknative [-a|-h] check native hadoop and compression libraries availability distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive classpath prints the class path needed to get the Hadoop jar and the required libraries credential interact with credential providers daemonlog get/set the log level for each daemon trace view and modify Hadoop tracing settingsMost commands print help when invoked w/o parameters. í´ë” ìƒì„±/ì¡°íšŒ/ì‚­ì œ í™•ì¸hadoop ëª…ë ¹ì–´ë¥¼ í†µí•´ í´ë”ë¥¼ ìƒì„±í•˜ê³  ì¡°íšŒí•˜ë©° ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚­ì œí•˜ëŠ” ì‘ì—…ì„ í•´ë³¸ë‹¤. 12345678[kuber@node2 hadoop]$ hadoop fs -mkdir -p /tmp/test/app[kuber@node2 hadoop]$ hadoop fs -ls -R /tmpdrwxr-xr-x - root supergroup 0 2019-10-25 05:15 /tmp/testdrwxr-xr-x - root supergroup 0 2019-10-25 05:15 /tmp/test/app[kuber@node2 hadoop]$ hadoop fs -rm -r /tmp/test/appDeleted /tmp/test/app[kuber@node2 hadoop]$ hadoop fs -ls -R /tmpdrwxr-xr-x - root supergroup 0 2019-10-25 05:16 /tmp/test Web UINameNodeì™€ DataNode ìƒíƒœë¥¼ Webì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. container ì‹¤í–‰ì„ ìœ„í•´ ì‘ì„±í•œ docker-compose.yml ì•ˆì— NameNodeì˜ port(50070)ë¥¼ ì´ìš©í•´ ì ‘ì†ì„ í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ í™”ë©´ì´ ë³´ì¼ ê²ƒì´ë‹¤. NameNode overview DataNode overview Ref. ê¹€ê·¼í˜¸ë‹˜ ë¸”ë¡œê·¸ : Dockerë¡œ Hadoop í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•í•˜ê¸° - HDFS Docker documenst made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Database] OLAP","slug":"hackerrank-olap","date":"2019-10-22T15:00:00.000Z","updated":"2020-03-30T15:06:23.577Z","comments":true,"path":"hackerrank-olap/","link":"","permalink":"https://jx2lee.github.io/hackerrank-olap/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Database ì¹´í…Œê³ ë¦¬ì˜ OLAP ë¬¸ì œë¥¼ í’€ì–´ë³´ê³  ê°œë…ì„ ì •ë¦¬í•œë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Database ì¹´í…Œê³ ë¦¬ì˜ OLAP ë¬¸ì œë¥¼ í’€ì–´ë³´ê³  ê°œë…ì„ ì •ë¦¬í•œë‹¤. OLAP - The Total viewë¬¸ì œWhich of these provides a total view of the organization? 1) OLAP2) OLTP3) Data Warehousing4) Database í’€ì´ì™œ í‹€ë ¸ëŠ”ì§€ë¥¼ ëª¨ë¥´ê² ëŠ” ë¬¸ì œì´ë‹¤. 1ë²ˆ, 2ë²ˆ, 4ë²ˆì´ ê²°êµ­ 3ë²ˆ : Data Warehousingì— í¬í•¨ëœ ë‚´ìš©ì´ë‹¤. ê°ê°ì˜ ê°œë…ì„ ê°„ë‹¨íˆ ì •ë¦¬í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. (4ë²ˆì˜ ê²½ìš° PASS) OLAPë°ì´í„° ì§‘ê³„ë¥¼ íš¨ìœ¨í™”í•˜ëŠ” ì ‘ê·¼ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ, ë‹¤ì°¨ì› ëª¨ë¸êµ¬ì¡°ë¥¼ MDX (Multidimensional expressions) ë“±ì˜ ì¿¼ë¦¬ ì–¸ì–´ë¡œ ì§‘ê³„í•œë‹¤. ë‹¤ì°¨ì› ëª¨ë¸ êµ¬ì¡°ë¥¼ OLAP íë¸Œë¼ í•˜ë©° ì´ëŸ¬í•œ íë¸Œë¥¼ ì´ìš©í•´ í¬ë¡œìŠ¤ ì§‘ê³„í•˜ëŠ” êµ¬ì¡°ê°€ OLAPì´ë‹¤. OLTP (Online Transaction Processing)ì •ì˜ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì„œë²„(DB)ê°€ ìë£Œë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì • ì¸ë°, ì‚¬ì‹¤ OLAP vs OLTPë¥¼ ë¹„êµí•˜ëŠ” ê²ƒì„ ì£¼ë¡œ ë³´ì•˜ëŠ”ë° ì •í™•í•œ ì˜ë¯¸ë¥¼ ëª¨ë¥´ê² ë‹¤. OLAPì€ í•˜ë‚˜ì˜ ê¸°ìˆ ë¡œ ë³´ëŠ”ê²ƒì¸ì§€, OLTPëŠ” ê¸°ìˆ ì´ ì•„ë‹Œ ì‹¤ì‹œê°„ì„± ì²˜ë¦¬ ê³¼ì •ìœ¼ë¡œ ë´ì•¼í•˜ëŠ”ì§€ëŠ” ì¢€ ë” ì‚´í´ë³¸ ì´í›„ì— ìì„¸íˆ ì •ë¦¬í•´ì•¼ê² ë‹¤. Data Warehousing Data Warehouseë¥¼ ì„¤ê³„í•˜ê³  ì‚¬ìš©í•˜ëŠ” ê³¼ì •ì„ ëœ»í•˜ëŠ” ë‹¨ì–´ì´ë‹¤. Data Warehouse íŠ¹ì§•ì„ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. Web Server ë˜ëŠ” RDBì™€ ë‹¬ë¦¬ ëŒ€ëŸ‰ ë°ì´í„° ì¥ê¸° ë³´ì¡´ ìµœì í™” ì •ë¦¬ëœ ë°ì´í„° ì „ì†¡ ê¸°ëŠ¥ì€ ë›°ì–´ë‚˜ì§€ë§Œ, ì†ŒëŸ‰ ë°ì´í„°ì˜ ê²½ìš° ì í•©í•˜ì§€ ì•ŠìŒ ì—…ë¬´ ì²˜ë¦¬ì— ìˆì–´ í•¨ë¶€ë¡œ ì‚¬ìš©í•´ ì‹œìŠ¤í…œ ê³¼ë¶€í•˜ ì´ˆë˜ëŠ” ìœ„í—˜í•¨, ì´ëŸ¬í•œ ë¬¸ì œë¡œ í•„ìš”í•œ ë°ì´í„°ë§Œì„ ì¶”ì¶œí•˜ì—¬ ë°ì´í„° ë§ˆíŠ¸ (Data Mart)ë¥¼ êµ¬ì„±í•¨ [ì°¸ê³ ] : ë¹…ë°ì´í„°ë¥¼ ì§€íƒ±í•˜ëŠ” ê¸°ìˆ , Wikipedia OLAP - OLAP Operation Typesë¬¸ì œConsider a fact table DataPoints(D1,D2,D3,x), and the following three queries: Q1: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3Q2: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3 WITH CUBEQ3: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3 WITH ROLLUP Suppose attributes D1, D2, and D3 have n1, n2, and n3 different values respectively, and assume that each possible combination of values appears at least once in the table DataPoints. The number of tuples in the result of each of the three queries above can be specified as an arithmetic formula involving n1, n2, and n3. Pick the one tuple (a,b,c,d,e,f) in the list below such that when n1=a, n2=b, and n3=c, then the result sizes of queries Q1, Q2, and Q3 are d, e, and f respectively. 1) (2, 2, 2, 6, 18, 8)2) (2, 2, 2, 8, 64, 15)3) (5, 10, 10, 500, 1000, 550)4) (4, 7, 3, 84, 160, 117) í’€ì´ë¬¸ì œë¥¼ ì˜ëª» ì´í•´í•´ í‘¸ëŠ”ë° ì˜¤ë˜ ê±¸ë ¸ë‹¤. ì£¼ì–´ì§„ ë³´ê¸° 4ê°œ tupleì˜ ì•ì— 3ê°œëŠ” ê°ê° D1, D2, D3ì¹¼ëŸ¼ì˜ value ë“¤ì´ì—ˆë‹¤. ë”°ë¼ì„œ, ê° ì§€ë¬¸ì˜ 3ê°œ ìˆ«ì (ex. 1ë²ˆ ë³´ê¸°ëŠ” 2,2,2 -&gt; D1, D2, D3) ë¡œ operation CUBE ë° ROLL UP ì„ ìˆ˜í–‰í•œ í›„ ì¡°íšŒë˜ëŠ” í–‰ì˜ ê°¯ìˆ˜ë¥¼ ë§ì¶”ëŠ” ë¬¸ì œì´ë‹¤. Q1ì€ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆì—ˆê³  CUBE ë° ROLLUP ì—°ì‚°ì„ êµ¬ê¸€ì„ í†µí•´ ì‚´í´ë³´ì•˜ë‹¤. ìš°ì„  CUBE operationì€ ëª¨ë“  ì°¨ì›ì—ì„œ ëª¨ë“  ì†ì„± ì¡°í•©ì„ ì‚¬ìš©í•œë‹¤. ì´ëŠ” ê³§, NULL êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— group byë¡œ ì¡°íšŒìˆ˜ì™€ëŠ” ë‹¤ë¥´ê²Œ ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°ëœë‹¤. (n1 + 1) * (n2 + 1) * (n3 + 1) ë§ˆì§€ë§‰ìœ¼ë¡œ ROLLUP operationì€ NULLì´ ìˆëŠ” ì†ì„±ì„ í¬í•¨í•˜ì—¬ ì†ì„± tupleì„ ìƒì„±í•œë‹¤. ì´ì— ê¸°ì¡´ CUBE ì—°ì‚°ì„ í†µí•´ ë‚˜ì˜¨ ìˆ˜ì™€ ROLLUPì—°ì‚°ì„ í†µí•´ ê³„ì‚°ë˜ëŠ” tuple ìˆ˜ë¥¼ ë”í•´ì¤€ë‹¤. ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤. [ê¸°ì¡´ CUBEë¡œ ê³„ì‚°ëœ ìˆ˜] + n1 * (n2 + 1) + 1 ROLLUP ì´ë¼ í•¨ì€ Drill Down (operation ì¤‘ í•˜ë‚˜)ê³¼ ë‹¬ë¦¬ ì‘ì€ ë²”ìœ„ì—ì„œ í° ë²”ìœ„ì˜ ë‹¨ê³„ì  ì ‘ê·¼ ë¶„ì„ ë°©ë²•ì„ ë§í•œë‹¤ (ex. ë²ˆì§€ -&gt; ë™ -&gt; êµ¬ -&gt; ì‹œë„ -&gt; ê´‘ì—­). ìœ„ì— ê¸°ì¡´ CUBE ì—°ì‚°ì„ í†µí•œ ê°’ê³¼ ê·¸ ë’¤ì— ìƒˆë¡œìš´ ì¶”ê°€ëœ ìˆ˜ë¥¼ ë”í•˜ëŠ” ë‚´ìš©ì´ í™•ì‹¤íˆ ì´í•´ê°€ ê°€ì§€ ì•Šì•„ ë‚˜ì¤‘ì— ì •ë¦¬í•´ì•¼í•  ê²ƒ ê°™ë‹¤. 2019.10.23 made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Hadoop] Hadoop Overview","slug":"hadoop-introduction_to_hadoop","date":"2019-10-21T15:00:00.000Z","updated":"2020-05-15T05:29:45.181Z","comments":true,"path":"hadoop-introduction_to_hadoop/","link":"","permalink":"https://jx2lee.github.io/hadoop-introduction_to_hadoop/","excerpt":"Hadoop ê´€ë ¨ ì±…ì„ ì½ìœ¼ë©° ê°œë…ì„ ê°„ë‹¨íˆ ì •ë¦¬í•œë‹¤.","text":"Hadoop ê´€ë ¨ ì±…ì„ ì½ìœ¼ë©° ê°œë…ì„ ê°„ë‹¨íˆ ì •ë¦¬í•œë‹¤. ë§¨ë‚  í•˜ë‘¡ ê³µë¶€í•´ì•¼ì§€.. ê³µë¶€í•´ì•¼ì§€ í•˜ë‹¤ê°€ ë¹…ë°ì´í„°ë¥¼ ì§€íƒ±í•˜ëŠ” ê¸°ìˆ  ì±…ì„ ì½ìœ¼ë©° ì •ë¦¬í•˜ê³ ì í•œë‹¤. ë¬´ì‘ì • ì‹¤ìŠµë¶€í„° í•˜ê¸° ë³´ë‹¤ëŠ”, ê¸°ë³¸ì ì¸ ê°œë…ì„ ìµíˆê³  Hadoop í™˜ê²½ì„ êµ¬ì„±í•  ê²ƒì´ë‹¤. ìš°ì„  ë‚´ìš© ì „ì²´ì ìœ¼ë¡œ ë„ì„œë¥¼ ì°¸ê³ í•´ ì‘ì„±í•˜ê³  ì¶”ê°€ì ì¸ ë¶€ë¶„ì€ êµ¬ê¸€ ì„œì¹˜ë¥¼ í†µí•´ ì±„ì›Œë„£ì„ ì˜ˆì •ì´ë‹¤. ìµœëŒ€í•œ ì±…ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œë…ì„ ì •ë¦¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. Contents: Hadoop ì´ë€ Hadoop ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ (HDFS) ê³¼ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì (YARN) ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ (MapReduce) ë° ì¿¼ë¦¬ ì—”ì§„ (Hive) Hive on Tez ëŒ€í™”í˜• ì¿¼ë¦¬ ì—”ì§„ (Impala &amp; Presto) Hadoop ì´ë€ê°œë…ì„ ë°°ìš°ëŠ”ë° ìˆì–´ì„œ ì—­ì‚¬ëŠ” í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ê³  ìƒê°í•œë‹¤. ì±…ì—ì„œëŠ” ì—­ì‚¬ê°€ ê¸°ìˆ ë˜ì–´ìˆì§€ë§Œ ë‚˜ëŠ” ì •ì˜(ìˆ˜í•™ê³¼ ì•„ë‹ˆë„ê¹Œë´) ë¶€í„° ì§šì–´ë³´ê³ ì í•œë‹¤. Hadoopì€ ë‹¨ì¼ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì•„ë‹Œ, ë¶„ì‚° ì‹œìŠ¤í…œ ì„ êµ¬ì„±í•˜ëŠ” ë‹¤ìˆ˜ì˜ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ì§‘í•©ì²´ ì´ë‹¤. Wikië°±ê³¼ì— ì˜í•˜ë©´, ëŒ€ëŸ‰ì˜ ìë£Œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í° ì»´í“¨í„° í´ëŸ¬ìŠ¤í„°ì—ì„œ ë™ì‘í•˜ëŠ” ë¶„ì‚° ì‘ìš© í”„ë¡œê·¸ë¨ì„ ì§€ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¼ê³  ì†Œê°œí•œë‹¤. ì¼ë§¥ ìƒí†µí•œë‹¤. ì¢€ ë” ìì„¸íˆ ì–´ë– í•œ ì–¸ì–´ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ë¥¼ í‘œí˜„í•˜ì˜€ì§€, ì˜ë¯¸ëŠ” ê°™ë‹¤ 2013ë…„ Hadoop2ë¶€í„° YARNì´ë¼ëŠ” ë¦¬ì†ŒíŠ¸ê´€ë¦¬ì ìƒì—ì„œ ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë™ì‘í•˜ëŠ” êµ¬ì„±ìœ¼ë¡œ ì„¤ê³„ë˜ì–´, ëŒ€ê·œëª¨ ë¶„ì‚°ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í”Œë«í¼ ì—­í• ì„ ë§¡ê³  ìˆë‹¤. [ê·¸ë¦¼] - ë¹…ë°ì´í„° ê´€ë ¨ Apache í”„ë¡œì íŠ¸ (ì°¸ê³  : ë¹…ë°ì´í„°ë¥¼ ì§€íƒ±í•˜ëŠ” ê¸°ìˆ ) Hadoop ê¸°ë³¸ êµ¬ì„± ìš”ì†Œê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¡œëŠ” ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ (distributed file system)ì¸ HDFS(Hadoop Distributed File System), *ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì** *(resource manager) ì¸ YARN(Yet Another Resource Negotiator), ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ (distributed data processing) ê¸°ë°˜ MapReduce 3ê°€ì§€ë‹¤. ì´ì™¸ êµ¬ì„±ìš”ì†Œ(í”„ë¡œì íŠ¸ë¼ê³  í‘œí˜„í•˜ê¸°ë„ í•¨)ëŠ” Hadoopê³¼ ë…ë¦½ì ìœ¼ë¡œ ê°œë°œë˜ì–´ ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë™ì‘í•œë‹¤. ì¦‰, ìœ„ì—ì„œ ì†Œê°œí•œ í”„ë¡œì íŠ¸ì—ì„œ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œìœ¼ë¡œëŠ” HDFSë¥¼ ì‚¬ìš©í•˜ê³  resource managerë¡œëŠ” Mesosë¥¼, ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ì—ëŠ” Sparkë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ìì‹ ì—ê²Œ ë§ê³  ìƒí™©ì— ë§ëŠ” í”„ë¡œì íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” ê²ƒì´ Hadoopì„ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ëŠ” ë°ì´í„° ì²˜ë¦¬ì˜ íŠ¹ì§•ì´ë‹¤. ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ (HDFS) ê³¼ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì (YARN)Hadoopì—ì„œ ì²˜ë¦¬ë˜ëŠ” ë°ì´í„°ëŠ” ëŒ€ë¶€ë¶„ HDFSì— ì €ì¥ëœë‹¤. ë³´í†µ íŒŒì¼ ì„œë²„ì™€ ë¹„ìŠ·í•œ ê°œë…ì´ì§€ë§Œ, ë‹¤ìˆ˜ ì»´í“¨í„°ì— íŒŒì¼ì„ ë³µì‚¬í•˜ì—¬ ì¤‘ë³µì„±ì„ ë†’ì¸ë‹¤ëŠ” íŠ¹ì§•ì´ ìˆë‹¤. HDFSëŠ” ë¸”ë¡ êµ¬ì¡°ì˜ file systemì´ë‹¤. íŒŒì¼ì„ íŠ¹ì • í¬ê¸° ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì‚°ëœ ì„œë²„ì— ì €ì¥í•œë‹¤. í¬ê¸°ëŠ” 64MB ì—ì„œ Hadoop2 ë¶€í„°ëŠ” 128Më¡œ ì¦ê°€í•˜ì˜€ë‹¤(ì°¸ê³ ) í•œí¸, CPUë‚˜ ë©”ëª¨ë¦¬ ë“±ì˜ ê³„ì‚° ë¦¬ì†ŒìŠ¤ëŠ” resource managerì¸ YARNì— ì˜í•´ ê´€ë¦¬ëœë‹¤. YARNì€ CPU ì½”ì–´ì™€ ë©”ëª¨ë¦¬ë¥¼ ì»¨í…Œì´ë„ˆ (Container) ë‹¨ìœ„ë¡œ ê´€ë¦¬í•œë‹¤ (ì—¬ê¸°ì„œ ContainerëŠ” Docker Containerì™€ëŠ” ë‹¤ë¥´ë‹¤. ì–´ë–¤ í˜¸ìŠ¤íŠ¸ì—ì„œ ì–´ë–¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰ì‹œí‚¬ ê²ƒì¸ì§€ ê²°ì •í•˜ëŠ” ì•± ìˆ˜ì¤€ì˜ ê¸°ìˆ ). Hadoopì—ì„œ ë¶„ì‚° ì•±ì„ ì‹¤í–‰í•˜ë©´ YARNì´ í´ëŸ¬ìŠ¤í„° ì „ì²´ì˜ ë¶€í•˜ë¥¼ ë³´ê³  ë¹„ì–´ ìˆëŠ” í˜¸ìŠ¤íŠ¸ë¶€í„° ì»¨í…Œì´ë„ˆë¥¼ í• ë‹¹í•œë‹¤. ì¦‰, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ìì¸ YARNì€ ì–´ëŠ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì–¼ë§ˆë§Œí¼ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ í• ë‹¹í•  ì§€ ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì°¨ì§ˆì—†ì´ ì‹¤í–‰ë˜ë„ë¡ ì œì–´ í•œë‹¤ ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ (MapReduce) ë° ì¿¼ë¦¬ ì—”ì§„ (Hive) MapReduceYARN ìƒì—ì„œ ë™ì‘í•˜ëŠ” ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ í•˜ë‚˜ë¡œ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤. ì„ì˜ì˜ java í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë¹„êµ¬ì¡°í™” ë°ì´í„° (Unstructured Data) ê°€ê³µì— ì í•©í•˜ë‹¤. ì´ˆê¸° ëª©ì ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ Batch*ì²˜ë¦¬í•˜ê¸° ìœ„í•¨ì´ì—ˆë‹¤. í•œ ë²ˆ ì‹¤í–‰í•˜ë©´ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ìˆì§€ë§Œ, ì‘ì€ í”„ë¡œê·¸ë¨ì„ *(ì‘ì€ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”) ì„ ì‹¤í–‰í•˜ë©´ ê³¼í•œ ì˜¤ë²„í—¤ë“œë¡œ ëª‡ ì´ˆ ì•ˆì— ëë‚˜ë²„ë¦¬ëŠ” ì¿¼ë¦¬ì—ëŠ” ì–´ìš¸ë¦¬ì§€ ì•Šë‹¤. [ê·¸ë¦¼] - MapReduce Process ì¿¼ë¦¬ ì—”ì§„ (Hive)HiveëŠ” SQL ë“± ì¿¼ë¦¬ ì–¸ì–´ì— ì˜í•œ ë°ì´í„° ì§‘ê³„ê°€ ëª©ì ìœ¼ë¡œ ì„¤ê³„ëœ ì¿¼ë¦¬ ì—”ì§„ ì¤‘ í•˜ë‚˜ì´ë‹¤. ì´ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìë™ìœ¼ë¡œ MapReduce í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜ì‹œí‚¨ë‹¤. ì‹¤í–‰ íŠ¹ì„± ìƒ MapReduceì— ì˜ì¡´í•˜ê³  ìˆë‹¤. ì¿¼ë¦¬ ì—”ì§„ Hiveë„ ê²°êµ­ MapReduceì— ì˜ì¡´í•˜ê³  ìˆê¸° ë•Œë¬¸ì—, ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì—ëŠ” ì í•©í•˜ë‚˜, ì• ë“œ í›… ë¶„ì„ì„ ìœ„í•œ ì¿¼ë¦¬(ê°„ë‹¨í•˜ê³  ë°”ë¡œë°”ë¡œ ë³¼ ìˆ˜ ìˆëŠ”)ë¥¼ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•˜ëŠ” ë° ì ì ˆí•˜ì§€ ì•Šë‹¤ [ê·¸ë¦¼] - Hive Architecture (https://medium.com/@yigiterbas/apache-hive-and-applications-1-31735b8823c7) Hive on TezHive ê°€ì†í™”ë¥¼ ìœ„í•´ ê°œë°œëœ ê²ƒìœ¼ë¡œ MapReduceì—ì„œ ë³´ì¸ ëª‡ ê°€ì§€ ë‹¨ì ì„ í•´ê²°í•˜ê³  ê³ ì†í™”ë¥¼ ì‹¤í˜„í•˜ê³  ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, MapReduceì˜ ê²½ìš° í•˜ë‚˜ì˜ stageê°€ ëë‚  ë•Œ ê¹Œì§€ ë‹¤ìŒì˜ ì²˜ë¦¬ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ì—ˆë‹¤. ì´ì— TezëŠ” stage ì¢…ë£Œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì²˜ë¦¬ê°€ ëë‚œ ë°ì´í„°ë¥¼ ì°¨ë¡€ëŒ€ë¡œ í›„ì† ì²˜ë¦¬ë¡œ ë„˜ê²¨ ì „ì²´ ì¿¼ë¦¬ ì‹œê°„ì˜ ë‹¨ì¶•ì„ ì‹¤í˜„í–ˆë‹¤. í˜„ì¬ì˜ HiveëŠ” MapReduce ë¿ ì•„ë‹ˆë¼ Tezë¥¼ ì‚¬ìš©í•´ë„ ë™ì‘í•˜ë¯€ë¡œ Hiveë¥¼ Hive on Tez ì™€ Hive on MRë¡œ êµ¬ë¶„í•œë‹¤. (MRì€ MapReduce ì¤„ì„ë§) [ê·¸ë¦¼] - Hive on MR &amp; Hive on Tez Process ëŒ€í™”í˜• ì¿¼ë¦¬ ì—”ì§„ (Impala &amp; Presto)Hive ê³ ì†í™”ê°€ ì•„ë‹Œ ëŒ€í™”í˜• ì¿¼ë¦¬ ì‹¤í–‰ë§Œì„ ìœ„í•œ ì—”ì§„ë„ ìˆë‹¤. ê·¸ ì¤‘ Impalaì™€ Prestoê°€ ëŒ€í‘œì ì´ë‹¤. Imapalaì™€ Prestoë¥¼ ê°„ë‹¨íˆ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. Impala ImpalaëŠ” í¬ê²Œ impaladì™€ impala state store í”„ë¡œì„¸ìŠ¤ë¡œ êµ¬ì„±í•œë‹¤. impaladëŠ” ë¶„ì‚° ì§ˆì˜ ì—”ì§„ ì—­í• ì„ ë‹´ë‹¹í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¡œ, Hadoop í´ëŸ¬ìŠ¤í„° ë‚´ ë°ì´í„°ë…¸ë“œ ìœ„ì—ì„œ ì§ˆì˜ì— ëŒ€í•œ plan ì„¤ê³„ì™€ ì§ˆì˜ ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. impala state store ëŠ” ê° ë°ì´í„° ë…¸ë“œì—ì„œ ìˆ˜í–‰ë˜ëŠ” impaladì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ìœ ì§€í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•œë‹¤. impalad í”„ë¡œì„¸ìŠ¤ê°€ í´ëŸ¬ìŠ¤í„° ë‚´ì— ì¶”ê°€ ë˜ëŠ” ì œê±°ë  ë•Œ impala state store í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ë©”íƒ€ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ëœë‹¤. impalad : ë¶„ì‚° ì§ˆì˜ ì—”ì§„, impala state store : Impaladì˜ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ [ê·¸ë¦¼] - impala high-level architecture (ì›ë³¸ì¶œì²˜) Presto PrestoëŠ” í¬ê²Œ Coordinatorì™€ Workerë¡œ êµ¬ì„±ëœë‹¤. CoordinatorëŠ” SQL query ë¶„ì„, query ê³„íšê³¼ Presto Worker ë…¸ë“œ (worker)ë¥¼ ê´€ë¦¬í•œë‹¤. REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ Worker ë° Clientì™€ í†µì‹ í•œë‹¤. WorkerëŠ” ì‘ì—…ì„ ì‹¤í–‰í•˜ê³  ë°ì´í„°ë¥¼ ì²˜ë¦¬í•œë‹¤. Workerê°€ ìˆ˜í–‰í•œ ê²°ê³¼ë¥¼ Coordinatorë¥¼ ê±°ì³ Clientì—ê²Œ ì „ë‹¬í•˜ë©° Coordinatorì™€ ë§ˆì°¬ê°€ì§€ë¡œ REST APIë¥¼ ì‚¬ìš©í•´ í†µì‹ í•œë‹¤. [ê·¸ë¦¼] - Presto architecture (ì¶œì²˜) ì´ëŸ¬í•œ ëŒ€í™”í˜• ì¿¼ë¦¬ ì—”ì§„ì€ Hive ì™€ëŠ” ë‹¬ë¦¬ ìˆœê°„ ìµœëŒ€ ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ëª¨ë“  ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í•˜ì—¬, ë¦¬ì†ŒìŠ¤ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œë‹¤ (ì´ëŠ” Hiveì˜ ë‹¨ì ìœ¼ë¡œ ì–¸ê¸‰í•œ ë¶€ë¶„ì„ í•´ê²°í•œë‹¤) . ê·¸ ê²°ê³¼, ëŒ€í™”í˜• ì¿¼ë¦¬ ì—”ì§„ì€ MPP DBì™€ ë¹„êµí•´ë„ ì†ìƒ‰ì—†ëŠ” ì‘ë‹µ ì‹œê°„ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. Hadoopì—ì„œëŠ” ì¿¼ë¦¬ ì—”ì§„ì„ ëª©ì ì— ë”°ë¼ êµ¬ë¶„í•œë‹¤. ëŒ€ëŸ‰ì˜ ë¹„êµ¬ì¡°í™” ë°ì´í„°ë¥¼ ê°€ê³µí•˜ëŠ” ë¬´ê±°ìš´ ë°°ì¹˜ ì²˜ë¦¬ì—ëŠ” ë†’ì€ ì²˜ë¦¬ëŸ‰ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” Hiveë¥¼, êµ¬ì¡°í™” ë° ì™„ì„±ëœ ë°ì´í„°ë¥¼ ëŒ€í™”ì‹ìœ¼ë¡œ ì§‘ê³„ë¥¼ ì›í•  ë• ì§€ì—°ì´ ì ì€ Impalaì™€ Prestoê°€ ì í•©í•˜ë‹¤. 2019.10.22 made by jaejun.lee","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"}],"tags":[]},{"title":"[Python] ë“±êµ£ê¸¸","slug":"programmers-tortoise","date":"2019-10-17T15:00:00.000Z","updated":"2020-03-30T15:06:23.526Z","comments":true,"path":"programmers-tortoise/","link":"","permalink":"https://jx2lee.github.io/programmers-tortoise/","excerpt":"ë“±êµí•˜ëŠ”ë° ê°€ëŠ¥í•œ ë£¨íŠ¸ì˜ ìµœì†Ÿê°’ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.","text":"ë“±êµí•˜ëŠ”ë° ê°€ëŠ¥í•œ ë£¨íŠ¸ì˜ ìµœì†Ÿê°’ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë¬¸ì œ ì„¤ëª…ë¬¸ì œ ì„¤ëª…ê³„ì†ë˜ëŠ” í­ìš°ë¡œ ì¼ë¶€ ì§€ì—­ì´ ë¬¼ì— ì ê²¼ìŠµë‹ˆë‹¤. ë¬¼ì— ì ê¸°ì§€ ì•Šì€ ì§€ì—­ì„ í†µí•´ í•™êµë¥¼ ê°€ë ¤ê³  í•©ë‹ˆë‹¤. ì§‘ì—ì„œ í•™êµê¹Œì§€ ê°€ëŠ” ê¸¸ì€ m x n í¬ê¸°ì˜ ê²©ìëª¨ì–‘ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì€ m = 4, n = 3 ì¸ ê²½ìš°ì…ë‹ˆë‹¤. ê°€ì¥ ì™¼ìª½ ìœ„, ì¦‰ ì§‘ì´ ìˆëŠ” ê³³ì˜ ì¢Œí‘œëŠ” (1, 1)ë¡œ ë‚˜íƒ€ë‚´ê³  ê°€ì¥ ì˜¤ë¥¸ìª½ ì•„ë˜, ì¦‰ í•™êµê°€ ìˆëŠ” ê³³ì˜ ì¢Œí‘œëŠ” (m, n)ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê²©ìì˜ í¬ê¸° m, nê³¼ ë¬¼ì´ ì ê¸´ ì§€ì—­ì˜ ì¢Œí‘œë¥¼ ë‹´ì€ 2ì°¨ì› ë°°ì—´ puddlesì´ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤. ì§‘ì—ì„œ í•™êµê¹Œì§€ ê°ˆ ìˆ˜ ìˆëŠ” ìµœë‹¨ê²½ë¡œì˜ ê°œìˆ˜ë¥¼ 1,000,000,007ë¡œ ë‚˜ëˆˆ ë‚˜ë¨¸ì§€ë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ ê²©ìì˜ í¬ê¸° m, nì€ 1 ì´ìƒ 100 ì´í•˜ì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. mê³¼ nì´ ëª¨ë‘ 1ì¸ ê²½ìš°ëŠ” ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬¼ì— ì ê¸´ ì§€ì—­ì€ 0ê°œ ì´ìƒ 10ê°œ ì´í•˜ì…ë‹ˆë‹¤. ì§‘ê³¼ í•™êµê°€ ë¬¼ì— ì ê¸´ ê²½ìš°ëŠ” ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ m n puddles return 4 3 [[2, 2]] 4 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª… ë¬¸ì œ ì ‘ê·¼Dynamic Programming ë¬¸ì œ. ì˜¤ëœë§Œì— íŒŒì´ì¬ ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œë¥¼ í’€ì—ˆë‹¤. ì‰¬ìš´ ë ˆë²¨ì´ë¼ ìƒê°í•´ ë„ì „í•˜ì˜€ì§€ë§Œ ì—­ì‹œë‚˜ êµ¬ê¸€ê²€ìƒ‰í–‰.. ìš°ì„  ì½”ë“œì— ì‚¬ìš©í•œ ë³€ìˆ˜ë“¤ì„ ì‚´í´ë³´ì grid : ê²©ì (index errorë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ +1 ë§Œí¼ ë” ìƒì„±) ì—¬ê¸°ì„œ ì¡°ì‹¬í•´ì•¼ í•  ê²ƒì€, ë¬¸ì œì—ì„œ ì œê³µí•˜ëŠ” m,nì´ í–‰ê³¼ ì—´ì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆëŠ”ë° ê·¸ ë°˜ëŒ€ì´ë‹¤. ì´ ì ì„ ëª…ì‹¬í•˜ê³  ë¬¸ì œë¥¼ í’€ì–´ì•¼ index errorë¥¼ ë°©ì§€í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. ë¬¼ì´ ê³ ì—¬ìˆëŠ” ì¢Œí‘œì—ëŠ” -1ë¡œ ëŒ€ì²´í•œë‹¤. 123if puddles: for x, y in puddles: grid[y][x] = -1 ì´ì œ (a,b) = (a-1, b) + (a, b-1) ì‹ì„ êµ¬í˜„í•˜ëŠ”ë° ìœ„ì— ì–¸ê¸‰í•œ ê²ƒ ì²˜ëŸ¼ í–‰ê³¼ ì—´ì„ ì¡°ì‹¬í•´ì„œ forë¬¸ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤. í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ì—´ì„ ì±„ì›Œë‚˜ê°€ëŠ” êµ¬ì¡°ë¡œ (1,1) ì¸ ë¶€ë¶„ì€ continueë¡œ ìˆ˜ì •í•˜ì§€ ì•Šê²Œ ì„¤ì •í•œë‹¤. ë˜í•œ, ë¬¼ì´ ìˆëŠ” ê²½ìš°ëŠ” 0ìœ¼ë¡œ ë°”ê¿” íšŸìˆ˜ê°€ ì»¤ì§€ê¸° ì•Šê²Œ ë°©ì§€í•˜ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ ì‹ì„ ì‘ì„±í•˜ë©´ grid ë³€ìˆ˜ëŠ” ì›í•˜ëŠ” ëŒ€ë¡œ ì±„ì›Œì§ˆ ê²ƒì´ë‹¤. 12345678for j in range(1, n+1): for i in range(1, m+1): if i == j == 1: continue if grid[j][i] == -1: grid[j][i] = 0 continue grid[j][i] = (grid[j][i-1] + grid[j-1][i])%1000000007 í–‰ê³¼ ì—´ ìˆœì„œê°€ ë°”ê¿” ìˆê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ return ê°’ë„ [m][n]ì´ ì•„ë‹Œ [n][m]ìœ¼ë¡œ return í•´ì•¼í•œë‹¤. return grid[n][m] full codeëŠ” í•˜ê¸°ì™€ ê°™ë‹¤ ë¬¸ì œ í•´ê²°12345678910111213141516def solution(m, n, puddles): grid = [[0] * (m+1) for _ in range(n+1)] grid[1][1] = 1 if puddles: for x, y in puddles: grid[y][x] = -1 for j in range(1, n+1): for i in range(1, m+1): if i == j == 1: continue if grid[j][i] == -1: grid[j][i] = 0 continue grid[j][i] = (grid[j][i-1] + grid[j-1][i])%1000000007 return grid[n][m] 2019.10.18 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[SQL] Print Prime Number","slug":"hackerrank-print_prime_number","date":"2019-10-14T15:00:00.000Z","updated":"2020-03-30T15:06:23.580Z","comments":true,"path":"hackerrank-print_prime_number/","link":"","permalink":"https://jx2lee.github.io/hackerrank-print_prime_number/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Print Prime Number ë¬¸ì œë¥¼ ì‚¬ìš©ì ë³€ìˆ˜ë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Print Prime Number ë¬¸ì œë¥¼ ì‚¬ìš©ì ë³€ìˆ˜ë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œWrite a query to print all prime numbers less than or equal to 1000. Print your result on a single line, and use the ampersand () character as your separator (instead of a space). For example, the output for all prime numbers &lt;= 10 would be: 12&amp;3&amp;5&amp;7 ì ‘ê·¼1000 ì´í•˜ì˜ ì†Œìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¡œ, sql queryë¡œëŠ” ì²˜ìŒ í’€ì–´ë³¸ë‹¤. ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ í’€ì–´ë³¼ ìˆ˜ ìˆë‹¤. (ì°¸ê³ í•œ ìë£ŒëŠ” urlì„ ìƒì–´ë²„ë ¸ë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤) ì²« ë²ˆì§¸, prime numberë¥¼ êµ¬í•˜ê¸° ìœ„í•œ num ë³€ìˆ˜ë¥¼ 2 ì´ìƒ 1000ì´í•˜ ê¹Œì§€ ì¡°íšŒí•˜ëŠ” ë¶€ë¶„ì´ë‹¤. information_schemaì˜ í…Œì´ë¸”ì„ ì´ìš©í•´ num := num + 1 ì„ ì¡°íšŒí•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤. 1234567select @num1 :=@num1 + 1 as num1from information_schema.tables t1, information_schema.tables t2, (select @num1 := 1) tmp; ë‘ ë²ˆì§¸, ì†Œìˆ˜ê°€ ì•„ë‹Œ ìˆ˜ë¥¼ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•´ exists ë¬¸ì„ ì‘ì„±í•œë‹¤. div ë³€ìˆ˜ë¥¼ num ë³€ìˆ˜ì™€ ê°™ì´ ì¡°íšŒí•˜ëŠ” ë¬¸ì„ ì´ìš©í•´ ì†Œìˆ˜(ì•½ìˆ˜ëŠ” ë‚˜ì™€ ê·¸ ìˆ˜ ë°–ì— ì—†ëŠ” íŠ¹ì§• : floor(num / div) != num / div )ë¥¼ êµ¬í•œë‹¤. ì´ë•Œ, whereì ˆì— ì†í•´ì•¼ í•œë‹¤. 12345678910111213141516171819where num1 &lt;= 1000and not exists ( select * from ( select @num2 :=@num2 + 1 as num2 from information_schema.tables as t1, information_schema.tables as t2, (select @num2 := 1) tmp2 limit 1000 ) t2 where floor(num1 / num2) = (num1 / num2) and num2 * num2 &lt;= num1 and num2 &gt; 1) ì´ì œ ì ì ˆíˆ ë‘ sql ë¬¸ì„ í•©ì³ì£¼ë©´ ëœë‹¤. í…Œì´ë¸”ëª…ì´ ì¤‘ë³µë˜ì§€ ì•Šê²Œ, ì´ë¯¸ ì‚¬ìš©í•œ ì‚¬ìš©ì ë³€ìˆ˜ ë˜í•œ ì¤‘ë³µë˜ì§€ ì•Šê²Œ ë‘ queryë¥¼ ì„ì–´ì£¼ë©´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ, ì‚¬ìš©ì ë³€ìˆ˜ num1, num2 ë¥¼ ê°™ì€ ê²ƒìœ¼ë¡œ ì‹¤í–‰í•˜ë‹ˆ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ë‹¤. ì•ìœ¼ë¡œ ì£¼ì˜í•  ê²ƒ! ì‚¬ìš©ì ë³€ìˆ˜ëŠ” ëª¨ë‘ ë‹¤ë¥´ê²Œ í•´ê²°123456789101112131415161718192021222324252627282930select group_concat(num1 separator '&amp;')from ( select @num1 :=@num1 + 1 as num1 from information_schema.tables as t1, information_schema.tables as t2, (select @num1 := 1) tmp1 ) t1where num1 &lt;= 1000and not exists ( select * from ( select @num2 :=@num2 + 1 as num2 from information_schema.tables as t1, information_schema.tables as t2, (select @num2 := 1) tmp2 limit 1000 ) t2 where floor(num1 / num2) = (num1 / num2) and num2 * num2 &lt;= num1 and num2 &gt; 1); 2019.10.15 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Symmetric Pairs & Draw The Triangle 1","slug":"hackerrank-symmetric_pairs_draw_triangle_1","date":"2019-10-13T15:00:00.000Z","updated":"2020-03-30T15:06:23.550Z","comments":true,"path":"hackerrank-symmetric_pairs_draw_triangle_1/","link":"","permalink":"https://jx2lee.github.io/hackerrank-symmetric_pairs_draw_triangle_1/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Symmetric Pairs &amp; Draw The Triangle 1 ë¬¸ì œë¥¼ ì •ë¦¬í•œë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Symmetric Pairs &amp; Draw The Triangle 1 ë¬¸ì œë¥¼ ì •ë¦¬í•œë‹¤. Symmetric Pairsë¬¸ì œYou are given a table, Functions, containing two columns: X and Y. Two pairs (X1, Y1) and (X2, Y2) are said to be symmetric pairs if X1 = Y2 and X2 = Y1. Write a query to output all such symmetric pairs in ascending order by the value of X. Sample Input Sample Output 12320 2020 2122 23 ì ‘ê·¼ë¬¸ì œëŠ” 1) x = yì¸ ì§ë“¤ê³¼ 2) x != y ì¸ ì§ë“¤ì˜ unionìœ¼ë¡œ ì ‘ê·¼í•˜ì˜€ë‹¤.ìš°ì„ , 1) x = yì¸ ê²½ìš°ëŠ” ì•„ë˜ ì¿¼ë¦¬ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. 12345678910select x, yfrom functions as f1where x = y and (select count(*) from functions where x = f1.x and y = f1.x) &gt; 1``` *count(*) &gt; 1*ì¸ ì´ìœ ëŠ” ë‚˜ì˜¨ ê°¯ìˆ˜ê°€ 2ê°œ ì´ìƒì¸ ì§ë“¤ë§Œ ë½‘ì•„ì¤˜ì•¼ í•˜ë¯€ë¡œ `where`ì ˆì— ì¡°ê±´ì„ ì¶”ê°€í•œ ê²ƒì´ë‹¤. ì´í›„ `2) x != y` ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.```sqlselect f1.x, f1.yfrom functions as f1, functions as f2where f1.x = f2.y and f1.y = f2.x and f1.x &lt; f1.y ì£¼ëª©í•´ì•¼í•˜ëŠ” ë¶€ë¶„ì€ f1.x &lt; f1.yì¸ ë¶€ë¶„ìœ¼ë¡œ, ë½‘ì•„ë‚´ëŠ” ì§ë“¤ì˜ xê°’ì´ yë³´ë‹¤ ì‘ì€ ì§ë“¤ë§Œ ì°¾ì•„ì£¼ê²Œ ë˜ë©´ 1) x = yì¸ ë¶€ë¶„ì€ ì œì™¸í•  ìˆ˜ ìˆë‹¤. ì´ì™€ ê°™ì€ ë‘ ì¿¼ë¦¬ë¥¼ unionìœ¼ë¡œ ë¬¶ì–´ì£¼ê³  ë§ˆì§€ë§‰ order byë¥¼ í†µí•´ ì •ë ¬ë§Œ í•˜ë©´ ë¬¸ì œê°€ í•´ê²°ëœë‹¤. í•´ê²°123456789select x, yfrom functions as f1where x = y and (select count(*) from functions where x = f1.x and y = f1.x) &gt; 1unionselect f1.x, f1.yfrom functions as f1, functions as f2where f1.x = f2.y and f1.y = f2.x and f1.x &lt; f1.yorder by x; Draw The Triangle 1ë¬¸ì œP(R) represents a pattern drawn by Julia in R rows. The following pattern represents P(5): 12345* * * * * * * * * * * * * * * Write a query to print the pattern P(20). ì ‘ê·¼ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ë¥¼ ì´ìš©í•´ ì ‘ê·¼í•˜ì˜€ë‹¤.ië¼ëŠ” ë³€ìˆ˜ë¥¼ 21ë¡œ ì„ ì–¸í•˜ê³ , repeatí•¨ìˆ˜ë¥¼ ì´ìš©í•´ i &gt; 0ì¼ ë•Œê¹Œì§€ ë°˜ë³µí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. 4ë¬¸ì¥ìœ¼ë¡œ ì‰½ê²Œ í’€ë¦¬ëŠ” ë¬¸ì œì¸ë°, ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ì— ëŒ€í•´ ë‹¤ì‹œ í•œ ë²ˆ ìƒê°í•´ë³´ìëŠ” ì˜ë¯¸ë¡œ ì •ë¦¬í•˜ì˜€ê³  ë‹¤ìŒì—ëŠ” ê¼­ í‹€ë¦¬ì§€ ë§ì. í•´ê²°1234set @i = 21;select repeat('* ', @i := @i - 1)from information_schema.tableswhere @i &gt; 0; 2019.10.14 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Contest Leaderboard","slug":"hackerrank-contest_leaderboard","date":"2019-10-09T15:00:00.000Z","updated":"2020-03-30T15:06:23.583Z","comments":true,"path":"hackerrank-contest_leaderboard/","link":"","permalink":"https://jx2lee.github.io/hackerrank-contest_leaderboard/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Contest Leaderboard ë¬¸ì œë¥¼ Group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Contest Leaderboard ë¬¸ì œë¥¼ Group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œYou did such a great job helping Julia with her last coding contest challenge that she wants you to work on this one, too! The total score of a hacker is the sum of their maximum scores for all of the challenges. Write a query to print the hacker_id, name, and total score of the hackers ordered by the descending score. If more than one hacker achieved the same total score, then sort the result by ascending hacker_id. Exclude all hackers with a total score of from your result. Input Format The following tables contain contest data: Hackers: The hacker_id is the id of the hacker, and name is the name of the hacker. Submissions: The submission_id is the id of the submission, hacker_id is the id of the hacker who made the submission, challenge_id is the id of the challenge for which the submission belongs to, and score is the score of the submission. Sample Input Hackers Table: Submissions Table: Sample Output 12345674071 Rose 19174842 Lisa 17484072 Bonnie 1004806 Angela 8926071 Frank 8580305 Kimberly 6749438 Patrick 43 Explanation Hacker 4071 submitted solutions for challenges 19797 and 49593, so the total score . Hacker 74842 submitted solutions for challenges 19797 and 63132, so the total score Hacker 84072 submitted solutions for challenges 49593 and 63132, so the total score . The total scores for hackers 4806, 26071, 80305, and 49438 can be similarly calculated. ì ‘ê·¼ìš°ì„ ì€, challenge_id / hacker_id ë³„ scoreì˜ ìµœëŒ“ê°’ì„ êµ¬í•˜ê³  ì´ë¥¼ hackers í…Œì´ë¸”ê³¼ ì¡°ì¸í•œë‹¤. 123456select h.hacker_id, h.name, sum(m.score) as total_scorefrom (select hacker_id, challenge_id, max(score) as score from submissions group by challenge_id, hacker_id) as mjoin hackers as h on h.hacker_id = m.hacker_id ì´í›„ max scoreë“¤ì˜ total_scoreë¥¼ êµ¬í•˜ê¸° ìœ„í•´ hacker_id / name ì„ keyë¡œ í•˜ì—¬ group by í•œë‹¤. 1234567select h.hacker_id, h.name, sum(m.score) as total_scorefrom (select hacker_id, challenge_id, max(score) as score from submissions group by challenge_id, hacker_id) as mjoin hackers as h on h.hacker_id = m.hacker_idgroup by h.hacker_id, h.name ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¸ì œì— ë”°ë¼ ì •ë ¬ë§Œ í•˜ë©´ ëœë‹¤. (total_score &gt; 0ì¸ ì¡°ê±´ë„ ì¶”ê°€) í•´ê²°123456789select h.hacker_id, h.name, sum(m.score) as total_scorefrom (select hacker_id, challenge_id, max(score) as score from submissions group by challenge_id, hacker_id) as mjoin hackers as h on h.hacker_id = m.hacker_idgroup by h.hacker_id, h.namehaving total_score &gt; 0order by total_score desc, h.hacker_id; 2019.10.10 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] SQL Project Planning","slug":"hackerrank-project_planning","date":"2019-10-09T15:00:00.000Z","updated":"2020-03-30T15:06:23.581Z","comments":true,"path":"hackerrank-project_planning/","link":"","permalink":"https://jx2lee.github.io/hackerrank-project_planning/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” SQL Project Planning ë¬¸ì œë¥¼ ì •ë¦¬í•œë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” SQL Project Planning ë¬¸ì œë¥¼ ì •ë¦¬í•œë‹¤. ë¬¸ì œYou are given a table, Projects, containing three columns: Task_ID, Start_Date and End_Date. It is guaranteed that the difference between the End_Date and the Start_Date is equal to 1 day for each row in the table. If the End_Date of the tasks are consecutive, then they are part of the same project. Samantha is interested in finding the total number of different projects completed. Write a query to output the start and end dates of projects listed by the number of days it took to complete the project in ascending order. If there is more than one project that have the same number of completion days, then order by the start date of the project. Sample Input Sample Output 12342015-10-28 2015-10-292015-10-30 2015-10-312015-10-13 2015-10-152015-10-01 2015-10-04 Explanation The example describes following four projects: Project 1: Tasks 1, 2 and 3 are completed on consecutive days, so these are part of the project. Thus start date of project is 2015-10-01 and end date is 2015-10-04, so it took 3 days to complete the project. Project 2: Tasks 4 and 5 are completed on consecutive days, so these are part of the project. Thus, the start date of project is 2015-10-13 and end date is 2015-10-15, so it took 2 days to complete the project. Project 3: Only task 6 is part of the project. Thus, the start date of project is 2015-10-28 and end date is 2015-10-29, so it took 1 day to complete the project. Project 4: Only task 7 is part of the project. Thus, the start date of project is 2015-10-30 and end date is 2015-10-31, so it took 1 day to complete the project. ì ‘ê·¼í”„ë¡œì íŠ¸ì˜ ì‹œì‘ê³¼ ë ë‚ ì§œë¥¼ ì¶œë ¥í•˜ëŠ” ë¬¸ì œ. í…Œì´ë¸”ì—ëŠ” ê°ê°ì˜ taskë“¤ì´ start_date, end_dateë¡œ êµ¬ì„±ë˜ì—ˆê³  ê°™ì€ í”„ë¡œì íŠ¸ëŠ” ê° taskê°€ ì´ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ì²˜ìŒ ì ‘ê·¼í–ˆì„ ë•Œ joinì„ ì´ìš©í•´ p1, p2 í…Œì´ë¸”ë¡œë¶€í„° p1.end_date=p2.start_dateë¥¼ ì´ìš©í•˜ì˜€ì§€ë§Œ ì‹¤íŒ¨í•˜ì—¬ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤. ìš°ì„  start_dateê°€ end_dateì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ë‚ ì§œë¥¼ í™•ì¸í•œë‹¤. ì´ëŠ” í”„ë¡œì íŠ¸ì˜ ì‹œì‘ì¼ ê²ƒì´ë‹¤ 1234select start_datefrom projectswhere start_date not in(select end_date from projects); ë§ˆì°¬ê°€ì§€ë¡œ end_dateê°€ start_dateì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ë‚ ì§œë¥¼ í™•ì¸í•œë‹¤. ì´ëŠ” í”„ë¡œì íŠ¸ì´ ëì¼ ê²ƒì´ë‹¤. 1234select end_datefrom projectswhere end_date not in(select start_date from projects); ê·¸ëŸ° ë‹¤ìŒ ê° í”„ë¡œì íŠ¸ì— ëŒ€í•´ (ì‹œì‘ ë‚ ì§œ, ì¢…ë£Œ ë‚ ì§œ) ìŒì„ ì°¾ì•„ì•¼í•œë‹¤. ê·¸ ì „ì— í”„ë¡œì íŠ¸ì˜ ì‹œì‘ ë‚ ì§œì™€ ì¢…ë£Œ ë‚ ì§œë¥¼ êµì°¨ì‹œì¼œ ëª¨ë“  ì ì¬ì  ìŒì„ ìƒì„±í•œë‹¤. ë˜í•œ, ë™ì¼í•œ í”„ë¡œì íŠ¸ì˜ ê²½ìš° ì¢…ë£Œ ë‚ ì§œëŠ” í”„ë¡œì íŠ¸ ì‹œì‘ ë‚ ì§œë³´ë‹¤ í° í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì¢…ë£Œ ë‚ ì§œ ì¤‘ ê°€ì¥ ì‘ì•„ì•¼í•œë‹¤. 123456select start_date, min(end_date)from (select start_date from projects where start_date not in (select end_date from projects)) as t1, (select end_date from projects where end_date not in (select start_date from projects)) as t2where start_date &lt; end_dategroup by start_date ë§ˆì§€ë§‰ ë¬¸ì œ ì¡°ê±´ ì¤‘ í”„ë¡œì íŠ¸ ìˆ˜í–‰ ê¸°ê°„ì´ ì§§ì€ ìˆœì„œë¡œ, ìˆ˜í–‰ ê¸°ê°„ì´ ê°™ë‹¤ë©´ ì‹œì‘ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ë©´ í•´ê²°í•  ìˆ˜ ìˆë‹¤. (datediff í•¨ìˆ˜ ì´ìš© - ë‘ ë‚ ì§œ ë°ì´í„° ì°¨ì´ê°’ ìƒì„±) ADD order by datediff(min(end_date), start_date), start_date í•´ê²°1234567select start_date, min(end_date)from (select start_date from projects where start_date not in (select end_date from projects)) as t1, (select end_date from projects where end_date not in (select start_date from projects)) as t2where start_date &lt; end_dategroup by start_dateorder by datediff(min(end_date), start_date), start_date; 2019.10.10 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Challenges","slug":"hackerrank-challenges","date":"2019-10-06T15:00:00.000Z","updated":"2020-03-30T15:06:23.549Z","comments":true,"path":"hackerrank-challenges/","link":"","permalink":"https://jx2lee.github.io/hackerrank-challenges/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Challenges ë¬¸ì œë¥¼ Joinì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Challenges ë¬¸ì œë¥¼ Joinì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œJulia asked her students to create some coding challenges. Write a query to print the hacker_id, name, and the total number of challenges created by each student. Sort your results by the total number of challenges in descending order. If more than one student created the same number of challenges, then sort the result by hacker_id. If more than one student created the same number of challenges and the count is less than the maximum number of challenges created, then exclude those students from the result. Input Format The following tables contain challenge data: Hackers: The hacker_id is the id of the hacker, and name is the name of the hacker. Challenges: The challenge_id is the id of the challenge, and hacker_id is the id of the student who created the challenge. Sample Input 0 Hackers Table: Challenges Table: Sample Output 0 12321283 Angela 688255 Patrick 596196 Lisa 1 Sample Input 1 Hackers Table: Challenges Table: Sample Output 1 1234512299 Rose 634856 Angela 679345 Frank 480491 Patrick 381041 Lisa 1 Explanation For Sample Case 0, we can get the following details:Students and both created challenges, but the maximum number of challenges created is so these students are excluded from the result. For Sample Case 1, we can get the following details:Students and both created challenges. Because is the maximum number of challenges created, these students are included in the result. ì ‘ê·¼group by ì¡°ê±´ ì¤‘ 1) ìµœëŒ“ê°’ì´ í•˜ë‚˜ì—¬ì•¼í•˜ê³ , 2) ìµœëŒ“ê°’ ì•„ë˜ë¡œ ì¤‘ë³µë˜ëŠ” íšŸìˆ˜ë¥¼ ê°€ì§€ë©´ ì•ˆëœë‹¤ ë¥¼ ë§Œì¡±í•˜ëŠ” ê²ƒì´ ì–´ë ¤ì› ë‹¤. count ê°’ì„ ORì„ ì´ìš©í•´ ë§Œì¡±í•˜ëŠ” ë²”ìœ„ë¡œ havingì ˆì„ ì‘ì„±í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆì—ˆë‹¤. ìˆœì„œëŠ” ì•„ë˜ì™€ ê°™ì´ í’€ì—ˆë‹¤. hackers í…Œì´ë¸”ê³¼ challenges í…Œì´ë¸”ì„ join ë° group by (group by keyëŠ” id / name) having ì ˆ cnt ì¡°ê±´ì„ ORë¡œ ì‘ì„± (1. max value, 2. not duplicated) ë¬¸ì œ ì¡°ê±´ì— ë§ëŠ” order by ì¶”ê°€ í•´ê²°1234567891011121314151617181920212223242526select c.hacker_id, h.name, count(c.challenge_id) as cntfrom challenges as cjoin hackers as h on c.hacker_id = h.hacker_idgroup by c.hacker_id, h.namehaving cnt = (select count(c1.challenge_id) from challenges as c1 group by c1.hacker_id order by count(c1.challenge_id) desc limit 1) or cnt not in (select count(c2.challenge_id) from challenges as c2 group by c2.hacker_id having c2.hacker_id &lt;&gt; c.hacker_id)order by cnt desc, c.hacker_id; 2019.10.07 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Ollivander's Inventory","slug":"hackerrank-ollivanders_inventory","date":"2019-10-06T15:00:00.000Z","updated":"2020-03-30T15:06:23.576Z","comments":true,"path":"hackerrank-ollivanders_inventory/","link":"","permalink":"https://jx2lee.github.io/hackerrank-ollivanders_inventory/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Ollivander&#39;s Inventory ë¬¸ì œë¥¼ Group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Ollivander&#39;s Inventory ë¬¸ì œë¥¼ Group byë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œHarry Potter and his friends are at Ollivanderâ€™s with Ron, finally replacing Charlieâ€™s old broken wand. Hermione decides the best way to choose is by determining the minimum number of gold galleons needed to buy each non-evil wand of high power and age. Write a query to print the id, age, coins_needed, and power of the wands that Ronâ€™s interested in, sorted in order of descending power. If more than one wand has same power, sort the result in order of descending age. Input Format The following tables contain data on the wands in Ollivanderâ€™s inventory: Wands: The id is the id of the wand, code is the code of the wand, coins_needed is the total number of gold galleons needed to buy the wand, and power denotes the quality of the wand (the higher the power, the better the wand is). Wands_Property: The code is the code of the wand, age is the age of the wand, and is_evil denotes whether the wand is good for the dark arts. If the value of is_evil is 0, it means that the wand is not evil. The mapping between code and age is one-one, meaning that if there are two pairs, and , then and . Sample Input Wands Table: Wands_Property Table: Sample Output 12345678910119 45 1647 1012 17 9897 101 20 3688 815 40 6018 719 20 7651 611 40 7587 510 20 504 518 40 3312 320 17 5689 35 45 6020 214 40 5408 1 Explanation The data for wands of age 45 (code 1): The minimum number of galleons needed for The minimum number of galleons needed for The data for wands of age 40 (code 2): The minimum number of galleons needed for The minimum number of galleons needed for The minimum number of galleons needed for The minimum number of galleons needed for The data for wands of age 20 (code 4): The minimum number of galleons needed for The minimum number of galleons needed for The minimum number of galleons needed for The data for wands of age 17 (code 5): The minimum number of galleons needed for The minimum number of galleons needed for ì ‘ê·¼determining the minimum number of gold galleons needed ë¶€ë¶„ì„ ë†“ì³¤ë‹¤. Wands í…Œì´ë¸”ì—ì„œ code/power ë³„ coins_neededì˜ ìµœì†Ÿê°’ì„ ì°¾ì€ í…Œì´ë¸”ê³¼ Wands / Wands_property í…Œì´ë¸”ì„ ì¡°ì¸í•˜ì—¬ order byë§Œ ì¶”ê°€í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì™„ì„±í•˜ë©´ ëœë‹¤. code, power, min(coins_needed) ë¥¼ code/power ë³„ group by wands/wands_property í…Œì´ë¸”ê³¼ join (wands í…Œì´ë¸” ì¡°ì¸ ì‹œ code/coins_needed ì¼ì¹˜) order by ë¡œ power/age descending í•´ê²°123456789select w.id, p.age, w.coins_needed, w.powerfrom (select code, power, min(coins_needed) as coins_needed from wands group by code, power) as mjoin wands as w on w.code = m.code and w.coins_needed = m.coins_neededjoin wands_property as p on p.code = m.codewhere p.is_evil = 0order by m.power desc, p.age desc; 2019.10.07 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Python] ë‹¨ì–´ ë³€í™˜","slug":"programmers-disk_controller","date":"2019-10-06T15:00:00.000Z","updated":"2020-03-30T15:06:23.545Z","comments":true,"path":"programmers-disk_controller/","link":"","permalink":"https://jx2lee.github.io/programmers-disk_controller/","excerpt":"íŠ¹ì • ê¸°ì¤€ì„ ê°€ì§€ê³  ë‹¨ì–´ë¥¼ ë³€í™˜í•  ë•Œ ìµœì†Œ íšŸìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.","text":"íŠ¹ì • ê¸°ì¤€ì„ ê°€ì§€ê³  ë‹¨ì–´ë¥¼ ë³€í™˜í•  ë•Œ ìµœì†Œ íšŸìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë¬¸ì œ ì„¤ëª…í•˜ë“œë””ìŠ¤í¬ëŠ” í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…ë§Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë””ìŠ¤í¬ ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ ìš”ì²­ì´ ë“¤ì–´ì˜¨ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.ì˜ˆë¥¼ë“¤ì–´ 123- 0ms ì‹œì ì— 3msê°€ ì†Œìš”ë˜ëŠ” Aì‘ì—… ìš”ì²­- 1ms ì‹œì ì— 9msê°€ ì†Œìš”ë˜ëŠ” Bì‘ì—… ìš”ì²­- 2ms ì‹œì ì— 6msê°€ ì†Œìš”ë˜ëŠ” Cì‘ì—… ìš”ì²­ ì™€ ê°™ì€ ìš”ì²­ì´ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤. ì´ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. í•œ ë²ˆì— í•˜ë‚˜ì˜ ìš”ì²­ë§Œì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê°ê°ì˜ ì‘ì—…ì„ ìš”ì²­ë°›ì€ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬ ë©ë‹ˆë‹¤. 123- A: 3ms ì‹œì ì— ì‘ì—… ì™„ë£Œ (ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 3ms)- B: 1msë¶€í„° ëŒ€ê¸°í•˜ë‹¤ê°€, 3ms ì‹œì ì— ì‘ì—…ì„ ì‹œì‘í•´ì„œ 12ms ì‹œì ì— ì‘ì—… ì™„ë£Œ(ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 11ms)- C: 2msë¶€í„° ëŒ€ê¸°í•˜ë‹¤ê°€, 12ms ì‹œì ì— ì‘ì—…ì„ ì‹œì‘í•´ì„œ 18ms ì‹œì ì— ì‘ì—… ì™„ë£Œ(ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 16ms) ì´ ë•Œ ê° ì‘ì—…ì˜ ìš”ì²­ë¶€í„° ì¢…ë£Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì˜ í‰ê· ì€ 10ms(= (3 + 11 + 16) / 3)ê°€ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ A â†’ C â†’ B ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•˜ë©´ 123- A: 3ms ì‹œì ì— ì‘ì—… ì™„ë£Œ(ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 3ms)- C: 2msë¶€í„° ëŒ€ê¸°í•˜ë‹¤ê°€, 3ms ì‹œì ì— ì‘ì—…ì„ ì‹œì‘í•´ì„œ 9ms ì‹œì ì— ì‘ì—… ì™„ë£Œ(ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 7ms)- B: 1msë¶€í„° ëŒ€ê¸°í•˜ë‹¤ê°€, 9ms ì‹œì ì— ì‘ì—…ì„ ì‹œì‘í•´ì„œ 18ms ì‹œì ì— ì‘ì—… ì™„ë£Œ(ìš”ì²­ì—ì„œ ì¢…ë£Œê¹Œì§€ : 17ms) ì´ë ‡ê²Œ A â†’ C â†’ Bì˜ ìˆœì„œë¡œ ì²˜ë¦¬í•˜ë©´ ê° ì‘ì—…ì˜ ìš”ì²­ë¶€í„° ì¢…ë£Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì˜ í‰ê· ì€ 9ms(= (3 + 7 + 17) / 3)ê°€ ë©ë‹ˆë‹¤. ê° ì‘ì—…ì— ëŒ€í•´ [ì‘ì—…ì´ ìš”ì²­ë˜ëŠ” ì‹œì , ì‘ì—…ì˜ ì†Œìš”ì‹œê°„]ì„ ë‹´ì€ 2ì°¨ì› ë°°ì—´ jobsê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ì‘ì—…ì˜ ìš”ì²­ë¶€í„° ì¢…ë£Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì˜ í‰ê· ì„ ê°€ì¥ ì¤„ì´ëŠ” ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ í‰ê· ì´ ì–¼ë§ˆê°€ ë˜ëŠ”ì§€ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ì˜ ìˆ˜ëŠ” ë²„ë¦½ë‹ˆë‹¤) ì œí•œ ì‚¬í•­ jobsì˜ ê¸¸ì´ëŠ” 1 ì´ìƒ 500 ì´í•˜ì…ë‹ˆë‹¤. jobsì˜ ê° í–‰ì€ í•˜ë‚˜ì˜ ì‘ì—…ì— ëŒ€í•œ [ì‘ì—…ì´ ìš”ì²­ë˜ëŠ” ì‹œì , ì‘ì—…ì˜ ì†Œìš”ì‹œê°„] ì…ë‹ˆë‹¤. ê° ì‘ì—…ì— ëŒ€í•´ ì‘ì—…ì´ ìš”ì²­ë˜ëŠ” ì‹œê°„ì€ 0 ì´ìƒ 1,000 ì´í•˜ì…ë‹ˆë‹¤. ê° ì‘ì—…ì— ëŒ€í•´ ì‘ì—…ì˜ ì†Œìš”ì‹œê°„ì€ 1 ì´ìƒ 1,000 ì´í•˜ì…ë‹ˆë‹¤. í•˜ë“œë””ìŠ¤í¬ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ìˆì§€ ì•Šì„ ë•Œì—ëŠ” ë¨¼ì € ìš”ì²­ì´ ë“¤ì–´ì˜¨ ì‘ì—…ë¶€í„° ì²˜ë¦¬í•©ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆjobs return [[0, 3], [1, 9], [2, 6]] 9 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª…ë¬¸ì œì— ì£¼ì–´ì§„ ì˜ˆì™€ ê°™ìŠµë‹ˆë‹¤. 0ms ì‹œì ì— 3ms ê±¸ë¦¬ëŠ” ì‘ì—… ìš”ì²­ì´ ë“¤ì–´ì˜µë‹ˆë‹¤. 1ms ì‹œì ì— 9ms ê±¸ë¦¬ëŠ” ì‘ì—… ìš”ì²­ì´ ë“¤ì–´ì˜µë‹ˆë‹¤. 2ms ì‹œì ì— 6ms ê±¸ë¦¬ëŠ” ì‘ì—… ìš”ì²­ì´ ë“¤ì–´ì˜µë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼heap ì„ ì´ìš©í•´ì•¼ í•˜ëŠ” ë¬¸ì œ. ì‚¬ì‹¤ ì´ì— ëŒ€í•œ ê°œë…ì´ ë¶€ì¡±í•˜ì—¬ ê³µë¶€í•˜ë ¤ í–ˆì§€ë§Œ ë°©ëŒ€í•˜ê¸¸ë˜ ìš°ì„  íŒ¨ì“°í•˜ê³  ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤. ì‹œê°„ì´ ëœë‹¤ë©´ heap ì— ëŒ€í•´ ê¸€ì„ ì •ë¦¬í•˜ê³  ìš°ì„  ì•„ë˜ì™€ ê°™ì€ ë³€ìˆ˜ë¥¼ í†µí•´ í•´ê²°í•˜ì˜€ë‹¤. ë³€ìˆ˜ in_, out_ : ì‘ì—…ì„ ì‹œì‘/ì¢…ë£Œí•œ ì‹œê°„ ans&#39; : ì´ ì‘ì—… ì‹œê°„ n : ì´ ì‘ì—…ì˜ ê°¯ìˆ˜ cnt : heap êµ¬ì¡°ì—ì„œ ìë£Œê°€ ë¹ ì ¸ë‚˜ê°„ íšŸìˆ˜ë¡œ whileë¬¸ì— ì‚¬ìš© wt : heapêµ¬ì¡°ë¡œ ì‘ì—…ì˜ ì¢…ë£Œ ì‹œê°„ì„ ë‹´ëŠ”ë‹¤. ë¬¸ì œ í•´ê²°ì°¸ê³  ë¸”ë¡œê·¸ 123456789101112131415161718192021import heapqdef solution(jobs): in_, out_, ans, cnt = -1, 0, 0, 0 wt = [] n = len(jobs) while cnt &lt; n: for job in jobs: if in_ &lt; job[0] &lt;= out_ : ans += (out_ - job[0]) heapq.heappush(wt, job[1]) if len(wt) &gt; 0: ans += len(wt) * wt[0] #len(wt)ë¥¼ ê³±í•˜ëŠ” ì´ìœ ëŠ” ëŒ€ê¸°ì—´ì— ë“¤ì–´ê°„ ì‘ì—…ë„ ì‘ì—… ì¤‘ì¸ ì‹œê°„ì„ ë”í•´ì•¼í•˜ë¯€ë¡œ wt ê¸¸ì´ë¥¼ ê³±í•´ì¤€ë‹¤. in_ = out_ out_ += heapq.heappop(wt) cnt += 1 else: out_ += 1 return ans // n 2019.10.07 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[SQL] The Report","slug":"hackerrank-the_report","date":"2019-10-03T15:00:00.000Z","updated":"2020-03-30T15:06:23.547Z","comments":true,"path":"hackerrank-the_report/","link":"","permalink":"https://jx2lee.github.io/hackerrank-the_report/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” The Report ë¬¸ì œë¥¼ Joinì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” The Report ë¬¸ì œë¥¼ Joinì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œYou are given two tables: Students and Grades. Students contains three columns ID, Name and Marks. Grades contains the following data: Ketty gives Eve a task to generate a report containing three columns: Name, Grade and Mark. Ketty doesnâ€™t want the NAMES of those students who received a grade lower than 8. The report must be in descending order by grade â€“ i.e. higher grades are entered first. If there is more than one student with the same grade (8-10) assigned to them, order those particular students by their name alphabetically. Finally, if the grade is lower than 8, use â€œNULLâ€ as their name and list them by their grades in descending order. If there is more than one student with the same grade (1-7) assigned to them, order those particular students by their marks in ascending order. Write a query to help Eve. Sample Input Sample Output 123456Maria 10 99Jane 9 81Julia 9 88 Scarlet 8 78NULL 7 63NULL 7 68 Note Print â€œNULLâ€ as the name if the grade is less than 8. Explanation Consider the following table with the grades assigned to the students: So, the following students got 8, 9 or 10 grades: Maria (grade 10) Jane (grade 9) Julia (grade 9) Scarlet (grade 8) ì ‘ê·¼order by ì— nameì´ NULLì¸ í•™ìƒë“¤ ì¤‘ ê°™ì€ Gradeì´ë©´ ì ìˆ˜ë¥¼ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•  ë•Œ í—·ê°ˆë ¸ë‹¤. name ì •ë ¬ í›„ marksë¡œ ì •ë ¬í•˜ë©´ ëë‚˜ëŠ” ë¬¸ì œ. ê·¸ë¦¬ê³  ì²˜ìŒì—” Unionìœ¼ë¡œ ë¬¸ì œë¥¼ ì ‘ê·¼í–ˆëŠ”ë° caseë¬¸ìœ¼ë¡œ ì‰½ê²Œ í’€ ìˆ˜ ìˆì—ˆë‹¤. í•´ê²°12345678910select case when g.grade &lt; 8 then null else s.name end, g.grade, s.marksfrom students as sjoin grades as g on s.marks between g.min_mark and g.max_markorder by g.grade desc, s.name, s.marks; 2019.10.04 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Weather Observation Station 20","slug":"hackerrank-weather_observation_station_20","date":"2019-10-01T15:00:00.000Z","updated":"2020-03-30T15:06:23.589Z","comments":true,"path":"hackerrank-weather_observation_station_20/","link":"","permalink":"https://jx2lee.github.io/hackerrank-weather_observation_station_20/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Weather Observation Station 20 ë¬¸ì œë¥¼ ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Weather Observation Station 20 ë¬¸ì œë¥¼ ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œA median is defined as a number separating the higher half of a data set from the lower half. Query the median of the Northern Latitudes (LAT_N) from STATION and round your answer to decimal places. Input Format The STATION table is described as follows: where LAT_N is the northern latitude and LONG_W is the western longitude. ì ‘ê·¼ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ë¥¼ ì´ìš©í•´ medianì„ êµ¬í•˜ëŠ” ë¬¸ì œì´ë‹¤. row indexê°€ 1ë¶€í„° ì‹œì‘í•˜ë©° LAT_Nì„ ê¸°ì¤€ìœ¼ë¡œ sortingëœ í…Œì´ë¸”ì—ì„œ, indexê°€ @ct/2.0, @ct/2.0+1 ë²”ìœ„ì¼ ê²½ìš° ì¡°íšŒí•˜ëŠ” queryë¥¼ ì‘ì„±í•˜ì˜€ë‹¤. ì—¬ê¸°ì„  @ctëŠ” median ê³„ì‚°ì„ ìœ„í•´ í…Œì´ë¸” ì „ì²´ í–‰ì„ ëœ»í•œë‹¤. í•´ê²°123456789set @row_id = 0;set @ct = (select count(*) from station);select round(avg(LAT_N), 4)from (select * from station order by LAT_N) as samplewhere (select @row_id := @row_id + 1) between @ct/2.0 and @ct/2.0 + 1; 2019.10.02 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Python] ì˜ˆì‚°","slug":"programmers-budgets","date":"2019-09-30T15:00:00.000Z","updated":"2020-03-30T15:06:23.530Z","comments":true,"path":"programmers-budgets/","link":"","permalink":"https://jx2lee.github.io/programmers-budgets/","excerpt":"ì •í•´ì§„ ì´ì•¡ ì´í•˜ì—ì„œ ê°€ëŠ¥í•œ í•œ ìµœëŒ€ ì˜ˆì‚°ì„ ë°°ì •í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.","text":"ì •í•´ì§„ ì´ì•¡ ì´í•˜ì—ì„œ ê°€ëŠ¥í•œ í•œ ìµœëŒ€ ì˜ˆì‚°ì„ ë°°ì •í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë¬¸ì œ ì„¤ëª…ë¬¸ì œ ì„¤ëª…êµ­ê°€ì˜ ì—­í•  ì¤‘ í•˜ë‚˜ëŠ” ì—¬ëŸ¬ ì§€ë°©ì˜ ì˜ˆì‚°ìš”ì²­ì„ ì‹¬ì‚¬í•˜ì—¬ êµ­ê°€ì˜ ì˜ˆì‚°ì„ ë¶„ë°°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. êµ­ê°€ì˜ˆì‚°ì˜ ì´ì•¡ì€ ë¯¸ë¦¬ ì •í•´ì ¸ ìˆì–´ì„œ ëª¨ë“  ì˜ˆì‚°ìš”ì²­ì„ ë°°ì •í•´ ì£¼ê¸°ëŠ” ì–´ë ¤ìš¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì •í•´ì§„ ì´ì•¡ ì´í•˜ì—ì„œ ê°€ëŠ¥í•œ í•œ ìµœëŒ€ì˜ ì´ ì˜ˆì‚°ì„ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë°°ì •í•©ë‹ˆë‹¤. 1231. ëª¨ë“  ìš”ì²­ì´ ë°°ì •ë  ìˆ˜ ìˆëŠ” ê²½ìš°ì—ëŠ” ìš”ì²­í•œ ê¸ˆì•¡ì„ ê·¸ëŒ€ë¡œ ë°°ì •í•©ë‹ˆë‹¤.2. ëª¨ë“  ìš”ì²­ì´ ë°°ì •ë  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” íŠ¹ì •í•œ ì •ìˆ˜ ìƒí•œì•¡ì„ ê³„ì‚°í•˜ì—¬ ê·¸ ì´ìƒì¸ ì˜ˆì‚°ìš”ì²­ì—ëŠ” ëª¨ë‘ ìƒí•œì•¡ì„ ë°°ì •í•©ë‹ˆë‹¤. ìƒí•œì•¡ ì´í•˜ì˜ ì˜ˆì‚°ìš”ì²­ì— ëŒ€í•´ì„œëŠ” ìš”ì²­í•œ ê¸ˆì•¡ì„ ê·¸ëŒ€ë¡œ ë°°ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì „ì²´ êµ­ê°€ì˜ˆì‚°ì´ 485ì´ê³  4ê°œ ì§€ë°©ì˜ ì˜ˆì‚°ìš”ì²­ì´ ê°ê° 120, 110, 140, 150ì¼ ë•Œ, ìƒí•œì•¡ì„ 127ë¡œ ì¡ìœ¼ë©´ ìœ„ì˜ ìš”ì²­ë“¤ì— ëŒ€í•´ì„œ ê°ê° 120, 110, 127, 127ì„ ë°°ì •í•˜ê³  ê·¸ í•©ì´ 484ë¡œ ê°€ëŠ¥í•œ ìµœëŒ€ê°€ ë©ë‹ˆë‹¤.ê° ì§€ë°©ì—ì„œ ìš”ì²­í•˜ëŠ” ì˜ˆì‚°ì´ ë‹´ê¸´ ë°°ì—´ budgetsê³¼ ì´ ì˜ˆì‚° Mì´ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ìœ„ì˜ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ìƒí•œì•¡ì„ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì œí•œ ì‚¬í•­ ì§€ë°©ì˜ ìˆ˜ëŠ” 3 ì´ìƒ 100,000 ì´í•˜ì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. ê° ì§€ë°©ì—ì„œ ìš”ì²­í•˜ëŠ” ì˜ˆì‚°ì€ 1 ì´ìƒ 100,000 ì´í•˜ì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. ì´ ì˜ˆì‚°ì€ ì§€ë°©ì˜ ìˆ˜ ì´ìƒ 1,000,000,000 ì´í•˜ì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ budgets M return [120, 110, 140, 150] 485 127 ì¶œì²˜ â€» ê³µì§€ - 2019ë…„ 3ì›” 15ì¼, í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ê°•í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì—…ë°ì´íŠ¸ë¡œ ì¸í•´ ì§€ë°©ì˜ ìˆ˜ê°€ ìµœëŒ€ 10,000ê°œì—ì„œ 100,000ê°œë¡œ ëŠ˜ì–´ë‚¬ìœ¼ë©°, ì´ì— ë”°ë¼ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì´ì „ì— í†µê³¼í•˜ë˜ ì½”ë“œê°€ ë” ì´ìƒ í†µê³¼í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼ì´ë¶„ íƒìƒ‰ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.. leftì™€ rigthì˜ ì¤‘ê°„ê°’ midë¥¼ êµ¬í•´ ë§¤ ë²ˆ ì´ì•¡ Mì„ ìµœëŒ€í•œ ë§ì¶˜ë‹¤. ë§Œì•½ Më³´ë‹¤ ì‘ìœ¼ë©´ left +1, Më³´ë‹¤ í¬ë©´ right -1ë¡œ ì´ë¶„ íƒìƒ‰í•œë‹¤. ë³€ìˆ˜ ì„¤ëª… res : left mid rightì— ë”°ë¥¸ ì´ ì˜ˆì‚°ì•¡ left, mid, right : ìµœì†Œ, ìµœëŒ€ì— ë”°ë¥¸ ì¤‘ê°„ê°’(ì´ë¶„ íƒìƒ‰ì„ ìœ„í•´) ë¬¸ì œ í•´ê²°í‹€ë¦° ì½”ë“œ12345678910111213141516def solution(budgets, M): sorted_budgets = sorted(budgets) res = 0 while M &gt; 0: tmp = sorted_budgets[0] if tmp &lt; M // len(sorted_budgets): res = tmp M -= tmp sorted_budgets.pop(0) else: res = M // len(sorted_budgets) M -= res sorted_budgets.pop(0) if len(sorted_budgets) == 1: return res return 0 ë§ì€ ì½”ë“œì°¸ê³  blog 12345678910111213141516def solution(budgets, M): left, right, tmp = 0, max(budgets), 0 while right &gt;= left: mid = (left + right) // 2 res = 0 for budget in budgets: if mid &gt; budget: res += budget else: res += mid if res &gt; M: right = mid - 1 else: answer = mid left = mid + 1 return answer 2019.10.01 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Python] ë‹¨ì–´ ë³€í™˜","slug":"programmers-convert_word","date":"2019-09-30T15:00:00.000Z","updated":"2020-03-30T15:06:23.533Z","comments":true,"path":"programmers-convert_word/","link":"","permalink":"https://jx2lee.github.io/programmers-convert_word/","excerpt":"íŠ¹ì • ê¸°ì¤€ì„ ê°€ì§€ê³  ë‹¨ì–´ë¥¼ ë³€í™˜í•  ë•Œ ìµœì†Œ íšŸìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤.","text":"íŠ¹ì • ê¸°ì¤€ì„ ê°€ì§€ê³  ë‹¨ì–´ë¥¼ ë³€í™˜í•  ë•Œ ìµœì†Œ íšŸìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë¬¸ì œ ì„¤ëª…ë‘ ê°œì˜ ë‹¨ì–´ begin, targetê³¼ ë‹¨ì–´ì˜ ì§‘í•© wordsê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ ê·œì¹™ì„ ì´ìš©í•˜ì—¬ beginì—ì„œ targetìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°€ì¥ ì§§ì€ ë³€í™˜ ê³¼ì •ì„ ì°¾ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤. 121. í•œ ë²ˆì— í•œ ê°œì˜ ì•ŒíŒŒë²³ë§Œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.2. wordsì— ìˆëŠ” ë‹¨ì–´ë¡œë§Œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ beginì´ hit, targetê°€ cog, wordsê°€ [hot,dot,dog,lot,log,cog]ë¼ë©´ hit -&gt; hot -&gt; dot -&gt; dog -&gt; cogì™€ ê°™ì´ 4ë‹¨ê³„ë¥¼ ê±°ì³ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ê°œì˜ ë‹¨ì–´ begin, targetê³¼ ë‹¨ì–´ì˜ ì§‘í•© wordsê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ìµœì†Œ ëª‡ ë‹¨ê³„ì˜ ê³¼ì •ì„ ê±°ì³ beginì„ targetìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆëŠ”ì§€ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ ê° ë‹¨ì–´ëŠ” ì•ŒíŒŒë²³ ì†Œë¬¸ìë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ê° ë‹¨ì–´ì˜ ê¸¸ì´ëŠ” 3 ì´ìƒ 10 ì´í•˜ì´ë©° ëª¨ë“  ë‹¨ì–´ì˜ ê¸¸ì´ëŠ” ê°™ìŠµë‹ˆë‹¤. wordsì—ëŠ” 3ê°œ ì´ìƒ 50ê°œ ì´í•˜ì˜ ë‹¨ì–´ê°€ ìˆìœ¼ë©° ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ëŠ” ì—†ìŠµë‹ˆë‹¤. beginê³¼ targetì€ ê°™ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” 0ë¥¼ return í•©ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ begin target words return hit cog [hot, dot, dog, lot, log, cog] 4 hit cog [hot, dot, dog, lot, log] 0 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª…ì˜ˆì œ #1ë¬¸ì œì— ë‚˜ì˜¨ ì˜ˆì™€ ê°™ìŠµë‹ˆë‹¤. ì˜ˆì œ #2targetì¸ cogëŠ” words ì•ˆì— ì—†ê¸° ë•Œë¬¸ì— ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼DFS/BFS ë¬¸ì œë¡œ ì‹¤íŒ¨í•˜ì—¬ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤. wordsê°€ ë¹ˆ ë¦¬ìŠ¤íƒ€ê°€ ë  ë•Œê¹Œì§€ íƒìƒ‰ì„ í†µí•´ ë¬¸ì í•œ ê°œë§Œ ë³€í˜•ëœ ë‹¨ì–´ë¥¼ cntë³€ìˆ˜ë¥¼ ì´ìš©í•´ ì°¾ê³ , tmpë¥¼ ê³„ì†í•´ì„œ ì—…ë°ì´íŠ¸ í•´ë‚˜ê°„ë‹¤. ì´í›„ tmpì•ˆì— target wordê°€ í¬í•¨ë˜ë©´ while íšŸìˆ˜ë¥¼ returní•˜ê³ , ì•„ë‹ˆë©´ answer = tmpë¡œ ê³„ì†í•´ì„œ ì°¾ì•„ë‚˜ê°€ëŠ” ë°©ë²•ìœ¼ë¡œ í’€ ìˆ˜ ìˆë‹¤. ë³€ìˆ˜ answer : íƒìƒ‰ì„ ì‹œì‘í•˜ëŠ” ë‹¨ì–´ë¥¼ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ res : ë¬¸ì œì˜ ê²°ê´ê°’ tmp : ë³€í™˜ë  ë‹¨ì–´ë“¤ì˜ í›„ë³´ cnt : í•œ ë¬¸ìë§Œ ë‹¤ë¥¸ ë‹¨ì–´ë¥¼ ë½‘ê¸°ìœ„í•œ ë³€ìˆ˜ (cnt == 1) ë¬¸ì œ í•´ê²°12345678910111213141516171819202122232425def solution(begin, target, words): answer = [begin] res = 0 if not target in words: return 0 while words: for ans in answer: tmp = [] for word in words: cnt = 0 for i in range(len(ans)): if ans[i] != word[i]: cnt += 1 if cnt == 2: break if cnt == 1: tmp.append(word) words.remove(word) res += 1 if target in tmp: return res else: answer = tmp return 0 2019.10.01 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[SQL] Occupations","slug":"hackerrank-occupations","date":"2019-09-26T15:00:00.000Z","updated":"2020-03-30T15:06:23.563Z","comments":true,"path":"hackerrank-occupations/","link":"","permalink":"https://jx2lee.github.io/hackerrank-occupations/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Occupations ë¬¸ì œë¥¼ pivotì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Occupations ë¬¸ì œë¥¼ pivotì„ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œPivot the Occupation column in OCCUPATIONS so that each Name is sorted alphabetically and displayed underneath its corresponding Occupation. The output column headers should be Doctor, Professor, Singer, and Actor, respectively. Note: Print NULL when there are no more names corresponding to an occupation. Input Format The OCCUPATIONS table is described as follows: Occupation will only contain one of the following values: Doctor, Professor, Singer or Actor. Sample Input Sample Output 123Jenny Ashley Meera JaneSamantha Christeen Priya JuliaNULL Ketty NULL Maria Explanation The first column is an alphabetically ordered list of Doctor names.The second column is an alphabetically ordered list of Professor names.The third column is an alphabetically ordered list of Singer names.The fourth column is an alphabetically ordered list of Actor names.The empty cell data for columns with less than the maximum number of names per occupation (in this case, the Professor and Actor columns) are filled with NULL values. ì ‘ê·¼ ë³€ìˆ˜ ì„¤ì •ê³¼(set @~) caseë¬¸ì„ ì´ìš© set @[ë³€ìˆ˜ëª…] = [ê°’] case ì ˆì€ ìœ„ ë¬¸ì œ ì°¸ê³  from ì ˆì— minëŒ€ì‹  maxë¥¼ í•´ë„ ê²°ê³¼ëŠ” ë™ì¼ í•´ê²°123456789101112131415161718set @drow=0, @prow=0, @srow=0, @arow=0;select min(doctor), min(professor), min(singer), min(actor)from( select case occupation when 'Doctor' then @drow := @drow + 1 when 'Professor' then @prow := @prow + 1 when 'Singer' then @srow := @srow + 1 when 'Actor' then @arow := @arow + 1 end as row, if(occupation='Doctor', name, null) as doctor, if(occupation='Professor', name, null) as professor, if(occupation='Singer', name, null) as singer, if(occupation='Actor', name, null) as actor from occupations order by name) as agroup by row; 2019.09.27 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[SQL] Type of Triangle","slug":"hackerrank-type_of_triangle","date":"2019-09-26T15:00:00.000Z","updated":"2020-03-30T15:06:23.564Z","comments":true,"path":"hackerrank-type_of_triangle/","link":"","permalink":"https://jx2lee.github.io/hackerrank-type_of_triangle/","excerpt":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Type of Triangle ë¬¸ì œë¥¼ caseë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤.","text":"hackerrankì—ì„œ ì œê³µí•˜ëŠ” Type of Triangle ë¬¸ì œë¥¼ caseë¥¼ í™œìš©í•´ í•´ê²°í•˜ì˜€ë‹¤. ë¬¸ì œWrite a query identifying the type of each record in the TRIANGLES table using its three side lengths. Output one of the following statements for each record in the table: Equilateral: Itâ€™s a triangle with sides of equal length. Isosceles: Itâ€™s a triangle with sides of equal length. Scalene: Itâ€™s a triangle with sides of differing lengths. Not A Triangle: The given values of A, B, and C donâ€™t form a triangle. Input Format The TRIANGLES table is described as follows: Each row in the table denotes the lengths of each of a triangleâ€™s three sides. Sample Input Sample Output 1234IsoscelesEquilateralScaleneNot A Triangle Explanation Values in the tuple form an Isosceles triangle, because .Values in the tuple form an Equilateral triangle, because . Values in the tuple form a Scalene triangle, because .Values in the tuple cannot form a triangle because the combined value of sides and is not larger than that of side ì ‘ê·¼IFë¬¸ì„ ì‚¬ìš©í•˜ë ¤ë‹¤ selectì— case::when-thenì„ ì´ìš©í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  Not a triangle ì¡°ê±´ì„ ë¨¼ì € ì£¼ì§€ì•Šê³  ë‚˜ì¤‘ì— ì¤€ë‹¤ë©´(Isosceles ì´í›„ì— ì¡°ê±´ì„ ì‚½ì…) ê²°ê³¼ê°’ì´ ë‹¬ë¼ì§€ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. caseë¬¸ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤. 123456case [column(ì„ íƒ)] when ~ then ~ when ~ then ~ ... ...end í•´ê²°123456789101112selectcase when a=b and b=c then \"Equilateral\" when a+b&lt;=c then \"Not A Triangle\" when a+c&lt;=b then \"Not A Triangle\" when b+c&lt;=a then \"Not A Triangle\" when a=b and a&lt;&gt;c then \"Isosceles\" when a=c and c&lt;&gt;b then \"Isosceles\" when b=c and c&lt;&gt;a then \"Isosceles\" when a&lt;&gt;b and b&lt;&gt;c then \"Scalene\"endfrom triangles; 2019.09.27 made by jaejun.lee","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"}],"tags":[{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"}]},{"title":"[Python] ë‹¨ì†ì¹´ë©”ë¼","slug":"programmers-camera","date":"2019-09-26T15:00:00.000Z","updated":"2020-03-30T15:06:23.525Z","comments":true,"path":"programmers-camera/","link":"","permalink":"https://jx2lee.github.io/programmers-camera/","excerpt":"ë‹¨ì†ì¹´ë©”ë¼ë¥¼ ì¼ì • ì¡°ê±´ì— ë§ê²Œ ìµœì†Œë¡œ ì„¤ì¹˜í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤","text":"ë‹¨ì†ì¹´ë©”ë¼ë¥¼ ì¼ì • ì¡°ê±´ì— ë§ê²Œ ìµœì†Œë¡œ ì„¤ì¹˜í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ ë¬¸ì œë¬¸ì œ ì„¤ëª…ê³ ì†ë„ë¡œë¥¼ ì´ë™í•˜ëŠ” ëª¨ë“  ì°¨ëŸ‰ì´ ê³ ì†ë„ë¡œë¥¼ ì´ìš©í•˜ë©´ì„œ ë‹¨ì†ìš© ì¹´ë©”ë¼ë¥¼ í•œ ë²ˆì€ ë§Œë‚˜ë„ë¡ ì¹´ë©”ë¼ë¥¼ ì„¤ì¹˜í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ê³ ì†ë„ë¡œë¥¼ ì´ë™í•˜ëŠ” ì°¨ëŸ‰ì˜ ê²½ë¡œ routesê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ëª¨ë“  ì°¨ëŸ‰ì´ í•œ ë²ˆì€ ë‹¨ì†ìš© ì¹´ë©”ë¼ë¥¼ ë§Œë‚˜ë„ë¡ í•˜ë ¤ë©´ ìµœì†Œ ëª‡ ëŒ€ì˜ ì¹´ë©”ë¼ë¥¼ ì„¤ì¹˜í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”. ì œí•œì‚¬í•­ ì°¨ëŸ‰ì˜ ëŒ€ìˆ˜ëŠ” 1ëŒ€ ì´ìƒ 10,000ëŒ€ ì´í•˜ì…ë‹ˆë‹¤. routesì—ëŠ” ì°¨ëŸ‰ì˜ ì´ë™ ê²½ë¡œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©° routes[i][0]ì—ëŠ” ië²ˆì§¸ ì°¨ëŸ‰ì´ ê³ ì†ë„ë¡œì— ì§„ì…í•œ ì§€ì , routes[i][1]ì—ëŠ” ië²ˆì§¸ ì°¨ëŸ‰ì´ ê³ ì†ë„ë¡œì—ì„œ ë‚˜ê°„ ì§€ì ì´ ì í˜€ ìˆìŠµë‹ˆë‹¤. ì°¨ëŸ‰ì˜ ì§„ì…/ì§„ì¶œ ì§€ì ì— ì¹´ë©”ë¼ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ë„ ì¹´ë©”ë¼ë¥¼ ë§Œë‚œê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. ì°¨ëŸ‰ì˜ ì§„ì… ì§€ì , ì§„ì¶œ ì§€ì ì€ -30,000 ì´ìƒ 30,000 ì´í•˜ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ routes return [[-20,15], [-14,-5], [-18,-13], [-5,-3]] 2 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª… -5 ì§€ì ì— ì¹´ë©”ë¼ë¥¼ ì„¤ì¹˜í•˜ë©´ ë‘ ë²ˆì§¸, ë„¤ ë²ˆì§¸ ì°¨ëŸ‰ì´ ì¹´ë©”ë¼ë¥¼ ë§Œë‚©ë‹ˆë‹¤. -15 ì§€ì ì— ì¹´ë©”ë¼ë¥¼ ì„¤ì¹˜í•˜ë©´ ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ ì°¨ëŸ‰ì´ ì¹´ë©”ë¼ë¥¼ ë§Œë‚©ë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼ Greedy ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œ. ì…ë ¥ë°›ì€ listë¥¼ sorting (ë„ì°© ì§€ì ì„ ê¸°ì¤€ìœ¼ë¡œ)í•˜ê³  tmpë³€ìˆ˜ì™€ ì¶œë°œì§€ì ì„ ë¹„êµí•´ ì‘ë‹¤ë©´ í•´ë‹¹ ë²”ìœ„ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ answerì„ ì¶”ê°€í•˜ë©° tmpë¥¼ ê°±ì‹ í•´ì£¼ë©´ ëœë‹¤. ë¬¸ì œ í•´ê²°ì•„ë˜ ì½”ë“œë¡œ í•´ê²°í•˜ì˜€ë‹¤. (ì°¸ê³ ) 1234567891011def solution(routes): routes = sorted(routes, key=lambda x: x[1]) answer = 0 tmp = -100000000000 for route in routes: if tmp &lt; route[0]: answer += 1 tmp = route[1] return answer 2019.09.27 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Python] ê°€ì¥ ë¨¼ ë…¸ë“œ","slug":"programmers-node","date":"2019-09-26T15:00:00.000Z","updated":"2020-03-30T15:06:23.561Z","comments":true,"path":"programmers-node/","link":"","permalink":"https://jx2lee.github.io/programmers-node/","excerpt":"ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ì‘ì„±í•˜ê³  ë…¸ë“œ 1ì—ì„œ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œ ê°¯ìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤","text":"ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ì‘ì„±í•˜ê³  ë…¸ë“œ 1ì—ì„œ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œ ê°¯ìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ ë¬¸ì œë¬¸ì œ ì„¤ëª…nê°œì˜ ë…¸ë“œê°€ ìˆëŠ” ê·¸ë˜í”„ê°€ ìˆìŠµë‹ˆë‹¤. ê° ë…¸ë“œëŠ” 1ë¶€í„° nê¹Œì§€ ë²ˆí˜¸ê°€ ì í˜€ìˆìŠµë‹ˆë‹¤. 1ë²ˆ ë…¸ë“œì—ì„œ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œì˜ ê°¯ìˆ˜ë¥¼ êµ¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œë€ ìµœë‹¨ê²½ë¡œë¡œ ì´ë™í–ˆì„ ë•Œ ê°„ì„ ì˜ ê°œìˆ˜ê°€ ê°€ì¥ ë§ì€ ë…¸ë“œë“¤ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë…¸ë“œì˜ ê°œìˆ˜ n, ê°„ì„ ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê¸´ 2ì°¨ì› ë°°ì—´ vertexê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, 1ë²ˆ ë…¸ë“œë¡œë¶€í„° ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œê°€ ëª‡ ê°œì¸ì§€ë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ ë…¸ë“œì˜ ê°œìˆ˜ nì€ 2 ì´ìƒ 20,000 ì´í•˜ì…ë‹ˆë‹¤. ê°„ì„ ì€ ì–‘ë°©í–¥ì´ë©° ì´ 1ê°œ ì´ìƒ 50,000ê°œ ì´í•˜ì˜ ê°„ì„ ì´ ìˆìŠµë‹ˆë‹¤. vertex ë°°ì—´ ê° í–‰ [a, b]ëŠ” aë²ˆ ë…¸ë“œì™€ bë²ˆ ë…¸ë“œ ì‚¬ì´ì— ê°„ì„ ì´ ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ n vertex return 6 [[3, 6], [4, 3], [3, 2], [1, 3], [1, 2], [2, 4], [5, 2]] 3 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª…ì˜ˆì œì˜ ê·¸ë˜í”„ë¥¼ í‘œí˜„í•˜ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ê³ , 1ë²ˆ ë…¸ë“œì—ì„œ ê°€ì¥ ë©€ë¦¬ ë–¨ì–´ì§„ ë…¸ë“œëŠ” 4,5,6ë²ˆ ë…¸ë“œì…ë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼ê·¸ë˜í”„ ê´€ë ¨ ë¬¸ì œë¥¼ ì²˜ìŒ í’€ì–´ë³´ì•˜ë‹¤. ì–´ë–»ê²Œ ì ‘ê·¼í•´ì•¼ ë ì§€ë¥¼ ëª°ë¼ êµ¬ê¸€ì—ì„œ ì°¾ì€ ì´ ë¸”ë¡œê·¸ë¥¼ ìš°ì„  ì°¸ê³ í–ˆë‹¤. í•´ê²° ë°©ë²•ì˜ ê°„ë‹¨í•œ ìŠ¤ì¼€ì¹˜ëŠ” 1) ê° ë…¸ë“œë³„ ì¸ì ‘í•œ ë…¸ë“œ index êµ¬í•˜ê¸°, 2) queueë¥¼ ì´ìš©í•´ ë°©ë¬¸ì—¬ë¶€(is_visit)ì´ Falseì¸ ê²½ìš° Trueë¡œ ë°”ê¿”ì£¼ë©° distance, queueë¥¼ ì—…ë°ì´íŠ¸, 3) distance ë³€ìˆ˜ë¥¼ sortingí•˜ê³  maxê°’ì„ countí•˜ì—¬ return ì´ë‹¤. ì¢€ ë” ìì„¸íˆ ì‚´í´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. ë³€ìˆ˜ ì„¤ì • graph : ì¸ì ‘í•œ ë…¸ë“œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ distance : ë…¸ë“œ 1ì—ì„œ ê° ë…¸ë“œindex ê¹Œì§€ì˜ ê±°ë¦¬ is_visit : ë°©ë¬¸ ì—¬ë¶€ (ëª¨ë‘ Falseë¡œ ì´ˆê¸°í™”, ë…¸ë“œ 1ì€ Trueë¡œ ë°”ê¾¸ê³  ì‹œì‘) queue : í ë³€ìˆ˜ graph ë³€ìˆ˜ ì±„ìš°ê¸° (ì—°ê²°ëœ ë…¸ë“œ append) queueê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ë  ë•Œê¹Œì§€ i : queueì˜ ë§¨ ì²« ë²ˆì§¸ index ì¶”ì¶œ jê°€ graph[i]ì•ˆ ì›ì†Œì¼ ë•Œ (for) if is_visit[j] : False, is_visit[j] = False queueì— j (ë…¸ë“œ index) append distance update (+1) distance ì •ë ¬ í›„ ì²« ë²ˆì§¸ ê°’(max) ì¹´ìš´íŠ¸ ê°’ return ë¬¸ì œ í•´ê²°123456789101112131415161718192021222324252627def solution(n, edge): graph =[ [] for _ in range(n + 1) ] distances = [ 0 for _ in range(n) ] is_visit = [False for _ in range(n)] queue = [0] is_visit[0] = True # ì—°ê²°ëœ node append for (a, b) in edge: graph[a-1].append(b-1) graph[b-1].append(a-1) # queueë¥¼ ì´ìš©í•œ distance ê³„ì‚° while queue: i = queue.pop(0) for j in graph[i]: if is_visit[j] == False: is_visit[j] = True queue.append(j) distances[j] = distances[i] + 1 # max distanceë¥¼ ê³„ì‚°í•œ í›„ count ê²°ê³¼ return distances.sort(reverse=True) answer = distances.count(distances[0]) return answer 2019.09.27 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Python] ì„¬ ì—°ê²°í•˜ê¸°","slug":"programmers-island","date":"2019-09-25T15:00:00.000Z","updated":"2020-03-30T15:06:23.553Z","comments":true,"path":"programmers-island/","link":"","permalink":"https://jx2lee.github.io/programmers-island/","excerpt":"ëª¨ë“  ì„¬ì„ ì—°ê²°í•  ë•Œ ìµœì†Œ ë¹„ìš©ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤","text":"ëª¨ë“  ì„¬ì„ ì—°ê²°í•  ë•Œ ìµœì†Œ ë¹„ìš©ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤ ë¬¸ì œnê°œì˜ ì„¬ ì‚¬ì´ì— ë‹¤ë¦¬ë¥¼ ê±´ì„¤í•˜ëŠ” ë¹„ìš©(costs)ì´ ì£¼ì–´ì§ˆ ë•Œ, ìµœì†Œì˜ ë¹„ìš©ìœ¼ë¡œ ëª¨ë“  ì„¬ì´ ì„œë¡œ í†µí–‰ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“¤ ë•Œ í•„ìš”í•œ ìµœì†Œ ë¹„ìš©ì„ return í•˜ë„ë¡ solutionì„ ì™„ì„±í•˜ì„¸ìš”. ë‹¤ë¦¬ë¥¼ ì—¬ëŸ¬ ë²ˆ ê±´ë„ˆë”ë¼ë„, ë„ë‹¬í•  ìˆ˜ë§Œ ìˆìœ¼ë©´ í†µí–‰ ê°€ëŠ¥í•˜ë‹¤ê³  ë´…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ A ì„¬ê³¼ B ì„¬ ì‚¬ì´ì— ë‹¤ë¦¬ê°€ ìˆê³ , B ì„¬ê³¼ C ì„¬ ì‚¬ì´ì— ë‹¤ë¦¬ê°€ ìˆìœ¼ë©´ A ì„¬ê³¼ C ì„¬ì€ ì„œë¡œ í†µí–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì œí•œì‚¬í•­ ì„¬ì˜ ê°œìˆ˜ nì€ 1 ì´ìƒ 100 ì´í•˜ì…ë‹ˆë‹¤. costsì˜ ê¸¸ì´ëŠ” ((n-1) * n) / 2ì´í•˜ì…ë‹ˆë‹¤. ì„ì˜ì˜ iì— ëŒ€í•´, costs[i][0] ì™€ costs[i] [1]ì—ëŠ” ë‹¤ë¦¬ê°€ ì—°ê²°ë˜ëŠ” ë‘ ì„¬ì˜ ë²ˆí˜¸ê°€ ë“¤ì–´ìˆê³ , costs[i] [2]ì—ëŠ” ì´ ë‘ ì„¬ì„ ì—°ê²°í•˜ëŠ” ë‹¤ë¦¬ë¥¼ ê±´ì„¤í•  ë•Œ ë“œëŠ” ë¹„ìš©ì…ë‹ˆë‹¤. ê°™ì€ ì—°ê²°ì€ ë‘ ë²ˆ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ ìˆœì„œê°€ ë°”ë€Œë”ë¼ë„ ê°™ì€ ì—°ê²°ë¡œ ë´…ë‹ˆë‹¤. ì¦‰ 0ê³¼ 1 ì‚¬ì´ë¥¼ ì—°ê²°í•˜ëŠ” ë¹„ìš©ì´ ì£¼ì–´ì¡Œì„ ë•Œ, 1ê³¼ 0ì˜ ë¹„ìš©ì´ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ì„¬ ì‚¬ì´ì˜ ë‹¤ë¦¬ ê±´ì„¤ ë¹„ìš©ì´ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ë‘ ì„¬ ì‚¬ì´ì˜ ê±´ì„¤ì´ ë¶ˆê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ ë´…ë‹ˆë‹¤. ì—°ê²°í•  ìˆ˜ ì—†ëŠ” ì„¬ì€ ì£¼ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ n costs return 4 [[0,1,1],[0,2,2],[1,2,5],[1,3,1],[2,3,8]] 4 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª… costsë¥¼ ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìœ¼ë©°, ì´ë•Œ ì´ˆë¡ìƒ‰ ê²½ë¡œë¡œ ì—°ê²°í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì ì€ ë¹„ìš©ìœ¼ë¡œ ëª¨ë‘ë¥¼ í†µí–‰í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼ì–´ë ¤ì›Œ ì—¬ëŸ¬ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤. conn, answerë³€ìˆ˜ë¥¼ ë°˜ë³µë¬¸ì„ ì´ìš©í•´ í’€ì—ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ ë¡œì§ìœ¼ë¡œ êµ¬ì„±í•˜ì˜€ë‹¤. costs ë¦¬ìŠ¤íŠ¸ ì •ë ¬ í›„ ë³€ìˆ˜ ì„¤ì • conn : ì—°ê²°ëœ ì„¬, answer : ë¹„ìš© connì˜ ê¸¸ì´ê°€ nì´ ë˜ì§€ ì•Šì„ ë•Œê¹Œì§€ tmp : ìµœì†Œ ë¹„êµë¥¼ ìœ„í•œ ë³€ìˆ˜, idx : costsì˜ ì¸ë±ìŠ¤ (í›‘ì–´ë³¸ costë¥¼ popí•˜ê¸° ìœ„í•œ ë³€ìˆ˜) costsë¥¼ ëŒë©° (for) costs[i][0] or costs[i][1]ì´ conn ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸ ë¹„ìš© ì €ì¥ì„ ìœ„í•´ tmpë¥¼ ì´ìš©í•´ costs[i][2]ê°’ì„ ì €ì¥í•˜ê³  idx ì €ì¥ costsë¥¼ í•œë²ˆ ë‹¤ í›‘ê³  answerì— tmpë§Œí¼ ë”í•œë‹¤. connì— ê°™ì€ ê·¸ë£¹ì˜ ì„¬ë“¤ì„ ì €ì¥í•œë‹¤ (append), ì¤‘ë³µ ì €ì¥ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ setìœ¼ë¡œ ì €ì¥í•œ ìˆ˜ list() idxë³€ìˆ˜ë¥¼ ì´ìš©í•´ costs pop í’€ë‹¤ë³´ë©´ ë‚œì´ë„ê°€ ì‘¥ì‘¥ ì˜¬ë¼ê°€ëŠ” ëŠë‚Œì´ë‹¤. ë” ë…¸ë ¥í•´ë³´ì. ë¬¸ì œ í•´ê²°ì•„ë˜ ì½”ë“œë¡œ í•´ê²°í•˜ì˜€ë‹¤. ì°¸ê³  1234567891011121314151617181920def solution(n, costs): costs.sort() conn=[costs[0][0]] answer = 0 while len(conn)!=n: tmp=1000000000000000 idx=0 for i in range(len(costs)): if costs[i][0] in conn or costs[i][1] in conn: if costs[i][0] in conn and costs[i][1] in conn: continue if tmp &gt; costs[i][2]: tmp=costs[i][2] idx=i answer+=tmp conn.append(costs[idx][0]) conn.append(costs[idx][1]) conn=list(set(conn)) costs.pop(idx) return answer 2019.09.26 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Python] ë„¤íŠ¸ì›Œí¬","slug":"programmers-network","date":"2019-09-24T15:00:00.000Z","updated":"2020-03-30T15:06:23.565Z","comments":true,"path":"programmers-network/","link":"","permalink":"https://jx2lee.github.io/programmers-network/","excerpt":"25ì¼ë¶€ë¡œ ë°±ì¤€ ëŒ€ì‹  í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë§¤ì¼ í•œ ë¬¸ì œì”©, í’€ë‹¤ê°€ ëª»í’€ì–´ì„œ ì°¸ê³ í•´ í‘¼ ë¬¸ì œëŠ” ëª¨ë‘ ë¸”ë¡œê·¸ë¡œ ë‚¨ê¸°ì","text":"25ì¼ë¶€ë¡œ ë°±ì¤€ ëŒ€ì‹  í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ë§¤ì¼ í•œ ë¬¸ì œì”©, í’€ë‹¤ê°€ ëª»í’€ì–´ì„œ ì°¸ê³ í•´ í‘¼ ë¬¸ì œëŠ” ëª¨ë‘ ë¸”ë¡œê·¸ë¡œ ë‚¨ê¸°ì ë¬¸ì œë„¤íŠ¸ì›Œí¬ë€ ì»´í“¨í„° ìƒí˜¸ ê°„ì— ì •ë³´ë¥¼ êµí™˜í•  ìˆ˜ ìˆë„ë¡ ì—°ê²°ëœ í˜•íƒœë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì»´í“¨í„° Aì™€ ì»´í“¨í„° Bê°€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ìˆê³ , ì»´í“¨í„° Bì™€ ì»´í“¨í„° Cê°€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆì„ ë•Œ ì»´í“¨í„° Aì™€ ì»´í“¨í„° Cë„ ê°„ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ì •ë³´ë¥¼ êµí™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì»´í“¨í„° A, B, CëŠ” ëª¨ë‘ ê°™ì€ ë„¤íŠ¸ì›Œí¬ ìƒì— ìˆë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì»´í“¨í„°ì˜ ê°œìˆ˜ n, ì—°ê²°ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê¸´ 2ì°¨ì› ë°°ì—´ computersê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, ë„¤íŠ¸ì›Œí¬ì˜ ê°œìˆ˜ë¥¼ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì‹œì˜¤. ì œí•œì‚¬í•­ ì»´í“¨í„°ì˜ ê°œìˆ˜ nì€ 1 ì´ìƒ 200 ì´í•˜ì¸ ìì—°ìˆ˜ì…ë‹ˆë‹¤. ê° ì»´í“¨í„°ëŠ” 0ë¶€í„° n-1ì¸ ì •ìˆ˜ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ië²ˆ ì»´í“¨í„°ì™€ jë²ˆ ì»´í“¨í„°ê°€ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ computers[i][j]ë¥¼ 1ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. computer[i][j]ëŠ” í•­ìƒ 1ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ n computers return 3 [[1, 1, 0], [1, 1, 0], [0, 0, 1]] 2 3 [[1, 1, 0], [1, 1, 1], [0, 1, 1]] 1 ì…ì¶œë ¥ ì˜ˆ ì„¤ëª…ì˜ˆì œ #1ì•„ë˜ì™€ ê°™ì´ 2ê°œì˜ ë„¤íŠ¸ì›Œí¬ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œ #2ì•„ë˜ì™€ ê°™ì´ 1ê°œì˜ ë„¤íŠ¸ì›Œí¬ê°€ ìˆìŠµë‹ˆë‹¤. ë¬¸ì œ ì ‘ê·¼ì²˜ìŒì—ëŠ” stack ì„ ì´ìš©í•˜ì§€ ì•Šê³  ë¬¸ì œë¥¼ í’€ì–´ë³´ì•˜ë‹¤. í•˜ì§€ë§Œ ì•„ë‹ˆë‚˜ ë‹¤ë¥¼ê¹Œ.. ì‹œê°„ì´ˆê³¼ê°€ ë‚¬ë‹¤. ê²°êµ­ êµ¬ê¸€ë§ì„ í†µí•´ í•œ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•´ì„œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤. ë¡œì§ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ì…ë ¥ë°›ì€ nì„ í†µí•´ êµ¬ì„±ì›ì´ ê°ìì¸ ê°ê°ì˜ ë„¤íŠ¸ì›Œí¬ì„ tupleë¡œ ìƒì„±í•œë‹¤. iì™€ jë¥¼ roofë¥¼ í†µí•´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸(computers[i][j]) ì—°ê²°ë˜ì–´ ìˆë‹¤ë©´, ë‘ ì»´í“¨í„°ê°€ ì†í•œ indexë¥¼ ì¶”ì¶œí•œë‹¤(idx1, idx2) idx1ê°€ idx2ê°€ ë‹¤ë¥´ë‹¤ë©´, í•˜ë‚˜ë¡œ ë¬¶ì–´ì¤€ë‹¤(if ë’·ë¶€ë¶„) hap ë³€ìˆ˜ ìƒì„±ê³¼ idx1 != idx2 ë¶€ë¶„ì´ ì´í•´ë˜ì§€ ì•Šì•„ ì •ë¦¬í•˜ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ê±¸ë ¸ë‹¤. ì–´ì¨Œë“ , ì–‘ë°©í–¥ìœ¼ë¡œ ì—°ê²°ëœ ë„¤íŠ¸ì›Œí¬ëŠ” ëŒ€ê°ì„  ê¸°ì¤€ ìœ„ìª½ë§Œ ì‚´í´ë³´ë©´ ë˜ê¸° ë•Œë¬¸ì— ì•„ë˜ì™€ ê°™ì´ ê°„ë‹¨íˆ í•´ê²°í•  ìˆ˜ ìˆì—ˆë˜ ê²ƒ ê°™ë‹¤. (ê·¸ë¦¬ê³  stackì˜ ì¤‘ìš”ì„±..) ë¬¸ì œ í•´ê²°ì•„ë˜ ì½”ë“œë¡œ í•´ê²°í•˜ì˜€ë‹¤ ì°¸ê³  123456789101112131415161718def solution(n, computers): res = [] for i in range(n): res.append(&#123;i&#125;) for i in range(0, n): for j in range(i+1, n): if computers[i][j] == 1: for idx,st in enumerate(res): if i in res[idx]: idx1 = idx if j in res[idx]: idx2 = idx if idx1 != idx2: hap = res[idx1] | res[idx2] res.pop(min(idx1,idx2)) res.pop(max(idx1,idx2)) res.append(hap) return len(res) 2019.09.25 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"}]},{"title":"[Cloud] Install Docker","slug":"cloud-install_docker","date":"2019-09-22T15:00:00.000Z","updated":"2020-09-26T13:38:48.156Z","comments":true,"path":"cloud-install_docker/","link":"","permalink":"https://jx2lee.github.io/cloud-install_docker/","excerpt":"ë„ì»¤ ê°œë°œ í™˜ê²½ì„ ì…‹ì—…í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. docker clientëŠ” ìœˆë„ìš°/ë§¥ì—ì„œ ëŒë¦¬ê³  docker serverë¥¼ ì œì–´í•  ìˆ˜ ìˆì§€ë§Œ, docker containerëŠ” linux í™˜ê²½ì—ì„œ ë§Œë“¤ê³  ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ docker serverë¥¼ ë„ìš°ê¸° ìœ„í•´ì„œëŠ” ê°€ìƒ ë¨¸ì‹ ì´ë‚˜ ì›ê²© ì„œë²„ê°€ í•„ìš”í•˜ë‹¤.","text":"ë„ì»¤ ê°œë°œ í™˜ê²½ì„ ì…‹ì—…í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¬ë‹¤. docker clientëŠ” ìœˆë„ìš°/ë§¥ì—ì„œ ëŒë¦¬ê³  docker serverë¥¼ ì œì–´í•  ìˆ˜ ìˆì§€ë§Œ, docker containerëŠ” linux í™˜ê²½ì—ì„œ ë§Œë“¤ê³  ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ docker serverë¥¼ ë„ìš°ê¸° ìœ„í•´ì„œëŠ” ê°€ìƒ ë¨¸ì‹ ì´ë‚˜ ì›ê²© ì„œë²„ê°€ í•„ìš”í•˜ë‹¤. key wordì±…ì—ì„œ ë‹¤ë£¨ëŠ” ìš©ì–´ë“¤ì— ëŒ€í•´ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. docker client ëŒ€ë¶€ë¶„ì˜ docker worflowë¥¼ ê´€ë¦¬, ì›ê²© docker serverì™€ í†µì‹ í•˜ëŠ” docker ëª…ë ¹ì–´ docker server docker ëª…ë ì–´ë¥¼ daemon ëª¨ë“œë¡œ ì‚¬ìš©, ì´ëŠ” ë¦¬ëˆ…ìŠ¤ ì‹œìŠ¤í…œì„ docker serverë¡œ ë§Œë“¤ê²Œ í•œë‹¤. docker clientë¥¼ í†µí•´ containerë¥¼ ë°°í¬ / ì‹¤í–‰ / ì œê±° docker image í•˜ë‚˜ ì´ìƒì˜ íŒŒì¼ ì‹œìŠ¤í…œ ê³„ì¸µ ë„ì»¤í™”(ë¦¬ëˆ…ìŠ¤ ì»¨í…Œì´ë„ˆë¡œ ìƒì„±ëœ)ëœ ì•± ì‹¤í–‰ì„ ìœ„í•œ ëª¨ë“  íŒŒì¼ë“¤ì˜ meta data í¬í•¨ í•˜ë‚˜ì˜ docker image -&gt; ì—¬ëŸ¬ hostì— ì¹´í”¼ ê°€ëŠ¥ Name, Tag : imageì˜ íŠ¹ì • realease í‘œì‹œ docker container docker imageì— ì˜í•´ ìƒì„±ë˜ëŠ” linux container íŠ¹ì • containerëŠ” ë‹¨ í•˜ë‚˜, ë™ì¼ image ë‚´ container ë‹¤ì¤‘ ìƒì„± ê°€ëŠ¥ atomic host(ì›ìì  í˜¸ìŠ¤íŠ¸) less, optimized ëœ CoreOSë‚˜ ì•„í† ë¯¹ í”„ë¡œì íŠ¸ ê°™ì€ OSì˜ ì´ë¯¸ì§€ container hosting &amp; OS ì—…ê·¸ë ˆì´ë“œ ì§€ì› [ì°¸ê³  - Docker Architecture] ì•„ë˜ì™€ ê°™ì€ Docker í™˜ê²½ì„ êµ¬ì„±í•œë‹¤. docker client : CentOS docker server : docker clinetê°€ ì„¤ì¹˜ëœ CentOS Docker Clientë¦¬ëˆ…ìŠ¤ ì‹œìŠ¤í…œì—ì„œ Docker ì„¤ì¹˜ëŠ” Clientë§Œ ì„¤ì¹˜í•˜ë©´ Serverë„ í•¨ê»˜ ì„¤ì¹˜ëœë‹¤. Yum packageë¥¼ ì´ìš©í•´ Dockerë¥¼ ì„¤ì¹˜í•œë‹¤. old version ì‚­ì œ12345678910111213141516171819[tibero@node5 ~]$ sudo yum remove docker \\&gt; docker-client \\&gt; docker-client-latest \\&gt; docker-common \\&gt; docker-latest \\&gt; docker-latest-logrotate \\&gt; docker-logrotate \\&gt; docker-engine[sudo] password for tibero: Loaded plugins: fastestmirror, langpacksNo Match for argument: dockerNo Match for argument: docker-clientNo Match for argument: docker-client-latestNo Match for argument: docker-commonNo Match for argument: docker-latestNo Match for argument: docker-latest-logrotateNo Match for argument: docker-logrotateNo Match for argument: docker-engineNo Packages marked for removal repositoryë¥¼ ì´ìš©í•œ ì„¤ì¹˜12345$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2$ sudo yum-config-manager \\ --add-repo https://download.docker.com/linux/centos/docker-ce.repo Run12$ sudo systemctl enable docker # ì„œë²„ ì¬ê¸°ë™ ì´í›„ ìë™ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì‹œì‘ì„ ìœ„í•¨$ sudo systemctl start docker Docker ëª…ë ¹ì–´ë¥¼ sudo ì—†ì´ ì‚¬ìš©ì„ ì›í•˜ë©´ docker ì‹¤í–‰ê¶Œí•œì„ ê°€ì§„ ê·¸ë£¹ì„ìƒì„±í•˜ì—¬ ê¶Œí•œì„ ë¶€ì—¬í•˜ë©´ ëœë‹¤ $ sudo groupadd docker $ sudo gpasswd -a $USER docker Testì„¤ì¹˜ê°€ ì˜ ë˜ì–´ìˆëŠ”ì§€ í™•ì¸ í•  ê²¸ centos ìµœì‹  ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ê³  ì´ì— ì ‘ê·¼í•´ë³´ë„ë¡ í•œë‹¤. 1234567891011[kuber@node2 ~]$ docker run --rm -ti centos:latest /bin/bashUnable to find image 'centos:latest' locallyTrying to pull repository docker.io/library/centos ... latest: Pulling from docker.io/library/centosd8d02d457314: Pull complete Digest: sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6ebStatus: Downloaded newer image for docker.io/centos:latest[root@0f84b088b2e6 /]# pwd/[root@0f84b088b2e6 /]# whoamiroot 2019.09.23 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Cloud] Docker Image","slug":"cloud-docker_image","date":"2019-09-22T15:00:00.000Z","updated":"2020-09-26T04:07:27.301Z","comments":true,"path":"cloud-docker_image/","link":"","permalink":"https://jx2lee.github.io/cloud-docker_image/","excerpt":"Docker Imageì— ëŒ€í•´ ì•Œì•„ë³´ì","text":"Docker Imageì— ëŒ€í•´ ì•Œì•„ë³´ì Docker Image ëª¨ë“  Docker ContainerëŠ” Imageì— ê¸°ë°˜í•˜ê³  ImageëŠ” Dockerë¡œ ë°°í¬í•˜ê³  ì‹¤í–‰í•˜ê¸° ìœ„í•œ ëª¨ë“  ê²ƒì˜ ê¸°ë°˜ì„ ì œê³µ Image íŠ¹ì§• Containerë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ docker Imageê°€ í•„ìš”í•œë°, ì´ëŠ” ê³µê°œëœ ê²ƒì„ ë‹¤ìš´ë¡œë“œ í•˜ê±°ë‚˜ ì§ì ‘ ì´ë¯¸ì§€ë¥¼ ìƒì„± ëª¨ë“  docker ImageëŠ” í•˜ë‚˜ ì´ìƒì˜ íŒŒì¼ ì‹œìŠ¤í…œ ê³„ì¸µìœ¼ë¡œ ì´ë£¨ì–´ì§ íŒŒì¼ ì‹œìŠ¤í…œ ê³„ì¸µì€ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ ì ìš©ë˜ëŠ” ê°œë³„ ë¹Œë“œ ë‹¨ê³„ë§ˆë‹¤ 1:1 ì§ì ‘ ë§¤í•‘ ì´ë¯¸ì§€ ê´€ë¦¬ë¥¼ ìœ„í•´ dockerëŠ” ìŠ¤í† ë¦¬ì§€ ë°±ì—”ë“œ(Stroage backend)ì— í¬ê²Œ ì˜ì¡´ ì´ë¯¸ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” íŒŒì¼ ì‹œìŠ¤í…œ ê³„ì¸µì„ ë§Œë“¤ê³  ê´€ë¦¬í•˜ê¸° ìœ„í•´ ë¦¬ëˆ…ìŠ¤ íŒŒì¼ ì‹œìŠ¤í…œê³¼ í†µì‹ í•˜ëŠ” ì—­í•  AUFS, BTRFS, ë””ë°”ì´ìŠ¤-ë§¤í¼, ì˜¤ë²„ë ˆì´ ë“± ë¹ ë¥¸ ì´ë¯¸ì§€ ê´€ë¦¬ë¥¼ ìœ„í•´ CoW(Copy-on-Write) ì‹œìŠ¤í…œ ì œê³µ DockerfileDockerfileì€ ì´ë¯¸ì§€ ìƒì„±ì— í•„ìš”í•œ ëª¨ë“  ë‹¨ê³„ë¥¼ ê¸°ìˆ í•œ íŒŒì¼ë¡œ, ë³´í†µ Appì˜ ì†ŒìŠ¤ ì½”ë“œ ì €ì¥ì˜ root ë””ë ‰í† ë¦¬ì— í¬í•¨ëœë‹¤. êµ¬ì¡° ì„¤ëª…ì„ ìœ„í•´ Node.js ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“œëŠ” ì˜ˆì œì˜ Dockerfileë¥¼ ì‚´í´ë³¸ë‹¤. 123456789101112131415161718192021222324252627FROM node:11.11.0LABEL \"maintainer\"=\"anna@example.com\"LABEL \"rating\"=\"Five Stars\" \"class\"=\"First Class\"USER rootENV AP /data/appENV SCPATH /etc/supervisor/conf.dRUN apt-get -y update# The daemonsRUN apt-get -y install supervisorRUN mkdir -p /var/log/supervisor# Supervisor ConfigurationADD ./supervisord/conf.d/* $SCPATH/# Application CodeADD *.js* $AP/WORKDIR $APRUN npm installCMD [\"supervisord\", \"-n\"] íŒŒì¼ ê° ë¼ì¸ì€ ë„ì»¤ì— ì˜í•´ ì €ì¥ë˜ëŠ” ìƒˆ ì´ë¯¸ì§€ ê³„ì¸µì„ ë§Œë“ ë‹¤. ì´ë ‡ê²Œ ì„¤ê³„í•œ ê²ƒì€ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œ í•  ë•Œ ë³€ê²½ëœ ê³„ì¸µë§Œì„ ìƒˆë¡œ ë¹Œë“œí•˜ê¸° ìœ„í•¨ì´ë‹¤. ê° ë¼ì¸ì„ ì°¨ë¡€ëŒ€ë¡œ í›‘ì–´ë³¸ë‹¤. FROM node:11.11.0 ì´ ë¶€ë¶„ì€ íŠ¹ì • ë…¸ë“œ ë²„ì ¼ (node.11.11.0)ìœ¼ë¡œ ê³ ì •í•œ ìš°ë¶„íˆ¬ ë¦¬ëˆ…ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì œê³µí•œë‹¤ëŠ” ëœ»ì´ë‹¤. ì´ì²˜ëŸ¼ ë„ì»¤ í—ˆë¸Œë¥¼ í†µí•´ ë…¸ë“œë¥¼ ìœ„í•œ ê³µì‹ ì´ë¯¸ì§€ë¥¼ ë°›ì„ ìˆ˜ ìˆê³ , ì¼ë°˜ì ì¸ ë¦¬ëˆ…ìŠ¤ ì´ë¯¸ì§€ì—ì„œë„ ë¹Œë“œ ê°€ëŠ¥í•˜ë‹¤. LABEL â€œmaintainerâ€=â€anna@example.comâ€œ (LABEL â€œratingâ€=â€Five Starsâ€ â€œclassâ€=â€First Classâ€) Imageë‚˜ Containerì— ë¼ë²¨ (Label)ì„ ì ìš©í•˜ëŠ” ê¸°ëŠ¥ì´ë‹¤. key-valueí˜•íƒœë¡œ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€í•  ìˆ˜ ìˆê³ , ì´ë¯¸ì§€ ë¹Œë“œ í›„ docker inspect ëª…ë ¹ì–´ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. 1234567891011121314151617[kuber@node2 ~]$ docker inspect test/docker-node-hello[ &#123; \"Id\": \"sha256:fd425ed5d292360c4b20bb193c402e4fb939b73e07a7f7b6f600e31c9d3a63f8\", ... ... \"Image\": \"sha256:40ce3ed86b2ce0c74ba5d6de3ec99fca6982ef43355956502bf7adb62b973d05\", \"Volumes\": null, \"WorkingDir\": \"/data/app\", \"Entrypoint\": null, \"OnBuild\": [], \"Labels\": &#123; \"class\": \"First Class\", \"maintainer\": \"anna@example.com\", \"rating\": \"Five Stars\" &#125; &#125;, USER root ê¸°ë³¸ì ìœ¼ë¡œdocker Container ë‚´ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ë¥¼ rootë¡œ ì‹¤í–‰í•˜ì§€ë§Œ, ë•Œì— ë”°ë¼ USER ëª…ë ¹ì–´ë¡œ íŠ¹ì • ì‚¬ìš©ìë¡œ ì§€ì •í•  ìˆ˜ ìˆë‹¤. (Containerê°€ í˜¸ìŠ¤íŠ¸ ì»¤ë„ ìœ„ì—ì„œ ë™ì‘í•˜ë¯€ë¡œ ì ì¬ì  ë³´ì•ˆ ìœ„í˜‘ì´ ìˆì„ ìˆ˜ ìˆë‹¤. root ë³´ë‹¨ íŠ¹ì • ì‚¬ìš©ì ê³„ì •ìœ¼ë¡œ ì‹¤í–‰í•´ì•¼ í•œë‹¤ê³  ê¶Œê³ í•œë‹¤.) ** ENV AP(SCPATH) /data/app( /etc/supervisor/conf.d) ** shell í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë‹¨ê³„ RUN ~ íŒŒì¼/ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ìš”êµ¬ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì„¤ì¹˜í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë¡œ, ìœ„ ENV ë‹¨ê³„ì—ì„œ ì„¤ì •í•œ í™˜ê²½ë³€ìˆ˜ë¡œ ê°„ëµí•˜ê²Œ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. RUN apt-get -y update RUN apt-get -y install supervisorRUN mkdir -p /var/log/supervisor (yum/apt-get updateì˜ ê²½ìš° ë¹Œë“œ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦´ ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ Dockerfileë‚´ ëª…ì‹œí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ì—…ë°ì´íŠ¸ê°€ ì ìš©ëœ ê¸°ë³¸ ë¦¬ëˆ…ìŠ¤ ì´ë¯¸ì§€ ìœ„ì— ë¹Œë“œí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  ê¶Œì¥í•œë‹¤) ADD ./supervisord/conf.d/* $SCPATH/ (ADD .js $AP/) ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì˜ íŒŒì¼ì„ Imageë¡œ ì¹´í”¼í•˜ëŠ” ë‹¨ê³„ì´ë‹¤. ì½”ë“œë‚˜ í•„ìš”í•œ ë³´ì¡° íŒŒì¼ë“¤ì„ ì¹´í”¼í•˜ëŠ”ë° ì£¼ë¡œ ì“°ì¸ë‹¤. WORKDIR $AP ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í•˜ëŠ” ë‹¨ê³„ì´ë‹¤. ì´ì²˜ëŸ¼ ë¹Œë“œ ì‹œ ë³€ê²½ë˜ëŠ” ì‚¬í•­ì˜ ê²½ìš°, Dockerfile ì‘ì„± ì‹œ ìµœëŒ€í•œ ë’¤ìª½ìœ¼ë¡œ ì‘ì„±í•˜ê¸°ë¥¼ ê¶Œì¥í•œë‹¤.ì™œëƒë©´ ì´ë¯¸ì§€ë¥¼ ìƒˆë¡œ ë¹Œë“œí•˜ë©´ ì²˜ìŒìœ¼ë¡œ ë°”ë€ ë¶€ë¶„ë¶€í„° ìƒˆë¡œ ë¹Œë“œë˜ê¸° ë•Œë¬¸ì´ë‹¤. CMD [â€œsupervisordâ€, â€œ-nâ€] Container ì•ˆì—ì„œ ì‹¤í–‰í•˜ê³ ì í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ë„ìš°ëŠ” ëª…ë ¹ì–´ë¥¼ ì‘ì„±í•˜ëŠ” ë‹¨ê³„ì´ë‹¤. ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œ ë§ì€ ë…¼ë€ì´ ìˆì—ˆì§€ë§Œ ì»¨í…Œì´ë„ˆ ë‚´ í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ë§Œ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ë‹¤ê³  ë§í•œë‹¤. ì»¨í…Œì´ë„ˆëŠ” ë‹¨ì¼ ê¸°ëŠ¥ë§Œì„ ì œê³µí•œë‹¤ëŠ” ì² í•™(?)ì— ê¸°ì´ˆí•œë‹¤. 123[kuber@node2 conf.d]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8affdbc03b3e example/docker-node-hello:lastest \"supervisord -n\" 22 hours ago Up 26 minutes 0.0.0.0:8080-&gt;8080/tcp romantic_haibt Image Buildìœ„ Dockerfileì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•´ë³´ê³ ì í•œë‹¤. gitì„ ì´ìš©í•´ ì˜ˆì œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì €ì¥ì†Œë¥¼ ë³µì œí•´ì˜¨ë‹¤. 12345678[kuber@node2 ~]$ git clone https://github.com/spkane/docker-node-hello.gitCloning into 'docker-node-hello'...remote: Enumerating objects: 47, done.remote: Total 47 (delta 0), reused 0 (delta 0), pack-reused 47Unpacking objects: 100% (47/47), done.[kuber@node2 ~]$ cd docker-node-hello/[kuber@node2 docker-node-hello]$ git ë””ë ‰í† ë¦¬ë¥¼ ì œì™¸í•œ íŒŒì¼ë“¤ì„ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 1234567891011121314[kuber@node2 docker-node-hello]$ tree -a -I .git.â”œâ”€â”€ Dockerfileâ”œâ”€â”€ .dockerignoreâ”œâ”€â”€ .gitignoreâ”œâ”€â”€ index.jsâ”œâ”€â”€ Makefileâ”œâ”€â”€ package.jsonâ”œâ”€â”€ README.mdâ”œâ”€â”€ supervisordâ”‚ â””â”€â”€ conf.dâ”‚ â”œâ”€â”€ node.confâ”‚ â””â”€â”€ supervisord.confâ””â”€â”€ Vagrantfile .dockerignore: docker Image ë¹Œë“œ ì‹œ ë„ì»¤ í˜¸ìŠ¤íŠ¸ì— ì—…ë¡œë“œí•˜ê³  ì‹¶ì§€ ì•Šì€ íŒŒì¼ì´ë‚˜ ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•˜ëŠ” íŒŒì¼ 12[kuber@node2 docker-node-hello]$ cat .dockerignore .git package.json : Node.js ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ì˜ ë° ì˜ì¡´ì„± ë‚˜ì—´ íŒŒì¼ index.js : ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ ì†ŒìŠ¤ ì½”ë“œ supervisord : ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ë° ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•œ supervisordì„ ìœ„í•œ ì„¤ì • íŒŒì¼ì´ í¬í•¨ëœ í´ë” ê·¸ëŸ¼ ì´ì œ Imageë¥¼ ë¹Œë“œí•´ë³´ë„ë¡ í•œë‹¤. ëª…ë ¹ì–´ì— ì“°ì´ëŠ” ìì„¸í•œ ì˜µì…˜ë“¤ì€ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ë©´ ëœë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117[kuber@node2 docker-node-hello]$ docker build -t example/docker-node-hello:lastest .Sending build context to Docker daemon 15.87 kBStep 1/14 : FROM node:11.11.0Trying to pull repository docker.io/library/node ... 11.11.0: Pulling from docker.io/library/node22dbe790f715: Pull complete 0250231711a0: Pull complete 6fba9447437b: Pull complete c2b4d327b352: Pull complete 270e1baa5299: Pull complete 08ba2f9dd763: Pull complete edf54285ab13: Pull complete 4d751c169397: Pull complete Digest: sha256:065610e9b9567dfecf10f45677f4d372a864a74a67a7b2089f5f513606e28edeStatus: Downloaded newer image for docker.io/node:11.11.0 ---&gt; 9ff38e3a6d9dStep 2/14 : LABEL \"maintainer\" \"anna@example.com\" ---&gt; Running in d0c3d1590e1f ---&gt; b4855e6ce77cRemoving intermediate container d0c3d1590e1fStep 3/14 : LABEL \"rating\" \"Five Stars\" \"class\" \"First Class\" ---&gt; Running in 04a73c43a44a ---&gt; 2ebbef69d1b3Removing intermediate container 04a73c43a44aStep 4/14 : USER root ---&gt; Running in 5de276a155e2 ---&gt; 8ad740a32fddRemoving intermediate container 5de276a155e2Step 5/14 : ENV AP /data/app ---&gt; Running in aa77a9763782 ---&gt; 45925bd0fb66Removing intermediate container aa77a9763782Step 6/14 : ENV SCPATH /etc/supervisor/conf.d ---&gt; Running in 931030d51457 ---&gt; a2975676fd6dRemoving intermediate container 931030d51457Step 7/14 : RUN apt-get -y update ---&gt; Running in ecc80b77c428Ign:1 http://deb.debian.org/debian stretch InReleaseGet:2 http://deb.debian.org/debian stretch-updates InRelease [91.0 kB]Get:3 http://deb.debian.org/debian stretch Release [118 kB]Get:4 http://security.debian.org/debian-security stretch/updates InRelease [94.3 kB]Get:5 http://deb.debian.org/debian stretch-updates/main amd64 Packages [27.4 kB]Get:6 http://security.debian.org/debian-security stretch/updates/main amd64 Packages [506 kB]Get:7 http://deb.debian.org/debian stretch Release.gpg [2365 B]Get:8 http://deb.debian.org/debian stretch/main amd64 Packages [7086 kB]Fetched 7925 kB in 3s (2531 kB/s)Reading package lists... ---&gt; 37d8e3e4a4b4Removing intermediate container ecc80b77c428Step 8/14 : RUN apt-get -y install supervisor ---&gt; Running in 74da13fa61deReading package lists...Building dependency tree...Reading state information...The following additional packages will be installed: python-meld3 python-pkg-resourcesSuggested packages: python-setuptools supervisor-docThe following NEW packages will be installed: python-meld3 python-pkg-resources supervisor0 upgraded, 3 newly installed, 0 to remove and 57 not upgraded.Need to get 483 kB of archives.After this operation, 2157 kB of additional disk space will be used.Get:1 http://deb.debian.org/debian stretch/main amd64 python-pkg-resources all 33.1.1-1 [166 kB]Get:2 http://deb.debian.org/debian stretch/main amd64 python-meld3 all 1.0.2-2 [37.3 kB]Get:3 http://deb.debian.org/debian stretch/main amd64 supervisor all 3.3.1-1+deb9u1 [280 kB]debconf: delaying package configuration, since apt-utils is not installedFetched 483 kB in 0s (488 kB/s)Selecting previously unselected package python-pkg-resources.(Reading database ... 29978 files and directories currently installed.)Preparing to unpack .../python-pkg-resources_33.1.1-1_all.deb ...Unpacking python-pkg-resources (33.1.1-1) ...Selecting previously unselected package python-meld3.Preparing to unpack .../python-meld3_1.0.2-2_all.deb ...Unpacking python-meld3 (1.0.2-2) ...Selecting previously unselected package supervisor.Preparing to unpack .../supervisor_3.3.1-1+deb9u1_all.deb ...Unpacking supervisor (3.3.1-1+deb9u1) ...Setting up python-meld3 (1.0.2-2) ...Setting up python-pkg-resources (33.1.1-1) ...Setting up supervisor (3.3.1-1+deb9u1) ...invoke-rc.d: could not determine current runlevelinvoke-rc.d: policy-rc.d denied execution of start. ---&gt; d66e13271f30Removing intermediate container 74da13fa61deStep 9/14 : RUN mkdir -p /var/log/supervisor ---&gt; Running in f85e1c0267de ---&gt; 9979f514ad99Removing intermediate container f85e1c0267deStep 10/14 : ADD ./supervisord/conf.d/* $SCPATH/ ---&gt; 6db6cac86654Removing intermediate container d565d65027c7Step 11/14 : ADD *.js* $AP/ ---&gt; 3a8554a9e86dRemoving intermediate container f60af33566beStep 12/14 : WORKDIR $AP ---&gt; 7437cca985ffRemoving intermediate container 6b1e8ae1aec2Step 13/14 : RUN npm install ---&gt; Running in e1038f1c1b6anpm WARN deprecated connect@2.7.9: connect 2.x series is deprecatednpm notice created a lockfile as package-lock.json. You should commit this file.added 18 packages from 15 contributors and audited 34 packages in 3.641sfound 16 vulnerabilities (5 low, 5 moderate, 6 high) run `npm audit fix` to fix them, or `npm audit` for details ---&gt; 40ce3ed86b2cRemoving intermediate container e1038f1c1b6aStep 14/14 : CMD supervisord -n ---&gt; Running in dd4b1488e1a7 ---&gt; fd425ed5d292Removing intermediate container dd4b1488e1a7Successfully built fd425ed5d292 Run ImageImage ë¹Œë“œê°€ ì„±ê³µí•˜ë©´ ì•„ë˜ì™€ ê°™ì´ Imageë¥¼ ì‹¤í–‰í•´ë³¸ë‹¤. 12345[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 example/docker-node-hello:lastest 8affdbc03b3ec66745ef5cb9e90f5d1f71b46c93932b706317b744fbb7212371in Web browser,Hello World. Wish you were here. ìœ„ ëª…ë ¹ì€ ì•„ë˜ì™€ ê°™ë‹¤. example/docker-node-hello:lastest íƒœê·¸ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ë¡œë¶€í„° ë°±ê·¸ë¼ìš´ë“œì— ì‹¤í–‰ ì»¨í…Œì´ë„ˆë¡œ ë§Œë“¤ê³  (-d) 8080 port ë¥¼ docker í˜¸ìŠ¤íŠ¸ì˜ 8080 portì— ë§¤í•‘ (-p 8080:8080) ê·¸ëŸ¼ ì‹¤ì œ ì›¹ì´ ì˜ ë„ì›Œì¡ŒëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ docker serverì˜ ipë¥¼ í™•ì¸í•˜ê³  ì ‘ì†í•´ë³¸ë‹¤. (ë¡œì»¬=ì„œë²„ì´ë¯€ë¡œ í•´ë‹¹ ì•„ì´í”¼:8080 ìœ¼ë¡œ ì ‘ì†í•˜ë©´ ë³´ì¸ë‹¤) 1Hello World. Wish you were here. í™˜ê²½ ë³€ìˆ˜index.jsë¥¼ ì‚´í´ë³´ì. $WHO ëŠ” Helloì˜ ëŒ€ìƒì´ ë˜ëŠ” ì•±ì´ ì‚¬ìš©í•˜ëŠ” ë³€ìˆ˜ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 1234567891011// Constantsvar DEFAULT_PORT = 8080;var DEFAULT_WHO = \"World\";var PORT = process.env.PORT || DEFAULT_PORT;var WHO = process.env.WHO || DEFAULT_WHO;// Appvar app = express();app.get('/', function (req, res) &#123; res.send('Hello ' + WHO + '. Wish you were here.\\n');&#125;); ê·¸ëŸ¼ Containerë¥¼ ë„ìš¸ ë•Œ í™˜ê²½ë³€ìˆ˜ë¥¼ ë„˜ê²¨ Hello ëŒ€ìƒì„ ë³€ê²½í•´ë³´ë„ë¡ í•œë‹¤. ìš°ì„  ë„ì›Œì ¸ ìˆëŠ” Containerë¥¼ í™•ì¸í•œ í›„ ì¤‘ì§€í•œë‹¤. ì¤‘ì§€í•˜ëŠ” ë°©ë²•ì€ CONTAINER IDì™€ NAMESë¥¼ ì´ìš©í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤. 1234567891011[kuber@node2 docker-node-hello]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8affdbc03b3e example/docker-node-hello:lastest \"supervisord -n\" About a minute ago Up About a minute 0.0.0.0:8080-&gt;8080/tcp romantic_haibt[kuber@node2 docker-node-hello]$ docker stop 8affdbc03b3e(or docker stop romantic_haibt)8affdbc03b3e[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 example/docker-node-hello:lastest a412191bdcdb7b55e687b44dedc0707164fff784c0e1c64f1ce11a22afe64b2a[kuber@node2 docker-node-hello]$ docker stop priceless_lovelacepriceless_lovelace[kuber@node2 docker-node-hello]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES run ëª…ë ¹ì–´ì— -e ë¥¼ ì¶”ê°€í•˜ì—¬ ì¬ì‹œì‘í•œë‹¤. (WHO : Jaejun Lee) 12[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 -e WHO=\"Jaejun Lee\" example/docker-node-hello:lastest 389f5be3ee7c2020ecacbd032a5ffa048339d0bdee66666e6dedc8e74e992e78 webìœ¼ë¡œ ì ‘ì†í•˜ì—¬ í™•ì¸í•´ë³¸ë‹¤. Hello World. Wish you were here. Image ì €ì¥Imageë„ ë§Œë“¤ì—ˆê² ë‹¤, ë°°í¬ë¥¼ ì›í•˜ëŠ” docker í˜¸ìŠ¤íŠ¸ì—ì„œ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ê³³ì—ë‹¤ê°€ ì €ì¥í•´ì•¼ í•œë‹¤. ì´ê³³ì„ Image ë¹Œë“œì™€ Image ì‹¤í–‰ ì‚¬ì´ì˜ ëª…ë°±í•œ í•¸ë“œì˜¤í”„ í¬ì¸íŠ¸(hand-off point)ë¼ê³  í•œë‹¤. ë³´í†µ Imageë¥¼ Serverì—ì„œ ì§ì ‘ ë¹Œë“œí•˜ê³  ì‹¤í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ê°œ Image ì €ì¥ì†Œì—ì„œ Imageë¥¼ ëŒì–´ì™€ í•˜ë‚˜ ì´ìƒì˜ Docker Serverì— ì‹¤í–‰í•  ìˆ˜ ìˆê²Œë” ë°°í¬í•œë‹¤. ì†ì‰½ê²Œ ì´ë¯¸ì§€ë¥¼ ëŒì–´ì˜¤ê¸° ìœ„í•´ Imageë¥¼ ì €ì¥í•˜ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì— ëŒ€í•´ ì‚´í´ë³´ì ê³µê°œ registry ê³µê°œ Imageë“¤ì„ ì €ì¥í•˜ê¸° ìœ„í•œ Image registryë¥¼ ì œê³µí•œë‹¤(https://hub.docker.com/). Linux ë°°í¬íŒ, WordPressë“± ë‹¤ì–‘í•œ Imageê°€ ì¡´ì¬í•œë‹¤. ë¹„ê³µê°œ registry Imageë¥¼ ì¸í„°ë„·ì„ í†µí•´ ê³µê°œí•˜ì§€ ì•Šê³  ë‚´ë¶€ì ìœ¼ë¡œ Docker Imageë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ë„ ì¡´ì¬í•œë‹¤. registry ì¸ì¦ Container Imageë¥¼ ì €ì¥í•˜ëŠ” registryì™€ì˜ í†µì‹ ì€ í•„ìˆ˜ì ì´ë‹¤. ì €ì¥í•˜ëŠ” ê³¼ì •ì—ì„œ ê¶Œí•œì„ ìš”êµ¬í•˜ëŠ”ë°, DockerëŠ” ìë™í™”ë¥¼ ìœ„í•´ Image ë‹¤ìš´ ìš”ì²­ì„ ë°›ëŠ” ê²½ìš° ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•´ ë¡œê·¸ì¸ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•œë‹¤. default registryëŠ” ì•ì—ì„œ ì–¸ê¸‰í•œ ê³µê°œ Imageê°€ ì €ì¥ë˜ì–´ ìˆëŠ” registry ì´ë‹¤. Docker Hub ê³„ì • ìƒì„± í›„ ë¡œê·¸ì¸ https://hub.docker.com/ì— ì ‘ì†í•˜ì—¬ ê°€ì…í•œ í›„ ë¡œê·¸ì¸ì„ í•´ë³´ë„ë¡ í•œë‹¤. 12345[kuber@node2 ~]$ docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: jaejunlee Password: Login Succeeded ë¡œê·¸ì¸ì´ ì„±ê³µë˜ë©´, ~/.docker/confing.jsonë¼ëŠ” íŒŒì¼ì´ ìƒì„±ë˜ëŠ”ë°, ë‚˜ì˜ ë¡œê·¸ì¸ ì •ë³´ë¥¼ ìºì‹œí•˜ê¸° ìœ„í•¨ì´ë‹¤. 1234567[kuber@node2 ~]$ cat ~/.docker/config.json &#123; \"auths\": &#123; \"https://index.docker.io/v1/\": &#123; \"auth\": \"amFlanVubGVlOndvd25zbGQ5NDg5\" &#125; &#125; ì´ëŸ¬í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” íŒŒì¼ì€ registryì— ì ‘ê·¼í•˜ê³ ì í•  ë•Œ DockerëŠ” ì´ë¥¼ ì°¸ê³ í•´ ì—°ê²°ì„ ì‹œë„í•œë‹¤. ì‚¬ìš©ì„ ë‹¤ í•œ ì´í›„ì— ë§Œì•½ ë¡œê·¸ì•„ì›ƒì„ í•˜ê²Œëœë‹¤ë©´, íŒŒì¼ì´ ë¹„ì–´ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 123456[kuber@node2 ~]$ docker logoutRemoving login credentials for https://index.docker.io/v1/[kuber@node2 ~]$ cat ~/.docker/config.json &#123; \"auths\": &#123;&#125;&#125; registryì— Image ì €ì¥ì•ì„œ Image build ì‹œ ìš°ë¦¬ëŠ” docker build -t example/docker-node-hello:lastest .ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í–ˆë‹¤. ì´ëŠ” ê³µê°œ registry ì˜ example/docker-node-hello ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•œ ê²ƒì¸ë°, ë§Œì•½ ë¡œì»¬ì—ì„œ ìƒì„±í•œ ì´ë¯¸ì§€ì˜ ê²½ìš° ì•„ë¬´ ì´ë¦„ì´ë‚˜(ë³´í†µ ì‚¬ìš©ì/ê·¸ë£¹ ì´ìš©) ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. tagëª…ë ¹ì–´ë¥¼ í†µí•´ ì´ë¯¸ì§€ì˜ íƒœê·¸ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆë‹¤. ì´ë¯¸ì§€ íƒœê·¸ëª…ì€ docker ì‚¬ìš©ì ì•„ì´ë””ë¡œ ì„¤ì •í•˜ì—¬ì•¼ ì¶”í›„ì— push/pullì´ ê°€ëŠ¥í•˜ë‹¤ 12345678[kuber@node2 ~]$ docker tag test/docker-node-hello:latest jaejunlee/docker-node-hello:latest[kuber@node2 ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEexample/docker-node-hello lastest fd425ed5d292 2 days ago 928 MBjaejunlee/docker-node-hello latest fd425ed5d292 2 days ago 928 MBtest/docker-node-hello latest fd425ed5d292 2 days ago 928 MBdocker.io/centos latest 67fa590cfc1c 5 weeks ago 202 MBdocker.io/node 11.11.0 9ff38e3a6d9d 6 months ago 904 MB ì´ë²ˆì—” ê·¸ëŸ¼ tagë¥¼ ë°”ê¾¼ ì´ë¯¸ì§€ë¥¼ push (ê³µê°œ registry) í•´ë³´ë„ë¡ í•œë‹¤. 12345678910111213141516[kuber@node2 ~]$ docker push jaejunlee/docker-node-hello-test:latestThe push refers to a repository [docker.io/jaejunlee/docker-node-hello-test]a233ae287464: Pushed 8f9ee22c1347: Pushed ce283841f218: Pushed f8fc35d38ecc: Pushed cb7a837507c0: Pushed 4ebe27287e94: Pushed abdde7643382: Pushed 909542b1bce2: Pushed 7de462056991: Pushed 3443d6cf0f1f: Pushed f3a38968d075: Pushed a327787b3c73: Pushed 5bb0785f2eee: Pushed latest: digest: sha256:98a38e1a53a9473ab1b083099d29d70d9a05d5f924533b378e70555b1f1714a3 size: 3055 Docker Hubì— ì ‘ì†í•˜ì—¬ ì œëŒ€ë¡œ push ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ë„ë¡ í•œë‹¤. (https://cloud.docker.com/u/jaejunlee/repository/docker/jaejunlee/docker-node-hello-test) 2019.09.23 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"}]},{"title":"[Python] ë™ì  ì¸ìˆ˜ ì§€ì • ì‹œ Noneê³¼ docstring í™œìš©","slug":"python-better_way_20","date":"2019-09-18T15:00:00.000Z","updated":"2020-03-30T15:06:23.586Z","comments":true,"path":"python-better_way_20/","link":"","permalink":"https://jx2lee.github.io/python-better_way_20/","excerpt":"ì•„ë˜ ë™ì  ì¸ìˆ˜ë¥¼ í™œìš©í•˜ëŠ” í•¨ìˆ˜ (ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°ì„ í¬í•¨í•˜ëŠ” log í•¨ìˆ˜) ë¥¼ ìƒê°í•´ë³´ì.","text":"ì•„ë˜ ë™ì  ì¸ìˆ˜ë¥¼ í™œìš©í•˜ëŠ” í•¨ìˆ˜ (ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°ì„ í¬í•¨í•˜ëŠ” log í•¨ìˆ˜) ë¥¼ ìƒê°í•´ë³´ì. 12345678910111213from datetime import datetimeimport timedef get_log(mes, date=datetime.now()): print('%s: %s'%(date, mes))get_log('Hi there!')time.sleep(0.1)get_log('Hi again!')&gt;&gt;&gt;2019-09-19 08:28:26.737742: Hi there!2019-09-19 08:28:26.737742: Hi again! ì›í•˜ëŠ” í•¨ìˆ˜ ê²°ê³¼ëŠ” 0.1ì´ˆ ì´í›„ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì°í˜€ì•¼ í•˜ëŠ”ë° ê°™ì§€ ì•Šì€ê°€!! ì´ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•  ë•Œ dateë³€ìˆ˜ê°€ defaultë¡œ ê·¸ ì‹œê°„ì„ ê°€ì ¸ê°€ê¸° ë•Œë¬¸ì— ì›í•˜ëŠ” ê²°ê³¼ê°’ì„ ì–»ì§€ ëª»í•œë‹¤. ì¦‰, ì¬í‰ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ì–´ë–»ê²Œ í•´ì•¼í•˜ëŠ”ê°€? default ë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•˜ê³  docstring(ë¬¸ì„œí™”) í•˜ì! í•¨ìˆ˜ ì •ì˜ ì‹œ ê¸°ë³¸ ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •í•˜ê³  ì´ì— ì‘ìš© ì›ë¦¬ì™€ ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë„ë¡ ë¬¸ì„œí™”í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. 123456789101112131415161718def get_log(mes, date=None): \"\"\"Log a message with a timestamp. Args: mes : message to print date : datetime of whe the message occured. Defaults to the present time. \"\"\" date = datetime.now() if date is None else date print('%s: %s'%(date, mes))get_log('Hi there!')time.sleep(0.1)get_log('Hi again!')&gt;&gt;&gt;2019-09-19 08:35:17.079609: Hi there!2019-09-19 08:35:17.180161: Hi again! íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë°”ë€ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤! ì´ì²˜ëŸ¼ Noneì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì¸ìˆ˜ê°€ ìˆ˜ì • ê°€ëŠ¥(Mutable)í•  ë•Œ ì¤‘ìš”í•˜ë‹¤ê³  í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì•„ë˜ í•¨ìˆ˜ë¥¼ ì‚´í´ë³´ì 123456789101112131415161718import jsondef decode(data, default=&#123;&#125;): try: return json.loads(data) except ValueError: return default test1 = decode('hi')test1['t']=10test2 = decode('hii')test2['t1']=100print('test1: ', test1)print('test2: ', test2)&gt;&gt;&gt;test1: &#123;'t': 10, 't1': 100&#125;test2: &#123;'t': 10, 't1': 100&#125; ì´ í•¨ìˆ˜ë„ ë§ˆì°¬ê°€ì§€ë¡œ get_log í•¨ìˆ˜ì™€ ê°™ì€ ë¬¸ì œê°€ ì¡´ì¬í•œë‹¤. ì›í–ˆë˜ ê²°ê³¼ëŠ” ê°ê° test1/test2 ì—ëŠ” tryë¶€ë¶„ì´ ì‹¤í–‰ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— print ë˜ëŠ” default ê°€ í•˜ë‚˜ì”© ì°í˜”ì–´ì•¼ í•œë‹¤. ì´ì²˜ëŸ¼ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ì›ì¸ì€ í•¨ìˆ˜ ì¸ìë¡œ ì„¤ì •í•œ dictionaryê°€ decode í˜¸ì¶œì—ì„œ ê³µìœ í•˜ê¸° ë•Œë¬¸ì´ë‹¤.ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê²ƒì€ default ì¸ìˆ˜ë¥¼ Noneìœ¼ë¡œ ë°›ê³  ë¬¸ì„œí™”í•˜ë©´ ëœë‹¤. 12345678910111213141516171819202122232425def updated_decode(data, default=None): \"\"\"Load JSON data from a string. Args: data : JSON data to decode default : Value to return if decoding fails. Defaults to an empty dictionary. \"\"\" if default is None: default = &#123;&#125; try: return json.loads(data) except ValueError: return defaulttest1 = updated_decode('hi')test1['t']=10test2 = updated_decode('hii')test2['t1']=100print('test1: ', test1)print('test2: ', test2)&gt;&gt;&gt;test1: &#123;'t': 10&#125;test2: &#123;'t1': 100&#125; Summary í•¨ìˆ˜ì˜ ê¸°ë³¸ ì¸ìˆ˜ëŠ” ëª¨ë“ˆ ë¡œë“œ ì‹œì ì— í•¨ìˆ˜ ì •ì˜ ê³¼ì •ì—ì„œ ë”± í•œ ë²ˆë§Œ í‰ê°€ëœë‹¤. í•¨ìˆ˜ì˜ ê¸°ë³¸ ì¸ìˆ˜ê°€ ë™ì ì¸ ê²½ìš°ì—ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ Noneì„ ì‚¬ìš©í•˜ì. ì´í›„ docstringì— ì‹¤ì œ ê¸°ë³¸ ë™ì‘ì„ ë¬¸ì„œí™”í•˜ì ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.09.19 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Python] ê°€ë³€ ìœ„ì¹˜ ì¸ìˆ˜ í™œìš©","slug":"python-better_way_18","date":"2019-09-17T15:00:00.000Z","updated":"2020-03-30T15:06:23.573Z","comments":true,"path":"python-better_way_18/","link":"","permalink":"https://jx2lee.github.io/python-better_way_18/","excerpt":"ì„ íƒì  ìœ„ì¹˜ ì¸ìˆ˜, \\args* ë¶ˆë¦¬ëŠ” star argsëŠ” í•¨ìˆ˜ì˜ í˜¸ì¶œì„ ë” ëª…í™•í•˜ê³  ê°€ë…ì„±ì„ ë†’ì¸ë‹¤. ë‹¤ìŒ ì•„ë˜ í•¨ìˆ˜ë¥¼ ë³´ì","text":"ì„ íƒì  ìœ„ì¹˜ ì¸ìˆ˜, \\args* ë¶ˆë¦¬ëŠ” star argsëŠ” í•¨ìˆ˜ì˜ í˜¸ì¶œì„ ë” ëª…í™•í•˜ê³  ê°€ë…ì„±ì„ ë†’ì¸ë‹¤. ë‹¤ìŒ ì•„ë˜ í•¨ìˆ˜ë¥¼ ë³´ì 123456789101112def get_log(mes, val): if not val: print(mes) else: val_str = ', '.join(str(x) for x in val) print('%s %s'%(mes, val_str))get_log('My numbers are', [1.2])get_log('Hi there', [])&gt;&gt;&gt;My numbers are 1.2Hi there í—ˆë‚˜, êµ³ì´ ë¡œê·¸ë¥¼ ë‚¨ê¸¸ ê°’ì´ ì—†ì„ ë•Œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì–´ì£¼ëŠ” ê²ƒì€ ì°¸ìœ¼ë¡œ ë¶ˆí¸í•œ ì§“ì´ë‹¤. ì´ëŸ¬í•œ ë¶ˆí¸í•¨ì„ í•´ì†Œí•˜ê¸° ìœ„í•´ * ê¸°í˜¸ë¥¼ ë§ˆì§€ë§‰ íŒŒë¼ë¯¸í„°ì— ë¶™ì´ë©´ ì´ ë³€ìˆ˜ëŠ” ì„ íƒì ì´ë‹¤. ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ë³´ì. 123456789def get_log(mes, *val): if not val: print(mes) else: val_str = ', '.join(str(x) for x in val) print('%s %s'%(mes, val_str))&gt;&gt;&gt;My numbers are [1.2]Hi there êµ³ì´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì–´ì£¼ì§€ ì•Šì•„ë„ í•¨ìˆ˜ê°€ ì•Œì•„ì„œ ì‘ë™í•œë‹¤. í•˜ì§€ë§Œ ê°€ë³€ ê°œìˆ˜ì˜ ìœ„ì¹˜ ë³€ìˆ˜ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  í•œë‹¤. return ê°’ì´ í•­ìƒ íŠœí”Œë¡œ ë°˜í™˜ generatorë¡œ ìƒì„±ëœ ëª¨ë“  ê°’ì„ ë‹´ìœ¼ë¯€ë¡œ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì°¨ì§€í•˜ëŠ” ë¬¸ì œì ì´ ìˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ë³´ì. 1234567891011def _generator(): for i in range(10): yield idef get_func(*args): print(args) it = _generator()get_func(*it)&gt;&gt;&gt;(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) ìœ„ì™€ ê°™ì´ ì…ë ¥ ìˆ˜ê°€ ì ë‹¤ë©´ì€ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ê¸°ë„ í•˜ë‹¤. í•˜ì§€ë§Œ ì…ë ¥ ìˆ˜ê°€ ë§ë‹¤ë©´ ìœ„ì™€ ê°™ì´ *args ë°©ë²•ì€ ë¹„íš¨ìœ¨ì ì¼ ê²ƒì´ë‹¤. ë‚˜ì¤‘ì— í•¨ìˆ˜ë¥¼ ê³ ì¹  ë•Œ ìƒˆ ìœ„ì¹˜ ì¸ìˆ˜ ì¶”ê°€ ë¶ˆê°€ëŠ¥ ì½”ë“œëŠ” ë°”ë€” ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ star agrsë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ì½”ë“œ ìˆ˜ì • ì‹œ ì•„ë˜ì™€ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. 123456789101112def get_log(seq, mes, *val): if not val: print('%s: %s'%(seq, mes)) else: val_str = ', '.join(str(x) for x in val) print('%s: %s: %s'%(seq, mes, val_str))get_log(1, 'My numbers are', 1, 2)get_log('Hi there', 1, 2)&gt;&gt;&gt;1: My numbers are: 1, 2Hi there: 1: 2 ì²« ë²ˆì§¸ í˜¸ì¶œê³¼ ë‘ ë²ˆì§¸ return ê°’ì´ ë‹¤ë¥¸ ì´ìœ ëŠ”, mesë¥¼ ì„œë¡œ ë‹¤ë¥´ê²Œ(â€˜My numbers areâ€™, 1) ë°›ì•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œê°€ ìƒê¸¸ ê°€ëŠ¥ì„±ì„ ì—†ì• ê¸° ìœ„í•´ì„œëŠ” *agrs ë¥¼ ë°›ëŠ” í•¨ìˆ˜ë¥¼ í™•ì¥í•  ë•Œ í‚¤ì›Œë“œ ì „ìš©(keyword-only) ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼í•œë‹¤. ì´ëŠ” Better Way 21ì—ì„œ ë‹¤ë£¨ë„ë¡ í•œë‹¤. Summary *args ë¥¼ ì´ìš©í•´ í•¨ìˆ˜ì—ì„œ ê°€ë³€ ê°œìˆ˜ì˜ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ *ê³¼ generatorë¥¼ í•¨ê»˜ ì‚¬ìš©í•œë‹¤ë©´ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆë‹¤ *args ë¥¼ ì´ìš©í•´ ë§Œë“  í•¨ìˆ˜ë¥¼ í™•ì¥í•  ë•Œ ë²„ê·¸ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤ ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.09.18 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Python] í‚¤ì›Œë“œ ì¸ìˆ˜ í™œìš©","slug":"python-better_way_19","date":"2019-09-17T15:00:00.000Z","updated":"2020-03-30T15:06:23.588Z","comments":true,"path":"python-better_way_19/","link":"","permalink":"https://jx2lee.github.io/python-better_way_19/","excerpt":"ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì¸ìˆ˜ë¥¼ ìœ„ì¹˜ë¡œ ì „ë‹¬ì´ ê°€ëŠ¥í•˜ë‹¤. ì•„ë˜ í•¨ìˆ˜ë¥¼ ë³´ì","text":"ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì¸ìˆ˜ë¥¼ ìœ„ì¹˜ë¡œ ì „ë‹¬ì´ ê°€ëŠ¥í•˜ë‹¤. ì•„ë˜ í•¨ìˆ˜ë¥¼ ë³´ì 12345678910111213141516def remainder(num, div): return num % divprint(remainder(20, 7))print(remainder(20, div=7))print(remainder(num=20, div=7))print(remainder(div=7, num=20))&gt;&gt;&gt;6666print(remainder(num=20, 7))&gt;&gt;&gt;SyntaxError: positional argument follows keyword argument ìœ„ ë„¤ ê°œ printëŠ” ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ë§Œ, ì•„ë˜ì˜ ê²½ìš° ìœ„ì¹˜ì¸ìˆ˜ë¥¼ í‚¤ì›Œë“œ ì¸ìˆ˜ ë’¤ì— ë°°ì¹˜í•  ê²½ìš° ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤. í‚¤ì›Œë“œ ì¸ìˆ˜ëŠ” ë‹¤ìŒ ì„¸ ê°€ì§€ ì¤‘ìš”í•œ ì´ì ì´ ìˆë‹¤ê³  í•œë‹¤. í•¨ìˆ˜ í˜¸ì¶œì„ ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤ í‚¤ì›Œë“œ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ê°ê°ì˜ ëª©ì ìœ¼ë¡œ ì–´ë–¤ parameterë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ ê³§ë°”ë¡œ ëª…í™•í•˜ê²Œ ì•Œ ìˆ˜ ìˆë‹¤. default ê°’ ì„¤ì •ì´ ê°€ëŠ¥ ì…ë ¥ ì¸ìˆ˜ë¥¼ ê¸°ë³¸ defaultë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ë³´ì 1234567891011def get_rate(wgt, time, period=1): return (wgt / time) * periodwgt = 0.5time = 3flow = get_rate(wgt, time)print('%.3f kg per second' % flow)flow = get_rate(wgt, time, period=3600)print('%.3f kg per second' % flow)&gt;&gt;&gt;0.167 kg per second period ì¸ìˆ˜ë¥¼ default 1ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. ì²« ë²ˆì¬ í˜¸ì¶œì—ì„œëŠ” periodë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ìë™ìœ¼ë¡œ 1ë¡œ ì…ë ¥ë°›ê³ , ë‘ ë²ˆì§¸ í˜¸ì¶œì—ì„œëŠ” 3600ì„ ì „ë‹¬ë°›ì•„ í˜¸ì¶œí•˜ì˜€ë‹¤. ì´ì²˜ëŸ¼ ì½”ë“œê°€ ê¹”ë”í•´ì§„ë‹¤. ê¸°ì¡´ í˜¸ì¶œ ì½”ë“œì™€ í˜¸í™˜ì„±ì„ ìœ ì§€-í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„° í™•ì¥ì´ ê°€ëŠ¥ ì´ëŠ” ë”±íˆ ì˜ˆì œê°€ í•„ìš”ì—†ì„ ê²ƒ ê°™ì•„ ë§ë¡œ í’€ê² ë‹¤. #2 ì™€ ë¹„ìŠ·í•œ í•­ëª©ìœ¼ë¡œ ê¸°ë³¸ default ì¸ìˆ˜ë¥¼ ì„¤ì •í•˜ë©´ íŒŒë¼ë¯¸í„° í™•ì¥ì´ ìš©ì´í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ ì±…ì—ì„œ ì£¼ì˜í•  ì ì€ ì„ íƒì  ì¸ìˆ˜ë¥¼ ìœ„ì¹˜ë¡œ ë„˜ê¸°ë©´ ì–´ë–¤ ì¸ìˆ˜ì¸ì§€ ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. ì´ë•Œ ê°€ì¥ ì¢‹ì€ ë°©ë²•ìœ¼ë¡œëŠ” í•­ìƒ í‚¤ì›Œë“œ ì´ë¦„ìœ¼ë¡œ ì„ íƒì  ì¸ìˆ˜ë¥¼ ì§€ì •í•˜ê³  ìœ„ì¹˜ ì¸ìˆ˜ë¡œëŠ” ì•„ì˜ˆ ë„˜ê¸°ì§€ ì•Šê²Œ í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤. Summary í•¨ìˆ˜ì˜ ì¸ìë¥¼ ìœ„ì¹˜ë‚˜ í‚¤ì›Œë“œë¡œ ì§€ì •ì´ ê°€ëŠ¥í•˜ë‹¤ í‚¤ì›Œë“œ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì¹˜ ì¸ìˆ˜ë§Œìœ¼ë¡œ ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤ í‚¤ì›Œë“œ ì¸ìˆ˜ì— default ê°’ì„ ì§€ì •í•˜ë©´ í™•ì¥ì´ ê°€ëŠ¥í•˜ë‹¤ ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.09.18 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Python] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ëŒ€ì‹  ì œë„¤ë ˆì´í„°","slug":"python-better_way_16","date":"2019-09-12T15:00:00.000Z","updated":"2020-03-30T15:06:23.569Z","comments":true,"path":"python-better_way_16/","link":"","permalink":"https://jx2lee.github.io/python-better_way_16/","excerpt":"ê²°ê³¼ ìƒì„± í•¨ìˆ˜ì—ì„œ íƒí•  ìˆ˜ ìˆëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ê²ƒì´ë‹¤. ì˜ˆë¡œ, ë¬¸ìì—´ì— í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•˜ê³ ì í•œë‹¤. append í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.","text":"ê²°ê³¼ ìƒì„± í•¨ìˆ˜ì—ì„œ íƒí•  ìˆ˜ ìˆëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ê²ƒì´ë‹¤. ì˜ˆë¡œ, ë¬¸ìì—´ì— í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•˜ê³ ì í•œë‹¤. append í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. 12345678910111213141516def get_word_index(text): result = [] if text: result.append(0) for idx, wd in enumerate(text): if wd == ' ': result.append(idx + 1) return resulttest = 'Four score and seven years ago...'result = get_word_index(test)print(result)&gt;&gt;&gt;[0, 5, 11, 15, 21, 27] í•˜ì§€ë§Œ ì´ í•¨ìˆ˜ëŠ” ë‘ ê°€ì§€ ë¬¸ì œì ì´ ìˆë‹¤ê³  í•œë‹¤ ì½”ë“œê°€ ë³µì¡í•˜ê³  ê¹”ë”í•˜ì§€ ì•Šë‹¤ ìƒˆë¡œìš´ ê²°ê³¼ë¥¼ ìƒì„±í•  ë•Œë§ˆë‹¤ append ë©”ì†Œë“œë¥¼ í˜¸ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ”ë° í•œ ì¤„, ë°˜í™˜í•˜ëŠ” ë°ë„ í•œ ì¤„..ì‘ì„±í•œ ì½”ë“œëŠ” ì „ì²´ 130ê°œ ìˆì§€ë§Œ ê·¸ ì¤‘ì—ì„œ ì¤‘ìš”í•œ ë¬¸ìëŠ” 75ê°œ ì •ë„ì´ë‹¤. ì´ëŸ¬í•œ í•¨ìˆ˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ì œë„¤ë ˆì´í„°(generator)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì‹¤ì œë¡œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ë°”ë¡œ ì´í„°ë ˆì´í„°(iterator)ë¥¼ ë°˜í™˜í•œë‹¤. ì´í„°ë ˆì´í„°(iteratorëŠ” ì œë„¤ë ˆì´í„°ê°€ ë‹¤ìŒ yield í‘œí˜„ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤. ì œë„¤ë ˆì´í„°ì—ì„œ yieldì— ì „ë‹¬í•œ ê°’ì„ ì´í„°ë ˆì´í„°ê°€ í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ë°˜í™˜í•œë‹¤.get_word_indexí•¨ìˆ˜ë¥¼ ì œë„¤ë ˆì´í„° í•¨ìˆ˜ë¡œ ìˆ˜ì •í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 123456789101112def get_word_index_2(text): if text: yield 0 for idx, wd in enumerate(text): if wd == ' ': yield idx + 1test = 'Four score and seven years ago...'result = list(get_word_index(test))print(result)&gt;&gt;&gt;[0, 5, 11, 15, 21, 27] get_word_index í•¨ìˆ˜ì™€ëŠ” ë‹¤ë¥´ê²Œ, index_2 í•¨ìˆ˜ëŠ” return ë˜ëŠ” iteratorë¥¼ listë¡œ ë„˜ê²¨ì£¼ë©´ ëœë‹¤. ë°˜í™˜ ì „ ëª¨ë“  ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•œë‹¤ ì…ë ¥ì´ ë§¤ìš° ë§ë‹¤ë©´ ë©”ëª¨ë¦¬ ê³ ê°ˆ -&gt; ë‹¤ìš´ë˜ëŠ” ì›ì¸ì´ ëœë‹¤.ë‹¤ìŒì€ fileì—ì„œ í•œ ì¤„ì”© ì½ì–´ì™€ ë‹¨ì–´ì˜ indexë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ generatorë¥¼ ì‚¬ìš©í•´ ì‘ì„±í•´ë³´ì 12345678910111213141516def index_file(handle): res = 0 for line in handle: yield res for wd in lune: offset += 1 if wd == ' ': yield resfrom itertools import islicewith open('./address.txt', 'r') as f: it = index_file(f) results = islice(it, 0) print(list(result))&gt;&gt;&gt;[0, 5, 11, 15, 21, 27] isliceëŠ” itertools ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ìˆëŠ” í•¨ìˆ˜ë¡œ, ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´(iterator)ë¥¼ sliceí•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.ìœ„ í•¨ìˆ˜ ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­ì€ ë°˜í™˜ë˜ëŠ” iteratorì—ì„œ ì¬ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤ëŠ” ì‚¬ì‹¤ì„ í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ë°˜ë“œì‹œ ì•Œì•„ì•¼ í•œë‹¤. ì´ëŠ” Better Way 17ì—ì„œ ë‹¤ë£° ì˜ˆì •ì´ë‹¤. Summary ì œë„¤ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ëˆ„ì ëœ ê²°ê³¼ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ return í•˜ëŠ” ê²ƒë³´ë‹¤ ë³´ê¸° ì´ì˜ë‹¤ generator í•¨ìˆ˜ return = yieldë¡œ ì „ë‹¬ëœ ê°’ë“¤ì˜ ì§‘.í•© generatorëŠ” ëª¨ë“  ì…ì¶œë ¥ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.09.13 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Python] ì¸ìˆ˜ë¥¼ ìˆœíšŒí•  ë•ŒëŠ” ë°©ì–´ì ìœ¼ë¡œ","slug":"python-better_way_17","date":"2019-09-12T15:00:00.000Z","updated":"2020-03-30T15:06:23.556Z","comments":true,"path":"python-better_way_17/","link":"","permalink":"https://jx2lee.github.io/python-better_way_17/","excerpt":"ì…ë ¥ê°’ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ëŠ” í•¨ìˆ˜ë¥¼ ìƒê°í•´ë³´ì. ì´ë•Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ìˆœíšŒí•´ì•¼ í•  ë•Œê°€ ì¢…ì¢… ìˆë‹¤.ì˜ˆë¥¼ ë“¤ì–´ ê° ë„ì‹œì˜ ë°©ë¬¸ì ìˆ˜ê°€ listë¡œ êµ¬ì„±ë˜ê³ , ê° ë„ì‹œì—ì„œ ì „ì²´ ì—¬í–‰ì ì¤‘ ëª‡ í¼ì„¼íŠ¸ë¥¼ ì°¨ì§€í•˜ëŠ”ì§€ return í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.","text":"ì…ë ¥ê°’ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ëŠ” í•¨ìˆ˜ë¥¼ ìƒê°í•´ë³´ì. ì´ë•Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ìˆœíšŒí•´ì•¼ í•  ë•Œê°€ ì¢…ì¢… ìˆë‹¤.ì˜ˆë¥¼ ë“¤ì–´ ê° ë„ì‹œì˜ ë°©ë¬¸ì ìˆ˜ê°€ listë¡œ êµ¬ì„±ë˜ê³ , ê° ë„ì‹œì—ì„œ ì „ì²´ ì—¬í–‰ì ì¤‘ ëª‡ í¼ì„¼íŠ¸ë¥¼ ì°¨ì§€í•˜ëŠ”ì§€ return í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 12345678910111213def normalize_pop(n): tot = sum(n) result = [] for val in n: per = 100 * val / tot result.append(per) return resultv = [15, 35, 80]portions = normalize_pop(v)print(portions)&gt;&gt;&gt;[11.538461538461538, 26.923076923076923, 61.53846153846154] ìœ„ì™€ ê°™ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ inputìœ¼ë¡œ ë°›ì§€ ì•Šê³  fileë¡œ ë°›ëŠ” í•¨ìˆ˜ë¥¼ ìƒê°í•´ë³´ë©´ generatorë¥¼ ì´ìš©í•´ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. 1234567891011def read_file(path): with open(path) as f: for line in f: yield int(line)it = read_file('./numbers.txt')portions = normalize_pop(it)print(portions)# ê³¼ì—° ê²°ê³¼ëŠ”?&gt;&gt;&gt;[] # ??? ê»ë°ê¸°ë§Œ ë‚˜ì˜¤ëŠ” ì´ìœ ëŠ”, iteratorëŠ” ê²°ê³¼ë¥¼ í•œ ë²ˆ ìƒì„±, ì¦‰ í•œ ë°”í€´ë¥¼ ë‹¤ ëŒê³ ë‚˜ë©´ ì¬ìƒì„±í•˜ì§€ ì•ŠëŠ” ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. 123456it = read_file('./numbers.txt')print(list(it), 'first')print(list(it), 'second') # secondë§Œ print, ì´ë¯¸ ì†Œì§„!&gt;&gt;&gt;[15, 35, 80] first[] second StopIterationì´ë¼ëŠ” ì—ëŸ¬ë¥¼ ë±‰ì–´ë‚¼ ì¤„ ì•Œì•˜ì§€ë§Œ ê·¸ëŸ¬í•œ ê²°ê³¼ëŠ” ì•Œë ¤ì£¼ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ìœ„ì™€ ê°™ì€ í•´ê²°ì„ ìœ„í•œ ë°©ì•ˆì€ ë‹¤ìŒê³¼ ê°™ì´ í¬ê²Œ ?ê°€ì§€ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤. case1) iteratorë¥¼ listë¡œ ì €ì¥ 1234567891011121314def normalize_pop_2(n): n = list(n) # iterator to list! tot = sum(n) result = [] for val in n: per = 100 * val / tot result.append(per) return resultit = read_file('./numbers.txt')portions = normalize_pop_2(it)print(portions)&gt;&gt;&gt;[11.538461538461538, 26.923076923076923, 61.53846153846154] í•˜ì§€ë§Œ ì´ ë°©ë²•ì˜ ê²½ìš° ë§Œì•½ listë¡œ ì €ì¥ë˜ëŠ” iteratorê°€ í¬ë‹¤ë©´ ë¬¸ì œê°€ ë°œìƒ í° iterator -&gt; í° list ì €ì¥ -&gt; ë©”ëª¨ë¦¬ ê³ ê°ˆ -&gt; ë‹¤ìš´! solution : í˜¸ì¶œ ë•Œë§ˆë‹¤ ìƒˆ iterator ë°˜í™˜..? case2) í˜¸ì¶œ ë•Œë§ˆë‹¤ iterator ë°˜í™˜ 123456789101112def normalize_pop_3(iter_): tot = sum(iter_()) result = [] for val in iter_(): per = 100 * val / tot result.append(per) return resultportions = normalize_pop_3(lambda: read_file('./numbers.txt'))print(portions)&gt;&gt;&gt;[11.538461538461538, 26.923076923076923, 61.53846153846154] ë§¤ë²ˆ iteratorë¥¼ ìƒì„±í•´ì•¼í•¨ ì…ë ¥ê°’ì„ lambdaë¥¼ ì´ìš©í•´ì•¼í•¨ìœ„ ë°©ë²•ì€ ì„¸ë ¨ë˜ì§€ ëª»í•œë‹¤ê³  ì±…ì—ì„œ ë§í•œë‹¤. ì´ì— ë§ˆì§€ë§‰ìœ¼ë¡œ iterator protocolì„ êµ¬í˜„í•œ ìƒˆ ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•œë‹¤. Iterator protocol ? 1234567891011121314class readVisits(object): def __init__(self, path): self.path = path def __iter__(self): with open(self.path) as f: for line in f: yield int(line)v = readVisits('./numbers.txt')portions = normalize_pop(v)print(portions)&gt;&gt;&gt;[11.538461538461538, 26.923076923076923, 61.53846153846154] normalize_pop ë‚´ sumì„ ìœ„í•´ __iter__ ë¥¼ í˜¸ì¶œ normalize_pop ë‚´ ì •ê·œí™”í•˜ëŠ” ê³¼ì •ì—ì„œ ë˜í•œ __iter__ ì„ í˜¸ì¶œì´ ë°©ë²•ì˜ ìœ ì¼í•œ ë‹¨ì ì€ ì…ë ¥ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë²ˆ ì½ì–´ë‚¸ë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ í•´ê²°ì„ ìœ„í•´ì„œëŠ” ì…ë ¥ê°’ì´ iteratorì¼ ê²½ìš° ì˜ˆì™¸ë¥¼ ì¼ìœ¼í‚¨ë‹¤. 123456789101112131415161718192021222324252627class readVisits(object): def __init__(self, path): self.path = path def __iter__(self): with open(self.path) as f: for line in f: yield int(line)def normalize_pop_final(n): if iter(n) is iter(n): raise TypeError('Must input be container') tot = sum(n) result = [] for val in n: per = 100 * val / tot result.append(per) return resultv = [15, 35, 80]normalize_pop_final(v) # no errorv = readVisits('./numbers.txt')normalize_pop_final(v) # no errorit = iter(v)normalize_pop_final(v)&gt;&gt;&gt;TypeError: Must input be container normalize_pop_finalì€ ì „ì²´ë¥¼ ë³µì‚¬í•˜ê³  ì‹¶ì§€ ì•Šì§€ë§Œ ì…ë ¥ê°’ì„ ì—¬ëŸ¬ ë²ˆ ìˆœíšŒí•´ì•¼ í•  ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤. Summary ì…ë ¥ê°’ì„ ì—¬ëŸ¬ ë²ˆ ìˆœíšŒí•˜ëŠ” í•¨ìˆ˜ëŠ” ì£¼ì˜í•˜ì iterator protocol : ì»¨í…Œì´ë„ˆì™€ iteratorê°€ ë‚´ì¥í•¨ìˆ˜ iter/nextì™€ for ë£¨í”„ ë° ê´€ë ¨ í¬í˜„ì‹ê³¼ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•œë‹¤ __iter__ ë©”ì„œë“œë¥¼ generatorë¡œ êµ¬í˜„í•˜ë©´ ìì‹ ë§Œì˜ iterable container typeì„ ì‰½ê²Œ ì •ì˜í•  ìˆ˜ ìˆë‹¤ ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.09.13 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Cloud] Kubernetes ê°œë… ë° ì•„í‚¤í…ì³","slug":"cloud-introduction_to_kubernetes","date":"2019-09-05T15:00:00.000Z","updated":"2020-03-30T15:06:23.590Z","comments":true,"path":"cloud-introduction_to_kubernetes/","link":"","permalink":"https://jx2lee.github.io/cloud-introduction_to_kubernetes/","excerpt":"ê³µìœ  ë° ì„¸ë¯¸ë‚˜ë¥¼ ìœ„í•´ Kubernetesë¥¼ ì •ë¦¬ ìµœê·¼ ì œí’ˆ ê´€ë ¨í•˜ì—¬ ì¿ ë²„ë„¤í‹°ìŠ¤ ì§€ì‹ì´ í•„ìš”í•˜ì—¬ ì„¸ë¯¸ë‚˜ë¥¼ ì¬ì‹œì‘ í•˜ì—¬ íŒ€ì›ë¶„ì´ ë°œí‘œí•œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚´ìš©ì„ ì¶”ê°€/ìˆ˜ì • í•˜ì˜€ë‹¤. (2020/01/10)","text":"ê³µìœ  ë° ì„¸ë¯¸ë‚˜ë¥¼ ìœ„í•´ Kubernetesë¥¼ ì •ë¦¬ ìµœê·¼ ì œí’ˆ ê´€ë ¨í•˜ì—¬ ì¿ ë²„ë„¤í‹°ìŠ¤ ì§€ì‹ì´ í•„ìš”í•˜ì—¬ ì„¸ë¯¸ë‚˜ë¥¼ ì¬ì‹œì‘ í•˜ì—¬ íŒ€ì›ë¶„ì´ ë°œí‘œí•œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚´ìš©ì„ ì¶”ê°€/ìˆ˜ì • í•˜ì˜€ë‹¤. (2020/01/10) Containerì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ê·¸ ì‹¤í–‰ì— í•„ìš”í•œ Library, Binary, êµ¬ì„± íŒŒì¼ ë“±ì„ íŒ¨í‚¤ì§€ë¡œ ë¬¶ì–´ ë°°í¬í•˜ëŠ” ê²ƒ ì»¨í…Œì´ë„ˆë¡œ ë¶ˆë¦¬ëŠ” ì´ìœ ëŠ” í”„ë¡œì„¸ìŠ¤ë“¤ì„ ì»¨í…Œì´ë„ˆí™” í•˜ì—¬ ê°™ì€ ë¦¬ëˆ…ìŠ¤ í˜¸ìŠ¤íŠ¸ë¥¼ ì“°ì§€ë§Œ ê²©ë¦¬ë˜ì–´ ìš´ì˜í•˜ê¸° ë•Œë¬¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ê²©ë¦¬í•˜ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” ë¦¬ëˆ…ìŠ¤ì—ì„œ ì»¨íŠ¸ë¡¤ ê·¸ë£¹ Cgroups ê³¼ ë¦¬ëˆ…ìŠ¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì´ìš©í•œ LXC (LInuX Containers) ìš´ì˜ì²´ì œ ë ˆë²¨ ê°€ìƒí™” ë³„ë„ì˜ ìš´ì˜ì²´ì—ì„œ í”„ë¡œì„¸ìŠ¤ê°€ ì‹¤í–‰ë˜ëŠ” ê°€ìƒë¨¸ì‹ ê³¼ ë‹¬ë¦¬ ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ëŠ” í˜¸ìŠ¤íŠ¸ì˜ ìš´ì˜ì²´ì œ ë‚´ë¶€ì—ì„œ ì‹¤í–‰í•˜ëŠ” êµ¬ì¡° í›¨ì”¬ ê°€ë³ê³  ìš´ì˜ì²´ì œ ì»¤ë„ì„ ê³µìœ í•˜ë©° ì‹œì‘ì´ ë¹ ë¦„ ìš´ì˜ì²´ì œ ì „ì²´ ë¶€íŒ…ë³´ë‹¤ ë©”ëª¨ë¦¬ë¥¼ ëœ ì‚¬ìš© DockerDockerëŠ” ì»¨í…Œì´ë„ˆ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ì—¬ëŸ¬ ì»´í“¨í„°ì— ì‰½ê²Œ ì´ì‹ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì‹œìŠ¤í…œ Docker íŒŒì¼ì„ ìƒì„±í•˜ì—¬ *â€ì–´ë–¤ SWë¥¼ ì»¨í…Œì´ë„ˆì— ë‹´ì•„ êµ¬ë™í•  ê²ƒì´ë‹¤â€* ëª…ì‹œí•˜ê³  ë¹Œë“œ ì´í›„ docker imageì— ë§ê²Œ docker container ìœ„ì— ìƒì„± Kubernetes (K8s) ì˜¤í”ˆì†ŒìŠ¤ ì»¨í…Œì´ë„ˆ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë„êµ¬ Declarative Orchestration ë‹¨ìˆœ ì‹¤í–‰ì´ ì•„ë‹Œ ì»¨í…Œì´ë„ˆì˜ ì‹¤í–‰ ìŠ¤ì¼€ì¥´ ê´€ë¦¬ ì»¨í…Œì´ë„ˆ ë°°ì¹˜, ìŠ¤ì¼€ì¼ë§, ìš´ì˜ ìë™í™” ê´€ë¦¬ Dockerì™€ Kubernetes ê´€ê³„ Docker : ì»¨í…Œì´ë„ˆ ìš´ì†¡ (ë¹Œë”© ë¸”ë¡) Kubernetes : ì»¨í…Œì´ë„ˆ ìš´ì†¡ì„ ì–´ìš°ë¥´ëŠ” ë¬¼ë¥˜ ì‹œìŠ¤í…œ Master &amp; Node í´ëŸ¬ìŠ¤í„° ì „ì²´ë¥¼ ê´€ë¦¬í•˜ëŠ” Masterì™€ ì»¨í…Œì´ë„ˆê°€ ë°°í¬ë˜ëŠ” ë¨¸ì‹  (ê°€ìƒ or ë¬¼ë¦¬ì  ë¨¸ì‹ ) ì¸ Nodeë¡œ Master ê´€ë¦¬ìë§Œ ì ‘ì†í•˜ì—¬ ë³´ì•ˆ ì„¤ì •ì´ í•„ìš” ë§ˆìŠ¤í„° ë‹¤ìš´ì´ ë°œìƒí•˜ë©´ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ì— ì¥ì• ê°€ ìƒê¸°ë¯€ë¡œ ë³´í†µ 3ëŒ€ë¡œ êµ¬ì„±í•˜ì—¬ í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì†Œê·œëª¨ í™˜ê²½ì—ì„œëŠ” ë§ˆìŠ¤í„°ì™€ ë…¸ë“œë¥¼ ë¶„ë¦¬í•˜ì§€ ì•Šê³  ê°™ì€ ì„œë²„ì— êµ¬ì„± ê´€ë¦¬ì˜ ì¸¡ë©´ë„ ìˆì§€ë§Œ í´ëŸ¬ìŠ¤í„° ì „ì²´ ë¦¬ì†ŒìŠ¤ ë°°ë¶„ì„ ìœ„í•´ íŒŒë“œë¥¼ ë„ìš¸ ìˆ˜ ìˆê²Œ ì„¤ì •ì´ ê°€ëŠ¥ (taint) Master component API server kubectl ìš”ì²­ ë° ë‚´ë¶€ ëª¨ë“ˆì˜ ìš”ì²­ ì²˜ë¦¬ ê¶Œí•œ ì²´í¬ë¥¼ í†µí•œ ìš”ì²­ í—ˆìš© ë° ê±°ë¶€ ì‹¤ì œë¡œëŠ” key-valueë¡œ ì €ì¥ëœ Etcdì— ì €ì¥ëœ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ì¡°íšŒ RESTful API ì œê³µ Etcd Kubernetes clusterì˜ DB ì—­í• ì„ í•˜ëŠ” ì„œë²„ë¡œ ì„¤ì •ê°’ì´ë‚˜ cluster ìƒíƒœë¥¼ ì €ì¥ etcdë¼ëŠ” ë¶„ì‚°í˜• key/value ìŠ¤í† ì–´ ì˜¤í”ˆì†ŒìŠ¤ ì´ìš© Etcd ë°±ì—…ì„ í†µí•´ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë³µêµ¬ê°€ ê°€ëŠ¥ API ì„œë²„ì™€ë§Œ í†µì‹  kube scheduler í• ë‹¹ì´ í•„ìš”í•œ Podë¥¼ ì—¬ëŸ¬ ì¡°ê±´(source, label)ì— ë”°ë¼ ì ì ˆí•œ ë…¸ë“œì— í• ë‹¹í•´ì£¼ëŠ” ëª¨ë“ˆ kube controller-manager K8s ëŒ€ë¶€ë¶„ì˜ object (Pod, ReplicaSet) ìƒíƒœ ê´€ë¦¬ Cloud controller-manager AWS, GCE, Azure ë“±ì˜ í´ë¼ìš°ë“œì— íŠ¹í™”ëœ ëª¨ë“ˆ ë…¸ë“œ ì¶”ê°€ ë° ì‚­ì œ, ë¡œë“œ ë°¸ëŸ°ì„œì™€ ë³¼ë¥¨ ì—°ê²° ê¸°ëŠ¥ Node Podë¥¼ ìƒì„±í•˜ê³  ë„¤íŠ¸ì›Œí¬ì™€ ë³¼ë¥¨ì„ ì„¤ì • ì‹¤ì œ ì»¨í…Œì´ë„ˆê°€ ìƒì„±ë˜ëŠ” ì„œë²„ ê° ì„œë²„ì— ë¼ë²¨ì„ ë¶™ì—¬ ì‚¬ìš©ëª©ì ì— ë”°ë¼ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ Node component kubelet ë…¸ë“œì— ë°°í¬ë˜ëŠ” ì—ì´ì „íŠ¸ë¡œ ë…¸ë“œì— í• ë‹¹í•œ Pod ìƒëª…ì£¼ê¸° ê´€ë¦¬ Pod ì•ˆ ì»¨í…Œì´ë„ˆ ìƒíƒœë¥¼ ì²´í¬í•˜ê³  ì£¼ê¸°ì ìœ¼ë¡œ Masterì— ì „ë‹¬ Masterì˜ APIì„œë²„ì™€ í†µì‹  ë° ë…¸ë“œê°€ ìˆ˜í–‰í•´ì•¼ í•  ëª…ë ¹ ìˆ˜í–‰ kube-proxy kubeletì´ podë¥¼ ê´€ë¦¬í•œë‹¤ë©´ kube-proxyëŠ” Podë¡œ ì—°ê²°ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ê´€ë¦¬ (ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ë¶„ì‚°) K8s ObjectKubernetsëŠ” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ëŒ€ìƒì„ Objectë¼ ì¹­í•˜ë©° í¬ê²Œ ê¸°ë³¸ ì˜¤ë¸Œì íŠ¸ì™€ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ êµ¬ë¶„ Pod Kubernetesì˜ ìµœì†Œ ì‹¤í–‰ ë‹¨ìœ„ KubernetesëŠ” ì»¨í…Œì´ë„ˆë¥¼ ê°œë³„ì ìœ¼ë¡œ ë°°í¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ Pod ë‹¨ìœ„ë¡œ ë°°í¬ í•­ìƒ ê°™ì€ Node ìœ„ì—ì„œ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ì»¨í…Œì´ë„ˆë“¤ Pod ë‚´ ë„¤íŠ¸ì›Œí¬ í™˜ê²½(IP, Port)ê³¼ ë””ìŠ¤í¬(Volume) ê³µìœ  A Container(Port 8080)ì™€ B Container(Port 7001)ê°€ í•˜ë‚˜ì˜ Podë¡œ ë°°í¬ë˜ì—ˆì„ë•Œ, localhostë¥¼ í†µí•´ í†µì‹ ì´ ê°€ëŠ¥ ë””ìŠ¤í¬ë¥¼ ê³µìœ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ë‘ ì„±ê²©ì˜ ì»¨í…Œì´ë„ˆë¥¼ ë°°í¬í•  ë•Œ íƒ€ ì»¨í…Œì´ë„ˆì˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆìŒ YAML / JSON í˜•ì‹ìœ¼ë¡œ ì„ ì–¸(config) Volume Container ì¬ì‹œì‘ì— ìƒê´€ì—†ì´ íŒŒì¼ì„ ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥í•´ì•¼í•˜ëŠ” ìŠ¤í† ë¦¬ì§€ Containerì˜ ì™¸ì¥ ë””ìŠ¤í¬ë¼ ìƒê°í•˜ê³ , Podì´ ê¸°ë™í•  ë•Œ ì»¨í…Œì´ë„ˆì—ì„œ ë§ˆìš´íŠ¸í•´ ì‚¬ìš© ReplicaSet Podë¥¼ ì—¬ëŸ¬ ê°œ ë³µì œí•˜ì—¬ ê´€ë¦¬í•˜ëŠ” ì˜¤ë¸Œì íŠ¸ Podë¥¼ ìƒì„±í•˜ê³  ê°œìˆ˜ë¥¼ ìœ ì§€í•˜ë ¤ë©´ ReplicaSet ì˜¤ë¸Œì íŠ¸ë¥¼ ì‚¬ìš©í•´ì•¼í•¨ ë³µì œ ìˆ˜, ë ˆì´ë¸”, ìƒì„±í•  Podì˜ í…œí”Œë¦¿ í¬í•¨ ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ë³´ë‹¨ Deployment ë“± ë‹¤ë¥¸ ì˜¤ë¸Œì íŠ¸ì— ì˜í•´ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ê°€ ë§ìŒ) Reference https://bcho.tistory.com/1256?category=731548 (https://www.slideshare.net/ext/devfair-kubernetes-101?qid=5ea32175-424b-4cda-b7b8-ccc96f01e7a5&amp;v=&amp;b=&amp;from_search=7 https://kubernetes.io/docs/concepts/architecture/cloud-controller/ 2019.09.06 made by jaejun.lee","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"}]},{"title":"[Etc] Sebastian Ruder Interview","slug":"etc-sebastian_interview","date":"2019-08-18T15:00:00.000Z","updated":"2020-03-30T15:06:23.541Z","comments":true,"path":"etc-sebastian_interview/","link":"","permalink":"https://jx2lee.github.io/etc-sebastian_interview/","excerpt":"Sebastian Ruder ì˜ ì¸í„°ë·°ë¥¼ ì •ë¦¬í•˜ì˜€ë‹¤ ì„¸ë°”ìŠ¤ì°¬ ë£¨ë” github : (https://github.com/sebastianruder) blog : (http://ruder.io/#open) í•«í•œ NLP ì—°êµ¬ì AYLIENì—ì„œ ë¦¬ì„œì¹˜ ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œ ì¼í•˜ë©° í˜„ì¬ PhD í•™ìƒ","text":"Sebastian Ruder ì˜ ì¸í„°ë·°ë¥¼ ì •ë¦¬í•˜ì˜€ë‹¤ ì„¸ë°”ìŠ¤ì°¬ ë£¨ë” github : (https://github.com/sebastianruder) blog : (http://ruder.io/#open) í•«í•œ NLP ì—°êµ¬ì AYLIENì—ì„œ ë¦¬ì„œì¹˜ ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œ ì¼í•˜ë©° í˜„ì¬ PhD í•™ìƒ QnANLP ì´ˆì‹¬ìë“¤ì—ê²Œ ì¡°ì–¸ì„ í•´ì¤„ ìˆ˜ ìˆê² ëŠ”ê°€?NLP-progress(http://nlpprogress.com/) ê°™ì€ ê³³ì—ì„œ ê´€ì‹¬ì´ ê°€ëŠ” ë¶„ì•¼ë¥¼ ì°¾ì•„ë¼. ë§Œì¼ ë‹¹ì‹ ì´ ë¦¬ì„œì¹˜ì— ê´€ì‹¬ì´ ìˆë‹¤ë©´, ë‹¤ë¥¸ ì‚¬ëŒì´ í•˜ì§€ ì•Šì€ íŠ¹ì •í•œ ì„¸ë¶€ ì£¼ì œë¥¼ ì°¾ì•„ë³´ë„ë¡ ë…¸ë ¥í•˜ë¼. ì˜ˆë¥¼ ë“¤ì–´ ê°ì • ë¶„ì„ì´ë¼ë©´ ì˜í™” ë¦¬ë·° ë¶„ì„ì„ í•˜ì§€ ë§ê³  ëŒ€í™”ë¥¼ ë¶„ì„í•˜ë¼. ìš”ì•½ì´ë¼ë©´ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ì§€ ë§ê³  ì˜í•™ ì €ë„ì„ ìš”ì•½í•˜ë¼. ê·¸ ë¶„ì•¼ì™€ ê´€ë ¨ëœ ë…¼ë¬¸ë“¤ì„ ì½ê³ , ê°€ì¥ ì²¨ë‹¨ì˜ ê¸°ìˆ ì´ ì–´ë– í•œ ì§€ë¥¼ ì´í•´í•˜ë¼. ë‹¹ì‹ ì´ ì§ì ‘ ëŒë ¤ë³¼ ìˆ˜ ìˆëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ êµ¬í˜„ì´ ìˆëŠ” ë¶„ì•¼ì´ë©´ ë” ì¢‹ë‹¤. ì–´ë–»ê²Œ ì´ëŸ¬í•œ ì‘ì—…ì´ ëŒì•„ê°€ëŠ”ì§€ë¥¼ ì˜ ì•Œê²Œ ë˜ì—ˆì„ ë•Œ, ì—°êµ¬ë¥¼ ìœ„í•´ì„œ ê·¸ ë…¼ë¬¸ì—ì„œ ë‹¹ì‹ ì„ ë†€ë¼ê²Œí•œ ì ì´ ìˆì—ˆëŠ”ì§€ë¥¼ ì˜ ìƒê°í•´ë³´ì•„ë¼. ê·¸ ëª¨ë¸ì´ ì–´ë– í•œ ì˜¤ë¥˜ë¥¼ ì €ì§ˆë €ëŠ” ì§€ë¥¼ ì´í•´í•˜ë ¤ ë…¸ë ¥í•˜ê³ , ì–´ë–»ê²Œ í•˜ë©´ ì´ë¥¼ ì¤„ì—¬ë³¼ ìˆ˜ ìˆì„ì§€ ìƒê°í•˜ë¼. ì–´ë– í•œ ëª¨ë¸ì´ íŠ¹ì •í•œ ì¢…ë¥˜ì˜ ì •ë³´ë¥¼ ì˜ ì¡ì•„ ë‚´ëŠ” ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì˜¤ë¥˜ ì ˆì œ í‰ê°€ë¥¼ í•´ë³´ê±°ë‚˜ í•©ì„± ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ë©´ ì¢‹ë‹¤. ë§Œì¼ ë‹¹ì‹ ì´ ê·¸ ë¬¸ì œë¥¼ ë” ë„ì „ì ìœ¼ë¡œ, í˜¹ì€ í˜„ì‹¤ì ìœ¼ë¡œ í•´ê²°í•´ë³¼ ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ê°€ ìˆë‹¤ë©´, ë°ì´í„° ì…‹ì„ ë§Œë“¤ê³  í˜„ì¡´í•˜ëŠ” ëª¨ë¸ì— ì ìš©í•´ë³´ë¼. ê·¸ë¦¬ê³  ë‹¤ì‹œ ê·¸ ë°ì´í„° ì…‹ì„ ë‹¹ì‹ ì˜ ì–¸ì–´ë¡œ ë§Œë“¤ì–´ë³´ë¼. ê·¸ë¦¬ê³  ê·¸ ëª¨ë¸ì´ ì—­ì‹œ ì˜ ì‘ë™í•˜ëŠ” ì§€ë¥¼ í™•ì¸í•˜ë¼. í”íˆ NLP ë¶„ì•¼ê°€ ì»´í“¨í„° ë¹„ì „ì— ë¹„í•´ ë’¤ì³ì¡Œë‹¤ê³ ë“¤ í•œë‹¤. í˜„ì¬ì˜ ìƒí™©ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê°€? NLP í˜„ì—…ìë¡œ ë›°ì–´ë“¤ê¸°ì— ì¢‹ì€ ì‹œê¸°ì¸ê°€?ë‚˜ëŠ” ì§€ê¸ˆì´ NLPì— ë›°ì–´ë“¤ê¸° ì¢‹ì€ ì‹œê¸°ë¼ ìƒê°í•œë‹¤. ìˆ˜ ë…„ì „ê³¼ ë¹„êµí•˜ë©´ ì„±ìˆ™ê¸°ì— ì ‘ì–´ë“¤ì—ˆë‹¤ê³  ë³¸ë‹¤. ë‹¨ìˆœíˆ ì›Œë“œ ì„ë² ë”©ì´ë‚˜ ê¸°ì¡´ì— ë‚˜ì˜¨ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ì œí•œë˜ì§€ ì•Šê³ , ë‹¤ì–‘í•œ ë¶€í’ˆë“¤ë¡œ ë‹¹ì‹ ë§Œì˜ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ í…Œë©´ ë‹¤ë¥¸ ì‹ ê²½ë§ ì¸µë“¤, ì‚¬ì „ í•™ìŠµëœ í‘œí˜„ë“¤, ë¶€ê°€ì ì¸ ë¡œìŠ¤ì˜ ì‚¬ìš© ë“±ì´ ìˆë‹¤. ë˜í•œ POS íƒœê¹…, ê°ì • ë¶„ì„ ë“± ê³ ì „ì ì¸ ë¬¸ì œë“¤ì´ ê±°ì˜ í•´ê²°ë˜ê³  ìˆë‹¤ëŠ” ì»¤ë®¤ë‹ˆí‹°ì˜ ë°˜ì‘ë„ ìˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ìš°ë¦¬ëŠ” ë” ì–´ë ¤ìš´ ë¬¸ì œë“¤ì—ì„œ ë°œì „ì„ ì´ë£¨ì–´ì•¼ë§Œ í•œë‹¤. ì´ë¥¼í…Œë©´ â€œì§„ì§œâ€ ìì—°ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•´ë‚´ëŠ” ì¼ë°˜í™”ëœ ëª¨ë¸ì´ ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ í’€ê¸° ìœ„í•´ì„  ë‚˜ëŠ” ìƒˆë¡œìš´ ì‚¬ëŒë“¤ì˜ ê´€ì ê³¼ ì•„ì´ë””ì–´ë“¤ì´ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•œë‹¤. ë§ë¶™ì—¬ ìš°ë¦¬ëŠ” ì´ì œ ë¶„ë¥˜ë‚˜ ë¬¸ì¥ ë¼ë²¨ë§ ë“±ì˜ ì‘ì—…ì„ ê½¤ ë†’ì€ ì •í™•ë„ë¡œ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ë“¤ì„ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë‹ˆ, ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì„ ë‹¤ë¥¸ ì–¸ì–´ì— ì ìš©í•´ ë³¼ ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ë§ì´ ìˆë‹¤. ë§Œì¼ ë‹¹ì‹ ì´ ë˜ ë‹¤ë¥¸ ì–¸ì–´ì˜ ì‚¬ìš©ìë¼ë©´, ë‹¹ì‹ ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ëª¨ë¸ í•™ìŠµê³¼ í‰ê°€ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì…‹ì„ ë§Œë“œëŠ” ê²ƒ ë§Œìœ¼ë¡œë„ í° ë³€í™”ë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. DL/ML ë¶„ì•¼ì—ì„œ ë§ì€ job ë“¤ì´ ì„ë°•ì‚¬ë‚˜ ì—°êµ¬ ê²½í—˜ì„ ìš”êµ¬í•œë‹¤. ë¨¸ì‹  ëŸ¬ë‹ì„ ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ë¡œ ê³ ë ¤í•˜ëŠ” ë…ìë“¤ì„ ìœ„í•´ì„œ, ì—°êµ¬ ê²½í—˜ì´ ë°˜ë“œì‹œ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ”ê°€?ë‚˜ëŠ” ë¦¬ì„œì¹˜ ê²½í—˜ì´ ë‹¹ì‹ ì´ íŠ¹ì • ëª¨ë¸ì— ëŒ€í•´ì„œ ì˜ ì•Œê³  ìˆëŠ”ì§€, ì°½ì˜ì ì¸ì§€, ìƒˆë¡œìš´ í•´ê²°ë°©ì•ˆì„ ìƒê°í•´ ë‚¼ ìˆ˜ ìˆì„ ë§Œí¼ í˜ì‹ ì ì¸ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì¢‹ì€ ì§€í‘œë¼ê³  ìƒê°í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ìŠ¤í‚¬ë“¤ì„ ìµíˆê¸° ìœ„í•´ì„œ PhDë‚˜ ë¦¬ì„œì¹˜ í ë¡œìš°ì‹­ì„ ì·¨ë“í•  í•„ìš”ëŠ” ì—†ë‹¤. ëŠ¥ë™ì ìœ¼ë¡œ ì›€ì§ì´ê³ , í¥ë¯¸ìˆëŠ” ë¶„ì•¼ì— ëŒ€í•´ì„œ ë°°ìš°ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ëª¨ë¸ì„ ê°œì„ í•˜ê³ , ë‹¹ì‹ ì˜ ê²½í—˜ì„ ê¸€ë¡œ ì“°ëŠ” ê²ƒì€ ì´ëŸ¬í•œ ìŠ¤í‚¬ë“¤ì„ í‚¤ìš°ê³  ì¦ëª…í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì´ë‹¤. í˜„ì¬ì˜ ML í™˜ê²½ì—ì„œ ë‹¹ì‹ ì€ ì™„ì „íˆ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ í’€ë„ë¡ ìš”êµ¬ë˜ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤. MLì´ë‚˜ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ëŒ€íšŒì— ì°¸ì—¬í•˜ëŠ” ê²ƒë„ ë¹„ìŠ·í•˜ê²Œ ë‹¹ì‹ ì´ ML ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‹¤ìš©ì ìœ¼ë¡œ ì ìš©í•˜ëŠ”ì§€ë¥¼ ì¦ëª…í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤. ë¦¬ì„œì¹˜ ë¶„ì•¼ì˜ í­ë°œì ì¸ ì„±ì¥ì„ ë†“ê³  ë´¤ì„ ë•Œ, ê°€ì¥ ì²¨ë‹¨ì˜ ê¸°ìˆ ë“¤ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ë”°ë¼ê°ˆ ìˆ˜ ìˆëŠ”ê°€?ë‚˜ëŠ” ë§¤ì¼ arXivì˜ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•œë‹¤. ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ë‚´ ì½ê¸° ëª©ë¡ì— ì¶”ê°€í•œ ë’¤ì— í•œë²ˆì— ì½ëŠ”ë‹¤. ì œí”„ ë”˜ì€ ìµœê·¼ Deep Learning Indabaì—ì„œ ì—´ ê°œ ë…¼ë¬¸ì˜ abstractë¥¼ ì½ëŠ” ê²ƒì´ í•œ ê°œ ë…¼ë¬¸ì„ ê¹Šì´ ìˆê²Œ ì½ëŠ” ê²ƒ ë³´ë‹¤ ë‚«ë‹¤ê³  í•œë‹¤. ì™œëƒë©´ ì–¸ì œë“  ë˜ëŒì•„ê°€ì„œ íŠ¹ì • ë…¼ë¬¸ì„ ê¹Šì´ ìˆê²Œ ì½ëŠ” ê²ƒì€ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì´ë‹¤.â€ê³  ë§í–ˆë‹¤. ê·¸ì˜ ë§ì— ë™ì˜í•˜ë©°, ìµœëŒ€í•œ ë„“ê²Œ ì½ì–´ë¼. ê·¸ë˜ì„œ ë‹¹ì‹ ì´ ëª©ë¡í™” í•  ìˆ˜ ìˆê³  ë‚˜ì¤‘ì— ì˜ê°ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ë¼. ì¢‹ì€ ë¬¸ì„œ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ê°–ëŠ” ê²ƒë„ í•µì‹¬ì´ë‹¤. ë‚˜ëŠ” Mendeleyë¥¼ ì‚¬ìš©í•´ì™”ë‹¤. ìµœê·¼ì—ëŠ” Arxiv Sanity Preserver(http://www.arxiv-sanity.com/recommend) ë¥¼ ì‚¬ìš©í•œë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•˜ê²Œ ë˜ì—ˆëŠ”ê°€? íŠ¹íˆ ì™œ ë”¥ ëŸ¬ë‹ê³¼ NLPì— ê´€ì‹¬ì„ ê°–ê²Œ ë˜ì—ˆëŠ”ê°€?ê³ ë“±í•™ìƒ ë•Œë¶€í„° ì–¸ì–´ì™€ ìˆ˜í•™ì— ê´€ì‹¬ì´ ìˆì—ˆê³ , ì—¬ëŸ¬ ëŒ€íšŒì— ì°¸ê°€í–ˆì—ˆë‹¤. ë‚´ í•™ì—…ì„ ìœ„í•´ì„œ ë‚˜ëŠ” ìˆ˜í•™ì˜ ë…¼ë¦¬ì™€ ì–¸ì–´ì˜ ì°½ì˜ì„±ì„ ê²°í•©í•˜ê³  ì‹¶ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ëŸ° ë¶„ì•¼ê°€ ì¡´ì¬í•˜ëŠ” ì§€ ëª°ëë‹¤. ê·¸ ë–„ ì „ì‚° ì–¸ì–´í•™ì´ë¼ëŠ”, ì»´í“¨í„° ê³¼í•™ê³¼ ì–¸ì–´í•™ì´ ì ì ˆí•˜ê²Œ êµì°¨í•˜ëŠ” ë¶„ì•¼ë¥¼ ì ‘í•˜ê²Œ ë˜ì—ˆë‹¤. ê·¸ë˜ì„œ ë…ì¼ ëŒ€í•™ì—ì„œ ì „ì‚° ì–¸ì–´í•™ í•™ì‚¬ë¥¼ ë•„ë‹¤. í•™ë¶€ìƒ ì‹œì ˆì— ë¨¸ì‹  ëŸ¬ë‹ì„ ì ‘í•˜ê²Œ ë˜ì—ˆê³ , ì¸í„´ì‰½ê³¼ ì˜¨ë¼ì¸ ê°•ì˜ë“¤ì„ í†µí•´ ìµœëŒ€í•œ ì§€ì‹ì„ ìŠµë“í–ˆë‹¤. word2vecì— ëŒ€í•´ ë“¤ì€ê±´ í•™ë¶€ë¥¼ ë§ˆì¹œ 2015ë…„ì´ì—ˆë‹¤. PhDë¥¼ ì‹œì‘í•˜ë©´ì„œ ë”¥ ëŸ¬ë‹ì— ëŒ€í•´ ì•Œê²Œ ë˜ì—ˆê³ , ì´ ë¶„ì•¼ì— ë”ìš± í¥ë¯¸ë¥¼ ê°€ì§€ê²Œ ë˜ì—ˆë‹¤. ì‚°ì—…ê³¼ ë¦¬ì„œì¹˜ ì¤‘ì—ì„œ ë¦¬ì„œì¹˜ë¥¼ íƒí•œ ì´ìœ ê°€ ìˆëŠ”ê°€?ì¡¸ì—… ì´í›„ì— ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ ì‚°ì—… ê²½í—˜ì„ ìŒ“ê³ ì í–ˆë‹¤. PhDëŠ” ë‚´ê°€ í•­ìƒ ê¿ˆê¾¸ë˜ ê²ƒì´ì—ˆì§€ë§Œ, ê·¸ ë‹¹ì‹œì—ëŠ” ì‹¬ê°í•˜ê²Œ ìƒê°í•˜ì§€ ì•Šì•˜ë‹¤. ë“€ë¸”ë¦°ì˜ NLP ìŠ¤íƒ€íŠ¸ì—… Aylienì—ì„œ ì¼í•˜ë©´ì„œ ê·¸ë“¤ì€ ë‚˜ì—ê²Œ ê³ ìš©ì´ ë³´ì¥ëœ PhD í”„ë¡œê·¸ë¨ì„ ì†Œê°œí•´ ì£¼ì—ˆê³ , ë‚˜ì—ê²Œ ì˜ ë“¤ì–´ë§ëŠ”ë‹¤ê³  ìƒê°í–ˆë‹¤. íšŒì‚¬ì—ì„œ ì¼í•˜ë©´ì„œ ë™ì‹œì— ì—°êµ¬ë¥¼ í•˜ëŠ” ê²ƒì€ ë§¤ìš° í˜ë“¤ì—ˆì§€ë§Œ, ê²°êµ­ ë‚˜ì—ê²Œ ëŒì•„ì˜¤ëŠ” ê²ƒì€ ë§ì•˜ë‹¤. ê°€ì¥ ì¤‘ìš”í•˜ê²Œë„, ë‚´ íšŒì‚¬ì™€ ì˜ ë§ì•˜ë‹¤. ì§€ê¸ˆê¹Œì§€ ì—°êµ¬ìë¡œ 3ë…„ê°„ ì¼í•´ì™”ë‹¤. ì´ ê¸°ê°„ë™ì•ˆ ë‹¹ì‹ ì˜ ìµœì•  í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì´ì—ˆëŠ”ê°€?ë°°ì›€ì˜ ê´€ì ì—ì„œëŠ” ì˜ ì•Œì§€ ëª»í•˜ëŠ” ë¶„ì•¼ì— ë›°ì–´ë“œëŠ” ê²ƒê³¼ ë…¼ë¬¸ë“¤ì„ ì½ëŠ” ê²ƒ, ê·¸ë¦¬ê³  í›Œë¥­í•œ ì‚¬ëŒë“¤ê³¼ í˜‘ì—…í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ë§¥ë½ì—ì„œ ì½”íœí•˜ê² ëŒ€í•™ì—ì„œ ì§„í–‰í–ˆë˜ multi-task learning í”„ë¡œì íŠ¸ê°€ êµ‰ì¥íˆ ìê·¹ì´ ë˜ëŠ” ê²½í—˜ì´ì—ˆë‹¤.ì˜í–¥ë ¥ì˜ ê´€ì ì—ì„œëŠ” fastai, ì œë ˆë¯¸ (fast ai ì°½ë¦½ì)ì™€ í˜‘ì—…í•˜ë©´ì„œ ê·¸ë“¤ì´ ì–´ë–»ê²Œ ìš°ë¦¬ì˜ ì–¸ì–´ ëª¨ë¸ì„ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ë¥¼ ë³¸ ê²ƒì´ë‹¤. ë‹¹ì‹ ì€ ë§¤ìš° í›Œë¥­í•œ ë¸”ë¡œê·¸ë¥¼ ê´€ë¦¬í–ˆë‹¤. ê¸°ìˆ ì ì¸ ê¸€ë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆëŠ” íŒë“¤ì´ ìˆëŠ”ê°€?ë‚˜ëŠ” ë‚´ ìì‹ ì´ íŠ¹ì •í•œ ì£¼ì œì— ëŒ€í•´ì„œ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ë¸”ë¡œê·¸ë¥¼ ì“¸ ë•Œ ì•„ì£¼ ì¢‹ì•˜ë˜ ê²½í—˜ì´ ìˆë‹¤. ë§Œì¼ ë‹¹ì‹ ì´ ì–´ë–¤ ì£¼ì œì— ëŒ€í•˜ì—¬ ë§ì€ ë¦¬ì„œì¹˜ë¥¼ í•˜ê±°ë‚˜ ì§ê´€ì„ ì–»ê³  ì‹¶ë‹¤ë©´, í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì•„ë¼. ê·¸ë¦¬ê³  ì´ê²ƒì€ í›—ë‚  ëˆ„êµ°ê°€ì˜ í•™ìŠµì„ ë”ìš± ë¹ ë¥´ê²Œ ë„ì™€ì¤„ ê²ƒì´ë‹¤. ì—°êµ¬ ë…¼ë¬¸ì—ì„œëŠ” ì§€ë©´ì´ ë¶€ì¡±í•˜ì—¬ ì¶©ë¶„íˆ ê¸€ë¡œì¨ ì„¤ëª…í•´ë‚´ì§€ ëª»í•˜ëŠ” ì¸¡ë©´ë“¤ì´ ìˆë‹¤. ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…ì€ ê¸°ìˆ ë“¤ì„ ë” ì ‘ê·¼í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì•„ì£¼ ì¢‹ì€ ë°©ë²•ì´ë‹¤. ë¸”ë¡œê·¸ì˜ ì¢‹ì€ ì ì€ ì™„ë²½í•˜ì§€ ì•Šì•„ë„ ì¢‹ë‹¤ëŠ” ì ì´ë‹¤. ë‹¹ì‹ ì€ ì´ë¥¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©í•´ë„ ì¢‹ê³ , ë‹¹ì‹ ì˜ ì•„ì´ë””ì–´ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì–»ê¸° ìœ„í•´ ì‚¬ìš©í•´ë„ ì¢‹ë‹¤. ê¸€ì„ ì“°ëŠ” ê´€ì ì—ì„œëŠ”, ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ëª…í™•í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•´ì•¼í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì• ë§¤ ëª¨í˜¸í•˜ì§€ ì•Šê³  ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” ê²ƒì— ëŒ€í•´ì„œë§Œ ì¨ë¼. ë§Œì¼ ì˜ì‹¬ìŠ¤ëŸ½ë‹¤ë©´ ëª…í™•í•˜ê²Œ noë¼ê³  ë§í•˜ë¼. ë‹¹ì‹ ì˜ ì´ˆê³ ì— ëŒ€í•´ì„œë„ ë‹¹ì‹ ì˜ ì¹œêµ¬ë“¤ì´ë‚˜ ë™ë£Œë“¤ì˜ í”¼ë“œë°±ì„ ë“¤ì–´ë¼. 100% ì™„ë²½í•˜ê²Œ ë§Œë“¤ë ¤ê³  ì• ì“°ì§€ ë§ì•„ë¼. ê·¸ëŸ¬ë‚˜ ë§Œì¡±í•  ë§Œí•œ ìˆ˜ì¤€ê¹Œì§€ëŠ” ëŒì–´ì˜¬ë ¤ì•¼í•œë‹¤. ê³µê°œ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œ ê±±ì •ì´ë˜ëŠ” ê²ƒì€ ë‹¹ì—°í•œ ê²ƒì´ë‹ˆ ë„ë§ì¹˜ì§€ ë§ë¼. ë¬´ì–¸ê°€ë¥¼ í¼ë¸”ë¦¬ì‹± í•œë‹¤ëŠ” ê²ƒì€ ì¥ê¸°ì ì¸ ê´€ì ì—ì„œ ë¶„ëª… ê°€ì¹˜ê°€ ìˆë‹¤. ë”¥ ëŸ¬ë‹ì´ ì–´ë ¤ìš´ ë¶„ì•¼ë¼ëŠ” ìƒê°ì— ì‹œì‘í•˜ê¸° ë§ì„¤ì´ëŠ” ì´ˆë³´ìë“¤ì„ ìœ„í•´ í•´ì£¼ê³  ì‹¶ì€ ë§ì€?ì•„ë¬´ë„ ë‹¹ì‹ ì—ê²Œ ë„Œ í•  ìˆ˜ ì—†ì–´ë¼ê³  ë§í•  ìˆ˜ ì—†ë‹¤. ì˜¨ë¼ì¸ ìˆ˜ì—…ë“¤ì„ ë“£ê³  ì´í•´í•˜ë¼. ê¸°ë³¸ì ì¸ ì§€ì‹ë“¤ì— ìµìˆ™í•´ì§€ë©´ ì‹œê°„ì´ ë  ë•Œë§ˆë‹¤ ì˜ê°ì„ ìœ„í•´ ë…¼ë¬¸ë“¤ì„ ì½ì–´ë¼. í¥ë¯¸ë¡œìš´ ë¶„ì•¼ë¥¼ ì„ íƒí•˜ê³ , ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„ íƒí•˜ê³  ì§„í–‰í•´ë³´ë¼. ë‹¹ì‹ ì´ ì˜ë¯¸ìˆëŠ” ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ê±°ëŒ€í•œ ì»´í“¨í„°ê°€ ìˆì–´ì•¼ ëœë‹¤ëŠ” ìƒê°ì„ ë²„ë ¤ë¼. íŠ¹íˆ NLP ë¶„ì•¼ì—ì„œëŠ” ë¼ë²¨ë§ ëœ ì˜ˆì‹œì˜ ìˆ˜ê°€ ì ì€ ë¬¸ì œë“¤ì´ ë§ì´ ìˆë‹¤. ë‹¹ì‹ ì´ í•˜ê³  ìˆê³  ë°°ìš°ê³  ìˆëŠ” ê²ƒì— ëŒ€í•´ì„œ ì¨ë¼. ë¹„ìŠ·í•œ ê´€ì‹¬ì‚¬ê°€ ìˆëŠ” ì‚¬ëŒë“¤ì„ ë§Œë‚˜ë¼. ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•˜ê³ , íŠ¹íˆ fast aiëŠ” ì¢€ ì©ë‹¤. íŠ¸ìœ„í„°ë¥¼ í•˜ë¼. íŠ¸ìœ„í„°ëŠ” í›Œë¥­í•œ ML ì»¤ë®¤ë‹ˆí‹°ì´ë‹¤. ë‹¹ì‹ ì€ íƒ‘ ì—°êµ¬ìë“¤ë¡œë¶€í„° ì´ë©”ì¼ë³´ë‹¤ ë¹¨ë¦¬ ë‹µì¥ì„ ë°›ì„ ìˆ˜ë„ ìˆë‹¤. ë©˜í† ë¥¼ ì°¾ìœ¼ë¼. ë§Œì¼ ëˆ„êµ°ê°€ì—ê²Œ ì¡°ì–¸ì„ êµ¬í•˜ê¸° ìœ„í•´ ì´ë©”ì¼ì„ ì“´ë‹¤ë©´, ê·¸ë“¤ì´ ë°”ì˜ë‹¤ëŠ” ê²ƒì„ ê³ ë ¤í•˜ë¼. ì¡´ì¤‘í•˜ê³  ë‹¤ë¥¸ ì´ë“¤ì„ ë„ì™€ë¼. ì¹­ì°¬ì„ ë§ì´ í•˜ê³ , ë¹„í‰í•  ë•ŒëŠ” ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ í•˜ë¼. END 2019.08.09 made by jaejun.lee","categories":[{"name":"Etc","slug":"Etc","permalink":"https://jx2lee.github.io/categories/Etc/"}],"tags":[{"name":"Review","slug":"Review","permalink":"https://jx2lee.github.io/tags/Review/"}]},{"title":"[Etc] How to Read Research Papers","slug":"etc-how_to_read_research","date":"2019-08-08T15:00:00.000Z","updated":"2020-03-30T15:06:23.527Z","comments":true,"path":"etc-how_to_read_research/","link":"","permalink":"https://jx2lee.github.io/etc-how_to_read_research/","excerpt":"Siraj Ravalì˜ research paperë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³´ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤","text":"Siraj Ravalì˜ research paperë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³´ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤ SirajëŠ” ë‹¤í–‰íˆ í•™ìœ„ ì†Œì§€ìê°€ ì•„ë‹ˆë‹¤. ì¦‰, í•™ìœ„ ì†Œì§€ìê°€ ì•„ë‹ˆì–´ë„ ì¶©ë¶„íˆ research ë…¼ë¬¸ì„ ì´í•´í•  ìˆ˜ ìˆê³  ì ‘í•  ìˆ˜ ìˆë‹¤. SirajëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë…¼ë¬¸ì„ ì¦ê²¨ ì½ëŠ”ë‹¤ê³  í•œë‹¤. SirajëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„¸ ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ë¡œ ë…¼ë¬¸ì„ ì´í•´í•˜ê³  ì½ëŠ”ë‹¤ê³  í•œë‹¤. ì´ ë°©ì‹ìœ¼ë¡œ ì¼ì£¼ì¼ì— ì•½ 10-20í¸ì˜ ë…¼ë¬¸ì„ ì†Œí™”í•œë‹¤ê³  í•œë‹¤. ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ í¬ê¸°í•˜ì§€ ì•ŠëŠ” ë§ˆìŒê°€ì§ì´ë©°, ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ discussioní•´ì•¼ í•œë‹¤ê³  ë§í•œë‹¤. 3-PASS Approachë…¼ë¬¸ì„ ê°€ë³ê²Œ íŒŒì•… ë…¼ë¬¸ ì œëª© / Abstract ë¨¼ì € ì½ê¸° Introduction ì‹ ì¤‘íˆ ì½ê¸° Section / Sub-sectionì˜ ê²½ìš° íƒ€ì´í‹€ë§Œ ì½ê³  PASS Conclusion ì‹ ì¤‘íˆ ì½ê¸° ì´ì™¸ ìˆ˜í•™ì ì¸ ë¶€ë¶„ì€ ì™„ì „íˆ ë¬´ì‹œ 1ë‹¨ê³„ì—ì„œëŠ” ìˆ˜í•™ì ì¸ ë¶€ë¶„ì€ PASS googlingì„ í†µí•´ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë¦¬ë·°í•œ ë‚´ìš©ì„ ì‚´í´ë³´ê³  ë‚´ ì˜ê²¬ê³¼ ë¹„êµí•´ë³´ê¸° (using reddit) High-level ì´í•´ 1ë‹¨ê³„ë³´ë‹¤ ë” deepí•˜ê²Œ ì½ê¸° ë¬¸ì¥ì„ ëª¨ë‘ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì‹ì„ ì •í™•íˆ ì´í•´í•˜ì§€ëŠ” ì•Šìœ¼ë‚˜ ì›ë¦¬ëŠ” ì´í•´í•˜ê³  ë„˜ì–´ê°€ê¸° ì†ŒìŠ¤ì½”ë“œê°€ ìˆë‹¤ë©´ ì†ŒìŠ¤ ë° ë¬¸ì„œë¥¼ ì½ì–´ë³´ê³  ì½”ë“œ ì‹¤í–‰ ë° ì¬í˜„í•´ë³´ê¸° ìˆ˜ì‹ì„ í†µí•´ ì´í•´ ì§€ê¸ˆê¹Œì§€ ì´í•´í•œ ë‚´ìš©ì„ ë¬¸ì„œë¡œ ì •ë¦¬í•˜ì—¬ ëˆ„êµ°ê°€ì—ê²Œ ì„¤ëª…ì´ ê°€ëŠ¥í•  ì •ë„ë¡œ ì •ë¦¬í•˜ê¸° ìˆ˜ì‹ì„ ìŠ¤ìŠ¤ë¡œ í’€ì–´ë³´ê³  ì™„ë²½íˆ ì´í•´í•˜ê¸° ìˆ˜ì‹ì˜ ë‚´ìš©ì„ ìŠ¤ìŠ¤ë¡œ í”„ë¡œê·¸ë˜ë°í•˜ë©° ìˆ˜ì‹ ì™„ë²½íˆ ì´í•´í•˜ê¸° summaryì •ë§ ì–´ë ¤ìš´ ê³¼ì •ì´ì§€ë§Œ ì •ë§ íš¨ê³¼ì ì¸ ë°©ë²•ì¸ ê²ƒ ê°™ë‹¤. íŠ¹íˆ, ìš°ë¦¬ê°€ ë¬´ì‹¬ì½” ë„˜ì–´ê°€ëŠ” ìˆ˜ì‹ ì™„ë²½íˆ ì´í•´í•˜ê¸°ëŠ” ì²˜ìŒì—ëŠ” ì–´ë µê³  ê·€ì°®ì„ ìˆ˜ ìˆì§€ë§Œ ë…¼ë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ê³  ì´ë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ì§€ì‹ì„ ìŒ“ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤. ì´ëŸ¬í•œ í”„ë¡œì„¸ìŠ¤ë„ ë„ì›€ì´ ë˜ì§€ë§Œ ë‚˜ë§Œì˜ ë…¼ë¬¸ ì½ëŠ” ë…¸í•˜ìš°ë¥¼ ìµíˆê³  ì‹¶ë‹¤. 2019.08.09 made by jaejun.lee","categories":[{"name":"Etc","slug":"Etc","permalink":"https://jx2lee.github.io/categories/Etc/"}],"tags":[{"name":"Review","slug":"Review","permalink":"https://jx2lee.github.io/tags/Review/"}]},{"title":"[Python] í´ë¡œì €ê°€ ë³€ìˆ˜ ìŠ¤ì½”í”„ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë°©ë²•","slug":"python-better_way_15","date":"2019-08-07T15:00:00.000Z","updated":"2020-03-30T15:06:23.546Z","comments":true,"path":"python-better_way_15/","link":"","permalink":"https://jx2lee.github.io/python-better_way_15/","excerpt":"í´ë¡œì €ê°€ ë³€ìˆ˜ ìŠ¤í¬í¬ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.","text":"í´ë¡œì €ê°€ ë³€ìˆ˜ ìŠ¤í¬í¬ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤. ìˆ«ì listë¥¼ ì •ë ¬í•  ë•Œ ì¼ì • ìˆ«ìë“¤ì„ ë¨¼ì € ì •ë ¬í•˜ê³ ì í•œë‹¤. ì´ëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ í‘œí˜„í•˜ê±°ë‚˜, ì¤‘ìš” ë©”ì„¸ì§€ ë˜ëŠ” ì˜ˆì™¸ ì´ë²¤íŠ¸ë¥¼ ë¨¼ì € ë³´ì—¬ì¤„ ë•Œ ìœ ìš©í•˜ë‹¤. ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œëŠ” listì˜ sort methodì— helper functionì„ key ë³€ìˆ˜ë¡œ ë„˜ê¸°ëŠ” ê²ƒì´ë‹¤. helper functionì˜ return ê°’ì€ ìˆ«ìë¥¼ ì •ë ¬í•˜ëŠ” ì‚¬ìš©ëœë‹¤. ë‹¤ìŒ ì½”ë“œë¥¼ í™•ì¸í•´ë³´ì. 12345678910111213def sort_priority(values, group): def helper(x): if x in group: return (0, x) return (1, x)numbers = [8, 3, 1, 2, 5, 4, 7, 6]group = &#123;2, 3, 5, 7&#125;sort_priority(numbers, group)print(numbers)&gt;&gt;&gt;[2, 3, 5, 7, 1, 4, 6, 8] ìœ„ í•¨ìˆ˜ê°€ ë™ì‘í•˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. pythonì€ closureë¥¼ ì§€ì›, closureë€ ìì‹ ì´ ì •ì˜ëœ ìŠ¤ì½”í”„ì— ìˆëŠ” ë³€ìˆ˜ë¥¼ ì°¸ì¡°í•˜ëŠ” í•¨ìˆ˜ë‹¤. ì´ ë•Œë¬¸ì— helper functionì´ sort_priorityì˜ groupì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. summary Noneì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ëŠ” None ì´ë‚˜ ë‹¤ë¥¸ ê°’ì´ ì¡°ê±´ì‹ì—ì„œ Falseë¡œ í‰ê°€ë˜ê¸° ë•Œë¬¸ì— ì‰½ê²Œ ì˜¤ë¥˜ë¥¼ ë²”í•  ìˆ˜ ìˆë‹¤. íŠ¹ë³„í•œ ìƒí™©ì„ ì•Œë¦´ ë•ŒëŠ” None ëŒ€ì‹  ì˜ˆì™¸ë¥¼ ì¼ìœ¼í‚¤ì. ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.08.08 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Python] Noneì„ ë°˜í™˜í•˜ê¸°ë³´ë‹¤ ì˜ˆì™¸ ë°œìƒ","slug":"python-better_way_14","date":"2019-08-05T15:00:00.000Z","updated":"2020-03-30T15:06:23.586Z","comments":true,"path":"python-better_way_14/","link":"","permalink":"https://jx2lee.github.io/python-better_way_14/","excerpt":"í•¨ìˆ˜ë¥¼ ì´ìš©í•´ Noneì„ ë°˜í™˜í•˜ê¸°ë³´ë‹¤ëŠ” ì˜ˆì™¸ë¥¼ ì¼ìœ¼í‚¤ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤","text":"í•¨ìˆ˜ë¥¼ ì´ìš©í•´ Noneì„ ë°˜í™˜í•˜ê¸°ë³´ë‹¤ëŠ” ì˜ˆì™¸ë¥¼ ì¼ìœ¼í‚¤ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë¨¸ë“¤ì€ ë³´í†µ Noneê°’ì— íŠ¹ë³„í•œ ì˜ë¯¸ë¥¼ ë¶€ì—¬í•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‚˜ëˆ—ì…ˆì„ ìˆ˜í–‰í•˜ëŠ” í—¬í¼í•¨ìˆ˜ë¥¼ ìƒê°í•´ë³´ì. 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²½ìš°ëŠ” ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Noneì„ ë°˜í™˜í•˜ëŠ” ê²Œ ìì—°ìŠ¤ëŸ½ë‹¤. 12345def divide(a,b): try: return a / b except ZeroDivisionError: return None ë°˜í™˜ ê°’ì„ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„í•  ìˆ˜ ìˆë‹¤. 123result = divide(x, y)if result is None: print('Invalid inputs') í•˜ì§€ë§Œ ë¶„ìê°€ 0, ì¦‰ ë‚˜ëˆ„ëŠ” ìˆ«ìë¥¼ 0ìœ¼ë¡œ í•˜ë©´?ì´ëŸ° ê²½ìš° ifë¬¸ìœ¼ë¡œ ê²°ê³¼ë¥¼ í‰ê°€í•  ë•Œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‹¤.ì¡°ê±´ì„ Noneì´ ì•„ë‹Œ Falseë¡œ ê²€ì‚¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. 1234x, y = 0, 5result = divide(x, y)if no result: print('Invalid inputs') # wrong! ìœ„ ì˜ˆëŠ” Noneì— íŠ¹ë³„í•œ ì˜ë¯¸ë¥¼ ë¶€ì—¬í•  ë•Œ íŒŒì´ì¬ ì½”ë“œì—ì„œ í”íˆ í•˜ëŠ ì‹¤ìˆ˜ë¼ê³  í•œë‹¤.ì´ëŸ¬í•œ ì‹¤ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë‘ ê°€ì§€ë¡œ ì„¤ëª…í•œë‹¤. ë°˜í™˜ ê°’ì„ ë‘ ê°œë¡œ ë‚˜ëˆ  íŠœí”Œì— ë‹´ìíŠœí”Œì˜ ì²« valueëŠ” ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤€ë‹¤. ë‘ ë²ˆì§¸ ê°’ì€ ê³„ì‚°ëœ ì‹¤ì œ ê²°ê³¼ë‹¤. 123456789def divide(a, b): try: return True, a / b except ZeroDivisionError: return False, Nonesuccess, result = divide(x, y)if no success: print('Invalid inputs') í—ˆë‚˜ ì´ ë°©ë²•ì€ íŠœí”Œ ì²« ê°’ì„ ì‰½ê²Œ ë¬´ì‹œí•  ìˆ˜ ìˆë‹¤(ê°€ë ¹ _ì„ ì´ìš©í•´ ë¬´ì‹œ ê°€ëŠ¥).ê²‰ë³´ê¸°ì—ëŠ ì˜ëª»ëœ ê²ƒ ê°™ì§€ ì•Šì§€ë§Œ ê·¸ëƒ¥ Noneì„ ë°˜í™˜í•˜ëŠ” ê²ƒë§Œí¼ ë‚˜ì˜ë‹¤. 123_, result = divide(x, y)if no result: print('Invalid inputs') ì ˆëŒ€ë¡œ Noneì„ ë°˜í™˜í•˜ì§€ ë§ì! -&gt; í˜¸ì¶œ í•¨ìˆ˜ì—ì„œ ì˜ˆì™¸ ì¼ìœ¼í‚¤ê¸°ì €ìëŠ” Noneì„ ì ˆëŒ€ë¡œ ë°˜í™˜í•˜ì§€ ì•ŠëŠ” ë°©ë²•ì„ ì¶”ì²œí•œë‹¤. ì¦‰, í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ ë‚´ì—ì„œ ì˜ˆì™¸ë¥¼ ì¼ìœ¼ì¼œZeroDivisionErrorì„ ValueErrorë¡œ ë³€ê²½í•˜ëŠ” ê²ƒì´ë‹¤. 12345def divide(a, b): try: return a / b except ZeroDivisionError as e: raise ValueError('Invalid inputs') from e ìœ„ì™€ ê°™ì´ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ë©´ í•¨ìˆ˜ì˜ ë°˜í™˜ ê°’ì„ ì¡°ê±´ì‹ìœ¼ë¡œ ê²€ì‚¬í•  í•„ìš”ê°€ ì—†ë‹¤. 1234567x, y = 0, 10try: result = divide(x, y)except ValueError: print('Invalid inputs')else: print('Result is %.1f' % result) summary Noneì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ëŠ” None ì´ë‚˜ ë‹¤ë¥¸ ê°’ì´ ì¡°ê±´ì‹ì—ì„œ Falseë¡œ í‰ê°€ë˜ê¸° ë•Œë¬¸ì— ì‰½ê²Œ ì˜¤ë¥˜ë¥¼ ë²”í•  ìˆ˜ ìˆë‹¤. íŠ¹ë³„í•œ ìƒí™©ì„ ì•Œë¦´ ë•ŒëŠ” None ëŒ€ì‹  ì˜ˆì™¸ë¥¼ ì¼ìœ¼í‚¤ì. ì°¸ì¡° : (http://www.yes24.com/Product/goods/25138160) 2019.08.07 made by jaejun.lee","categories":[{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"}],"tags":[{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"}]},{"title":"[Database] Connect to Tibero using Python","slug":"database-connect_to_tibero_using_python","date":"2019-08-01T15:00:00.000Z","updated":"2020-09-24T14:34:37.718Z","comments":true,"path":"database-connect_to_tibero_using_python/","link":"","permalink":"https://jx2lee.github.io/database-connect_to_tibero_using_python/","excerpt":"docker imageë¡œ ë„ìš´ Python ì—ì„œ Tibero ì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤.","text":"docker imageë¡œ ë„ìš´ Python ì—ì„œ Tibero ì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¬ë‹¤. Preliminariespython ì€ ì´ë¯¸ ì„¤ì¹˜ëœ ê²ƒì„ ì „ì œiodbc Containerì— tibero clientê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì • tibero clientê°€ ì—†ë‹¤ë©´ ì„œë²„ì— ìˆëŠ” tibero6 ë³µì‚¬ tbdsn.tbr ì— í˜¸ìŠ¤íŠ¸ë¥¼ ì°¸ì¡°í•˜ê³ ìí•˜ëŠ” Tibero ipë¡œ ë³€ê²½ $TB_HOME/client/lib(ë˜ëŠ” $TB_HOME/client/lib32) ë””ë ‰í„°ë¦¬ì— libtbodbc.so íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ http://iodbc.org ì—ì„œ ë‹¤ìš´ë¡œë“œ tar íŒŒì¼ì„ ì„¤ì¹˜ ë””ë ‰í† ë¦¬ì— ì˜®ê¸´ í›„ makeë¥¼ ì´ìš©í•´ build í•œë‹¤. 1234567$ ./configure --prefix=/app/odbc/iodbc --disable-gui$ make$ make install......$ file /app/odbc/lib/libtbodbc.so$ file /app/odbc/lib/libiodbcinst.so.2.1.18 unixODBC-develapt-get install unixodbc-dev ~/.profile12345678910111213## Tibero RDBMS 6 Client ENV ##export TB_HOME=/app/tibero6export TB_SID=tiberoexport TB_PROF_DIR=$TB_HOME/bin/profexport PATH=$TB_HOME/bin:$TB_HOME/client/bin:$PATHexport LD_LIBRARY_PATH=$TB_HOME/lib:$TB_HOME/client/lib:$LD_LIBRARY_PATHexport TB_NLS_LANG=UTF8export TBCLI_WCHAR_TYPE=UCS2## IODBC ENV ##export IODBC_HOME=/app/odbc/iodbcexport LD_LIBRARY_PATH=$IODBC_HOME/lib:$LD_LIBRARY_PATHexport PATH=$IODBC_HOME/bin:$PATH Set DSN$HOME/odbc.ini íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•œë‹¤ 1234567891011[ODBC Data Sources]tibero6 = Tibero6 ODBC driver[ODBC]Trace = 1TraceFile = /tmp/odbc.trace[tibero6]Driver = /app/tibero6/client/lib/libtbodbc.soDescription = Tibero6 ODBC DatasourceSID = tibero156 # tbdsn.tbr íŒŒì¼ì— ì„¤ì •í•œ DSN ì •ë³´User = erpPassword = xxxxx isqlë¥¼ í†µí•´ ì ‘ì†ì´ ë˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì¡°íšŒí•´ë³¸ë‹¤. 1234567891011121314151617$ isql -v tibero6+---------------------------------------+| Connected! || || sql-statement || help [tablename] || quit || |+---------------------------------------+SQL&gt; select count(*) from BPRJT00T;+------------------------------------------------------+| COUNT(*) |+------------------------------------------------------+| 56125 |+------------------------------------------------------+SQLRowCount returns 11 rows fetched .py1234567891011121314151617181920import pyodbctry: # db connection dbuser = 'erp' dbpw = 'tibero' conn = pyodbc.connect('DSN=tibero6;UID=' + dbuser + ';PWD=' + dbpw) cur = conn.cursor() stmt = \"SELECT COUNT(*) FROM BPRJT00T;\" rows = cur.execute(stmt) for row in rows: print (row) # db connection close cur.close() conn.close()except Exception as ex: print(ex) 12root@ff5f929d7f7f:~# python3 test2.py (56125.0, ) .py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì§€ë§Œ, Notebookì„ ì´ìš©í•˜ë©´ Data Sourceë¥¼ ì°¾ì§€ ëª»í•œë‹¤ëŠ” ì—ëŸ¬ë¥¼ ë±‰ì–´ë‚¸ë‹¤. ì´ëŠ” ì¶”í›„ì— í•´ê²°í•˜ê³  ë”°ë¡œ í¬ìŠ¤íŒ… í•  ì˜ˆì •ì´ë‹¤ 2019.08.02 made by jaejun.lee","categories":[{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"}],"tags":[{"name":"Tibero","slug":"Tibero","permalink":"https://jx2lee.github.io/tags/Tibero/"}]},{"title":"[Machine Learning] Understanding Hyperparameter","slug":"ml-introduction_to_grid_search","date":"2019-07-01T15:00:00.000Z","updated":"2020-03-30T15:06:23.567Z","comments":true,"path":"ml-introduction_to_grid_search/","link":"","permalink":"https://jx2lee.github.io/ml-introduction_to_grid_search/","excerpt":"Hyperparameter ë€? Wikiì— ë”°ë¥´ë©´ í•™ìŠµì´ ì‹œì‘ë˜ê¸° ì „ ì„¤ì •ëœ ë³€ìˆ˜ ë¼ê³  ì •ì˜ ì¦‰, í•™ìŠµ ì´ì „ initialized variable í•™ìŠµ parameterëŠ” í¬ê²Œ Model parameter ì™€ Hyperparameter ë¡œ êµ¬ë¶„","text":"Hyperparameter ë€? Wikiì— ë”°ë¥´ë©´ í•™ìŠµì´ ì‹œì‘ë˜ê¸° ì „ ì„¤ì •ëœ ë³€ìˆ˜ ë¼ê³  ì •ì˜ ì¦‰, í•™ìŠµ ì´ì „ initialized variable í•™ìŠµ parameterëŠ” í¬ê²Œ Model parameter ì™€ Hyperparameter ë¡œ êµ¬ë¶„ Model parametersModel paramtersëŠ” ML modelì— ì˜í•´ í•™ìŠµí•  ë°ì´í„°ì˜ ì†ì„±ìœ¼ë¡œ ëª¨ë¸ì´ í•™ìŠµë¨ê³¼ ë™ì‹œì— í•™ìŠµí•˜ëŠ” parameterë¥¼ ì˜ë¯¸í•œë‹¤. ì˜ˆë¡œ Weightê³¼ Biasesë¥¼ Model parameterë¼ ë¶€ë¥¸ë‹¤. Model HyperparametersModel HyperparametersëŠ” ML modelì˜ ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ê´€ë¦¬í•˜ëŠ” ì†ì„±ì´ë‹¤. Model parameterê³¼ëŠ” ë‹¤ë¥´ê²Œ í•™ìŠµ ë„ì¤‘ ë³€í•˜ì§€ ì•ŠëŠ”ê²ƒì´ íŠ¹ì§•ì´ë‹¤. Learning Rate Epochs Hidden Layers(Units) Activation functions model_parameter Hyperparameterê°€ ì™œ í•„ìš”í•œê°€?HyperparamterëŠ” training algorithm ë™ì‘ì„ ì§ì ‘ ì œì–´, ëª¨ë¸ ì„±ëŠ¥ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤. â€œì ì ˆí•œ Hyperparameter ì„ íƒì€ algorithmì„ ë¹›ë‚˜ê²Œ ë§Œë“ ë‹¤â€ (A good choice of hyperparameters can really make an algorithm shine) ì´ë¼ëŠ” ë§ë„ ìˆë‹¤.Hyperparameterê°€ ì¤‘ìš”í•œ ì´ìœ ëŠ” ì˜ˆë¥¼ ë“¤ì–´ Learning rateì´ ë„ˆë¬´ ë‚®ê²Œë˜ë©´ ëª¨ë¸ íŒ¨í„´ì„ ë†“ì¹  ìˆ˜ ìˆê³ , ë†’ìœ¼ë©´ ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì¦‰ í•™ìŠµì´ ì œëŒ€ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ì´ì— ì ì ˆí•œ Hyperparameter ì„ íƒì€ ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì´ ìˆë‹¤. íš¨ìœ¨ì ì¸ ë§¤ê°œ ë³€ìˆ˜ ê³µê°„ ì—¬ëŸ¬ ì‹¤í—˜(experiment)ë“¤ì„ ì†ì‰¬ìš´ ê´€ë¦¬ Hyperparameters ìµœì í™” ê¸°ë²• (Optimisation Techniques)MLì—ì„œ ìµœì ì˜ Hyperparameterë¥¼ ì°¾ëŠ” ê³¼ì •ì„ Hyperparameter optimisationì´ë¼ í•œë‹¤. ê¸°ë²•ë“¤ì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ë‹¤. Grid Search Random Search Bayesian Optimisation 20190702 ê¸°ì¤€ìœ¼ë¡œëŠ” Grid Search ë§Œ ë‹¤ë£¨ê³  ë‚˜ì¤‘ì— ì‹œê°„ì´ ëœë‹¤ë©´ ë‚˜ë¨¸ì§€ ê¸°ë²•ë„ ì •ë¦¬í•  ì˜ˆì •ì´ë‹¤ Grid SearchGrid SearchëŠ” Hyperparameter ë¥¼ ì°¾ëŠ” ê°€ì¥ ì „í†µì ì¸ ë°©ë²•ì´ë‹¤. ëª¨ë“  ì¡°í•©ì„ ê³ ë ¤í•´ ìµœì ì˜ setë¥¼ ì°¾ì•„ë‚´ëŠ” ì•½ê°„ ë¬´ì‹í•œ ë°©ë²•ì´ë‹¤. Grid Search ëŠ” ë³´í†µ 2ê°œì˜ Hyperparamter ì¡°í•©ì„ ë§Œë“ ë‹¤. (ë³¸ ê²Œì‹œê¸€ì—” Learning Rate / Number of Layers ë¡œ ë˜ì–´ìˆë‹¤) Grid SearchëŠ” ë‘ ê°œì˜ Hyperparameterë¥¼ ì´ìš©í•´ ëª¨ë“  ì¡°í•©ì„ ë§Œë“¤ì–´ í•™ìŠµí•˜ê³  Cross Validation ê¸°ìˆ ì„ ì‚¬ìš©í•´ ì„±ëŠ¥ì„ ì¸¡ì •í•œë‹¤. grid search Grid SearchëŠ” ì‚¬ìš©í•˜ê¸° ê°„í¸í•˜ì§€ë§Œ curse of dimensionality(ì°¨ì›ì˜ ì €ì£¼)ë¼ëŠ” ë¬¸ì œë¥¼ ì•ˆê³  ìˆë‹¤. Training dataì˜ dimensionì´ ë†’ìœ¼ë©´ ê·¸ë§Œí¼ ìƒê¸°ëŠ” Hyperparamter ì¡°í•©ë„ ë§ì•„ì ¸ ì°¨ì›ì˜ ì €ì£¼ê°€ ë°œìƒí•œë‹¤. 2019.07.02 made by jaejun.lee","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jx2lee.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://jx2lee.github.io/tags/Algorithm/"}]}],"categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://jx2lee.github.io/categories/Jenkins/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://jx2lee.github.io/categories/Hadoop/"},{"name":"Cloud","slug":"Cloud","permalink":"https://jx2lee.github.io/categories/Cloud/"},{"name":"Linux","slug":"Linux","permalink":"https://jx2lee.github.io/categories/Linux/"},{"name":"TroubleShoot","slug":"TroubleShoot","permalink":"https://jx2lee.github.io/categories/TroubleShoot/"},{"name":"Database","slug":"Database","permalink":"https://jx2lee.github.io/categories/Database/"},{"name":"Python","slug":"Python","permalink":"https://jx2lee.github.io/categories/Python/"},{"name":"SQL","slug":"SQL","permalink":"https://jx2lee.github.io/categories/SQL/"},{"name":"Etc","slug":"Etc","permalink":"https://jx2lee.github.io/categories/Etc/"},{"name":"Shell","slug":"Shell","permalink":"https://jx2lee.github.io/categories/Shell/"},{"name":"BI","slug":"BI","permalink":"https://jx2lee.github.io/categories/BI/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://jx2lee.github.io/categories/Machine-Learning/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jx2lee.github.io/tags/Docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jx2lee.github.io/tags/Kubernetes/"},{"name":"Tibero","slug":"Tibero","permalink":"https://jx2lee.github.io/tags/Tibero/"},{"name":"Review","slug":"Review","permalink":"https://jx2lee.github.io/tags/Review/"},{"name":"Kubeflow","slug":"Kubeflow","permalink":"https://jx2lee.github.io/tags/Kubeflow/"},{"name":"Programmers","slug":"Programmers","permalink":"https://jx2lee.github.io/tags/Programmers/"},{"name":"MySQL","slug":"MySQL","permalink":"https://jx2lee.github.io/tags/MySQL/"},{"name":"Spark","slug":"Spark","permalink":"https://jx2lee.github.io/tags/Spark/"},{"name":"Hackerrank","slug":"Hackerrank","permalink":"https://jx2lee.github.io/tags/Hackerrank/"},{"name":"Python Better Way","slug":"Python-Better-Way","permalink":"https://jx2lee.github.io/tags/Python-Better-Way/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://jx2lee.github.io/tags/Algorithm/"}]}
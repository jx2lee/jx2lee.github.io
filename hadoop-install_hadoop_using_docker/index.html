<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jx2lee.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"Z4A3UF1R2X","apiKey":"dee49d5f8367c0f900b64906cfe42f19","indexName":"my_blog","hits":{"per_page":10},"labels":{"input_placeholder":"무엇을 검색하시나요?","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Hadoop 환경을 구성해보자!">
<meta property="og:type" content="article">
<meta property="og:title" content="[Hadoop] Install Hadoop using Docker">
<meta property="og:url" content="https://jx2lee.github.io/hadoop-install_hadoop_using_docker/index.html">
<meta property="og:site_name" content="머릿속에 안남으니 기록하자:">
<meta property="og:description" content="Hadoop 환경을 구성해보자!">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jx2lee.github.io/image/namenode-web.png">
<meta property="og:image" content="https://jx2lee.github.io/image/datanode-web.png">
<meta property="article:published_time" content="2019-10-24T15:00:00.000Z">
<meta property="article:modified_time" content="2020-05-15T05:22:11.687Z">
<meta property="article:author" content="JaeJun Lee">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jx2lee.github.io/image/namenode-web.png">

<link rel="canonical" href="https://jx2lee.github.io/hadoop-install_hadoop_using_docker/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>[Hadoop] Install Hadoop using Docker | 머릿속에 안남으니 기록하자:</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  <!-- Google AdSense start -->
  <script data-ad-client="ca-pub-2024744229492552" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  <!-- Google AdSense end -->
  <meta name="google-site-verification" content="mt-wza5WUtvq1j8P-WsZN7mrSgXgOawPOdnhsjdlUGg" />
<link rel="alternate" href="/rss2.xml" title="머릿속에 안남으니 기록하자:" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">머릿속에 안남으니 기록하자:</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">focusing@</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section">About</a>

  </li>
        <li class="menu-item menu-item-posts">

    <a href="/" rel="section">Posts</a>

  </li>
        <li class="menu-item menu-item-github">

    <a href="https://github.com/jx2lee" rel="noopener" target="_blank">Github</a>

  </li>
        <li class="menu-item menu-item-linkedin">

    <a href="https://www.linkedin.com/in/jaejun-lee-3287b0137/" rel="noopener" target="_blank">LinkedIn</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger">Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jx2lee.github.io/hadoop-install_hadoop_using_docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JaeJun Lee">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="머릿속에 안남으니 기록하자:">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [Hadoop] Install Hadoop using Docker
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-25 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-25T00:00:00+09:00">2019-10-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/hadoop-install_hadoop_using_docker/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="hadoop-install_hadoop_using_docker/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>Hadoop</strong> 환경을 구성해보자!</p>
<a id="more"></a>

<p>드디어 엔지니어로써의 능력을 배양할 수 있는 <code>환경 구성</code>이다. 우선, 회사에서 지급받은 서버로 이미 하둡 환경이 구축되어 있지만, 개인 할당받은 서버에서 <code>Docker</code>를 이용해 실습 환경을 구축하고자 한다.</p>
<blockquote>
<p><em>Docker Hub 에서 스타가 가장 많은 이미지를 이용할 것이다. Docker를 이용하는 것은 <code>혹여나 나중에도 써먹을 경우</code>를 대비한 것이다.</em></p>
</blockquote>
<h1 id="PLAN"><a href="#PLAN" class="headerlink" title="PLAN"></a>PLAN</h1><p>3개의 DataNode와 1개의 NameNode로 구성된 하둡 환경을 구축한다. 여러 개 서버를 연결하는 구조 대신, 쉽게 환경을 바꾸고 입맛대로 수정이 가능한 <strong>docker</strong>를 이용해 구성한다. docker를 공부해보자는 의미도 있고 새롭게 환경을 재구성할 때 유용할 것 같다.</p>
<h1 id="ENVIRONMENT"><a href="#ENVIRONMENT" class="headerlink" title="ENVIRONMENT"></a>ENVIRONMENT</h1><p>hadoop 폴더를 생성하여 아래와 같은 구조를 갖는다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ tree .</span><br><span class="line">.</span><br><span class="line">├── base</span><br><span class="line">│   ├── core-site.xml</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── data-node</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   ├── hdfs-site.xml</span><br><span class="line">│   └── install.sh</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">└── name-node</span><br><span class="line">    ├── Dockerfile</span><br><span class="line">    ├── hdfs-site.xml</span><br><span class="line">    └── install.sh</span><br><span class="line"></span><br><span class="line">3 directories, 9 files</span><br></pre></td></tr></table></figure>

<p>hadoop의 기본 환경을 구성하는 <code>base</code>와 이를 활용해 <code>name / data -node</code> 폴더를 구성하였고, Dockerfile을 작성하여 직접 image를 build하고 <code>docker-compose</code>를 활용해 배포한다. </p>
<h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>각 component의 밑바당이 되는 이미지를 구성하는 단계이다. 이는 <code>base</code> 폴더에서 수행하며, 고려사항은 다음과 같다.</p>
<ul>
<li>Hadoop 설치를 위한 binary</li>
<li>Java</li>
</ul>
<p>이미지 빌드를 위해 <code>Dockerfile</code>, <code>core-site.xml</code>을 작성해보도록 한다.</p>
<h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p>
<blockquote>
<p><em>Dockerfile 작성을 많이 해버릇 해야겠다. 참고한 블로그에서 사용한 내용을 복사 붙여넣지 않고 직접 작성하니 어느정도 흐름은 파악하였다</em></p>
</blockquote>
<ul>
<li><p>환경변수 설정</p>
<ul>
<li><code>HADOOP_VERSION</code> : hadoop version을 의미</li>
<li><code>HADOOP_URL</code> : hadoop 설치 binary 다운을 위한 url</li>
</ul>
</li>
<li><p>환경변수를 이용해 download 및 압축해제</p>
</li>
<li><p>링크파일 생성</p>
</li>
<li><p>호스트(in base directory) 파일을 container에 추가</p>
</li>
<li><p>hadoop 실행을 위한 환경변수 설정</p>
<ul>
<li><code>HADOOP_PREFIX</code> : hadoop root directory</li>
<li><code>HADOOP_CONF_DIR</code> : hadoop config directory</li>
<li><code>JAVA_HOME</code> : Java directory</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ENV for installation</span></span><br><span class="line">ENV HADOOP_VERSION=2.9.2</span><br><span class="line">ENV HADOOP_URL=http://mirror.apache-kr.org/hadoop/common/hadoop-<span class="variable">$HADOOP_VERSION</span>/hadoop-<span class="variable">$HADOOP_VERSION</span>.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">## Download Hadoop on /app/hadoop</span></span><br><span class="line">RUN curl -fSL <span class="string">"<span class="variable">$HADOOP_URL</span>"</span> -o /tmp/hadoop.tar.gz \</span><br><span class="line">	&amp;&amp; tar -xvf /tmp/hadoop.tar.gz -C /opt/ \</span><br><span class="line">	&amp;&amp; rm /tmp/hadoop.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># make directory &amp; symbolic link</span></span><br><span class="line">RUN ln -s /opt/hadoop-<span class="variable">$HADOOP_VERSION</span> /opt/hadoop \</span><br><span class="line">	&amp;&amp; mkdir /opt/hadoop/dfs \</span><br><span class="line">	&amp;&amp; ln -s /opt/hadoop-<span class="variable">$HADOOP_VERSION</span>/etc/hadoop /etc/hadoop \</span><br><span class="line">	&amp;&amp; rm -rf /opt/hadoop/share/doc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># copy local-site.xml file to container</span></span><br><span class="line">ADD core-site.xml /etc/hadoop/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ENV for run</span></span><br><span class="line">ENV HADOOP_PREFIX /opt/hadoop</span><br><span class="line">ENV HADOOP_CONF_DIR /etc/hadoop</span><br><span class="line">ENV PATH <span class="variable">$HADOOP_PREFIX</span>/bin/:<span class="variable">$PATH</span></span><br><span class="line">ENV JAVA_HOME /usr/lib/jvm/zulu-8-amd64</span><br></pre></td></tr></table></figure>

<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><p><code>core-site.xml</code>은 아래와 같이 작성한다.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">connfiguration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://namenode:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>NameNode URI</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">connfiguration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>fs.defaultFS</code> : NameNode의 위치를 찾는 설정으로 읽기/쓰기 요청을 할 때 사용되는 항목</p>
</li>
<li><p>URI hostname 은 namenode라 설정하였는데, NameNode container의 host name을 지정한 것</p>
</li>
</ul>
<blockquote>
<p><em><code>connfiguration</code> tag 명을 제대로 확인하도록 하자. (내 경우 connfiguration -&gt; configuration으로 이미지를 빌드 후 실행하였더니 container가 정상적으로 작동하지 않았다)</em></p>
</blockquote>
<h3 id="Build-hadoop-base-2-9-2"><a href="#Build-hadoop-base-2-9-2" class="headerlink" title="Build hadoop-base:2.9.2"></a>Build hadoop-base:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>base</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> base/</span><br><span class="line">[kuber@node2 base]$ docker build -t hadoop-base:2.9.2 .</span><br></pre></td></tr></table></figure>

<h2 id="NAMENODE"><a href="#NAMENODE" class="headerlink" title="NAMENODE"></a>NAMENODE</h2><p>base image를 생성하였다면, 이를 이용해 NameNode Container를 빌드하기 위한 환경을 구성한다. 고려 사항은 다음과 같다.</p>
<ul>
<li>NameNode 용 <code>hdfs-site.xml</code></li>
<li>FsImage, EditLog 저장을 위한 로컬 파일 시스템 경로</li>
<li>NameNode의 첫 구동 확인 <em>(첫 구동이 아니라면 포맷 후 구동 필요)</em></li>
</ul>
<p>NameNode 이미지 빌드를 위해 <code>Dockerfile</code>, <code>hdfs-site.xml</code>, <code>install.sh</code>를 작성해보도록 한다.</p>
<h3 id="Dockerfile-1"><a href="#Dockerfile-1" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p>
<ul>
<li>이전에 만든 hadoop-base:2.9.2 image를 불러온다</li>
<li>Web UI 응답 여부 확인을 위한 HEALTHCHECK</li>
<li>호스트(in name-node directory) 파일을 container에 추가</li>
<li>FSIMage, EditLog 파일 경로 연결</li>
<li>포트 노출</li>
<li>명령어 등록</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">FROM hadoop-base:2.9.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># CON NameNode Web UI</span></span><br><span class="line">HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50070/ || <span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY hdfs-site.xml</span></span><br><span class="line">ADD hdfs-site.xml /etc/hadoop/</span><br><span class="line"></span><br><span class="line"><span class="comment"># FSImage/EditLog path -&gt; volume</span></span><br><span class="line">RUN mkdir /opt/hadoop/dfs/name</span><br><span class="line">VOLUME /opt/hadoop/dfs/name</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY shell scrip</span></span><br><span class="line">ADD install.sh /install.sh</span><br><span class="line">RUN chmod a+x /install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># EXPOSE Port</span></span><br><span class="line">EXPOSE 50070 9000</span><br><span class="line"></span><br><span class="line"><span class="comment"># ADD command line for run</span></span><br><span class="line">CMD [<span class="string">"/install.sh"</span>, <span class="string">"opt/hadoop/dfs/name"</span>]</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p><code>hdfs-site.xml</code>은 아래와 같이 작성한다.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.use.datanode.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.servicerpc-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.https-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>dfs.namenode.name.dir</code> : FSImage / EditLog 파일을 저장하는 경로</p>
</li>
<li><p><code>dfs.blocksize</code> : HDFS 파일 블록의 크기로 본 환경에서는 10MB로 설정하였다<em>(default : 128MB)</em></p>
<p>(기타 항목들은 ( <a href="https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/" target="_blank" rel="noopener">https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/</a> ) 확인)</p>
</li>
</ul>
<h3 id="install-sh"><a href="#install-sh" class="headerlink" title="install.sh"></a>install.sh</h3><p> <code>install.sh</code>은 NameNode의 네임스페이스의 포맷 여부를 확인하는 쉘 스크립트이다. 만약 네임스페이스가 포맷되어 있다면 NameNode를 구동하고, 포맷되어있지 않다면 포맷을 진행한 후 구동한다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> SET namespace directory</span></span><br><span class="line">NAME_DIR=$1</span><br><span class="line">echo $NAME_DIR</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> CHECK <span class="keyword">if</span> dir is empty</span></span><br><span class="line">if [ "$(ls -A $NAME_DIR)" ]; then</span><br><span class="line">	echo "NameNode is already formatted !!"</span><br><span class="line">else</span><br><span class="line">	echo "Format NameNode.."</span><br><span class="line"><span class="meta">	$</span><span class="bash">HADOOP_PREFIX/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> namenode -format</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> RUN</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_PREFIX/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> namenode</span></span><br></pre></td></tr></table></figure>

<h3 id="Build-hadoop-namenode-2-9-2"><a href="#Build-hadoop-namenode-2-9-2" class="headerlink" title="Build hadoop-namenode:2.9.2"></a>Build hadoop-namenode:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>name-node</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> name-node/</span><br><span class="line">[kuber@node2 name-node]$ docker build -t hadoop-namenode:2.9.2 .</span><br></pre></td></tr></table></figure>

<h2 id="DATANODE"><a href="#DATANODE" class="headerlink" title="DATANODE"></a>DATANODE</h2><p>NameNode 이미지 생성과 마찬가지로, base image를 이용해 DataNode image를 생성해본다. 고려사항은 아래와 같다.</p>
<ul>
<li>DataNode 용 <code>hdfs-site.xml</code></li>
<li>파일 블록 저장을 위한 경로</li>
</ul>
<p>DataNode 이미지 빌드를 위해 <code>Dockerfile</code>, <code>hdfs-site.xml</code>, <code>install.sh</code>를 작성해보도록 한다.</p>
<h3 id="Dockerfile-2"><a href="#Dockerfile-2" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p>
<ul>
<li>이전에 만든 hadoop-base:2.9.2 image를 불러온다</li>
<li>Web UI 응답 여부 확인을 위한 HEALTHCHECK</li>
<li>host(in name-node directory) 파일을 container에 추가</li>
<li>FSIMage, EditLog 파일 경로 연결</li>
<li>port 노출</li>
<li>cmd 등록</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">FROM hadoop-base:2.9.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># CONN NameNode Web UI</span></span><br><span class="line">HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || <span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">RUN mkdir /opt/hadoop/dfs/data</span><br><span class="line">VOLUME /opt/hadoop/dfs/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY shell scrip</span></span><br><span class="line">ADD install.sh /install.sh</span><br><span class="line">RUN chmod a+x /install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># EXPOSE Port</span></span><br><span class="line">EXPOSE 50075 50010</span><br><span class="line"></span><br><span class="line"><span class="comment"># ADD command line for run</span></span><br><span class="line">CMD [<span class="string">"/install.sh"</span>]</span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p><code>hdfs-site.xml</code> 아래와 같이 작성한다. container 에 datanode의 dir path와 blocksize를 지정한다.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.use.datanode.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="install-sh-1"><a href="#install-sh-1" class="headerlink" title="install.sh"></a>install.sh</h3><p>DataNode의 <code>install.sh</code> 은 별거 없다. DataNode를 구동하는 명령어를 추가하여 작성한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP_PREFIX</span>/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> datanode</span><br></pre></td></tr></table></figure>

<h3 id="Build-hadoop-datanode-2-9-2"><a href="#Build-hadoop-datanode-2-9-2" class="headerlink" title="Build hadoop-datanode:2.9.2"></a>Build hadoop-datanode:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>data-node</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> data-node/</span><br><span class="line">[kuber@node2 data-node]$ docker build -t hadoop-datanode:2.9.2 .</span><br><span class="line">Sending build context to Docker daemon 4.096 kB</span><br><span class="line">Step 1/8 : FROM hadoop-base:2.9.2</span><br><span class="line"> ---&gt; 765c9acb59fd</span><br><span class="line">Step 2/8 : HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || <span class="built_in">exit</span> 1</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> e2b20d7d5fd1</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Successfully built 3f1372bf4fdb</span><br></pre></td></tr></table></figure>

<p><strong>container 구동을 위한 준비가 거의 끝나간다</strong></p>
<h1 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h1><p>빌드된 이미지를 하나하나 실행<em>(ex. docker run ~)</em>해도 되지만, <code>docker compose</code>라는 툴을 이용해 한꺼번에 배포해보도록 한다. yml 형식의 스크립트를 작성하여 NadeNode와 DataNode를 한 번에 배포할 것이다.</p>
<h2 id="Install-docker-compose"><a href="#Install-docker-compose" class="headerlink" title="Install docker-compose"></a>Install <code>docker-compose</code></h2><p>docker 설치 시 자동으로 설치된 줄 알았는데, 설치가 안되있었다. 아래 명령어를 통해 <code>docker-compose</code>를 설치한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100   617    0   617    0     0   1382      0 --:--:-- --:--:-- --:--:--  1380</span><br><span class="line">100 15.4M  100 15.4M    0     0  2327k      0  0:00:06  0:00:06 --:--:-- 3535k</span><br><span class="line">[kuber@node2 hadoop]$ sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">[kuber@node2 hadoop]$ sudo ln -s /usr/<span class="built_in">local</span>/bin/docker-compose /usr/bin/docker-compose</span><br></pre></td></tr></table></figure>

<h2 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h2><p><code>docker-compose.yml</code>은 docker 실행 옵션들을 미리 적어둔 파일이다. <em>services`</em> 부분은 우리가 구동할 NameNode 및 DataNode에 관련된 옵션들을 작성하고, 계획에서 언급한 것처럼 DataNode 3개 구동을 위해 01/02/03으로 구분하여 작성한다.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">version: "3.4"</span><br><span class="line"></span><br><span class="line">x-datanode_base: &amp;datanode_base</span><br><span class="line">  image: hadoop-datanode:2.9.2</span><br><span class="line">  networks:</span><br><span class="line">    - bridge</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  namenode:</span><br><span class="line">    image: hadoop-namenode:2.9.2</span><br><span class="line">    container_name: namenode</span><br><span class="line">    hostname: namenode</span><br><span class="line">    ports:</span><br><span class="line">      - "50070:50070"</span><br><span class="line">      - "9000:9000"</span><br><span class="line">    volumes:</span><br><span class="line">      - namenode:/opt/hadoop/dfs/name</span><br><span class="line">      - /tmp:/tmp</span><br><span class="line">    networks:</span><br><span class="line">      - bridge</span><br><span class="line"></span><br><span class="line">  datanode01:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode01</span><br><span class="line">    hostname: datanode01</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode01:/opt/hadoop/dfs/data</span><br><span class="line">  datanode02:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode02</span><br><span class="line">    hostname: datanode02</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode02:/opt/hadoop/dfs/data</span><br><span class="line">  datanode03:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode03</span><br><span class="line">    hostname: datanode03</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode03:/opt/hadoop/dfs/data</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  namenode:</span><br><span class="line">  datanode01:</span><br><span class="line">  datanode02:</span><br><span class="line">  datanode03:</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  bridge:</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>version의 경우, 자신의 서버에 설치된 docker engine release에 따라 format이 정해져있으므로 이 <a href="https://docs.docker.com/compose/compose-file/compose-versioning/" target="_blank" rel="noopener">문서</a>를 참고</em></p>
</blockquote>
<h2 id="Run-Container-using-docker-compose"><a href="#Run-Container-using-docker-compose" class="headerlink" title="Run Container using docker-compose"></a>Run Container using docker-compose</h2><p>docker-compose를 이용해 배포해 보도록 하자. 볼륨을 생성하고 NameNode / DataNode가 구동되었다는 메세지가 보일 것이다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ docker-compose up -d</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode01"</span> with default driver</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode02"</span> with default driver</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode03"</span> with default driver</span><br><span class="line">namenode is up-to-date</span><br><span class="line">Creating datanode01 ... <span class="keyword">done</span></span><br><span class="line">Creating datanode02 ... <span class="keyword">done</span></span><br><span class="line">Creating datanode03 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h1 id="Installation-Check"><a href="#Installation-Check" class="headerlink" title="Installation Check"></a>Installation Check</h1><p>노드들이 정상 작동하는지 확인해보는 단계이다. 구동을 했으면 제대로 되는지 확인하는게 중요하겠죠? 아래 순서와 같이 설치 확인을 진행한다.</p>
<h2 id="NameNode-컨테이너의-hadoop-client-실행-확인"><a href="#NameNode-컨테이너의-hadoop-client-실행-확인" class="headerlink" title="NameNode 컨테이너의 hadoop client 실행 확인"></a>NameNode 컨테이너의 hadoop client 실행 확인</h2><p>NameNode의 컨테이너에 접속해 커맨드라인을 확인하는 명령어<em>(docker exec)</em>를 통해 확인해본다. 그러면 아래와 같이 Usage가 출력되는 것을 확인할 수 있다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ docker <span class="built_in">exec</span> namenode /opt/hadoop/bin/hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use <span class="string">"yarn jar"</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">  daemonlog            get/<span class="built_in">set</span> the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure>

<p>이처럼 매 번 docker exec 명령어를 작성하는 건 정말 귀찮을 것이다. alias를 등록해 간편하게 명령어를 날려보자.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ vi ~/.bash_profile </span><br><span class="line"><span class="comment"># bash_profile</span></span><br><span class="line"><span class="built_in">alias</span> hadoop=<span class="string">"docker exec namenode /opt/hadoop/bin/hadoop"</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">[kuber@node2 hadoop]$ <span class="built_in">source</span> ~/.bash_profile </span><br><span class="line">[kuber@node2 hadoop]$ hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use <span class="string">"yarn jar"</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">  daemonlog            get/<span class="built_in">set</span> the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure>



<h2 id="폴더-생성-조회-삭제-확인"><a href="#폴더-생성-조회-삭제-확인" class="headerlink" title="폴더 생성/조회/삭제 확인"></a>폴더 생성/조회/삭제 확인</h2><p>hadoop 명령어를 통해 폴더를 생성하고 조회하며 마지막으로 삭제하는 작업을 해본다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ hadoop fs -mkdir -p /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -ls -R /tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:15 /tmp/<span class="built_in">test</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:15 /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -rm -r /tmp/<span class="built_in">test</span>/app</span><br><span class="line">Deleted /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -ls -R /tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:16 /tmp/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h2 id="Web-UI"><a href="#Web-UI" class="headerlink" title="Web UI"></a>Web UI</h2><p>NameNode와 DataNode 상태를 Web에서 확인할 수 있다. container 실행을 위해 작성한 <code>docker-compose.yml</code> 안에 NameNode의 port<em>(50070)</em>를 이용해 접속을 하면 아래와 같은 화면이 보일 것이다.</p>
<ul>
<li><p><code>NameNode</code> overview</p>
<p><img src="/image/namenode-web.png" alt=""></p>
</li>
<li><p><code>DataNode</code> overview</p>
<p><img src="/image/datanode-web.png" alt=""></p>
</li>
</ul>
<h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref."></a>Ref.</h1><ol>
<li><a href="https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/" target="_blank" rel="noopener">김근호님 블로그 : Docker로 Hadoop 테스트 환경 구축하기 - HDFS</a></li>
<li><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">Docker documenst</a></li>
</ol>
<hr>
<p>made by <em>jaejun.lee</em></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/hackerrank-olap/" rel="prev" title="[Database] OLAP">
      <i class="fa fa-chevron-left"></i> [Database] OLAP
    </a></div>
      <div class="post-nav-item">
    <a href="/hackerrank-interviews/" rel="next" title="[SQL] Interviews">
      [SQL] Interviews <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#PLAN"><span class="nav-number">1.</span> <span class="nav-text">PLAN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ENVIRONMENT"><span class="nav-number">2.</span> <span class="nav-text">ENVIRONMENT</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#BASE"><span class="nav-number">2.1.</span> <span class="nav-text">BASE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dockerfile"><span class="nav-number">2.1.1.</span> <span class="nav-text">Dockerfile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#core-site-xml"><span class="nav-number">2.1.2.</span> <span class="nav-text">core-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Build-hadoop-base-2-9-2"><span class="nav-number">2.1.3.</span> <span class="nav-text">Build hadoop-base:2.9.2</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NAMENODE"><span class="nav-number">2.2.</span> <span class="nav-text">NAMENODE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dockerfile-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">Dockerfile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-site-xml"><span class="nav-number">2.2.2.</span> <span class="nav-text">hdfs-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#install-sh"><span class="nav-number">2.2.3.</span> <span class="nav-text">install.sh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Build-hadoop-namenode-2-9-2"><span class="nav-number">2.2.4.</span> <span class="nav-text">Build hadoop-namenode:2.9.2</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DATANODE"><span class="nav-number">2.3.</span> <span class="nav-text">DATANODE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dockerfile-2"><span class="nav-number">2.3.1.</span> <span class="nav-text">Dockerfile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs-site-xml-1"><span class="nav-number">2.3.2.</span> <span class="nav-text">hdfs-site.xml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#install-sh-1"><span class="nav-number">2.3.3.</span> <span class="nav-text">install.sh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Build-hadoop-datanode-2-9-2"><span class="nav-number">2.3.4.</span> <span class="nav-text">Build hadoop-datanode:2.9.2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RUN"><span class="nav-number">3.</span> <span class="nav-text">RUN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Install-docker-compose"><span class="nav-number">3.1.</span> <span class="nav-text">Install docker-compose</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#docker-compose-yml"><span class="nav-number">3.2.</span> <span class="nav-text">docker-compose.yml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Run-Container-using-docker-compose"><span class="nav-number">3.3.</span> <span class="nav-text">Run Container using docker-compose</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Installation-Check"><span class="nav-number">4.</span> <span class="nav-text">Installation Check</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#NameNode-컨테이너의-hadoop-client-실행-확인"><span class="nav-number">4.1.</span> <span class="nav-text">NameNode 컨테이너의 hadoop client 실행 확인</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#폴더-생성-조회-삭제-확인"><span class="nav-number">4.2.</span> <span class="nav-text">폴더 생성&#x2F;조회&#x2F;삭제 확인</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Web-UI"><span class="nav-number">4.3.</span> <span class="nav-text">Web UI</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ref"><span class="nav-number">5.</span> <span class="nav-text">Ref.</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">JaeJun Lee</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jaejuning" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jaejuning" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jaejun.lee.1991@gmail.com" title="E-Mail → mailto:jaejun.lee.1991@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JaeJun Lee</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://jjlee.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://jx2lee.github.io/hadoop-install_hadoop_using_docker/";
    this.page.identifier = "hadoop-install_hadoop_using_docker/";
    this.page.title = "[Hadoop] Install Hadoop using Docker";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://jjlee.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>

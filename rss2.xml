<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>머릿속에 안남으니 기록하자:</title>
    <link>https://jx2lee.github.io/</link>
    
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Sat, 19 Sep 2020 01:02:33 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>[Database] 일 단위 적재 프로세스 훑어보기</title>
      <link>https://jx2lee.github.io/database-daily_batch_process/</link>
      <guid>https://jx2lee.github.io/database-daily_batch_process/</guid>
      <pubDate>Wed, 09 Sep 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;프로젝트 시범과제 중 &lt;strong&gt;[데이터 마트 구축]&lt;/strong&gt;을 수행하면서 고객요건에 맞는 테이블을 생성하고 갱신하는 프로세스를 경험하였다. 별 어려운 내용은 없지만 내 머릿속에 저장히기 위해 글로 남겨놓는다. &lt;em&gt;(도움을 주신 갓정희님께 감사의 인사를)&lt;/em&gt;&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>프로젝트 시범과제 중 <strong>[데이터 마트 구축]</strong>을 수행하면서 고객요건에 맞는 테이블을 생성하고 갱신하는 프로세스를 경험하였다. 별 어려운 내용은 없지만 내 머릿속에 저장히기 위해 글로 남겨놓는다. <em>(도움을 주신 갓정희님께 감사의 인사를)</em></p><a id="more"></a><p><strong><span class="github-emoji" alias="sparkles" style="" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png?v8">&#x2728;</span> Contents:</strong><br><a href="#createuser">유저 생성</a><br><a href="#createtable">TARGET 테이블 생성</a><br><a href="#update">주 단위 데이터 마감</a><br><a href="#reference">Reference</a>  </p><h1 id="유저-생성"><a href="#유저-생성" class="headerlink" title=" 유저 생성"></a><a name="createuser"></a> 유저 생성</h1><p>해당 테이블을 관리하는 계정을 생성하였다.</p><ul><li><code>user/pw</code>: mart_20/<strong>***</strong></li><li><code>role</code>: connect, resource</li><li>User create 문<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--Create "MART_20" User</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> MART_20 <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'*******'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">CONNECT</span>, <span class="keyword">RESOURCE</span> <span class="keyword">TO</span> MART_20;</span><br></pre></td></tr></table></figure></li></ul><h1 id="TARGET-테이블-생성"><a href="#TARGET-테이블-생성" class="headerlink" title=" TARGET 테이블 생성"></a><a name="createtable"></a> TARGET 테이블 생성</h1><p>고객이 사용하던 SQL 쿼리를 살펴보면, 총 12개 Table 및 View 를 조합하여 네 덩어리 SELECT 조회 결과를 UNION ALL 한다. 운영자가 수정하는 부분은 날짜 칼럼을 입력하게끔 쿼리를 작성하여 이를 EXCEL 로 다운받아 요청자에게 전달하는 방식이다. 우리는 이 쿼리의 결과물을 미리 테이블로 정의하고, 일 적재를 통해 고객이 쉽게 우리 제품을 이용해 분석하고 싶을 때 분석 가능하게 환경을 구성할 예정이다. 하지만 요청자를 위해 작성된 Query는 다음과 같은 제약사항이 있다. </p><ul><li>Primary Key 로 설정한 SEQ 는 추후 중복이 발생할 수 있다.<ul><li>수집을 하다보면 언젠가 UNION ALL 전의 한 덩어리에서의 SEQ 칼럼과 나머지 세 덩어리에서의 SEQ 와 동일해질 수 있다. 서로 다르게 SEQ Value 관리하기 때문이다.</li><li>이를 해결할 방법으로 UNION ALL 전의 네 덩어리를 적재 테이블로 각각 관리하면 된다. 이후 생성한 네 개 테이블을 UNION ALL 한 VIEW 를 바라보면 되는데, 이는 1) 관리 포인트가 많아지고  2) View를 사용하기 대문에 성능 이슈가 발생할 수 있다.</li><li>그럼에도 나는 하나의 테이블로 관리하고자 한다.</li></ul></li><li>Source Table 에서 수정이 발생하면 이에 대한 Target Source 처리가 필요하다. 즉, 이전 날짜의 데이터에 대한 수정이 발생하면 Target Source 에 대한 반영이 필요하다.<ul><li>이는 주 또는 월 단위 DEL_FLAG 변수를 활용해 삭제 또는 추가 여부를 확인하는 <strong>배치 작업</strong> 으로 반영할 수 있다. 단, Update period 는 협의가 필요한 상황!</li><li><code>HABITAUL_PRACTICE_TEMP</code> 테이블을 생성하여 마감 처리를 진행할 것이다.</li></ul></li></ul><p>테이블 <em>Create Query</em> 는 아래와 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MART_20.HABITAUL_PRACTICE_ANALYSIS (</span><br><span class="line">SEQ <span class="built_in">NUMBER</span>(<span class="number">22</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">DOMAIN_SEQ <span class="built_in">NUMBER</span>(<span class="number">22</span>),</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="string">"위변조 통장"</span> <span class="built_in">NUMBER</span>,</span><br><span class="line"><span class="string">"위변조 기타"</span> <span class="built_in">NUMBER</span>,</span><br><span class="line">DEL_FLAG <span class="built_in">VARCHAR</span>(<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="string">'N'</span></span><br><span class="line">)</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> MART_20.HABITAUL_PRACTICE_ANALYSIS_IDX_01 <span class="keyword">ON</span> MART_20.HABITAUL_PRACTICE_ANALYSIS (</span><br><span class="line">TFD_DATE,</span><br><span class="line">DOMAIN_LINK,</span><br><span class="line">DEL_FLAG</span><br><span class="line">)</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MART_20.HABITAUL_PRACTICE_TEMP (</span><br><span class="line">SEQ <span class="built_in">NUMBER</span>(<span class="number">22</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">DOMAIN_SEQ <span class="built_in">NUMBER</span>(<span class="number">22</span>),</span><br><span class="line">...</span><br><span class="line">...<span class="string">"위변조 통장"</span> <span class="built_in">NUMBER</span>,</span><br><span class="line"><span class="string">"위변조 기타"</span> <span class="built_in">NUMBER</span></span><br><span class="line">)</span><br><span class="line">;</span><br></pre></td></tr></table></figure><ul><li>PK: SEQ</li><li>INDEX: DOMAIN_LINK, TFD_DATE, DEL_FLAG</li><li>TEMP 테이블과 원본 테이블의 차이점은 <strong>DEL_FLAG</strong> 칼럼의 여부이다.</li></ul><h1 id="주-단위-데이터-마감"><a href="#주-단위-데이터-마감" class="headerlink" title=" 주 단위 데이터 마감"></a><a name="update"></a> 주 단위 데이터 마감</h1><p>운영진에서 수정된 데이터를 반영하기 위해 주 단위 데이터를 마감할 것이다. 아래와 같은 순서로 진행하는데, 이는 실시간 수정 반영이 어려워(구조상) 고객와 협의하여 진행하였다. <em>(마감 주기, 즉 Update 반영을 한 주 전까지만 반영)</em></p><h2 id="1-현재-기준-이-전-데이터-조회-후-저장"><a href="#1-현재-기준-이-전-데이터-조회-후-저장" class="headerlink" title="1) 현재 기준 이 전 데이터 조회 후 저장"></a>1) 현재 기준 이 전 데이터 조회 후 저장</h2><p><em>데이터 주 단위 갱신 마감을 위한 조회 Query</em>는 다음과 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> *</span><br><span class="line">   <span class="keyword">FROM</span> ( <span class="keyword">SELECT</span> SEQ,</span><br><span class="line">                 DOMAIN_SEQ,</span><br><span class="line">                 DOMAIN_LINK,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">                 <span class="keyword">CASE</span> <span class="keyword">WHEN</span> <span class="keyword">INSTR</span>(ILLE_EXPR,</span><br><span class="line">                 <span class="string">'0209'</span>) &gt; <span class="number">0</span> <span class="keyword">THEN</span> <span class="number">1</span> <span class="keyword">END</span> <span class="keyword">AS</span> <span class="string">"위변조 기타"</span></span><br><span class="line">            <span class="keyword">FROM</span> (        <span class="keyword">SELECT</span> A.SEQ,</span><br><span class="line">                          <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,A.DOMAIN_SEQ,<span class="number">100000001</span>) <span class="keyword">AS</span> DOMAIN_SEQ,</span><br><span class="line">                          <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,B.DOMAIN_LINK,<span class="string">'webcache.googleusercontent.com'</span>) <span class="keyword">AS</span> DOMAIN_LINK,</span><br><span class="line">                          <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,F.DOMAIN_NAME,<span class="string">'구글웹캐시'</span>) <span class="keyword">AS</span> DOMAIN_NAME,</span><br><span class="line">                          F.DOMAIN_CODE2,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">                          WM_CONCAT (E.EXPR_CATEGORY || E.EXPR_SUB_CATE) ILLE_EXPR</span><br><span class="line">                     <span class="keyword">FROM</span> PIRST_19.DETECTED_URL@DS16 A <span class="keyword">INNER</span> <span class="keyword">JOIN</span> PIRST_19.DOMAIN_MASTER@DS16 B <span class="keyword">ON</span> A.DOMAIN_SEQ = B.DOMAIN_SEQ </span><br><span class="line">                          <span class="keyword">INNER</span> <span class="keyword">JOIN</span> PIRST_19.DOMAIN_INFORMATION@DS16 F <span class="keyword">ON</span> A.DOMAIN_SEQ = F.DOMAIN_SEQ </span><br><span class="line">                          <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> PIRST_19.KEYWORD_MASTER@DS16 C <span class="keyword">ON</span> A.KEYWORD_SEQ = C.KEYWORD_SEQ </span><br><span class="line">                          <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> PIRST_19.A_ILLEGAL_TRADER_MST@DS16 D <span class="keyword">ON</span> A.SEQ = D.URL_SEQ </span><br><span class="line">                          <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> PIRST_19.DETECTED_URL_EXPR@DS16 E <span class="keyword">ON</span> A.SEQ = E.URL_SEQ <span class="keyword">AND</span> E.EXPR_USE = <span class="string">'Y'</span> </span><br><span class="line">                          <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> (<span class="keyword">SELECT</span> * </span><br><span class="line">                                           <span class="keyword">FROM</span> PIRST_19.DETECTED_IMG@DS16</span><br><span class="line">                                           <span class="keyword">WHERE</span> <span class="keyword">ROWID</span> <span class="keyword">IN</span> (<span class="keyword">SELECT</span> <span class="keyword">MAX</span>(<span class="keyword">ROWID</span>) <span class="keyword">FROM</span> PIRST_19.DETECTED_IMG@DS16</span><br><span class="line">                                           <span class="keyword">GROUP</span> <span class="keyword">BY</span> DETECTED_SEQ)) G <span class="keyword">ON</span> A.SEQ = G.DETECTED_SEQ</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">                      <span class="keyword">AND</span> C.KEYWORD_REG_USER_ID != <span class="string">'covid19'</span></span><br><span class="line">                    <span class="keyword">GROUP</span> <span class="keyword">BY</span> A.SEQ,</span><br><span class="line">                             <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,A.DOMAIN_SEQ,<span class="number">100000001</span>),</span><br><span class="line">                             <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,B.DOMAIN_LINK,<span class="string">'webcache.googleusercontent.com'</span>),</span><br><span class="line">                             <span class="keyword">DECODE</span>(WEB_CACHE_URL,<span class="literal">NULL</span>,F.DOMAIN_NAME,<span class="string">'구글웹캐시'</span>),</span><br><span class="line">                             F.DOMAIN_CODE2,</span><br><span class="line">                             F.DOMAIN_CODE3,            </span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">                             D.URL_SEQ,</span><br><span class="line">                             A.POST_DATE</span><br><span class="line">                  ) A <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> PIRST_19.A_ILLEGAL_TRADER_MST@DS16 B <span class="keyword">ON</span> A.TRADER_SEQ = B.TRADER_SEQ</span><br><span class="line">             <span class="keyword">AND</span> A.URL_SEQ = B.URL_SEQ)</span><br><span class="line"><span class="comment">--한 덩어리 끝</span></span><br><span class="line"> <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"> <span class="keyword">SELECT</span> A.MANUAL_SEARCH_SEQ,</span><br><span class="line">        A.DETECTED_DOMAIN_SEQ,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">DECODE</span>(<span class="keyword">SUBSTR</span>(D.exposure_type, <span class="keyword">INSTR</span>(D.exposure_type, <span class="string">'C09'</span>),<span class="number">3</span>),<span class="string">'C09'</span>,<span class="number">1</span>) <span class="keyword">as</span> SIXTEEN     </span><br><span class="line">   <span class="keyword">FROM</span> PIRST_19.MANUAL_DETECTED_URL@DS16 A,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">        PIRST_19.A_ILLEGAL_TRADER_MST@DS16 E</span><br><span class="line">  <span class="keyword">WHERE</span> A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ</span><br><span class="line">    <span class="keyword">AND</span> A.DETECTED_DOMAIN_SEQ = C.DOMAIN_SEQ</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="comment">--두 덩어리 끝</span></span><br><span class="line"> <span class="keyword">SELECT</span> A.MANUAL_SEARCH_SEQ,</span><br><span class="line">        A.DETECTED_DOMAIN_SEQ,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">DECODE</span>(<span class="keyword">SUBSTR</span>(D.exposure_type, <span class="keyword">INSTR</span>(D.exposure_type, <span class="string">'C08'</span>),<span class="number">3</span>),<span class="string">'C08'</span>,<span class="number">1</span>) <span class="keyword">as</span> FIFTEEN,</span><br><span class="line">        <span class="keyword">DECODE</span>(<span class="keyword">SUBSTR</span>(D.exposure_type, <span class="keyword">INSTR</span>(D.exposure_type, <span class="string">'C09'</span>),<span class="number">3</span>),<span class="string">'C09'</span>,<span class="number">1</span>) <span class="keyword">as</span> SIXTEEN     </span><br><span class="line">  <span class="keyword">FROM</span> PIRST_19.MANUAL_CACHE_URL@DS16 A,</span><br><span class="line">       PIRST_19.DOMAIN_MASTER@DS16 B,</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"> <span class="keyword">WHERE</span> A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">   <span class="keyword">AND</span> A.MBER_ID != <span class="string">'itno_cmbok'</span></span><br><span class="line"><span class="comment">----세 덩어리 끝 </span></span><br><span class="line">  <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"> <span class="keyword">SELECT</span> A.MANUAL_SEARCH_SEQ,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">DECODE</span>(<span class="keyword">SUBSTR</span>(D.exposure_type, <span class="keyword">INSTR</span>(D.exposure_type, <span class="string">'C08'</span>),<span class="number">3</span>),<span class="string">'C08'</span>,<span class="number">1</span>) <span class="keyword">as</span> FIFTEEN,</span><br><span class="line">        <span class="keyword">DECODE</span>(<span class="keyword">SUBSTR</span>(D.exposure_type, <span class="keyword">INSTR</span>(D.exposure_type, <span class="string">'C09'</span>),<span class="number">3</span>),<span class="string">'C09'</span>,<span class="number">1</span>) <span class="keyword">as</span> SIXTEEN     </span><br><span class="line">   <span class="keyword">FROM</span> PIRST_19.MANUAL_IMAGE_URL@DS16 A,</span><br><span class="line">        PIRST_19.DOMAIN_MASTER@DS16 B,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">WHERE</span> A.DETECTED_DOMAIN_SEQ = B.DOMAIN_SEQ</span><br><span class="line">    <span class="keyword">AND</span> A.DETECTED_DOMAIN_SEQ = C.DOMAIN_SEQ</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="comment">--네 덩어리 끝</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><ul><li>TFD_DATE 를 SYSDATE(현재 시간) 기준 7일 기준으로 검색한다. 즉, 이전 일주일 치 데이터를 조회한다.<ul><li>20.09.03~20.09.09: 3993건</li></ul></li><li>결과물을 <code>HABITUAL_TEMP</code> 테이블에 저장한다.</li></ul><h2 id="2-현재-기준-일주일-전-데이터의-DEL-FLAG-변경"><a href="#2-현재-기준-일주일-전-데이터의-DEL-FLAG-변경" class="headerlink" title="2) 현재 기준 일주일 전 데이터의 DEL_FLAG 변경"></a>2) 현재 기준 일주일 전 데이터의 DEL_FLAG 변경</h2><p><em><code>HABITUAL_BUYER</code> 에 위 기간 데이터의 DEL_FLAG 변경 Query</em> 는 다음과 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> HABITUAL_BUYER</span><br><span class="line"><span class="keyword">SET</span> DEL_FLAG=<span class="string">'Y'</span></span><br><span class="line"><span class="keyword">WHERE</span> TFD_DATE &gt;= <span class="keyword">TO_DATE</span>(TO_CHAR(<span class="keyword">SYSDATE</span>, <span class="string">'YYYYMMDD'</span>),<span class="string">'YYYYMMDD'</span>) - <span class="number">7</span></span><br><span class="line">       <span class="keyword">AND</span> TFD_DATE &lt; <span class="keyword">TO_DATE</span>(TO_CHAR(<span class="keyword">SYSDATE</span>, <span class="string">'YYYYMMDD'</span>),<span class="string">'YYYYMMDD'</span>)</span><br></pre></td></tr></table></figure><h2 id="3-TEMP-테이블과-TARGET-테이블-간-Merge"><a href="#3-TEMP-테이블과-TARGET-테이블-간-Merge" class="headerlink" title="3) TEMP 테이블과 TARGET 테이블 간 Merge"></a>3) TEMP 테이블과 TARGET 테이블 간 Merge</h2><p><em>두 테이블 간 (<code>HABITUAL_BUYER</code> // <code>HABITUAL_TEMP</code>) Merge Ouery</em>는 다음과 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> (<span class="keyword">SELECT</span> *</span><br><span class="line"><span class="keyword">FROM</span> HABITUAL_BUYER</span><br><span class="line"> <span class="keyword">WHERE</span> TFD_DATE &gt;= <span class="keyword">TO_DATE</span>(TO_CHAR(<span class="keyword">SYSDATE</span>, <span class="string">'YYYYMMDD'</span>),<span class="string">'YYYYMMDD'</span>) - <span class="number">7</span></span><br><span class="line">   <span class="keyword">AND</span> TFD_DATE &lt; <span class="keyword">TO_DATE</span>(TO_CHAR(<span class="keyword">SYSDATE</span>, <span class="string">'YYYYMMDD'</span>),<span class="string">'YYYYMMDD'</span>)</span><br><span class="line">) <span class="keyword">AS</span> A</span><br><span class="line"><span class="keyword">USING</span> HABITUAL_TEMP <span class="keyword">AS</span> B</span><br><span class="line"><span class="keyword">ON</span> (A.SEQ = B.SEQ)</span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">MATCHED</span> <span class="keyword">THEN</span></span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">SET</span></span><br><span class="line">A.DEL_FLAG = <span class="string">'N'</span></span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> <span class="keyword">MATCHED</span> <span class="keyword">THEN</span></span><br><span class="line"><span class="keyword">INSERT</span> (A.SEQ,A.DOMAIN_SEQ ,A.DOMAIN_LINK ,A.DOMAIN_NAME ,A.CODE_NM2 ,A.CODE_NM3,A.DETECTED_CRAWL_COUNT,A.DETECTED_LINK,A.DETECTED_COUNT ,A.TRUE_DETECTION_COUNT ,A.FALSE_DETECTION_COUNT ,A.DETECTED_NEW_EXPOSURE_COUNT ,A.DETECTED_RE_EXPOSURE,A.DETECTED_RE_EXPOSURE_COUNT ,A.DOMAIN_CATEGORY01,A.DOMAIN_CATEGORY02,A.SEARCH_COL_TYPE,A.DOMAIN_GROUP,A.DETECTED_DEPTH,A.DOMAIN_COUNTRY_CODE,A.DETECTED_STATUS,A.DETECTED_GROUP,A.DETECTED_TYPE,A.DETECTED_CHECK_TYPE,A.KEYWORD_SEQ,A.KEYWORD_VALUE,A.INDI_DOMAIN_SEQ,A.WEB_CACHE_URL,A.DETECTED_TIME ,A.TFD_DATE ,A.DEL_DONE_DATE ,A.UPDATOR,A.REQUEST_ORDINAL,A.DETECTED_POST_TYPE,A.GATHERING_TYPE,A.IMG_DETECTION_TYPE,A.POST_DATE ,A.REFERENCE,A.TRADER_TYPE,A.<span class="string">"판매자ID"</span>,A.<span class="string">"이메일"</span>,A.<span class="string">"카카오톡"</span>,A.<span class="string">"네이트온"</span>,A.<span class="string">"MSN메신저"</span>,A.<span class="string">"스카이프"</span>,A.<span class="string">"위챗"</span>,A.QQ,A.<span class="string">"텔레그램"</span>,A.<span class="string">"기타1"</span>,A.<span class="string">"기타2"</span>,A.<span class="string">"핸드폰번호"</span>,A.<span class="string">"일반번호"</span>,A.<span class="string">"거래 개인정보DB"</span> ,A.<span class="string">"거래 통장"</span> ,A.<span class="string">"거래 ID판매"</span> ,A.<span class="string">"거래 아이핀"</span> ,A.<span class="string">"거래 대포폰"</span> ,A.<span class="string">"거래 해킹"</span> ,A.<span class="string">"거래 기타"</span> ,A.<span class="string">"위변조 증명서"</span> ,A.<span class="string">"위변조 성적표"</span> ,A.<span class="string">"위변조 신분증"</span> ,A.<span class="string">"위변조 자격증"</span> ,A.<span class="string">"위변조 여권"</span> ,A.<span class="string">"위변조 기록부"</span> ,A.<span class="string">"위변조 내역서"</span> ,A.<span class="string">"위변조 통장"</span> ,A.<span class="string">"위변조 기타"</span> )</span><br><span class="line"><span class="keyword">VALUES</span> (B.SEQ,B.DOMAIN_SEQ ,B.DOMAIN_LINK ,B.DOMAIN_NAME ,B.CODE_NM2 ,B.CODE_NM3,B.DETECTED_CRAWL_COUNT,B.DETECTED_LINK,B.DETECTED_COUNT ,B.TRUE_DETECTION_COUNT ,B.FALSE_DETECTION_COUNT ,B.DETECTED_NEW_EXPOSURE_COUNT ,B.DETECTED_RE_EXPOSURE,B.DETECTED_RE_EXPOSURE_COUNT ,B.DOMAIN_CATEGORY01,B.DOMAIN_CATEGORY02,B.SEARCH_COL_TYPE,B.DOMAIN_GROUP,B.DETECTED_DEPTH,B.DOMAIN_COUNTRY_CODE,B.DETECTED_STATUS,B.DETECTED_GROUP,B.DETECTED_TYPE,B.DETECTED_CHECK_TYPE,B.KEYWORD_SEQ,B.KEYWORD_VALUE,B.INDI_DOMAIN_SEQ,B.WEB_CACHE_URL,B.DETECTED_TIME ,B.TFD_DATE ,B.DEL_DONE_DATE ,B.UPDATOR,B.REQUEST_ORDINAL,B.DETECTED_POST_TYPE,B.GATHERING_TYPE,B.IMG_DETECTION_TYPE,B.POST_DATE ,B.REFERENCE,B.TRADER_TYPE,B.<span class="string">"판매자ID"</span>,B.<span class="string">"이메일"</span>,B.<span class="string">"카카오톡"</span>,B.<span class="string">"네이트온"</span>,B.<span class="string">"MSN메신저"</span>,B.<span class="string">"스카이프"</span>,B.<span class="string">"위챗"</span>,B.QQ,B.<span class="string">"텔레그램"</span>,B.<span class="string">"기타1"</span>,B.<span class="string">"기타2"</span>,B.<span class="string">"핸드폰번호"</span>,B.<span class="string">"일반번호"</span>,B.<span class="string">"거래 개인정보DB"</span> ,B.<span class="string">"거래 통장"</span> ,B.<span class="string">"거래 ID판매"</span> ,B.<span class="string">"거래 아이핀"</span> ,B.<span class="string">"거래 대포폰"</span> ,B.<span class="string">"거래 해킹"</span> ,B.<span class="string">"거래 기타"</span> ,B.<span class="string">"위변조 증명서"</span> ,B.<span class="string">"위변조 성적표"</span> ,B.<span class="string">"위변조 신분증"</span> ,B.<span class="string">"위변조 자격증"</span> ,B.<span class="string">"위변조 여권"</span> ,B.<span class="string">"위변조 기록부"</span> ,B.<span class="string">"위변조 내역서"</span> ,B.<span class="string">"위변조 통장"</span> ,B.<span class="string">"위변조 기타"</span> )</span><br></pre></td></tr></table></figure><ul><li>SEQ 기준으로 데이터가 존재하면 DEL_FLAG를 N 으로 수정한다.</li><li>만약 기존 적재된 SEQ가 없는 데이터가 있다면, 새롭게 INSERT (삭제될 경우도 있지만 추가될 경우도 존재) 한다.</li></ul><p>각 테이블 조회해보면 FLAG가 변경된 값을 확인할 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--20.09.03~20.09.09 새로 수집한 데이터 조회</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> MART_20.HABITUAL_TEMP</span><br><span class="line">;</span><br><span class="line"><span class="comment">--3993</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--BUYER 테이블에서 일주일 전 데이터 FLAG Y로 수정 후 COUNT</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> MART_20.HABITUAL_BUYER</span><br><span class="line"><span class="keyword">WHERE</span> DEL_FLAG=<span class="string">'Y'</span></span><br><span class="line">;</span><br><span class="line"><span class="comment">--3993</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--MERGE 이후 COUNT</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> MART_20.HABITUAL_BUYER</span><br><span class="line"><span class="keyword">WHERE</span> DEL_FLAG=<span class="string">'Y'</span></span><br><span class="line">;</span><br><span class="line"><span class="comment">--0, 왜냐면 수정된 데이터가 없으므로..</span></span><br></pre></td></tr></table></figure><p>데이터 주 단위 마감 순서를 한 줄로 요약하면, 마감 기준 치 데이터를 조회 후 TEMP 테이블에 저장하고 TARGET 테이블(TEMP 테이블에 저장한 데이터의 같은 날짜)의 DEL_FLAG 를 Y로 변경하여 TEMP 테이블과 Merge 한다.  </p><p>직접 수행하면서 느낀점은 Merge 로 인한 성능 이슈가 발생할 수 있는데, 이를 어떻게 처리할 수 있는지는 더 연구해봐야겠다는 생각이 들었다. 배치 작업을 수행하면서 울팀 선배님이 많은 도움을 주셨다. 앞으로 나도 내 후배에게 많은 도움을 줄 수 있는 선배로 거듭나길.. </p><h1 id="Reference"><a href="#Reference" class="headerlink" title=" Reference"></a><a name="reference"></a> Reference</h1><ol><li><a href="https://kookyungmin.github.io/db/2018/07/30/oracle_32/" target="_blank" rel="noopener">https://kookyungmin.github.io/db/2018/07/30/oracle_32/</a></li><li><a href="https://jennylee4517.github.io/sql/oracle-1%EC%9D%BC%EC%B0%A8/" target="_blank" rel="noopener">https://jennylee4517.github.io/sql/oracle-1일차/</a></li><li><a href="https://m.blog.naver.com/PostView.nhn?blogId=ojini21c&logNo=221193420479&proxyReferer=https:%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">https://m.blog.naver.com/PostView.nhn?blogId=ojini21c&amp;logNo=221193420479&amp;proxyReferer=https:%2F%2Fwww.google.com%2F</a></li></ol><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/database-daily_batch_process/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Rook Ceph] Rook ceph dashboard 사용하기</title>
      <link>https://jx2lee.github.io/cloud-export_rook_ceph_dashboard/</link>
      <guid>https://jx2lee.github.io/cloud-export_rook_ceph_dashboard/</guid>
      <pubDate>Wed, 02 Sep 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Toolbox POD 로 접근하여 ceph cluster 를 확인하곤 한다. alias 로 바로 접근할 수 있게 설정하였지만, 좀 더 직관적으로 보기 위해 dashboard 를 배포해 보자! &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Toolbox POD 로 접근하여 ceph cluster 를 확인하곤 한다. alias 로 바로 접근할 수 있게 설정하였지만, 좀 더 직관적으로 보기 위해 dashboard 를 배포해 보자! </p><a id="more"></a><p><strong>Contents:</strong><br><a href="#checksvc">rook-ceph service 확인하기</a><br><a href="#makesvc">rook-ceph-mgr-dashboard-external-http 서비스 생성하기</a><br><a href="#connect">dashboard 접속</a><br><a href="#ref">Reference</a></p><h1 id="rook-ceph-Service-확인"><a href="#rook-ceph-Service-확인" class="headerlink" title=" rook-ceph Service 확인"></a><a name="checksvc"></a> rook-ceph Service 확인</h1><p><code>kubectl get service -n rook-ceph</code> 명령어로 기동중인 서비스를 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl get service -n rook-ceph</span></span><br><span class="line">NAME                                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">csi-cephfsplugin-metrics                ClusterIP   10.96.205.129   &lt;none&gt;        8080/TCP,8081/TCP   2d17h</span><br><span class="line">csi-rbdplugin-metrics                   ClusterIP   10.96.158.126   &lt;none&gt;        8080/TCP,8081/TCP   2d17h</span><br><span class="line">rook-ceph-mgr                           ClusterIP   10.96.133.224   &lt;none&gt;        9283/TCP            2d17h</span><br><span class="line">rook-ceph-mgr-dashboard                 ClusterIP   10.96.37.245    &lt;none&gt;        8443/TCP            2d17h</span><br><span class="line">rook-ceph-mon<span class="_">-a</span>                         ClusterIP   10.96.59.113    &lt;none&gt;        6789/TCP,3300/TCP   2d17h</span><br><span class="line">rook-ceph-mon-b                         ClusterIP   10.96.26.250    &lt;none&gt;        6789/TCP,3300/TCP   2d17h</span><br><span class="line">rook-ceph-mon-c                         ClusterIP   10.96.235.59    &lt;none&gt;        6789/TCP,3300/TCP   2d17h</span><br></pre></td></tr></table></figure><p><code>rook-ceph-mgr-dashboard</code> 서비스가 8443 포트로 통신 가능하게 설정되어 있다. 외부로 dashboard 를 노출하는 방법은 <em>1) rook-ceph-mgr 서비스 type 바꾸기</em> 와 <em>2) external service</em> 가 있다. 이번 글에서는 2번 방법을 이용해 dashboard 를 사용해보겠다.</p><h1 id="rook-ceph-mgr-dashboard-external-http-서비스-생성하기"><a href="#rook-ceph-mgr-dashboard-external-http-서비스-생성하기" class="headerlink" title=" rook-ceph-mgr-dashboard-external-http 서비스 생성하기"></a><a name="makesvc"></a> rook-ceph-mgr-dashboard-external-http 서비스 생성하기</h1><p>다음과 같은 yaml 를 작성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/hypercloud-rook-ceph-master/deploy<span class="comment"># cat dashboard-external-http.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: rook-ceph-mgr-dashboard-external-http</span><br><span class="line">  namespace: rook-ceph</span><br><span class="line">  labels:</span><br><span class="line">    app: rook-ceph-mgr</span><br><span class="line">    rook_cluster: rook-ceph</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: dashboard</span><br><span class="line">    port: 8443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    app: rook-ceph-mgr</span><br><span class="line">    rook_cluster: rook-ceph</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br></pre></td></tr></table></figure><ul><li>Service 타입은 <code>NodePort</code> 로 설정한다. 이외 외부로 노출하고 싶다면 <code>LoadBalancer</code> 로 변경한다. <em>(로드밸런서 경우 퍼블릭 IP가 존재해야한다.)</em></li><li>rook-ceph-mgr Port 가 만약 나와 다른 번호(예. 7775) 로 설정되어 있다면, 위 yaml 에서도 같은 포트로 설정해야한다.</li></ul><p>생성한 yaml 을 이용해 <code>kubectl apply -f dashboard-external-http.yaml</code> 커맨드로 service 를 생성한다. 이후 접속하기 위한 초기 admin 비밀번호 확인을 위해 다음과 같은 커맨드를 수행한다.</p><p><code>kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=&quot;{[&#39;data&#39;][&#39;password&#39;]}&quot; | base64 --decode &amp;&amp; echo</code></p><h1 id="dashboard-접속"><a href="#dashboard-접속" class="headerlink" title=" dashboard 접속"></a><a name="connect"></a> dashboard 접속</h1><p>클러스터 노드 중 하나를 골라 <code>https://[노드ip]:[port]</code> 로 접속한다.</p><ul><li>ID/PW:  <code>admin/[바로 위 커맨드 수행 결과]</code></li><li>최초 접속 후 설정에 들어가 PW를 바꾸도록 하자.</li></ul><p>dashboard UI 를 통해 ceph cluster 상태를 직관적으로 볼 수 있어 편리하긴 하다.  그래도 조금 더 쿠버네티스와 친해지기 위해 커맨드로 ceph cluster 상태를 확인하는 것이 더 나을듯 하다!</p><h1 id="Reference"><a href="#Reference" class="headerlink" title=" Reference"></a><a name="ref"></a> Reference</h1><ul><li><a href="https://github.com/rook/rook/blob/master/Documentation/ceph-dashboard.md" target="_blank" rel="noopener">https://github.com/rook/rook/blob/master/Documentation/ceph-dashboard.md</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-export_rook_ceph_dashboard/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 단순 키워드 매칭 모듈</title>
      <link>https://jx2lee.github.io/python-keyword_match/</link>
      <guid>https://jx2lee.github.io/python-keyword_match/</guid>
      <pubDate>Wed, 19 Aug 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;프로젝트 시범 과제 중 하나인 “게시판 및 회원가입 여부 판단”을 위해 파이썬으로 모듈을 하나 작성했다. 알고리즘 자체는 정말 단순한데, 해당 &lt;code&gt;게시판과 회원가입&lt;/code&gt; 여부에 대한 키워드를 통해 있는지 없는지만 확인하여 판단한다. 모듈 작성 배경과 간단한 테스트를 수행한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>프로젝트 시범 과제 중 하나인 “게시판 및 회원가입 여부 판단”을 위해 파이썬으로 모듈을 하나 작성했다. 알고리즘 자체는 정말 단순한데, 해당 <code>게시판과 회원가입</code> 여부에 대한 키워드를 통해 있는지 없는지만 확인하여 판단한다. 모듈 작성 배경과 간단한 테스트를 수행한다.</p><a id="more"></a><p><strong>Contents:</strong><br><a href="#background">모듈 작생 배경</a><br><a href="#howto">어떻게 작성할까?</a><br><a href="#test">테스트 결과는요?</a><br><a href="#review">어땠나요?</a></p><h1 id="모듈-작성-배경"><a href="#모듈-작성-배경" class="headerlink" title=" 모듈 작성 배경"></a><a name="background"></a> 모듈 작성 배경</h1><p>원래 <code>키워드 매칭</code> 관련 시범과제는 주 사업자 영역인 크롤러에서 수행하기로 하였지만, 빅데이터 플랫폼을 구축하면서 <code>빅데이터 플랫폼 안에서 수행해야 그림이 이쁘지 않을까?</code> 라는 의견이 나와 우리쪽에서 수행하기로 결정하였다. 관련하여 연구소에 문의했지만, 키워드 포함 여부에 대한 연구는 이루어지지 않아 우리 팀에서 맡아 진행하기로 협의하였다.  </p><p>구글링을 통해서 많은 키워드 매칭 자료를 찾았지만, <code>시범과제</code> 성격이 크기 때문에 거창한 알고리즘을 쓰지 않기로 하였다. 단순 해당 여부에 대한 키워드를 받아 이 키워드가 있는지? 없는지? 만 판단하는 쪽으로 시범과제를 수행하기로 했다.  </p><p>우리는 총 2개 DB table 에서 데이터를 받기로 했다. <code>첫 번째</code> 는 <em>URL / URL 내 텍스트 / timestamp</em> 칼럼으로 이루어진 테이블이다. <code>두 번째</code> 는 <em>keyword type / keyword value (type: 해당 프로젝트에서는 <code>회원가입</code> 과 <code>게시판</code>)</em> 으로 이루어진 테이블이다. 위 테이블 데이터는 우리 제품 python API 를 이용해 dataframe 으로 가져올 수 있는 상황이다.  </p><blockquote><p><em>모듈 작성 배경: 프로젝트 시범과제 중 키워드 매칭을 Pyhthon 으로 수행하기 위해 작성!</em></p></blockquote><h1 id="어떻게-작성할까"><a href="#어떻게-작성할까" class="headerlink" title=" 어떻게 작성할까?"></a><a name="howto"></a> 어떻게 작성할까?</h1><p>사실 막막했다. 아니, 대충대충 짜면 금방 짤 수 있는 부분이지만 Python 역량을 키워볼 겸 모듈화로 진행하기로 결정했다. 그러던 중, <a href="https://github.com/vi3k6i5/flashtext" target="_blank" rel="noopener">FlashText</a> 알고리즘을 찾았고 이 패키지를 참고하고자 했다. 본 패키지는 <code>string/list/dictionary/file</code> 로 데이터를 읽어와 해당 키워드 사전을 만들고, 변환할 수 있는 기능을 제공한다. 하지만 내가 수행해야 하는 것은 <code>Pandas Dataframe</code> 형태의 데이터를 다뤄야 하기 때문에, FlashText <code>KeywordProcessor</code> 클래스를 차용하여 작성하였다.  </p><p>관련 모듈 사용법은 <a href="https://github.com/jx2lee/keywordmatch" target="_blank" rel="noopener">Github</a>에 올려두었다. 참고하길 바라며, 프로젝트 테스트를 위해 <code>금융인지, 주택인지?</code> 에 대한 키워드 매칭 결과를 확인해본다.  </p><blockquote><p><em>어떻게? FlashText 모듈 기반으로 작성!</em></p></blockquote><h1 id="테스트-결과는요"><a href="#테스트-결과는요" class="headerlink" title=" 테스트 결과는요?"></a><a name="test"></a> 테스트 결과는요?</h1><p><a href="https://github.com/jx2lee/keywordmatch" target="_blank" rel="noopener">Github</a>에 <code>example.py</code> 로 작성하였다. 규칙으로는 test 할 수 있는 document 등을 작성해야지만 그건 추후에 시간이 남는다면 진행하도록 한다. <code>exmaple.py</code> 는 다음과 같고 각 줄 마다 짧은 설명을 달도록 하겠다.  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> keywordmatch <span class="keyword">import</span> MatchingProcessor</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"example.pickle"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        test_df = pickle.load(f)</span><br><span class="line">    test_df_keyword = pd.DataFrame(&#123;<span class="string">'타입'</span>:[<span class="string">'금융'</span>, <span class="string">'주택'</span>, <span class="string">'금융'</span>, <span class="string">'주택'</span>, <span class="string">'금융'</span>, <span class="string">'주택'</span>],</span><br><span class="line">                                    <span class="string">'키워드'</span>:[<span class="string">'은행'</span>, <span class="string">'중랑구'</span>, <span class="string">'송금'</span>, <span class="string">'부산'</span>, <span class="string">'출금'</span>, <span class="string">'경남'</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    instance = MatchingProcessor(test_df, <span class="string">'기사내용'</span>, [<span class="string">'주택'</span>, <span class="string">'금융'</span>])</span><br><span class="line">    instance.set_logger(<span class="string">'t1'</span>, is_file=<span class="literal">False</span>)</span><br><span class="line">    instance.add_column()</span><br><span class="line">    instance.get_keyword_processor(test_df_keyword, <span class="string">'타입'</span>, <span class="string">'키워드'</span>)</span><br><span class="line">    result = instance.is_keyword()</span><br><span class="line"></span><br><span class="line">    instance._data[<span class="string">'수집시간'</span>] = datetime(<span class="number">2020</span>, <span class="number">8</span>, <span class="number">19</span>).strftime(<span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">    tibero = &#123;<span class="string">'ip'</span>: <span class="string">'192.168.179.166'</span>,</span><br><span class="line">              <span class="string">'port'</span>: <span class="string">'8629'</span>,</span><br><span class="line">              <span class="string">'sid'</span>: <span class="string">'tibero'</span>,</span><br><span class="line">              <span class="string">'id_pw'</span>: [<span class="string">'tibero'</span>, <span class="string">'tmax'</span>],</span><br><span class="line">              <span class="string">'output_columns'</span>: [<span class="string">'기사제목'</span>, <span class="string">'기사내용'</span>, <span class="string">'수집시간'</span>],</span><br><span class="line">              <span class="string">'table'</span>: <span class="string">'CRAWLER_DATA'</span>,</span><br><span class="line">              <span class="string">'table_columns'</span>: [<span class="string">'DETECTED_LINK'</span>, <span class="string">'DETECTED_CONTENTS'</span>, <span class="string">'DETECTED_TIME'</span>]&#125;</span><br><span class="line">    instance.save_output_database(jar_file=<span class="string">'/Users/jj/python/coding-test/tibero6-jdbc.jar'</span>, db_info=tibero)</span><br></pre></td></tr></table></figure><ul><li><strong>Line 1-4</strong>: 패키지 import 부분, 설치한 패키지는 <em>Jaydebeapi, pandas</em></li><li><strong>Line 7-10</strong>: 첫 번째 테이블과 두 번째 테이블 데이터를 DataFrame 으로 로드</li><li><strong>Line 12-16</strong>: <code>MatchingProcessor</code> 클래스로 생성한 객체로 테스트</li><li><strong>Line 18</strong>: 테스트를 위한 TimeStamp 열 추가</li><li><strong>Line 19-25</strong>: DB info 를 dictionary 형태로 표현</li><li><strong>Line 26</strong>: 해당 DB 로 Insert 함수 실행</li></ul><p><strong>결과는 다음과 같다:</strong>  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">~/python/keywordmatch master</span><br><span class="line">keyword-matching ❯ python example.py</span><br><span class="line">[2020-08-20 16:29:16,632][INFO] Finished Adding Columns: [<span class="string">'주택'</span>, <span class="string">'금융'</span>]</span><br><span class="line">[2020-08-20 16:29:16,636][INFO] Finished Setting Keyword_processor: &#123;<span class="string">'중랑구'</span>: <span class="string">'주택'</span>, <span class="string">'부산'</span>: <span class="string">'주택'</span>, <span class="string">'경남'</span>: <span class="string">'주택'</span>, <span class="string">'은행'</span>: <span class="string">'금융'</span>, <span class="string">'송금'</span>: <span class="string">'금융'</span>, <span class="string">'출금'</span>: <span class="string">'금융'</span>&#125;</span><br><span class="line">[2020-08-20 16:29:16,636][INFO] Start Keyword Match.</span><br><span class="line">100%|███████████████████████████████████████████████████████████████████████████████████████| 8468/8468 [00:05&lt;00:00, 1530.62it/s]</span><br><span class="line">[2020-08-20 16:29:22,200][INFO] Finished Keyword Match.</span><br><span class="line">[2020-08-20 16:29:23,781][INFO] Connected Tibero: 192.168.179.166:8629:tibero</span><br><span class="line">[2020-08-20 16:29:23,781][INFO] Started Creating SQL dump.</span><br><span class="line">100%|██████████████████████████████████████████████████████████████████████████████████████| 8468/8468 [00:00&lt;00:00, 50532.56it/s]</span><br><span class="line">[2020-08-20 16:29:23,964][INFO] Finished Creating SQL dump. dump size: 8468</span><br><span class="line">[2020-08-20 16:29:23,964][INFO] Started pushing data. SQL Query: INSERT INTO CRAWLER_DATA VALUES (?,?,?)</span><br><span class="line">[2020-08-20 16:29:25,305][INFO] Finished pushing data.</span><br><span class="line">[2020-08-20 16:29:25,305][INFO] Disconnected Tibero.</span><br></pre></td></tr></table></figure><h1 id="어땠나요"><a href="#어땠나요" class="headerlink" title=" 어땠나요?"></a><a name="review"></a> 어땠나요?</h1><p>키워드 매칭이 제대로 수행되었는지는 <code>아무도 모른다</code>. 나는 이번 프로젝트를 통해 <code>Python</code> 을 좀 더 살펴볼 수 있는 기회였고, 좀 더 다양한 모듈을 작성할 수 있는 역량을 확보한 것으로 만족한다. 물론 프로젝트에는 이 모듈을 들고 들어갈 생각이다. 왜? 결과가 제대로 나왔는지는 <code>고객도 모르기 때문이다</code>. 물론 좀 더 결과를 향상시킬 수 있는 방안을 생각하고 추가해보도록 노력하겠지만.. 10월 말 목표인 이 프로젝트에서<em>(아 물론 한 달 정도 딜레이 될 예정)</em> 튜닝은 필요할 지 모르겠다. 아, 추가적으로 필요한 부분은 아마 이러한 키워드 매칭을 <code>배치성</code>으로 수행할지는 직접 들어가봐야 알 것 같다.  </p><p>하여튼, Python을 더 알아보고 싶은 마음이 생겼다.</p><blockquote><p><em>결론: Python 을 알게되면서 점점 빠져들었다.</em> </p></blockquote><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-keyword_match/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] SQL 함수 정리</title>
      <link>https://jx2lee.github.io/sql-function/</link>
      <guid>https://jx2lee.github.io/sql-function/</guid>
      <pubDate>Tue, 21 Jul 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;프로젝트 참여 중 데이터 마트 구축을 위한 SQL 쿼리를 분석하면서, 관련된 지식을 내 머릿속에 쌓기(?)위해 정리한다. 필요 시 업데이트 할 예정&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>프로젝트 참여 중 데이터 마트 구축을 위한 SQL 쿼리를 분석하면서, 관련된 지식을 내 머릿속에 쌓기(?)위해 정리한다. 필요 시 업데이트 할 예정</p><a id="more"></a><h1 id="DECODE"><a href="#DECODE" class="headerlink" title="DECODE"></a>DECODE</h1><p>표준 SQL 함수는 아니지만 잘 사용하면 편한 오라클 함수, <code>CASE WHEN</code> 구문을 권장하기도 하지만 이왕 나왔으니 공부해보자.<br><code>DECODE</code> 는 Programming 에서의 <code>if else</code> 와 같은 역할을 한다. 사용방법은 다음과 같다.  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DECODE(&#123;column&#125;, &#123;condition_01&#125;, &#123;return_01&#125;, &#123;condition_02&#125;, &#123;return_02&#125;, &#123;condition_03&#125;, &#123;return_03&#125;, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment">--example</span></span><br><span class="line"></span><br><span class="line">DECODE(WEB_CACHE_URL,NULL,A.DOMAIN_SEQ,100000001)</span><br></pre></td></tr></table></figure><ul><li><code>WEB_CACHE_URL</code> 칼럼이 만약 NULL 이라면 A 테이블 <code>DOMAIN_SEQ</code> 대입</li><li>만약 NULL이 아니면 100000001 대입</li><li>결론: <code>WEB_CACHE_URL</code> 칼럼이 만약 NULL 이라면 A 테이블 <code>DOMAIN_SEQ</code> 값을 대입하고 아니면 100000001 대입</li></ul><h1 id="CASE-WHEN"><a href="#CASE-WHEN" class="headerlink" title="CASE WHEN"></a>CASE WHEN</h1><p><code>DECODE</code> 대신 <code>CASE WHEN</code> 을 권장한다니 알아보도록 한다. <code>DECODE</code> 랑 같이 <code>if else</code> 와 같은 역할을 하며 <code>CASE WHEN</code> 이 가독성이 더 좋다고들 한다. 사용방법은 다음과 같다.  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CASE WHEN &#123;condition_01&#125; THEN &#123;return_01&#125;</span><br><span class="line"> WHEN &#123;condition_02&#125; THEN &#123;return_02&#125;</span><br><span class="line"> ...</span><br><span class="line"> ELSE &#123;return_other&#125;</span><br><span class="line"><span class="keyword">END</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--example</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CASE</span> <span class="keyword">WHEN</span> ( <span class="keyword">SELECT</span> CODE_NM</span><br><span class="line">              <span class="keyword">FROM</span> COMTCCMMNDETAILCODE</span><br><span class="line">             <span class="keyword">WHERE</span> CODE = D.DOMAIN_CODE2) <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">OR</span> ( <span class="keyword">SELECT</span> CODE_NM</span><br><span class="line">                                                             <span class="keyword">FROM</span> COMTCCMMNDETAILCODE</span><br><span class="line">                                                            <span class="keyword">WHERE</span> CODE = D.DOMAIN_CODE2) != <span class="string">''</span> <span class="keyword">THEN</span> ( <span class="keyword">SELECT</span> CODE_NM</span><br><span class="line">                                                                                                        <span class="keyword">FROM</span> COMTCCMMNDETAILCODE</span><br><span class="line">                                                                                                       <span class="keyword">WHERE</span> CODE = D.DOMAIN_CODE2) <span class="keyword">ELSE</span> <span class="literal">NULL</span> <span class="keyword">END</span> <span class="keyword">AS</span> CODE_NM2</span><br></pre></td></tr></table></figure><ul><li>condition<ul><li>COMTCCMMNDETAILCODE 테이블에서 <code>CODE</code>가 D 테이블 <code>DOMATIN_CODE2</code> 와 같을때, <code>CODE_NM</code> 이 NULL 이 아니거나 <em>(or)</em></li><li>COMTCCMMNDETAILCODE 테이블에서 <code>CODE</code>가 D 테이블 <code>DOMATIN_CODE2</code> 와 같을때, <code>CODE_NM</code> 이 ‘’ 이 아니라면</li></ul></li><li>return: COMTCCMMNDETAILCODE 테이블에서 <code>CODE</code>가 D 테이블 <code>DOMATIN_CODE2</code> 와 같을때 <code>CODE_NM</code> 대입</li><li>ELSE: NULL 대입</li><li>결론: <code>CODE_NM</code> 값이 있으면 <code>CODE_NM</code>, 없으면 NULL</li></ul><h1 id="CAST"><a href="#CAST" class="headerlink" title="CAST"></a>CAST</h1><p>칼럼 형변환에 사용하는 함수로 UNION(UNION ALL) 사용 시 칼럼 형태를 일치시킬 때 사용할 수 있다. 사용방법은 다음과 같다.  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CAST(&#123;column&#125; as &#123;data_type&#123;length&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">--exmaple</span></span><br><span class="line"></span><br><span class="line">CAST(A.DETECTED_LINK AS NVARCHAR(4000)) AS DETECTED_LINK</span><br></pre></td></tr></table></figure><ul><li>A 테이블 <code>DETECTED_LINK</code> 칼럼을 <em>NVARCHAR</em> length 4000 형태로 변환</li></ul><h1 id="INSTR"><a href="#INSTR" class="headerlink" title="INSTR"></a>INSTR</h1><p>문자열에 특정 문자열(substring)을 검색해서 위치를 return(만약 없다면 0) 하는 함수로 사용방법은 다음과 같다.  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">INSTR(&#123;string or column&#125; &#123;substring&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">--example</span></span><br><span class="line"></span><br><span class="line">INSTR(D.exposure_type, 'S01')</span><br></pre></td></tr></table></figure><ul><li>D 테이블 <code>EXPOSURE_TYPE</code> 칼럼 내 S01 문자열 위치를 반환</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://gent.tistory.com/227" target="_blank" rel="noopener">https://gent.tistory.com/227</a></li><li><a href="https://gent.tistory.com/311" target="_blank" rel="noopener">https://gent.tistory.com/311</a></li><li><a href="http://www.incodom.kr/SQL/INSTR%2CINSTRB" target="_blank" rel="noopener">http://www.incodom.kr/SQL/INSTR%2CINSTRB</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/sql-function/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Etcd 백업을 위한 CronJob 생성</title>
      <link>https://jx2lee.github.io/cloud-etcd_cronjob/</link>
      <guid>https://jx2lee.github.io/cloud-etcd_cronjob/</guid>
      <pubDate>Tue, 16 Jun 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;최근 Control Plane 노드 복구 때문에 Etcd 백업에 대한 중요성을 깨달았다. 매 특정 시간 스냅샷을 찍어내는 CronJob 을 배포하는 과정을 다룬다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>최근 Control Plane 노드 복구 때문에 Etcd 백업에 대한 중요성을 깨달았다. 매 특정 시간 스냅샷을 찍어내는 CronJob 을 배포하는 과정을 다룬다.</p><a id="more"></a><h1 id="준비사항"><a href="#준비사항" class="headerlink" title="준비사항"></a>준비사항</h1><h2 id="control-plane-노드의-인증서-파일"><a href="#control-plane-노드의-인증서-파일" class="headerlink" title="control plane 노드의 인증서 파일"></a>control plane 노드의 인증서 파일</h2><ul><li><code>/etc/kubernetes/pki/ca.crt</code></li><li><code>/etc/kubernetes/pki/ca.key</code></li></ul><h2 id="etcd-버전-확인"><a href="#etcd-버전-확인" class="headerlink" title="etcd 버전 확인"></a>etcd 버전 확인</h2><ul><li>cluster 내 etcd 파드를 조회하여 버젼 체크<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod/etcd-k8s-master -n kube-system | grep Image:</span><br><span class="line">    Image:         k8s.gcr.io/etcd:3.3.10</span><br></pre></td></tr></table></figure></li></ul><h2 id="setup-sh"><a href="#setup-sh" class="headerlink" title="setup.sh"></a><code>setup.sh</code></h2><ul><li>apply 할 yaml 파일 내 docker registry 와 node name 을 변경하는 스크립트</li><li><code>Usage</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./setup.sh</span><br><span class="line">Usage   : ./script.sh &#123;registry_endpoint&#125; &#123;master_node&#125;</span><br><span class="line">Example : ./script.sh 192.168.179.185:5000 k8s-master</span><br></pre></td></tr></table></figure></li></ul><h1 id="etcd-snapshot-yaml"><a href="#etcd-snapshot-yaml" class="headerlink" title="etcd_snapshot.yaml"></a><code>etcd_snapshot.yaml</code></h1><h2 id="control-plane-인증서-파일을-volume-부분-etc-kubernetes-pki-etcd-폴더에-복사"><a href="#control-plane-인증서-파일을-volume-부분-etc-kubernetes-pki-etcd-폴더에-복사" class="headerlink" title="control plane 인증서 파일을 volume 부분 /etc/kubernetes/pki/etcd 폴더에 복사"></a>control plane 인증서 파일을 <code>volume</code> 부분 <code>/etc/kubernetes/pki/etcd</code> 폴더에 복사</h2><h2 id="etcd-백업-스냅샷의-저장-위치를-volume-부분-backup-으로-설정"><a href="#etcd-백업-스냅샷의-저장-위치를-volume-부분-backup-으로-설정" class="headerlink" title="etcd 백업 스냅샷의 저장 위치를 volume 부분 backup 으로 설정"></a>etcd 백업 스냅샷의 저장 위치를 <code>volume</code> 부분 <code>backup</code> 으로 설정</h2><ul><li>스냅샷이 해당 디렉토리에 저장</li><li>원하는 스냅샷 저장 주기를 crontab 으로 표현<ul><li>본인은 매일 오전 6시에 수행하는 <code>0 6 * * *</code> 으로 설정</li></ul></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">etcd-backup</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">"0 6 * * *"</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">etcd-backup</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">&#123;registry_endpoint&#125;/k8s.gcr.io/etcd:3.3.10</span></span><br><span class="line">            <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ETCDCTL_API</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"3"</span></span><br><span class="line">            <span class="attr">command:</span> <span class="string">["/bin/sh"]</span></span><br><span class="line">            <span class="attr">args:</span> <span class="string">["-c",</span> <span class="string">"etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key snapshot save /backup/etcd-snapshot-$(date +%Y-%m-%d_%H-%M-%S_%Z).db"</span><span class="string">]</span></span><br><span class="line">            <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/kubernetes/pki/etcd</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">etcd-certs</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/backup</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">backup</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">          <span class="attr">nodeSelector:</span></span><br><span class="line">            <span class="attr">kubernetes.io/hostname:</span> <span class="string">&#123;master_node&#125;</span></span><br><span class="line">          <span class="attr">tolerations:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">          <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">volumes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">etcd-certs</span></span><br><span class="line">            <span class="attr">hostPath:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/etc/kubernetes/pki/etcd</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">backup</span></span><br><span class="line">            <span class="attr">hostPath:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/etc/kubernetes/pki/etcd/snapshot</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br></pre></td></tr></table></figure><h2 id="script-실행으로-etcd-snapshot-yaml-내-node-name-과-private-registry-주소-변경"><a href="#script-실행으로-etcd-snapshot-yaml-내-node-name-과-private-registry-주소-변경" class="headerlink" title="script 실행으로 etcd_snapshot.yaml 내 node name 과 private registry 주소 변경"></a>script 실행으로 <code>etcd_snapshot.yaml</code> 내 node name 과 private registry 주소 변경</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./setup.sh 192.168.179.185:5000 k8s-master</span><br></pre></td></tr></table></figure><h1 id="배포"><a href="#배포" class="headerlink" title="배포"></a>배포</h1><p><code>$ kubectl apply -f etcd_snapshot.yaml</code></p><h1 id="배포-확인"><a href="#배포-확인" class="headerlink" title="배포 확인"></a>배포 확인</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get cronjob -n kube-system</span><br><span class="line">NAME          SCHEDULE    SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">etcd-backup   0 6 * * *   False     0        &lt;none&gt;          14m</span><br><span class="line"></span><br><span class="line">$ ll /etc/kubernetes/pki/etcd/snapshot</span><br><span class="line">drwxr-xr-x 2 root root     4096  6월 18 15:00 ./</span><br><span class="line">drwxr-xr-x 3 root root     4096  6월 17 15:00 ../</span><br><span class="line">-rw-r--r-- 1 root root 41095200  6월 17 15:00 etcd-snapshot-2020-06-17_06-00-04_UTC.db</span><br><span class="line">-rw-r--r-- 1 root root 41095200  6월 18 15:00 etcd-snapshot-2020-06-18_06-00-08_UTC.db</span><br></pre></td></tr></table></figure><ul><li><code>hostPath</code> 로 설정한 <code>/etc/kubernetes/pki/etcd/snapshot</code> 내 snapshot.db 확인</li></ul><blockquote><p><em>사용한 소스코드는 <a href="https://github.com/jx2lee/etcd-cronjob" target="_blank" rel="noopener">https://github.com/jx2lee/etcd-cronjob</a> 에서 확인 가능하다.</em></p></blockquote><h1 id="Refernce"><a href="#Refernce" class="headerlink" title="Refernce"></a>Refernce</h1><ul><li><a href="https://labs.consol.de/kubernetes/2018/05/25/kubeadm-backup.html" target="_blank" rel="noopener">https://labs.consol.de/kubernetes/2018/05/25/kubeadm-backup.html</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-etcd_cronjob/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[TroubleShoot] Control Plane Node 추가</title>
      <link>https://jx2lee.github.io/troubleshoot-add_controlplane_node/</link>
      <guid>https://jx2lee.github.io/troubleshoot-add_controlplane_node/</guid>
      <pubDate>Mon, 15 Jun 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;클러스터 운영 시 컨트롤 플레인 노드가 삭제되었을 때 클러스터에 재 추가하는 과정을 살펴본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>클러스터 운영 시 컨트롤 플레인 노드가 삭제되었을 때 클러스터에 재 추가하는 과정을 살펴본다.</p><a id="more"></a><h1 id="Kubernetes-컨트롤-플레인-노드-추가-방법"><a href="#Kubernetes-컨트롤-플레인-노드-추가-방법" class="headerlink" title="Kubernetes 컨트롤 플레인 노드 추가 방법"></a>Kubernetes 컨트롤 플레인 노드 추가 방법</h1><h2 id="기존-클러스터-노드-내-etc-kubernetes-pki-폴더를-추가-노드의-etc-kubernetes에-복사"><a href="#기존-클러스터-노드-내-etc-kubernetes-pki-폴더를-추가-노드의-etc-kubernetes에-복사" class="headerlink" title="기존 클러스터 노드 내 /etc/kubernetes/pki 폴더를 추가 노드의 /etc/kubernetes에 복사"></a>기존 클러스터 노드 내 <code>/etc/kubernetes/pki</code> 폴더를 추가 노드의 <code>/etc/kubernetes</code>에 복사</h2><h2 id="기존-클러스터-노드-내-var-lib-etcd-member-폴더를-추가-노드-내-특정-디렉토리-나의-경우-init-폴더-로-복사"><a href="#기존-클러스터-노드-내-var-lib-etcd-member-폴더를-추가-노드-내-특정-디렉토리-나의-경우-init-폴더-로-복사" class="headerlink" title="기존 클러스터 노드 내 /var/lib/etcd/member 폴더를 추가 노드 내 특정 디렉토리 (나의 경우 init 폴더) 로 복사"></a>기존 클러스터 노드 내 <code>/var/lib/etcd/member</code> 폴더를 추가 노드 내 특정 디렉토리 <em>(나의 경우 init 폴더)</em> 로 복사</h2><h3 id="기존-클러스터-노드-내-etcd-파드에-접근하여-다음-명령어로-snap-db-생성"><a href="#기존-클러스터-노드-내-etcd-파드에-접근하여-다음-명령어로-snap-db-생성" class="headerlink" title="기존 클러스터 노드 내 etcd 파드에 접근하여 다음 명령어로 snap db 생성"></a>기존 클러스터 노드 내 etcd 파드에 접근하여 다음 명령어로 snap db 생성</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 \</span><br><span class="line">--cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt \</span><br><span class="line">--key /etc/kubernetes/pki/etcd/server.key snapshot save snap</span><br></pre></td></tr></table></figure><h3 id="생성한-snap-db-를-추가하고자-하는-노드의-특정-디렉토리-나의-경우-init-폴더-로-이동"><a href="#생성한-snap-db-를-추가하고자-하는-노드의-특정-디렉토리-나의-경우-init-폴더-로-이동" class="headerlink" title="생성한 snap db 를 추가하고자 하는 노드의 특정 디렉토리 (나의 경우 init 폴더) 로 이동"></a>생성한 snap db 를 추가하고자 하는 노드의 특정 디렉토리 <em>(나의 경우 init 폴더)</em> 로 이동</h3><h2 id="초기-클러스터-구축-시-사용한-kubeadm-config-yaml-준비"><a href="#초기-클러스터-구축-시-사용한-kubeadm-config-yaml-준비" class="headerlink" title="초기 클러스터 구축 시 사용한 kubeadm-config.yaml 준비"></a>초기 클러스터 구축 시 사용한 kubeadm-config.yaml 준비</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: <span class="string">"v1.15.3"</span></span><br><span class="line">controlPlaneEndpoint: <span class="string">"192.168.179.185:6443"</span> <span class="comment"># VIP:6443</span></span><br><span class="line">networking:</span><br><span class="line"> serviceSubnet: <span class="string">"10.96.0.0/16"</span></span><br><span class="line"> podSubnet: <span class="string">"10.244.0.0/16"</span> <span class="comment"># must equal CIDR in calico.yaml</span></span><br><span class="line">apiServer:</span><br><span class="line">  extraArgs:</span><br><span class="line">    advertise-address: <span class="string">"192.168.179.185"</span> <span class="comment"># VIP</span></span><br></pre></td></tr></table></figure><h2 id="새로-추가할-노드-k8s-node5-라-가정-에-다음-명령어를-통해-etcd-데이터-복구"><a href="#새로-추가할-노드-k8s-node5-라-가정-에-다음-명령어를-통해-etcd-데이터-복구" class="headerlink" title="새로 추가할 노드(k8s-node5 라 가정)에 다음 명령어를 통해 etcd 데이터 복구"></a>새로 추가할 노드<em>(k8s-node5 라 가정)</em>에 다음 명령어를 통해 etcd 데이터 복구</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm \</span><br><span class="line">    -v <span class="string">'/root/init:/backup'</span> \</span><br><span class="line">    -v <span class="string">'/var/lib/etcd:/var/lib/etcd'</span> \</span><br><span class="line">    --env ETCDCTL_API=3 \</span><br><span class="line">    <span class="string">'k8s.gcr.io/etcd:3.3.10'</span> \</span><br><span class="line">    /bin/sh -c <span class="string">"etcdctl snapshot restore '/backup/snap.db' ; mv /default.etcd/member/ /var/lib/etcd/"</span></span><br></pre></td></tr></table></figure><h2 id="새로-추가할-노드-k8s-node5-에-kubeadm-init-수행"><a href="#새로-추가할-노드-k8s-node5-에-kubeadm-init-수행" class="headerlink" title="새로 추가할 노드 (k8s-node5) 에 kubeadm init 수행"></a>새로 추가할 노드 <em>(k8s-node5)</em> 에 kubeadm init 수행</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config=kubeadm-config.yaml\</span><br><span class="line">--ignore-preflight-errors=DirAvailable--var-lib-etcd</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://codefarm.me/2019/05/22/kubernetes-recovery-master-failure/" target="_blank" rel="noopener">https://codefarm.me/2019/05/22/kubernetes-recovery-master-failure/</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/troubleshoot-add_controlplane_node/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Etc] DevOps 인터뷰 기술질문 정리</title>
      <link>https://jx2lee.github.io/etc-devops_interview_questions/</link>
      <guid>https://jx2lee.github.io/etc-devops_interview_questions/</guid>
      <pubDate>Wed, 10 Jun 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;DevOps 직무 실무자 면접에서 받은 인터뷰 내용을 정리하였다. 기술적인 내용만 정리하였고 이외에는 &lt;strong&gt;이직 사유&lt;/strong&gt;에 대해 많이 궁금해 하였다. 나에게 이직사유 보단 기술을 알고 넓히는게 중요할 것 같아.. 추가적으로 면접을 진행하면 앞으로 계속 추가할 예정이며 질문은 기술을 기준으로 나누었다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>DevOps 직무 실무자 면접에서 받은 인터뷰 내용을 정리하였다. 기술적인 내용만 정리하였고 이외에는 <strong>이직 사유</strong>에 대해 많이 궁금해 하였다. 나에게 이직사유 보단 기술을 알고 넓히는게 중요할 것 같아.. 추가적으로 면접을 진행하면 앞으로 계속 추가할 예정이며 질문은 기술을 기준으로 나누었다.</p><a id="more"></a><p>구분은 다음과 같다.<br><strong>Contents:</strong>  </p><ul><li><a href="#kubernetes">Kubernetes</a></li><li><a href="#python">Python</a></li><li><a href="#db">Database</a></li><li><a href="#linux">Linux</a></li><li><a href="#network">Network</a></li><li><a href="#hadoop">Hadoop</a></li></ul><hr><ol><li><a name="kubernetes"></a> <em>Kubernetes</em><ul><li><code>VM vs container</code><br>:두 개 모두 가상화 기술로 큰 차이는 HyperVisor 유무이다. VM의 경우 운영체제에서 프로세스가 시작하는 반면 컨테이너는 호스트 운영체제의 내부에서 실행되어 좀 더 가볍고 MSA 구현이 가능하다. 또한, 운영체제 커널의 공유함으로써 빠르며 메모리 사용량이 적다.</li><li><code>Docker Swarm</code><br>:컨테이너 오케스트레이션 도구 중 하나로 Docker 호스트들을 하나인 것처럼 만들어주는 도구. Master/Worker 노드로 시스템을 구성한다.<br>:<a href="https://medium.com/@chrisjune_13837/infra-docker-swarm이란-595d33160379" target="_blank" rel="noopener">https://medium.com/@chrisjune_13837/infra-docker-swarm이란-595d33160379</a></li><li><code>proxy (k8s)</code><br>:Pod 로 연결되는 네트워크를 관리하며 파드 간 통신을 위해 라우팅을 돕는다. 파드 간 통신을 관리하기 때문에 파드 네트워크를 관리하는 서비스와의 통신을 원활히 해준다.</li><li><code>istio</code><br>:Data Plane<em>(프록시들로 이루어져 트래픽을 설정값에 따라 컨트롤 하는 부분)*의 메인 프록시로 Envoy Proxy를 사용하며 이를 컨트롤 해주는 Control Plane</em>(프록시들에 설정값을 전달하고 관리하는 컨트롤러)*의 오픈소스 솔루션. 이 부분에 대해서는 아래 포스트가 잘 정리되어 있다.<br>:<a href="https://gruuuuu.github.io/cloud/service-mesh-istio/#" target="_blank" rel="noopener">https://gruuuuu.github.io/cloud/service-mesh-istio/#</a></li><li><code>readiness/liveness probe</code><br>:컨테이너가 살아있는지 확인하는 health check 방법인 liveness probe, 컨테이너가 서비스 가능한 상태인지 확인하는 health check 방법인 readiness probe<br>:<a href="https://bcho.tistory.com/m/1264" target="_blank" rel="noopener">https://bcho.tistory.com/m/1264</a>  </li></ul></li></ol><ol start="2"><li><a name="python"></a> <strong><em>Python</em></strong><ul><li><code>global interpreter lock</code><br>:특정 시점에서의 하나의 쓰레드만 실행하도록 만드는 것<br>:<a href="https://m.blog.naver.com/alice_k106/221566619995" target="_blank" rel="noopener">https://m.blog.naver.com/alice_k106/221566619995</a></li><li><code>async</code><br>:하나의 쓰레드로 동시 처리를 할 수 있는 비동기 프로그래밍을 위한 파이썬 패키지<br>:<a href="https://www.daleseo.com/python-asyncio/" target="_blank" rel="noopener">https://www.daleseo.com/python-asyncio/</a></li><li><code>garbage collection</code><br>:파이썬은 보통 <code>garbage collection</code> 과 <code>reference counting</code> 을 통해 할당된 메모리를 관리한다. 기본적으로 참조 횟수가 0이 된 객체를 해제하는 <code>reference counting</code> 방식을 사용하지만, <code>reference cycles (순환참조)</code> 가 발생하면 <code>garbage collection</code> 으로 이를 해결한다.<br>:<a href="https://winterj.me/python-gc/" target="_blank" rel="noopener">https://winterj.me/python-gc/</a></li><li><code>decorator</code><br>:대상 함수를 wrapping 하고 이 wrapping 된 함수의 앞뒤에 추가적으로 꾸며질 구문들을 정의해 손쉽게 재사용 가능하게 해주는 기능으로 <code>함수를 꾸며주는 함수</code> 라고 표현할 수 있다.<br>:<a href="https://bluese05.tistory.com/30" target="_blank" rel="noopener">https://bluese05.tistory.com/30</a><br>:<a href="https://nachwon.github.io/decorator/" target="_blank" rel="noopener">https://nachwon.github.io/decorator/</a>  </li></ul></li></ol><ol start="3"><li><a name="db"></a> <strong><em>Database</em></strong><ul><li><code>Tibero vs MySQL</code><br>:사실 이 질문에 답변은 오픈소스 vs 상용이라고 말했다.. 구글링을 하면 비교자료가 나오긴 하지만 어떻게 작성해야될 지 몰라 링크만 남겨두고 면접전에 보고 들어가자!<br>:<a href="https://db-engines.com/en/system/MySQL%3BTibero" target="_blank" rel="noopener">https://db-engines.com/en/system/MySQL%3BTibero</a></li><li><code>Dead Lock</code><br>:데이터 일관성을 보장하기 위한 방법 중 하나로 트랜잭션 간 교착상태를 의미한다. 두 개의 트랜잭션 간 각각의 트랜잭션이 가지고 있는 리소스의 Lock 을 획득하려고 할 때 발생한다. (예를들어, A-&gt;D1 트랜잭션 발생 / B-&gt;D2 트랜잭션 발생 이후 A가 D2에 커밋을 하게 되면 Dead Lock 발생)<br>:<a href="https://medium.com/@chrisjune_13837/db-lock-락이란-무엇인가-d908296d0279" target="_blank" rel="noopener">https://medium.com/@chrisjune_13837/db-lock-락이란-무엇인가-d908296d0279</a>  </li></ul></li></ol><ol start="4"><li><a name="linux"></a> <strong><em>Linux</em></strong><ul><li><code>fstrim</code><br>:디스크 IO(주로 SSD) 성능 저하를 피하기 위해 사용하는 리눅스 명령어<br><img src="http://forum.falinux.com/zbxe/files/attach/images/583/202/783/7cb0f69c8ebc4e151fcf222b4bffb25b.png" alt="http://forum.falinux.com/zbxe/files/attach/images/583/202/783/7cb0f69c8ebc4e151fcf222b4bffb25b.png"></li><li><code>/dev 디렉토리</code><br>:장치 파일을 위한 디렉토리로 <code>Node(노드)</code> 라고 불리는 요소를 포함하며, 각 노드는 시스템의 한 장치를 나타낸다. <code>/dev/null</code> 은 가상장치로써 프로그램의 출력을 무시하여 화면 상 텍스트를 표시하지 않을 때 유용하다. <code>/dev/0(zero)</code> 는 write 수행 시 성공적인 리턴 코드를 제공하며 특정 크기의 파일을 생성하거나 저장 장치를 포맷하기 위해 주로 사용한다.</li><li><code>LAID (리눅스 디스크)</code><br>:여러 개 HDD 를 하나의 HDD 로 사용하는 방식<br>:<a href="https://infrajp.tistory.com/9" target="_blank" rel="noopener">https://infrajp.tistory.com/9</a></li><li><code>pipe / redirect</code><br>:<code>pipe)</code> 프로세스 혹은 실행된 프로그램의 결과를 다른 프로그램으로 전달하거나 남길 때 사용<br>:<code>redirect)</code> 프로그램의 결과 혹은 출력을 파일이나 다른 스트림으로 전달하거나 남길 때 사용  <ul><li>0: standard input <em>(stdin)</em></li><li>1: standard output <em>(stdout)</em></li><li>2: standard error <em>(stderr)</em><br><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Stdstreams-notitle.svg/450px-Stdstreams-notitle.svg.png" alt="https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Stdstreams-notitle.svg/450px-Stdstreams-notitle.svg.png">  </li></ul></li><li><code>kernel parameter 변경 이유 (사용 이유)</code><br>:<code>kernel parameter</code> 란 커널(시스템을 관리하는 거대한 어플리케이션)이 메모리와 프로세스를 할당하기 위한 값으로, <code>/proc/sys</code> (OS마다 상이할 수 있음) 디렉토리에 존재한다.  </li></ul></li></ol><ol start="5"><li><a name="network"></a> <strong><em>Network</em></strong><ul><li><code>DNS(Domain Name Server)</code><br>:TCP/IP 네트워크에서 사람이 기억하기 쉬운 문자로 만들어진 도메인을, 컴퓨터가 처리할 수 있는 인터넷 주소(IP)로 바꾸는 시스템인 Domain Name System 또는 이런 역할을 수행하는 Domain Name Server 를 의미<br>:<a href="https://samsikworld.tistory.com/489" target="_blank" rel="noopener">https://samsikworld.tistory.com/489</a></li><li><code>CNAME, A record</code><br>:<code>CNAME)</code> Canonical Name 으로 하나의 도메인에 다른 이름을 부여하는 방식<br>:<code>A record)</code> 도메인 이름에 하나의 IP address 가 있음을 의미<br>:<a href="https://twpower.github.io/40-difference-between-cname-and-a-record" target="_blank" rel="noopener">https://twpower.github.io/40-difference-between-cname-and-a-record</a>  </li><li><code>TCP / UDP</code><br>:TCP/IP의 전송계층에 사용하는 프로토콜로, <code>전송계층</code>이란 IP에 의해 전달하는 패킷의 오류를 검사하고 재전송 요구 등의 제어를 담당한다.<br>:<code>TCP(Transmission Control Protocol)</code> 신뢰성을 요구하는 애플리케이션에 사용(양방향 전송)<br>:<code>UDP(User Datagram Protocol)</code> 간단한 데이터를 빠른 속도로 전송하고자 하는 애플리케이션에 사용  </li></ul></li></ol><ul><li><a name="hadoop"></a> <strong><em>Hadoop / Spark</em></strong><ul><li><code>broadcasting join vs shuffle join</code><br>:<code>broadcasting join)</code> 데이터를 executor 로 복사하지만 executor 간 데이터 복사가 없어 속도가 빨라질 수 있다.<br><img src="https://henningkropponlinede.files.wordpress.com/2016/12/spark-broadcast.png" alt="broadcasting join"><br>:<code>shuffle join</code> 은 조인된 데이터로 동일한 executor 로 이동하기 위해 셔플 연산을 사용하여 데이터 이동이 많이 발생한다.<br><img src="https://henningkropponlinede.files.wordpress.com/2016/12/spark-broadcast-torrent.png" alt="shuffle join"><br>:<a href="https://knight76.tistory.com/entry/spark-스파크-조인-전략-셔플-조인-브로캐스트-조인-shuffle-join-broadcast-join" target="_blank" rel="noopener">https://knight76.tistory.com/entry/spark-스파크-조인-전략-셔플-조인-브로캐스트-조인-shuffle-join-broadcast-join</a>  </li></ul></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/etc-devops_interview_questions/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] 스토리지 클래스를 이용한 파드 배포 시 transport endpoint is not connected</title>
      <link>https://jx2lee.github.io/cloud-mount_failed/</link>
      <guid>https://jx2lee.github.io/cloud-mount_failed/</guid>
      <pubDate>Sun, 07 Jun 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;kubernetes 클러스터 운영 중 control plane 노드 장애가 발생해 여러 삽질을 하던 중.. 기존 운영중이던 Pod 가 떠 있지를 못해 확인&lt;em&gt;(describe)&lt;/em&gt;해보니 &lt;code&gt;transport endpoint is not connected&lt;/code&gt; 문구와 함께 Mount failed 하였다. 이 문제를 해결하는 과정을 다룬다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>kubernetes 클러스터 운영 중 control plane 노드 장애가 발생해 여러 삽질을 하던 중.. 기존 운영중이던 Pod 가 떠 있지를 못해 확인<em>(describe)</em>해보니 <code>transport endpoint is not connected</code> 문구와 함께 Mount failed 하였다. 이 문제를 해결하는 과정을 다룬다.</p><a id="more"></a><h1 id="Describe-Pod"><a href="#Describe-Pod" class="headerlink" title="Describe Pod"></a>Describe Pod</h1><p>장애가 발생한 파드를 Describe 한 결과이다.<br>총 3 Waring-FailedMount 에러가 발생하였는데, <code>Rook-ceph</code> 의 cephfs 스토리지 클래스를 이용해 공유볼륨<em>(rserver-share)</em>/Home디렉토리<em>(rserver-home)</em>/토큰<em>(default-token-4w7gr)</em> 저장소를 생성하고자 했다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason       Age                     From                Message</span><br><span class="line">  ----     ------       ----                    ----                -------</span><br><span class="line">  Warning  FailedMount  13m (x143 over 5h2m)    kubelet, k8s-node1  MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">"pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339"</span> : <span class="built_in">stat</span> /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount: transport endpoint is not connected</span><br><span class="line">  Warning  FailedMount  3m1s (x125 over 4h44m)  kubelet, k8s-node1  Unable to mount volumes <span class="keyword">for</span> pod <span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)"</span>: timeout expired waiting <span class="keyword">for</span> volumes to attach or mount <span class="keyword">for</span> pod <span class="string">"nps"</span>/<span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5"</span>. list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr]</span><br></pre></td></tr></table></figure><p>Pod log 를 확인하고 싶었지만 애초에 뜨기도 전에 Mount Failed 되었기에 해당 노드로 접속하여 Kubelet 로그를 확인하였다.</p><h1 id="Kubelet-log"><a href="#Kubelet-log" class="headerlink" title="Kubelet log"></a>Kubelet log</h1><p>해당 노드에 <code>journal -f | grep kubelet</code> 으로 로그를 살펴보니 Describe 와 다른 점이 없어보이지만, 각 Pod 의 볼륨의 Path <em>(메세지에는 <code>stat /</code> 으로 표현)</em> 를 출력해준다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Jun 08 13:49:57 k8s-node1 kubelet[4638]: E0608 13:49:57.738465    4638 nestedpendingoperations.go:270] Operation <span class="keyword">for</span> <span class="string">"\"kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com^0001-0009-rook-ceph-0000000000000001-d90262eb-a499-11ea-a466-52c8f6e260ed\""</span> failed. No retries permitted until 2020-06-08 13:51:59.738429723 +0000 UTC m=+21911.512876014 (durationBeforeRetry 2m2s). Error: <span class="string">"MountVolume.SetUp failed for volume \"pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339\" (UniqueName: \"kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com^0001-0009-rook-ceph-0000000000000001-d90262eb-a499-11ea-a466-52c8f6e260ed\") pod \"rserver-3.6.3-deployment-776f6b8ddc-gwbk5\" (UID: \"eea991e6-9908-4d41-bd01-141af0566079\") : stat /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount: transport endpoint is not connected"</span></span><br><span class="line">Jun 08 13:50:01 k8s-node1 kubelet[4638]: E0608 13:50:01.755308    4638 kubelet.go:1665] Unable to mount volumes <span class="keyword">for</span> pod <span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)"</span>: timeout expired waiting <span class="keyword">for</span> volumes to attach or mount <span class="keyword">for</span> pod <span class="string">"nps"</span>/<span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5"</span>. list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr]; skipping pod</span><br><span class="line">Jun 08 13:50:01 k8s-node1 kubelet[4638]: E0608 13:50:01.755344    4638 pod_workers.go:190] Error syncing pod eea991e6-9908-4d41-bd01-141af0566079 (<span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5_nps(eea991e6-9908-4d41-bd01-141af0566079)"</span>), skipping: timeout expired waiting <span class="keyword">for</span> volumes to attach or mount <span class="keyword">for</span> pod <span class="string">"nps"</span>/<span class="string">"rserver-3.6.3-deployment-776f6b8ddc-gwbk5"</span>. list of unmounted volumes=[rserver-home]. list of unattached volumes=[rserver-share rserver-home default-token-6w7gr]</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">stat</span> /var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339/mount</span><br></pre></td></tr></table></figure><p>이 부분을 주목해서 보자. 해당 Path 으로 접근하여 <code>mount</code> 폴더를 확인하면 다음과 같다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">pwd</span></span><br><span class="line">/var/lib/kubelet/pods/eea991e6-9908-4d41-bd01-141af0566079/volumes/kubernetes.io~csi/pvc-3a160803-5d2e-4a45-9c9f-b78a0a2e7339</span><br><span class="line">$ ll</span><br><span class="line">ls: cannot access <span class="string">'mount'</span>: Transport endpoint is not connected</span><br><span class="line">total 12</span><br><span class="line">drwxr-x--- 3 root root 4096 Jun  2 06:27 ./</span><br><span class="line">drwxr-x--- 4 root root 4096 Jun  2 06:27 ../</span><br><span class="line">d????????? ? ?    ?       ?            ? mount/</span><br><span class="line">-rw-r--r-- 1 root root  328 Jun  8 13:54 vol_data.json</span><br></pre></td></tr></table></figure><p><code>mount</code> 폴더의 표현이 이상한 것을 확인할 수 있다. 분명 폴더에 대한 읽기쓰기실행 권한과 소유자/그룹이 나와야 하지만 모두 물음표로 출력한다. 이에 대한 구글링을 해본 결과, 해당 디렉토리의 mount 가 비정상 작동하여 이를 해제해야 한다고 한다.  </p><p>정확한 원인은 모르겠지만, <strong>해당 폴더에 대한 잘못된 mount 로 인해 PVC 가 PV 를 제대로 바라보지 못하여 Mount Failed</strong> 난 것으로 이해했다. 해당 디렉토리를 <code>umount</code> 를 이용해 마운트를 해제하고, Kubelet 로그를 더 확인하여 다른 PV stat 으로 접근해 마운트 해제를 수행한다.  </p><p>보아하니 한 번의 <code>umount</code> 로 끝나지 않아 나의 경우,<br><code>/var/lib/kubelet/pods/{위UUID}/volumes/kubernetes.io~csi/</code> 내 모든 PVC 로 접근하여 폴더가 이상하면 마운트를 해제 하였다. 무식할 수 있지만.. 어쨌든 모두 수행하여 Kubelet 로그에 이상이 없는 것을 확인한다.</p><h1 id="정상-작동-확인"><a href="#정상-작동-확인" class="headerlink" title="정상 작동 확인"></a>정상 작동 확인</h1><p><code>kubectl get all -n nps</code> 명령어로 기존에 떠있지 못한 파드가 정상 기동하였는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node2:~<span class="comment"># kubectl get all -n nps -o wide</span></span><br><span class="line">NAME                                            READY   STATUS              RESTARTS   AGE</span><br><span class="line">pod/jupyter-3.7-deployment-f798bb7f4-n2kqq      1/1     Running             0          5h21m</span><br><span class="line">pod/jupyter-3.8-deployment-d47c78475-9gsb8      0/1     ContainerCreating   0          4d12h</span><br><span class="line">pod/pypiserver-deployment-7bbbb48f8c-rkbhk      1/1     Running             0          6d3h</span><br><span class="line">pod/rserver-3.5.3-deployment-96f5d6b4-dhgkg     1/1     Running             0          6d7h</span><br><span class="line">pod/rserver-3.6.3-deployment-776f6b8ddc-gwbk5   1/1     Running             0          6d7h</span><br></pre></td></tr></table></figure><blockquote><p><em>3.8 jupyter 의 경우 해당 파드는 노드가 달라.. 귀찮아서 아직 고치지 않은 모습이다. 이를 고치려면 같은 방법으로 해당 노드로 접근하여 해결해야 할 것 같다.</em></p></blockquote><h1 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h1><p>이번 장애를 겪으면서 얻은 교훈으로는,<br>Pod Describe 도 좋지만 장애가 나는 리소스의 노드로 접근하여 Kubelet 로그도 함께 보는 습관을 가져야 겠다. 물론 Describe로도 충분히 알아낼 수 있는 정보지만, 노드들 간 통신을 담당하는 Kubelet 로그를 통해 좀 더 세부적인 Info 와 Warning 을 확인하여 일석이조의 효과를 누릴 수 있다 생각한다.</p><blockquote><p>엔지니어의 삶은.. 로그라는 선배의 말이 생각난다.</p></blockquote><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-mount_failed/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] Jupyter Notebook 로그 파일 생성</title>
      <link>https://jx2lee.github.io/python-jupyter_logging/</link>
      <guid>https://jx2lee.github.io/python-jupyter_logging/</guid>
      <pubDate>Wed, 27 May 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Jupyter Notebook 실행 이력을 로그파일로 생성하는 과정을 다룬다.  &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Jupyter Notebook 실행 이력을 로그파일로 생성하는 과정을 다룬다.  </p><a id="more"></a><p><strong>Contents:</strong>  </p><ul><li><a href="#env">Environment</a></li><li><a href="#history">log_history.py</a></li><li><a href="#tunning">Customize IPython/core/history.py</a></li><li><a href="#result">Result</a></li><li><a href="#ref">Reference</a></li></ul><h1 id="Environment"><a href="#Environment" class="headerlink" title=" Environment"></a><a name="env"></a> Environment</h1><p>Kubernetes 환경에서 Jupyter Notebook 도커 이미지를 이용해 deployment 로 관리하고 서비스는 노드포트로 구성하여 특정 포트로 Jupyter Notebook 에 접근할 수 있게 설정하였다. Python 버젼은 3.8에서 진행하였으며, Docker image는 3.8, 3.7 등 소수 첫 째 자리까지의 버젼만 빌드할 수 있게 작성되었다. 환경 구성은 다음과 같다.  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kg all -n jupyter-logging</span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/jupyter-3.8-deployment-6676cc56d6-xth7b     1/1     Running   0          13h</span><br><span class="line"></span><br><span class="line">NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/jupyter-38-svc    NodePort   10.96.187.185   &lt;none&gt;        8888:30180/TCP   24d</span><br><span class="line"></span><br><span class="line">NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/jupyter-3.8-deployment     1/1     1            1           13h</span><br><span class="line"></span><br><span class="line">NAME                                                  DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/jupyter-3.8-deployment-6676cc56d6     1         1         1       13h</span><br></pre></td></tr></table></figure><p>Dockerfile 를 통한 빌드 환경은 다음과 같다.  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ll</span><br><span class="line">total 104</span><br><span class="line">drwxr-xr-x 2 root root  4096 May 28 09:05 ./</span><br><span class="line">drwxr-xr-x 6 root root  4096 May 26 09:56 ../</span><br><span class="line">-rw-r--r-- 1 root root    71 May 26 01:52 create_pwd_hash.py</span><br><span class="line">-rw-r--r-- 1 root root  8160 May 26 08:10 Dockerfile</span><br><span class="line">-rw-r--r-- 1 root root   965 May 26 01:52 fix-permissions</span><br><span class="line">-rw-r--r-- 1 root root 33023 May 28 09:05 history.py</span><br><span class="line">-rw-r--r-- 1 root root  1877 May 26 09:54 jupyter_notebook_config.py</span><br><span class="line">-rw-r--r-- 1 root root   949 May 28 09:04 log_history.py</span><br><span class="line">-rwxr-xr-x 1 root root   524 May 26 01:52 start-notebook.sh*</span><br><span class="line">-rwxr-xr-x 1 root root  6302 May 26 01:52 start.sh*</span><br><span class="line">-rwxr-xr-x 1 root root  1181 May 26 01:52 start-singleuser.sh*</span><br></pre></td></tr></table></figure><blockquote><p><em>파일 목록 중 새로 추가한 것은 <code>log_history.py</code>와 <code>history.py</code>이다. 추후에 Dockerfile 커스텀화 한 결과를 추가할 예정이다.</em></p></blockquote><h1 id="log-history-py"><a href="#log-history-py" class="headerlink" title=" log_history.py"></a><a name="history"></a> log_history.py</h1><p>생소할 것이다. 맞다. 왜냐하면 파일 네이밍은 내가 생각한 것이기 때문이다.  </p><p>고객사 요건은 간단하다. Jupyter Notebook 을 이용해 분석가가 코드를 실행하였을 때, 코드 이력을 남기는 log가 필요했다. 물론 python 로그의 경우 python 을 실행한 디렉토리에서 .python_history 가 작성되지만, 이놈의 Jupyter Notebook 은 어디에다 로그를 남기는지 파악이 어려웠다.  </p><p>But, Jupyter Notebook 과 IPython 의 관계를 파악하면 쉽게 풀린다. 구글링 하면 쉽게 차이점을 살필 수 있겠지만, 간단히 설명하면 차이가 있는 것 보다 <code>포함관계</code>를 가진다. 즉, Jupyter Notebook 은 다양한 언어를 지원하는데 그 중 IPython 이 파이썬 언어를 이용할 수 있게 도와준다. 다시 말해 Jupyter Notebook은 IPython 을 포함한다.  </p><p>서론이 길었다. 결국 Jupyter POD 를 기동하면 $HOME 디렉토리에 <code>.ipython</code> 폴더가 생성된다. 구조를 살피면 다음과 같다.  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@jupyter-3:~/.ipython<span class="comment"># tree .</span></span><br><span class="line">.</span><br><span class="line">├── extensions</span><br><span class="line">├── nbextensions</span><br><span class="line">└── profile_default</span><br><span class="line">    ├── db</span><br><span class="line">    ├── history.sqlite</span><br><span class="line">    ├── jupyter.log</span><br><span class="line">    ├── <span class="built_in">log</span></span><br><span class="line">    ├── pid</span><br><span class="line">    ├── security</span><br><span class="line">    └── startup</span><br><span class="line">        └── README</span><br></pre></td></tr></table></figure><p>우리가 주의있게 볼 디렉토리는 <code>startup</code> 폴더다. 이름에서 보이듯, startup 폴더의 README 를 열어보면 쉽게 파악할 수 있다. Notebook 을 실행하기 전 환경 구성을 도와주는 공간이다. 이 폴더에 다음과 같이 <code>log_history.py</code> 를 작성한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> atexit</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">ip = get_ipython()</span><br><span class="line">LIMIT = <span class="number">100000</span> <span class="comment"># limit the size of the history</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_history</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""save the IPython history to a plaintext file"""</span></span><br><span class="line">    histfile = os.path.join(ip.profile_dir.location, <span class="string">"jupyter.log"</span>)</span><br><span class="line">    print(<span class="string">"[INFO] Saving plaintext history to %s"</span> % histfile)</span><br><span class="line">    lines = []</span><br><span class="line">    lines.extend(<span class="string">'[&#123;0&#125;]\n&#123;1&#125;'</span>.format(record[<span class="number">2</span>][<span class="number">1</span>], record[<span class="number">2</span>][<span class="number">0</span>]) + <span class="string">'\n'</span> <span class="keyword">for</span> record <span class="keyword">in</span> ip.history_manager.get_range())</span><br><span class="line">    <span class="comment"># get previous lines</span></span><br><span class="line">    <span class="comment"># this is only necessary because we truncate the history,</span></span><br><span class="line">    <span class="comment"># otherwise we chould just open with mode='a'</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(histfile):</span><br><span class="line">        <span class="keyword">with</span> open(histfile, <span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment">#lines = f.readlines()</span></span><br><span class="line">            f.writelines(lines)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> open(histfile, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.writelines(lines)</span><br><span class="line"></span><br><span class="line"><span class="comment"># do the save at exit</span></span><br><span class="line">atexit.register(save_history)</span><br></pre></td></tr></table></figure><p>코드를 간단히 설명하면 log 파일이 있다면 파일을 수정모드로 열어 Notebook 안에서 실행한 Python 실행 이력을 추가하고, 없으면 새로 만들어 처음으로 생성한 로그를 추가한다. 여기서 주의깊게 볼 곳은 <code>history_manager</code> 오브젝트이다.  </p><p>Jupyter Notebook 의 History 를 관리하는 클래스로 다음 챕터에서 간단히 설명하고 수정한 부분을 설명하겠다.  </p><h1 id="Customize-IPython-core-history-py"><a href="#Customize-IPython-core-history-py" class="headerlink" title=" Customize IPython/core/history.py"></a><a name="tunning"></a> Customize IPython/core/history.py</h1><p>python 설치 디렉토리 내 site-package 에는 IPython 이 존재할 것이다. <code>$PY_PKG_DIR/IPython/core</code> 에 <code>history.py</code> 를 수정할 것이다.  </p><p>수정이 왜 필요한가? 기본적으로 Jupyter Notebook 은 sqlite3 DB에 history 를 남기지만 Timestamp 는 없다. 이를 위해 수정하는 것이기 때문에 <code>history.py</code> 를 열어 <code>def store_inputs</code> 함수를 찾아본다. 그 다음은 쉽다, 한 줄만 추가하면 된다.  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_inputs</span><span class="params">(self, line_num, source, source_raw=None)</span>:</span></span><br><span class="line">    <span class="string">"""Store source and raw input in history and create input cache</span></span><br><span class="line"><span class="string">    variables ``_i*``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    line_num : int</span></span><br><span class="line"><span class="string">      The prompt number of this input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    source : str</span></span><br><span class="line"><span class="string">      Python input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    source_raw : str, optional</span></span><br><span class="line"><span class="string">      If given, this is the raw input without any IPython transformations</span></span><br><span class="line"><span class="string">      applied to it.  If not given, ``source`` is used.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> source_raw <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        source_raw = source</span><br><span class="line">    source = source.rstrip(<span class="string">'\n'</span>)</span><br><span class="line">    source_raw = source_raw.rstrip(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># do not store exit/quit commands</span></span><br><span class="line">    <span class="keyword">if</span> self._exit_re.match(source_raw.strip()):</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    self.input_hist_parsed.append(source)</span><br><span class="line">    <span class="comment">#############</span></span><br><span class="line">    <span class="comment">###append</span></span><br><span class="line">    self.input_hist_raw.append([source_raw, datetime.datetime.now().strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)])</span><br><span class="line">    <span class="comment">###append-end</span></span><br><span class="line">    <span class="comment">#############</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> self.db_input_cache_lock:</span><br><span class="line">        self.db_input_cache.append((line_num, source, source_raw))</span><br><span class="line">        <span class="comment"># Trigger to flush cache and write to DB.</span></span><br><span class="line">        <span class="keyword">if</span> len(self.db_input_cache) &gt;= self.db_cache_size:</span><br><span class="line">            self.save_flag.set()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># update the auto _i variables</span></span><br><span class="line">    self._iii = self._ii</span><br><span class="line">    self._ii = self._i</span><br><span class="line">    self._i = self._i00</span><br><span class="line">    self._i00 = source_raw</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hackish access to user namespace to create _i1,_i2... dynamically</span></span><br><span class="line">    new_i = <span class="string">'_i%s'</span> % line_num</span><br><span class="line">    to_main = &#123;<span class="string">'_i'</span>: self._i,</span><br><span class="line">               <span class="string">'_ii'</span>: self._ii,</span><br><span class="line">               <span class="string">'_iii'</span>: self._iii,</span><br><span class="line">               new_i : self._i00 &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.shell <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.shell.push(to_main, interactive=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>이 함수를 간단히 설명하면, Jupyter Notebook 에서 발생한 python history input 을 sqlite3 DB 에 저장하는 함수다. 추가 내용은 다음과 같다.<br><code>self.input_hist_raw.append([source_raw, datetime.datetime.now().strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)])</code>  </p><blockquote><p><em>이 함수를 추적한 과정은 history_manager.get_range() 가 generator 형태로 반환하기 때문에 <code>yield</code> 검색을 해보니 담당 함수는 <code>_get_range_session</code> 임을 확인했다. 첫 줄 <code>input_hist_raw</code> 가 history 의 raw data 를 포함하는 것을 확인하고 <code>input_hist_raw</code> 검색하여 <code>store_inputs</code> 함수를 trace 하였다.</em></p></blockquote><h1 id="Result"><a href="#Result" class="headerlink" title=" Result"></a><a name="result"></a> Result</h1><p>간단한 Notebook 을 생성하고 log 파일을 확인해본다. log 경로는 <code>$HOME/.ipython/profile-default</code> 경로이다. <em>(log_history.py 에서 수정 가능)</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ cat jupyter.log</span><br><span class="line">[2020-05-28 08:43:46]</span><br><span class="line"><span class="built_in">print</span>(1)</span><br><span class="line">[2020-05-28 08:43:47]</span><br><span class="line">def sum(a, b): <span class="comment"># 3과 5가 각각 매개변수 a와 b에 할당된다.</span></span><br><span class="line">    result = a + b <span class="comment"># 변수 result에는 매개변수 a와 b의 합이 할당되므로 이 경우에는 3과 5의 합인 8이 할당된다.</span></span><br><span class="line">    <span class="built_in">return</span> result <span class="comment"># 8을 함수 바깥으로 반환한다.</span></span><br><span class="line">[2020-05-28 08:43:47]</span><br><span class="line">sum(10,20)</span><br><span class="line">[2020-05-28 08:43:47]</span><br><span class="line"><span class="built_in">print</span>(2)</span><br><span class="line">[2020-05-28 08:43:47]</span><br><span class="line">def say_hello(func):                    <span class="comment"># 1</span></span><br><span class="line">    def wrapper2(*args, **kwargs):      <span class="comment"># 8</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'Hello'</span>)                  <span class="comment"># 11</span></span><br><span class="line">        <span class="built_in">return</span> func(*args, **kwargs)    <span class="comment"># 12</span></span><br><span class="line">    <span class="built_in">return</span> wrapper2                     <span class="comment"># 9</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def say_hi(func):                       <span class="comment"># 2</span></span><br><span class="line">    def wrapper1(*args, **kwargs):      <span class="comment"># 5</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">'Hi'</span>)                     <span class="comment"># 13</span></span><br><span class="line">        <span class="built_in">return</span> func(*args, **kwargs)    <span class="comment"># 14</span></span><br><span class="line">    <span class="built_in">return</span> wrapper1                     <span class="comment"># 6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@say_hello                              <span class="comment"># 7</span></span><br><span class="line">@say_hi                                 <span class="comment"># 4</span></span><br><span class="line">def introduce(name):                    <span class="comment"># 3</span></span><br><span class="line">    <span class="built_in">print</span>(f<span class="string">'My name is &#123;name&#125;!'</span>)        <span class="comment"># 15</span></span><br><span class="line"></span><br><span class="line">introduce(<span class="string">'Jaejun'</span>)                    <span class="comment"># 10</span></span><br></pre></td></tr></table></figure><blockquote><p><em>추가적으로 고려할 사항이 있다. log 파일 관리인데 최대 크기를 지정해서 용량이 커지면 이전 History 를 삭제하는 방안을 마련하고 있다. 조만간 Dockerfile 도 완성되면 추가할 예정이다.</em></p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title=" Reference"></a><a name="ref"></a> Reference</h1><ul><li><a href="https://anaconda.org/conda-forge/python-json-logger" target="_blank" rel="noopener">https://anaconda.org/conda-forge/python-json-logger</a></li><li><a href="https://velog.io/@log327" target="_blank" rel="noopener">https://velog.io/@log327</a></li><li><a href="https://stackoverflow.com/" target="_blank" rel="noopener">https://stackoverflow.com/questions/16858724/how-to-log-ipython-history-to-text-file</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-jupyter_logging/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] Jupyter Notebook 을 이용한 Hadoop 및 Database 연동</title>
      <link>https://jx2lee.github.io/python-connection_test/</link>
      <guid>https://jx2lee.github.io/python-connection_test/</guid>
      <pubDate>Thu, 14 May 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Python 을 이용한 Hadoop 및 Database 연동 테스트를 진행하였다.  &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Python 을 이용한 Hadoop 및 Database 연동 테스트를 진행하였다.  </p><a id="more"></a><p><strong>환경구성</strong>:  </p><ul><li>Hadoop Cluster <em>(CDH 6.3.2)</em><ul><li>cdh1: 192.168.179.181</li><li>cdh2: 192.168.179.182</li><li>cdh3: 192.168.179.183 <em>(master)</em></li></ul></li><li>Jupyter Notebook<ul><li>docker custom image <em>(python version: 3.7)</em></li><li>kubernetes deployment 배포<ul><li><code>namespace</code>: nps</li></ul></li><li>컨테이너 환경 : Ubuntu 18.04.4 LTS</li></ul></li></ul><p><strong>Contents</strong>:  </p><ul><li><a href="#hdfs">HDFS</a></li><li><a href="#hive">Hive</a></li><li><a href="#hbase">HBase</a></li><li><a href="#impala">Impala</a></li><li><a href="#spark">Spark</a></li><li><a href="#sybase">Sybase</a></li><li><a href="#oracle">Oracle</a></li></ul><h1 id="HDFS"><a href="#HDFS" class="headerlink" title=" HDFS"></a><a name="hdfs"></a> HDFS</h1><h2 id="설치-패키지"><a href="#설치-패키지" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><ul><li>hdfs<ul><li>Requirement already satisfied: docopt in /opt/conda/lib/python3.8/site-packages (from hdfs) (0.6.2)</li><li>Requirement already satisfied: six&gt;=1.9.0 in /opt/conda/lib/python3.8/site-packages (from hdfs) (1.14.0)</li><li>Requirement already satisfied: requests&gt;=2.7.0 in /opt/conda/lib/python3.8/site-packages (from hdfs) (2.23.0)</li><li>Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.8/site-packages (from   - requests&gt;=2.7.0-&gt;hdfs) (1.25.9)</li><li>Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (3.0.4)</li><li>Requirement already satisfied: idna&lt;3,&gt;=2.5 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (2.9)</li><li>Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests&gt;=2.7.0-&gt;hdfs) (2020.4.5.1)</li></ul></li></ul><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> hdfs <span class="keyword">import</span> InsecureClient</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection</span></span><br><span class="line"></span><br><span class="line">client_hdfs = InsecureClient(<span class="string">'http://192.168.179.183:9870'</span>, user=<span class="string">'hdfs'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create</span></span><br><span class="line"></span><br><span class="line">create_df = pd.DataFrame([<span class="number">1000</span>, <span class="number">2000</span>, <span class="number">3000</span>, <span class="number">4000</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> client_hdfs.write(<span class="string">'/tmp/t2.csv'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    create_df.to_csv(writer)</span><br><span class="line"></span><br><span class="line">print(client_hdfs.list(<span class="string">'/tmp'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Read</span></span><br><span class="line"></span><br><span class="line">client_hdfs.list(<span class="string">'/tmp'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> client_hdfs.read(<span class="string">'/tmp/test.csv'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    df = pd.read_csv(reader)</span><br><span class="line">    print(df)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Update</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> client_hdfs.read(<span class="string">'/tmp/t2.csv'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> reader:</span><br><span class="line">    df = pd.read_csv(reader)</span><br><span class="line">df.loc[<span class="number">4</span>] = [<span class="number">4</span>,<span class="number">5000</span>]</span><br><span class="line">client_hdfs.delete(<span class="string">'/tmp/t2.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> client_hdfs.write(<span class="string">'/tmp/t2.csv'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    df.to_csv(writer)</span><br><span class="line">    print(df)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Delete</span></span><br><span class="line"></span><br><span class="line">client_hdfs.delete(<span class="string">'/tmp/t2.csv'</span>)</span><br><span class="line"><span class="string">'t2.csv'</span> <span class="keyword">in</span> client_hdfs.list(<span class="string">'/tmp'</span>)</span><br></pre></td></tr></table></figure><h2 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://pypi.org/project/hdfs/" target="_blank" rel="noopener">https://pypi.org/project/hdfs/</a></li><li><a href="https://hdfscli.readthedocs.io/en/latest/api.html" target="_blank" rel="noopener">https://hdfscli.readthedocs.io/en/latest/api.html</a></li></ul><h1 id="Hive"><a href="#Hive" class="headerlink" title=" Hive"></a><a name="hive"></a> Hive</h1><h2 id="설치-패키지-1"><a href="#설치-패키지-1" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-1"><a href="#Linux-1" class="headerlink" title="Linux"></a>Linux</h3><ul><li>libsasl2-dev</li><li>libsasl2-modules</li></ul><h3 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h3><ul><li>pyhive<ul><li>Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from pyhive) (0.18.2)</li><li>Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from pyhive) (2.8.1)</li><li>Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil-&gt;pyhive) (1.14.0)</li></ul></li><li>thrift</li><li>sasl</li><li>thrift_sasl<ul><li>Requirement already satisfied: thrift&gt;=0.10.0 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (0.13.0)</li><li>Requirement already satisfied: sasl&gt;=0.2.1 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (0.2.1)</li><li>Requirement already satisfied: six&gt;=1.13.0 in /opt/conda/lib/python3.8/site-packages (from thrift_sasl) (1.14.0)</li></ul></li></ul><h3 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyhive.hive <span class="keyword">as</span> hive</span><br><span class="line">conn = hive.Connection(host=<span class="string">'cdh3'</span>, port=<span class="number">10000</span>, username=<span class="string">'root'</span>, password=<span class="string">'tmaxtmax'</span>, database=<span class="string">'default'</span>, auth=<span class="string">'CUSTOM'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create</span></span><br><span class="line"></span><br><span class="line">cur = conn.cursor()</span><br><span class="line">sql = <span class="string">"CREATE TABLE `default`.`create_test` (  `field_1` bigint ,  `field_2` string ,  `field_3` string ,  `field_4` string ,  `field_5` string ,  `field_6` bigint ,  `field_7` string ,  `field_8` double ,  `field_9` string ,  `field_10` string ) ROW FORMAT   DELIMITED    FIELDS TERMINATED BY '|'    COLLECTION ITEMS TERMINATED BY ''    MAP KEYS TERMINATED BY ''  STORED AS TextFile"</span></span><br><span class="line">cur.execute(sql)</span><br><span class="line"></span><br><span class="line">cur = conn.cursor()</span><br><span class="line">cur.execute(<span class="string">'select * from create_test'</span>)</span><br><span class="line">res = cur.fetchall()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read</span></span><br><span class="line"></span><br><span class="line">cur.execute(<span class="string">'select count(*) from create_test'</span>)</span><br><span class="line">res = cur.fetchall()</span><br><span class="line"></span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update</span></span><br><span class="line"></span><br><span class="line">cur.execute(<span class="string">'alter table create_test rename to create_test_rev'</span>)</span><br><span class="line">cur.execute(<span class="string">'describe create_test_rev'</span>)</span><br><span class="line">res = cur.fetchall()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete</span></span><br><span class="line"></span><br><span class="line">cur.execute(<span class="string">'drop table create_test_rev'</span>)</span><br><span class="line">cur.execute(<span class="string">'show tables'</span>)</span><br><span class="line">res = cur.fetchall()</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure><h2 id="Ref-1"><a href="#Ref-1" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://sungwookkang.com/m/1367" target="_blank" rel="noopener">https://sungwookkang.com/m/1367</a></li></ul><h1 id="HBase"><a href="#HBase" class="headerlink" title=" HBase"></a><a name="hbase"></a> HBase</h1><ul><li>Hbase 서버 내 Thrift 가 동작하고 있어야함<ul><li>클러스터 내 아무 노드에서 <code>$ hbase thrift &amp;</code> 명령어로 thrift 실행<ul><li>backgroud 구동</li></ul></li></ul></li></ul><h2 id="설치-패키지-2"><a href="#설치-패키지-2" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-2"><a href="#Linux-2" class="headerlink" title="Linux"></a>Linux</h3><h3 id="Python-2"><a href="#Python-2" class="headerlink" title="Python"></a>Python</h3><ul><li>happybase<ul><li>Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from happybase) (1.14.0)</li><li>Requirement already satisfied: thriftpy2&gt;=0.4 in /opt/conda/lib/python3.8/site-packages (from happybase) (0.4.11)</li><li>Requirement already satisfied: ply&lt;4.0,&gt;=3.4 in /opt/conda/lib/python3.8/site-packages (from thriftpy2&gt;=0.4-&gt;happybase) (3.11)</li></ul></li></ul><h2 id="Code-2"><a href="#Code-2" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> happybase</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection</span></span><br><span class="line"></span><br><span class="line">conn = happybase.Connection(<span class="string">'192.168.179.183'</span>, <span class="number">9090</span>, autoconnect=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create </span></span><br><span class="line"></span><br><span class="line">conn.create_table(<span class="string">'test'</span>,&#123;<span class="string">'cf'</span>:&#123;&#125;&#125;)</span><br><span class="line">conn.tables()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Read</span></span><br><span class="line"></span><br><span class="line">tbl = conn.table(<span class="string">'test'</span>)</span><br><span class="line"><span class="keyword">for</span> key, data <span class="keyword">in</span> tbl.scan():</span><br><span class="line">    print(key, data)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Update</span></span><br><span class="line"></span><br><span class="line">table = conn.table(<span class="string">'test'</span>)</span><br><span class="line">table.put(<span class="string">'row-key'</span>,&#123;<span class="string">'cf:col1'</span>:<span class="string">'value1'</span>,<span class="string">'cf:col2'</span>:<span class="string">'value2'</span>&#125;)</span><br><span class="line">row = dict(table.row(<span class="string">'row-key'</span>))</span><br><span class="line"></span><br><span class="line">print(row)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Delete</span></span><br><span class="line"></span><br><span class="line">conn.delete_table(<span class="string">'test'</span>, disable=<span class="literal">True</span>)</span><br><span class="line">conn.tables()</span><br></pre></td></tr></table></figure><h2 id="Ref-2"><a href="#Ref-2" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://creatorw.tistory.com/entry/Hbase%EC%99%80-python-%EC%97%B0%EA%B2%B0-%ED%95%98%EA%B8%B0%EA%B8%B0" target="_blank" rel="noopener">https://creatorw.tistory.com/entry/Hbase%EC%99%80-python-%EC%97%B0%EA%B2%B0-%ED%95%98%EA%B8%B0%EA%B8%B0</a></li></ul><h1 id="Impala"><a href="#Impala" class="headerlink" title=" Impala"></a><a name="impala"></a> Impala</h1><ul><li>connection 시 host 는 마스터로 작성하니 connection 이 되지 않음<ul><li>마스터 외 노드 ip로 host 설정 필요</li></ul></li></ul><h2 id="설치-패키지-3"><a href="#설치-패키지-3" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-3"><a href="#Linux-3" class="headerlink" title="Linux"></a>Linux</h3><h3 id="Python-3"><a href="#Python-3" class="headerlink" title="Python"></a>Python</h3><ul><li>impyla==0.15a1 *(꼭 0.15a1 버젼 설치 필요)<ul><li>Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (1.14.0)</li><li>Requirement already satisfied: bitarray in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (1.2.1)</li><li>Requirement already satisfied: thrift&gt;=0.9.3 in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (0.13.0)</li><li>Requirement already satisfied: thriftpy2==0.4.0; python_version &gt;= “3.0” in /opt/conda/lib/python3.8/site-packages (from impyla==0.15a1) (  - 0.4.0)</li><li>Requirement already satisfied: ply&lt;4.0,&gt;=3.4 in /opt/conda/lib/python3.8/site-packages (from thriftpy2==0.4.0; python_version &gt;=   - “3.0”-&gt;impyla==0.15a1) (3.11)</li></ul></li></ul><h2 id="Code-3"><a href="#Code-3" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> impala.dbapi <span class="keyword">import</span> connect</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection</span></span><br><span class="line"></span><br><span class="line">conn = connect(host=<span class="string">'192.168.179.181'</span>, port=<span class="number">21050</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">cursor.get_databases()</span><br><span class="line"></span><br><span class="line">drop = <span class="string">"DROP TABLE IF EXISTS default.tab;"</span></span><br><span class="line"></span><br><span class="line">create = <span class="string">"""</span></span><br><span class="line"><span class="string">CREATE EXTERNAL TABLE default.tab</span></span><br><span class="line"><span class="string">(</span></span><br><span class="line"><span class="string">id INT,</span></span><br><span class="line"><span class="string">col_1 BOOLEAN,</span></span><br><span class="line"><span class="string">col_2 DOUBLE,</span></span><br><span class="line"><span class="string">col_3 TIMESTAMP</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">ROW FORMAT DELIMITED FIELDS TERMINATED BY ','</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Create</span></span><br><span class="line"></span><br><span class="line">cursor.execute(create)</span><br><span class="line">cursor.execute(<span class="string">'select count(*) from default.tab'</span>)</span><br><span class="line">res = cursor.fetchall()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Read</span></span><br><span class="line"></span><br><span class="line">cursor.execute(<span class="string">'select * from tab'</span>)</span><br><span class="line">res = cursor.fetchall()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Update</span></span><br><span class="line"></span><br><span class="line">cursor.execute(<span class="string">'alter table default.tab rename to default.tab_rev'</span>)</span><br><span class="line">cursor.execute(<span class="string">'describe default.tab_rev'</span>)</span><br><span class="line">res = cursor.fetchall()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Delete</span></span><br><span class="line"></span><br><span class="line">cursor.execute(<span class="string">'drop table default.tab_rev'</span>)</span><br><span class="line">cursor.execute(<span class="string">'show tables'</span>)</span><br><span class="line">res = cursor.fetchall()</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure><h2 id="Ref-3"><a href="#Ref-3" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://euriion.com/?p=411856" target="_blank" rel="noopener">https://euriion.com/?p=411856</a></li><li><a href="https://m.blog.naver.com/PostView.nhn?blogId=hancury&logNo=220755129588&proxyReferer=https:%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">https://m.blog.naver.com/PostView.nhn?blogId=hancury&amp;logNo=220755129588&amp;proxyReferer=https:%2F%2Fwww.google.com%2F</a></li></ul><h1 id="Spark"><a href="#Spark" class="headerlink" title=" Spark"></a><a name="spark"></a> Spark</h1><ul><li>python 3.8 패키지 미지원 <em>(pyspark)</em><ul><li><code>python 3.7</code> 환경에서만 진행</li></ul></li><li>컨테이너 내 <code>hadoop client</code> 및 <code>spark</code> 설치 필요<ul><li>hadoop: <code>$ wget https://archive.apache.org/dist/hadoop/core/hadoop-3.0.0/hadoop-3.0.0.tar.gz</code><ul><li>cdh 클라이언트 구성파일 중 core-site.xml, hdfs-site.xml, yarn-site.xml 을 <code>$HADOOP_HOME/etc/hadoop</code> 으로 copy&amp;paste</li></ul></li><li>spark: <a href="https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz" target="_blank" rel="noopener">spark-2.4.0-bin-hadoop2.7.tgz</a></li></ul></li><li><code>.bashrc</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/jovyan/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CMD=/home/jovyan/hadoop/bin/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/home/jovyan/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_CMD</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/home/jovyan/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br></pre></td></tr></table></figure></li><li>CDH spark 구성<ul><li>master: yarn</li><li>deploy mode: client</li></ul></li></ul><h2 id="설치-패키지-4"><a href="#설치-패키지-4" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-4"><a href="#Linux-4" class="headerlink" title="Linux"></a>Linux</h3><ul><li>default-jdk</li></ul><h3 id="Python-4"><a href="#Python-4" class="headerlink" title="Python"></a>Python</h3><ul><li>pyspark<ul><li>Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.8/site-packages (from pyspark) (0.10.7)</li></ul></li></ul><h2 id="Ref-4"><a href="#Ref-4" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://www.sicara.ai/blog/2017-05-02-get-started-pyspark-jupyter-notebook-3-minutes" target="_blank" rel="noopener">https://www.sicara.ai/blog/2017-05-02-get-started-pyspark-jupyter-notebook-3-minutes</a></li><li><a href="https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark_ipython.html" target="_blank" rel="noopener">https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark_ipython.html</a></li><li><a href="https://github.com/mike-wendt/cloudera-jupyter-notebook-spark" target="_blank" rel="noopener">https://github.com/mike-wendt/cloudera-jupyter-notebook-spark</a></li></ul><blockquote><p>위와 같은 환경에서 Spark 연동은 사실 어렵다. 왜냐하면 CDH 내 Yarn 에서 컨테이너 호스트명을 인식하지 못하는 문제가 발생하기 때문이다. 이는 CDH Yarn config 를 수정해서, 컨테이너 호스트명을 바라볼 수 있게끔 변경하면 yarn-client 모드로 연동이 가능하다. 아니면 <code>Livy</code> 라는 패키지를 CDH 클러스터에 설치하여 API 로 연동하는 방법이 존재한다. <em>(구글링 추천)</em></p></blockquote><h1 id="Sybase"><a href="#Sybase" class="headerlink" title=" Sybase"></a><a name="sybase"></a> Sybase</h1><ul><li>jar file<ul><li>jconn3.jar <em>(jdk 버젼별로 상이할 수 있으므로 jconn4.jar 준비 필요)</em></li></ul></li></ul><h2 id="설치-패키지-5"><a href="#설치-패키지-5" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-5"><a href="#Linux-5" class="headerlink" title="Linux"></a>Linux</h3><ul><li>default-jdk</li></ul><h3 id="Python-5"><a href="#Python-5" class="headerlink" title="Python"></a>Python</h3><ul><li>jpype1==0.6.3</li><li>Jaydebeapi</li></ul><h2 id="Code-4"><a href="#Code-4" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jpype</span><br><span class="line"><span class="keyword">import</span> jaydebeapi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection</span></span><br><span class="line"></span><br><span class="line">conn = jaydebeapi.connect(<span class="string">'com.sybase.jdbc3.jdbc.SybDriver'</span>, <span class="string">'jdbc:sybase:Tds:192.168.179.169:2638'</span>, &#123;<span class="string">'user'</span>: <span class="string">'DBA'</span>, <span class="string">'password'</span>: <span class="string">'sql'</span>&#125;</span><br><span class="line">                          ,[<span class="string">'/home/jovyan/jconn3.jar'</span>])</span><br><span class="line">c1 = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'create table aa(a int)'</span>)</span><br><span class="line">c1.execute(<span class="string">'select * from aa'</span>)</span><br><span class="line">print(c1.fetchall())</span><br><span class="line"></span><br><span class="line"><span class="comment">## Read</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'select * from aa'</span>)</span><br><span class="line">print(c1.fetchall())</span><br><span class="line"></span><br><span class="line"><span class="comment">## Update</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'insert into aa (a) values (1000)'</span>)</span><br><span class="line">c1.execute(<span class="string">'select * from aa'</span>)</span><br><span class="line">print(c1.fetchall())</span><br><span class="line"></span><br><span class="line"><span class="comment">## Delete</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'drop table aa'</span>)</span><br><span class="line">c1.execute(<span class="string">'select * from aa'</span>)</span><br><span class="line">print(c1.fetchall())</span><br></pre></td></tr></table></figure><h2 id="Ref-5"><a href="#Ref-5" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://stackoverflow.com/questions/3319788/what-is-the-best-way-to-connect-to-a-sybase-database-from-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/3319788/what-is-the-best-way-to-connect-to-a-sybase-database-from-python</a></li></ul><h1 id="Oracle"><a href="#Oracle" class="headerlink" title=" Oracle"></a><a name="oracle"></a> Oracle</h1><ul><li>jar file<ul><li>ojdbc6.jar</li></ul></li></ul><h2 id="설치-패키지-6"><a href="#설치-패키지-6" class="headerlink" title="설치 패키지"></a>설치 패키지</h2><h3 id="Linux-6"><a href="#Linux-6" class="headerlink" title="Linux"></a>Linux</h3><ul><li>default-jdk</li></ul><h3 id="Python-6"><a href="#Python-6" class="headerlink" title="Python"></a>Python</h3><ul><li>jpype1==0.6.3</li><li>Jaydebeapi</li></ul><h2 id="Code-5"><a href="#Code-5" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jpype</span><br><span class="line"><span class="keyword">import</span> jaydebeapi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#jpype.startJVM(jpype.getDefaultJVMPath(), classpath='/home/jovyan/ojdbc6.jar', convertStrings=True)</span></span><br><span class="line">conn = jaydebeapi.connect(<span class="string">'oracle.jdbc.driver.OracleDriver'</span>, <span class="string">'jdbc:oracle:thin:scott/tiger@192.168.179.167:1521:ORCL1'</span>, jars=<span class="string">'/home/jovyan/ojdbc6.jar'</span>)</span><br><span class="line"></span><br><span class="line">c1 = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'create table bb(a number)'</span>)</span><br><span class="line">c1.execute(<span class="string">'select * from bb'</span>)</span><br><span class="line">res = c1.fetchone()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Read</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'select * from emp'</span>)</span><br><span class="line">res = c1.fetchone()</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Update</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'insert into bb values (1000)'</span>)</span><br><span class="line">c1.execute(<span class="string">'select * from bb'</span>)</span><br><span class="line">print(c1.fetchall())</span><br><span class="line"></span><br><span class="line"><span class="comment">## Delete</span></span><br><span class="line"></span><br><span class="line">c1.execute(<span class="string">'drop table scott.bb'</span>)</span><br></pre></td></tr></table></figure><h2 id="Ref-6"><a href="#Ref-6" class="headerlink" title="Ref"></a>Ref</h2><ul><li><a href="https://m.blog.naver.com/PostView.nhn?blogId=axzswq&logNo=221533592504&proxyReferer=https:%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">https://m.blog.naver.com/PostView.nhn?blogId=axzswq&amp;logNo=221533592504&amp;proxyReferer=https:%2F%2Fwww.google.com%2F</a></li><li><a href="http://blog.naver.com/PostView.nhn?blogId=delfood&logNo=221666021769&categoryNo=33&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=search" target="_blank" rel="noopener">http://blog.naver.com/PostView.nhn?blogId=delfood&amp;logNo=221666021769&amp;categoryNo=33&amp;parentCategoryNo=0&amp;viewDate=&amp;currentPage=1&amp;postListTopCurrentPage=1&amp;from=search</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-connection_test/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] CDH(ClouDera Hadoop) Client 설정</title>
      <link>https://jx2lee.github.io/hadoop-client/</link>
      <guid>https://jx2lee.github.io/hadoop-client/</guid>
      <pubDate>Thu, 14 May 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Python 을 이용해 CDH 연동하는 과정에서 Hadoop Client 설정 방법에 대해 정리한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Python 을 이용해 CDH 연동하는 과정에서 Hadoop Client 설정 방법에 대해 정리한다.</p><a id="more"></a><p><strong>Contents:</strong>  </p><ul><li><a href="#download">Bianry Download</a></li><li><a href="#config">CDH Hadoop Config</a></li><li><a href="#tar">Client 압축 해제</a></li><li><a href="#apply">Config 적용</a></li><li><a href="#hosts">/etc/hosts 적용</a></li><li><a href="#env">ENV</a></li></ul><h1 id="Bianry-Download"><a href="#Bianry-Download" class="headerlink" title=" Bianry Download"></a><a name="donwload"></a> Bianry Download</h1><ul><li>wget 을 이용해 CDH hadoop 3 버젼을 다운</li><li><code>$ wget https://archive.apache.org/dist/hadoop/core/hadoop-3.0.0/hadoop-3.0.0.tar.gz</code></li></ul><h1 id="CDH-Hadoop-Config"><a href="#CDH-Hadoop-Config" class="headerlink" title=" CDH Hadoop Config"></a><a name="config"></a> CDH Hadoop Config</h1><ul><li>CDH 웹에서 hadoop config 을 다운로드<ul><li>core-site.xml</li><li>hdfs-site.xml</li><li>yarn-site.xml <em>(Yarn 구성 시)</em></li></ul></li></ul><h1 id="Client-압축-해제"><a href="#Client-압축-해제" class="headerlink" title=" Client 압축 해제"></a><a name="tar"></a> Client 압축 해제</h1><ul><li>특정 directory 에 압축 해제</li><li><code>$ tar -xvf hadoop-3.0.0.tar.gz &amp;&amp; mv hadoop-3.0.0 hadoop</code></li></ul><h1 id="Config-적용"><a href="#Config-적용" class="headerlink" title=" Config 적용"></a><a name="apply"></a> Config 적용</h1><ul><li><code>$HADOOP_HOME/etc/hadoop</code> 에 위에 준비한 CDH config 을 copy &amp; paste</li><li><code>$ cp *-site.xml $HADOOP_HOME/etc/hadoop</code></li></ul><h1 id="etc-hosts-적용"><a href="#etc-hosts-적용" class="headerlink" title=" /etc/hosts 적용"></a><a name="hosts"></a> /etc/hosts 적용</h1><ul><li>Client 서버의 IP hostname 에 마찬가지로 클러스터 노드 정보를 작성<ul><li>example<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#/etc/hosts</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">192.168.179.181  chd1</span><br><span class="line">192.168.179.182  chd2</span><br><span class="line">192.168.179.183  chd3</span><br></pre></td></tr></table></figure></li><li><code>$ touch /etc/hosts</code> 로 파일 적용</li></ul></li></ul><h1 id="ENV"><a href="#ENV" class="headerlink" title=" ENV"></a><a name="env"></a> ENV</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/jovyan/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CMD=/home/jovyan/hadoop/bin/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_CMD</span></span><br></pre></td></tr></table></figure><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-client/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubeflow Katib 소개</title>
      <link>https://jx2lee.github.io/cloud-kubeflow_katib/</link>
      <guid>https://jx2lee.github.io/cloud-kubeflow_katib/</guid>
      <pubDate>Sun, 03 May 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Kubeflow 책을 공부하며 내용을 정리하고자 한다. 이번 파트는 &lt;code&gt;Katib&lt;/code&gt; 이다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kubeflow 책을 공부하며 내용을 정리하고자 한다. 이번 파트는 <code>Katib</code> 이다.</p><a id="more"></a><h1 id="Katib"><a href="#Katib" class="headerlink" title="Katib"></a>Katib</h1><p>Kubeflow 설치 시 자동으로 설치하는 컴포넌트로, 하이퍼파라미터 최적화와 뉴럴 아키텍처 탐색(NAS)으로 구성한다. 하이퍼파라미터 최적화와 뉴럴 아키텍처 탐색(NAS)에 대한 개념은 이번 글에서 다루지 않는다.</p><ul><li>하이퍼파라미터 참고<ul><li><a href="https://jx2lee.github.io/2019/07/02/ml-introduction_to_grid_search/">https://jx2lee.github.io/2019/07/02/ml-introduction_to_grid_search/</a></li><li><a href="https://medium.com/@jorgesleonel/hyperparameters-in-machine-deep-learning-ca69ad10b981" target="_blank" rel="noopener">Hyperparameters in Machine /Deep Learning</a></li></ul></li><li>뉴럴 아키텍쳐 탐색(NAS)<ul><li><a href="http://research.sualab.com/review/2018/09/28/nasnet-review.html" target="_blank" rel="noopener">AutoML을 이용한 Architecture Search 소개 및 NASNet 논문 리뷰</a></li><li><a href="http://www.secmem.org/blog/2019/07/19/Network-Architecture-Search/" target="_blank" rel="noopener">Network Architecture Search - Samsung Software Membership</a></li></ul></li></ul><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Katib 은 크게 4가지 개념으로 이루어졌다.</p><p><img src="/image/katib-architecture.png" alt="Katib 구조"></p><ul><li>Experiment : 하나의 실행단위로 Job 개념으로 생각하면 된다. K8s 커스텀 리소스로 Trial 를 실행하는 역할을 하며 Experiment 는 5개 영역으로 나뉜다.<ul><li>Trial Count : 실행 횟수 (병렬)</li><li>Trial Template : Trial 파드 템플릿</li><li>Objective : 목표 수치 (최곳값 또는 최솟값 설정)</li><li>Search Parameter : 탐색하고자 하는 파라미터 값의 range</li><li>Search Algorithm : 탐색 알고리즘</li></ul></li><li>Trial : 최적화 과정의 반복 단위. Experiment의 Trial Count 값 만큼 Trial을 생성하고 순차적으로 실행. 하나의 Trial 에서 하나의 worker job을 실행, Trial 도 K8s 커스텀 리소스</li><li>Suggestion : Search Algorithm 으로 생성한 하이퍼파라미터 값의 모음. 하나의 Experiment 에서 하나의 Suggestion 을 생성</li><li>Worker job : 파라미터와 Suggestion 값을 이용해 Trial, 각각의 값을 평가하고 계사하는 프로세스. 실제로 학습을 수행하며 K8s Job 과 TFJob, PyTorch 을 사용</li></ul><h2 id="Experiment-example"><a href="#Experiment-example" class="headerlink" title="Experiment example"></a>Experiment example</h2><p>MNIST 예제 템플릿을 함께 보며 위에서 설명한 구조와 비교하며 살펴본다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">"kubeflow.org/v1alpha3"</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Experiment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubeflow</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">controller-tools.k8s.io:</span> <span class="string">"1.0"</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">handson-experiment-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">parallelTrialCount:</span> <span class="number">5</span><span class="comment"># 병렬로 실행할 Trial 수로, 리소스 허용한도까지 동시에 5개 Trial 을 실행한다.</span></span><br><span class="line">  <span class="attr">maxTrialCount:</span> <span class="number">30</span> <span class="comment"># 최대로 실행할 Trial 수로 총 30개. parallelTrialCount 가 5 이므로 병렬로 5개 Trial 을 실행하고 6번 반복</span></span><br><span class="line">  <span class="attr">maxFailedTrialCount:</span> <span class="number">3</span>  <span class="comment"># 실패 한도 수로 Trial 이 3번 실패하면 Experiment 를 중지한다. </span></span><br><span class="line">  <span class="attr">objective:</span>  <span class="comment"># 수집 대상의 메트릭 설정 단계 </span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">maximize</span>  <span class="comment"># 최댓값 또는 최솟값 설정 (본 예제는 maximize, 최댓값)</span></span><br><span class="line">    <span class="attr">goal:</span> <span class="number">0.99</span><span class="comment"># 목표 수치 설정</span></span><br><span class="line">    <span class="attr">objectiveMetricName:</span> <span class="string">validation-accuracy</span>  <span class="comment"># 수집할 메트릭 name, validation-accuracy 로 설정</span></span><br><span class="line">    <span class="attr">additionalMetricNames:</span>  <span class="comment"># 이외 수집할 메트릭을 정의 (accuracy, loss, validation-loss 3개를 추가 수집할 예정)</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">accuracy</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">loss</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">Validation-loss</span></span><br><span class="line">  <span class="attr">algorithm:</span>  <span class="comment"># Search Algorithm 설정 (그리드, 랜덤, 하이퍼밴드, 베이지안최적화 선택 가능)</span></span><br><span class="line">    <span class="attr">algorithmName:</span> <span class="string">random</span></span><br><span class="line">  <span class="attr">trialTemplate:</span>  <span class="comment"># Trial 템플릿 정의</span></span><br><span class="line">    <span class="attr">goTemplate:</span></span><br><span class="line">        <span class="attr">rawTemplate:</span> <span class="string">|-</span></span><br><span class="line">          <span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line">          <span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line">          <span class="attr">metadata:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">&#123;&#123;.Trial&#125;&#125;</span></span><br><span class="line">            <span class="attr">namespace:</span> <span class="string">&#123;&#123;.NameSpace&#125;&#125;</span></span><br><span class="line">          <span class="attr">spec:</span></span><br><span class="line">            <span class="attr">template:</span></span><br><span class="line">              <span class="attr">spec:</span></span><br><span class="line">                <span class="attr">containers:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#123;&#123;.Trial&#125;&#125;</span></span><br><span class="line">                  <span class="attr">image:</span> <span class="string">brightfly/katib-job:handson</span></span><br><span class="line">                  <span class="attr">command:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">"python"</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">"/app/katib_keras_mnist.py"</span></span><br><span class="line">                  <span class="string">&#123;&#123;-</span> <span class="string">with</span> <span class="string">.HyperParameters&#125;&#125;</span><span class="comment"># 설정 파라미터의 iteration 구문. .Name=.Value 형태로 메트릭 수집</span></span><br><span class="line">                  <span class="string">&#123;&#123;-</span> <span class="string">range</span> <span class="string">.&#125;&#125;</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">"<span class="template-variable">&#123;&#123;.Name&#125;&#125;</span>=<span class="template-variable">&#123;&#123;.Value&#125;&#125;</span>"</span></span><br><span class="line">                  <span class="string">&#123;&#123;-</span> <span class="string">end&#125;&#125;</span></span><br><span class="line">                  <span class="string">&#123;&#123;-</span> <span class="string">end&#125;&#125;</span></span><br><span class="line">                <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">parameters:</span> <span class="comment"># 하이퍼파라미터 입력값으로 learning rate 와 dropout 설정</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">--learning_rate</span></span><br><span class="line">      <span class="attr">parameterType:</span> <span class="string">double</span></span><br><span class="line">      <span class="attr">feasibleSpace:</span>  <span class="comment"># 각 하이퍼파라미터의 range 설정</span></span><br><span class="line">        <span class="attr">min:</span> <span class="string">"0.01"</span></span><br><span class="line">        <span class="attr">max:</span> <span class="string">"0.03"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">--dropout_rate</span></span><br><span class="line">      <span class="attr">parameterType:</span> <span class="string">double</span></span><br><span class="line">      <span class="attr">feasibleSpace:</span></span><br><span class="line">        <span class="attr">min:</span> <span class="string">"0.1"</span></span><br><span class="line">        <span class="attr">max:</span> <span class="string">"0.9"</span></span><br></pre></td></tr></table></figure><p>본 템플릿으로 Experiment 를 실행하면 <code>python /app/katib_keras_mnist.py -learning_rate=0.012--dropout_rate=0.381</code> 와 같이 실행한다.</p><h1 id="Katib-Component"><a href="#Katib-Component" class="headerlink" title="Katib Component"></a>Katib Component</h1><p>Katib 을 구성하는 컴포넌트로는 총 4개가 존재한다. 각 컴포넌트는 kubectl 로 조회 가능하며 K8s의 Deployment 로 관리한다.</p><ul><li>katib-manager : GRPC API server</li><li>katib-db : Katib 의 백엔드 저장소, mysql</li><li>katib-ui : Katib UI</li><li>katib-controller : katib CRD의 컨트롤러</li></ul><h1 id="Katib-UI"><a href="#Katib-UI" class="headerlink" title="Katib UI"></a>Katib UI</h1><p>Web UI를 제공하는데 크게 Hyperparameter Tuning 과 NAS 2개 메뉴가 존재한다. Hyperparameter Tuning 에서는 직접 YAML 을 작성하거나 마우스와 키보드로 값을 추가할 수 있는 페이지를 제공한다.</p><p><img src="https://www.kubeflow.org/docs/images/katib-home.png" alt="Katib UI"></p><h1 id="Katib-Command-line-interface"><a href="#Katib-Command-line-interface" class="headerlink" title="Katib Command-line interface"></a>Katib Command-line interface</h1><p>UI 외에 커맨드라인 인터페이스를 제공하는데, kfctl 또는 kubectl 을 이용해 Experiment 을 실행할 수 있다. 단, Experiment 리소스 권한이 존재해야한다.</p><p><code>kubectl apply -f mnist_experiment_random.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@master my-kubeflow]<span class="comment"># kubectl get pod -n kubeflow</span></span><br><span class="line">NAME                                                           READY   STATUS             RESTARTS   AGE</span><br><span class="line">admission-webhook-bootstrap-stateful-set-0                     1/1     Running            1          26d</span><br><span class="line">admission-webhook-deployment-68c6dd4cc5-sb6hq                  1/1     Running            0          6d23h</span><br><span class="line">application-controller-stateful-set-0                          1/1     Running            1          26d</span><br><span class="line">argo-ui-78bf45b698-r5zhr                                       1/1     Running            0          26d</span><br><span class="line">centraldashboard-6957f8bcbc-6nktd                              1/1     Running            1          26d</span><br><span class="line">handson-experiment-1-random-57698b477b-dzmwm                   1/1     Running            0          98s</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>mnist_experimnet_random.yaml : (<a href="https://github.com/mojokb/handson-kubeflow/blob/master/katib/mnist_experiment_random.yaml" target="_blank" rel="noopener">https://github.com/mojokb/handson-kubeflow/blob/master/katib/mnist_experiment_random.yaml</a>)</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="http://book.interpark.com/product/BookDisplay.do?_method=detail&sc.prdNo=332046194&gclid=CjwKCAjwqJ_1BRBZEiwAv73uwCjVo3_lnw6A88qkbJmo2pBfMRE2p047vy7Cg4VhMsimg_dqSpxewBoCKwsQAvD_BwE" target="_blank" rel="noopener">쿠버네티스에서 머신러닝이 처음이라면! 쿠브플로우!</a></li><li><a href="https://www.kubeflow.org" target="_blank" rel="noopener">Kubeflow.org</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-kubeflow_katib/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubeflow Fairing 소개</title>
      <link>https://jx2lee.github.io/cloud-kubeflow_fairing/</link>
      <guid>https://jx2lee.github.io/cloud-kubeflow_fairing/</guid>
      <pubDate>Mon, 27 Apr 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Kubeflow 책을 공부하며 내용을 정리하고자 한다. 이번 파트는 &lt;code&gt;Faring&lt;/code&gt; 이다. &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kubeflow 책을 공부하며 내용을 정리하고자 한다. 이번 파트는 <code>Faring</code> 이다. </p><a id="more"></a><h1 id="Fairing"><a href="#Fairing" class="headerlink" title="Fairing"></a>Fairing</h1><p>Kubeflow 환경에서 ML 모델을 손쉽게 학습-배포할 수 있는 Python Package</p><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><ul><li>work flow<ul><li>python 으로 작성한 파일을 도커 이미지로 빌드</li><li>빌드된 이미지를 레지스트리 push</li><li>배포 리소스에 따라 k8s Job, TFJob, KFServing 등으로 변환하여 k8s API 서버 요청</li></ul></li><li>위 work flow 는 <em>preprocessor, builder, deployer</em> 구조로 설계<ul><li><em>preprocessor</em> : Python 파일을 도커 이미지로 빌드할 수 있게 패키지화</li><li><em>builder</em> : 패키지된 파일을 도커 이미지화</li><li><em>deployer</em> : 생성한 이미지 배포</li></ul></li></ul><p>Fairing 은 Kubeflow 설치 후 생성한 노트북 이미지에는 default 로 설정되어 있어 따로 설치를 하지 않아도 테스트가 가능하다.</p><h1 id="Faring-예제"><a href="#Faring-예제" class="headerlink" title="Faring 예제"></a>Faring 예제</h1><p>Fairing 예제는 Kubeflow 노트북 서버에서 진행한다. 앞서 소개했듯이 Fairing 은 K8s 리소스를 이용하기 때문에 docker registry 와 kubeflow 접근 권한이 필요하다. 테스트 결과, private docker registry 에 fairing 이미지를 push/pull 할 때 에러가 발생하였다. 장애 해결이 이루어지지 않아 docker hub 의 공개 레지스트리를 사용할 예정이며, 책 순서에 따라 진행한다.</p><h2 id="fairing-config-ipynb"><a href="#fairing-config-ipynb" class="headerlink" title="fairing_config.ipynb"></a>fairing_config.ipynb</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in Jupyter Notebook</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kubeflow.fairing <span class="keyword">as</span> fairing</span><br><span class="line"></span><br><span class="line">docker_registry = <span class="string">"jaejunlee"</span></span><br><span class="line"></span><br><span class="line">fairing.config.set_builder(</span><br><span class="line">    <span class="string">'append'</span>,</span><br><span class="line">    base_image=<span class="string">'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'</span>,</span><br><span class="line">    image_name=<span class="string">'fairing-test'</span>,</span><br><span class="line">    registry=docker_registry, push=<span class="literal">True</span>)</span><br><span class="line">fairing.config.set_deployer(<span class="string">'job'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    hostname = tf.constant(os.environ[<span class="string">'HOSTNAME'</span>])</span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    print(<span class="string">'Hostname : '</span>, sess.run(hostname).decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">remote_train = fairing.config.fn(train)</span><br><span class="line">remote_train()</span><br></pre></td></tr></table></figure><p>위 예제는 HOSTNAME 환경변수를 출력한다. <code>gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0</code> 기본 이미지에 위 출력함수를 입힌 이미지를 생성하여 jaejunlee public registry 에 푸쉬하고 fairing-job 이란 이름의 k8s job 이 k8s 에 실행을 요청한다. 쉽게 말해, 기본 이미지 위에 담아 fairing 이미지를 생성하고 k8s 를 이용해 정의한 함수를 k8s 에서 실행한다. <code>hub.docker.io</code> 에 접속하여 확인하면 해당 프로세스를 실행할 때 마다 이미지를 push 한다. <em>(set_builder 부분 push=True 로 설정했기 때문이다.)</em></p><p>코드를 통해 Config 클래스는 preprocessor, builder, deployer 에 대응하는 setter들을 가지고 있다. 각각의 default 값은 다음과 같다.</p><ul><li><em>preprocessor</em> : Notebook 환경은 “notebook”, else “python”</li><li><em>builder</em> : “append”</li><li><em>deploy”</em> : job</li></ul><p>Fairing 구조 3개를 살펴보도록 한다.</p><h1 id="Preprocessor-in-Fairing"><a href="#Preprocessor-in-Fairing" class="headerlink" title="Preprocessor in Fairing"></a>Preprocessor in Fairing</h1><p>preprocessor 는 도커 이미지로 패키지화 할 대상을 설정하는데, 타입은 총 4개이다.</p><ul><li><p><em>python</em> : 파이썬 file 패키지화</p><ul><li>도커 이미지 내 app/{파일명}.py 로 cmd 생성</li><li>example<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os, time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Training..."</span>)</span><br><span class="line">    <span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">    x = tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], shape=[<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">    print(x)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> os.getenv(<span class="string">'FAIRING_RUNTIME'</span>, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment"># if else 구조를 통해 이미지가 생성되면 FAIRING_RUNTIME 변수가 1 로 변환된다. 즉, 이미지 생성후에는 train() 만 작업</span></span><br><span class="line">        train()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">from</span> kubeflow <span class="keyword">import</span> fairing</span><br><span class="line">        DOCKER_REGISTRY = <span class="string">'jaejunlee'</span></span><br><span class="line">        file_name = os.path.basename(__file__)</span><br><span class="line">        print(<span class="string">"Executing &#123;&#125; remotely."</span>.format(file_name))</span><br><span class="line">        fairing.config.set_preprocessor(<span class="string">'python'</span>, executable=file_name, input_files=[file_name])</span><br><span class="line">        fairing.config.set_builder(</span><br><span class="line">            <span class="string">'append'</span>, base_image=<span class="string">'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'</span>,</span><br><span class="line">            registry=DOCKER_REGISTRY, push=<span class="literal">True</span>)</span><br><span class="line">        fairing.config.run()</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x fairing_preprocessor_python.py</span><br><span class="line">$ ./fairing_preprocessor_python.py</span><br><span class="line">[I 200428 09:36:11 config:134] Using preprocessor: &lt;kubeflow.fairing.preprocessors.base.BasePreProcessor object at 0x7f8b2fc1e278&gt;</span><br><span class="line">[I 200428 09:36:11 config:136] Using builder: &lt;kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f8b2fc1e2b0&gt;</span><br><span class="line">[I 200428 09:36:11 config:138] Using deployer: &lt;kubeflow.fairing.deployers.job.job.Job object at 0x7f8b2fc1e9b0&gt;</span><br><span class="line">[W 200428 09:36:11 append:50] Building image using Append builder...</span><br><span class="line">[I 200428 09:36:11 base:107] Creating docker context: /tmp/fairing_context_jvkk0mqm</span><br><span class="line">[I 200428 09:36:11 docker_creds_:234] Loading Docker credentials <span class="keyword">for</span> repository <span class="string">'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'</span></span><br><span class="line">[W 200428 09:36:13 append:54] Image successfully built <span class="keyword">in</span> 1.9876068960002158s.</span><br><span class="line">[W 200428 09:36:13 append:94] Pushing image jaejunlee/fairing-job:13B00B9B...</span><br><span class="line">[I 200428 09:36:13 docker_creds_:234] Loading Docker credentials <span class="keyword">for</span> repository <span class="string">'jaejunlee/fairing-job:13B00B9B'</span></span><br><span class="line">[W 200428 09:36:15 append:81] Uploading jaejunlee/fairing-job:13B00B9B</span><br><span class="line">[I 200428 09:36:16 docker_session_:280] Layer sha256:823f4685c03b26a545ca41dcdca1e782ad5e52cf85bac03113edaa6aebdca1b3 exists, skipping</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">sha256:19f71f3a178549ee1bacd534f061e4b465d85c3378ecddb4dc716f1283aff2a8 pushed.</span><br><span class="line">[I 200428 09:36:22 docker_session_:334] Finished upload of: jaejunlee/fairing-job:13B00B9B</span><br><span class="line">[W 200428 09:36:22 append:99] Pushed image jaejunlee/fairing-job:13B00B9B <span class="keyword">in</span> 9.045510983996792s.</span><br><span class="line">[W 200428 09:36:22 job:101] The job fairing-job-gm8hb launched.</span><br><span class="line">[W 200428 09:36:22 manager:296] Waiting <span class="keyword">for</span> fairing-job-gm8hb-87z5h to start...</span><br><span class="line">[W 200428 09:36:22 manager:296] Waiting <span class="keyword">for</span> fairing-job-gm8hb-87z5h to start...</span><br><span class="line">[W 200428 09:36:22 manager:296] Waiting <span class="keyword">for</span> fairing-job-gm8hb-87z5h to start...</span><br><span class="line">[W 200428 09:36:23 manager:296] Waiting <span class="keyword">for</span> fairing-job-gm8hb-87z5h to start...</span><br><span class="line">[I 200428 09:36:29 manager:302] Pod started running True</span><br><span class="line">Training...</span><br><span class="line">Tensor(<span class="string">"Const:0"</span>, shape=(2, 3), dtype=int32)</span><br><span class="line">[W 200428 09:36:31 job:173] Cleaning up job fairing-job-gm8hb...</span><br></pre></td></tr></table></figure></li></ul></li><li><p><em>notebook</em> : jupyter notebook 내용을 파이썬 file 로 변환하여 파이썬 file 을 패키지화  </p><ul><li>example<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># jupyter notebook</span><br><span class="line"># fairing_preprocessor_notebook.ipynb</span><br><span class="line"></span><br><span class="line">import os, time</span><br><span class="line"></span><br><span class="line">def train():</span><br><span class="line">    print(&quot;Training...&quot;)</span><br><span class="line">    import tensorflow as tf</span><br><span class="line">    x &#x3D; tf.constant([1,2,3,4,5,6], shape&#x3D;[2,3])</span><br><span class="line">    print(x)</span><br><span class="line">    time.sleep(1)</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">train()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># fairing_preprocessor_notebook.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> kubeflow <span class="keyword">import</span> fairing</span><br><span class="line"></span><br><span class="line">DOCKER_REGISTRY = <span class="string">'jaejunlee'</span></span><br><span class="line">file_name = os.path.basename(__file__)</span><br><span class="line">print(<span class="string">"Executing &#123;&#125; remotely."</span>.format(file_name))</span><br><span class="line">fairing.config.set_preprocessor(<span class="string">'notebook'</span>, notebook_file=<span class="string">'fairing_preprocessor_notebook.ipynb'</span>)</span><br><span class="line">fairing.config.set_builder(</span><br><span class="line">    <span class="string">'append'</span>, base_image=<span class="string">'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'</span>,</span><br><span class="line">    registry=DOCKER_REGISTRY, push=<span class="literal">True</span>)</span><br><span class="line">fairing.config.run()</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x fairing_preprocessor_notebook.py</span><br><span class="line">$ ./fairing_preprocessor_notebook.py</span><br><span class="line">[I 200428 09:44:27 config:134] Using preprocessor: &lt;kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7fd480eb0908&gt;</span><br><span class="line">[I 200428 09:44:27 config:136] Using builder: &lt;kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7fd480eb0860&gt;</span><br><span class="line">[I 200428 09:44:27 config:138] Using deployer: &lt;kubeflow.fairing.deployers.job.job.Job object at 0x7fd4809d6240&gt;</span><br><span class="line">[W 200428 09:44:27 append:50] Building image using Append builder...</span><br><span class="line">[I 200428 09:44:27 base:107] Creating docker context: /tmp/fairing_context_b254bkb_</span><br><span class="line">[I 200428 09:44:27 converted_notebook:127] Converting fairing_preprocessor_notebook.ipynb to fairing_preprocessor_notebook.py</span><br><span class="line">[I 200428 09:44:27 docker_creds_:234] Loading Docker credentials <span class="keyword">for</span> repository <span class="string">'gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0'</span></span><br><span class="line">[W 200428 09:44:29 append:54] Image successfully built <span class="keyword">in</span> 1.9862057870050194s.</span><br><span class="line">[W 200428 09:44:29 append:94] Pushing image jaejunlee/fairing-job:7FCC2CF6...</span><br><span class="line">[I 200428 09:44:29 docker_creds_:234] Loading Docker credentials <span class="keyword">for</span> repository <span class="string">'jaejunlee/fairing-job:7FCC2CF6'</span></span><br><span class="line">[W 200428 09:44:31 append:81] Uploading jaejunlee/fairing-job:7FCC2CF6</span><br><span class="line">[I 200428 09:44:31 docker_session_:280] Layer </span><br><span class="line">sha256:380fe9d3ba2fe8c69d05cc9038b72aa9ec669cd0d51b0e61f312edb13586d5a8 pushed.</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[I 200428 09:44:38 docker_session_:334] Finished upload of: jaejunlee/fairing-job:7FCC2CF6</span><br><span class="line">[W 200428 09:44:38 append:99] Pushed image jaejunlee/fairing-job:7FCC2CF6 <span class="keyword">in</span> 9.018262255005538s.</span><br><span class="line">[W 200428 09:44:38 job:101] The job fairing-job-bbpjs launched.</span><br><span class="line">[W 200428 09:44:38 manager:296] Waiting <span class="keyword">for</span> fairing-job-bbpjs-5jq22 to start...</span><br><span class="line">[W 200428 09:44:38 manager:296] Waiting <span class="keyword">for</span> fairing-job-bbpjs-5jq22 to start...</span><br><span class="line">[W 200428 09:44:38 manager:296] Waiting <span class="keyword">for</span> fairing-job-bbpjs-5jq22 to start...</span><br><span class="line">[W 200428 09:44:39 manager:296] Waiting <span class="keyword">for</span> fairing-job-bbpjs-5jq22 to start...</span><br><span class="line">[I 200428 09:44:44 manager:302] Pod started running True</span><br><span class="line">Training...</span><br><span class="line">Tensor(<span class="string">"Const:0"</span>, shape=(2, 3), dtype=int32)</span><br><span class="line">[W 200428 09:44:47 job:173] Cleaning up job fairing-job-bbpjs...</span><br></pre></td></tr></table></figure></li></ul></li><li><p><em>full_notebook</em> : jupyter notebook 패키지화 하는데, 수행 후 결과를 다시 노트북 파일로 생성</p></li><li><p><em>function</em> : 단일 함수 패키지화</p></li></ul><h1 id="Builder-in-Fairing"><a href="#Builder-in-Fairing" class="headerlink" title="Builder in Fairing"></a>Builder in Fairing</h1><p>Builder 는 preprocessor 가 생성한 패키지를 도커 이미지화 한다.</p><ul><li><p>빌드 타입</p><ul><li>append : docker client 를 사용하지 않고 파이선 라이브러리를 이용해 이미지를 빌드하는 방식<ul><li>self-signed 로 인증된 레지스트리는 사용 불가</li><li><code>.local</code> 로 설정한 주소는 허용 가능 (kubeflow 용 레지스트리 구축시)</li><li>로그인이 필요한 레지스트리, 즉 docker hub 를 이용하려면 노트북 컨테이너 내 <code>.docker/config.json</code> 파일을 수정해야한다. 수정하는 방법은, 도커 서버에서 docker loging 을 통해 생성한 <code>config.json</code> 파일을 노트북 컨테이너 <code>~/.docker/config.json</code> 으로 복사한다.<ul><li>cluster : 구글 컨테이너 툴인 Kaniko 를 이용해 이미지를 빌드하는 방식</li><li>docker : 도커 클라이언트를 이용해 이미지를 빌드하는 방식</li></ul></li><li>해당 환경이 도커 레지스트리에 접근할 수 있는 권한이 존재해야함</li></ul></li></ul></li><li><p>format</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_REGISTRY=<span class="string">'&#123;이미지를 push/pull 주소&#125;'</span></span><br><span class="line">fairing.config.set_builder(</span><br><span class="line">    <span class="string">'&#123;build type&#125;'</span>,</span><br><span class="line">    base_image=<span class="string">'&#123;python 을 실행한 기본 이미지 명&#125;:&#123;태그&#125;'</span>,</span><br><span class="line">    registry=DOCKER_REGISTRY,</span><br><span class="line">    push=True)</span><br></pre></td></tr></table></figure></li></ul><h1 id="Deployer-in-Fairing"><a href="#Deployer-in-Fairing" class="headerlink" title="Deployer in Fairing"></a>Deployer in Fairing</h1><p>Deployer 는 builder 로 생성한 이미지를 배포한다.</p><ul><li>format</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fairing.config.set_deployer(<span class="string">'job'</span>,</span><br><span class="line">                       namespace=?,</span><br><span class="line">                       pod_spec_mutators=?                         </span><br><span class="line">                       )</span><br></pre></td></tr></table></figure><ul><li>배포형태 : job, tfjob, pytorchjob, serving, kfserving, gcpjob, gcpserving등</li><li>namespace : 배포가 실행할 namespace</li><li>pod_spec_mutators : 배포 pod 의 spec 정의</li></ul><p>이렇게 각각 정의한 Preprocessor, Builder, Deployer 를 통해 <code>Config.run</code> 으로 Fairing 을 실행한다. 실행 순서는 설명한 흐름대로 preprocessor 로 패키지화 할 대상을 선택하고, Builder 로 이미지를 생성하며 Deployer 로 배포한다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="http://book.interpark.com/product/BookDisplay.do?_method=detail&sc.prdNo=332046194&gclid=CjwKCAjwqJ_1BRBZEiwAv73uwCjVo3_lnw6A88qkbJmo2pBfMRE2p047vy7Cg4VhMsimg_dqSpxewBoCKwsQAvD_BwE" target="_blank" rel="noopener">쿠버네티스에서 머신러닝이 처음이라면! 쿠브플로우!</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-kubeflow_fairing/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Shell] k8s Pod 내 alias 적용 스크립트</title>
      <link>https://jx2lee.github.io/shell-append_alias_to_pod/</link>
      <guid>https://jx2lee.github.io/shell-append_alias_to_pod/</guid>
      <pubDate>Thu, 23 Apr 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;사내 클라우드 제품을 이용해 업무를 보던 중, 계속되는 패치 작업으로 매번 생성하는 컨테이너의 alias 가 사라지는 문제가 발생하였다. 이러한 문제를 해결하고자 패치 이후 새로 생성하는 파드를 검색하고 &lt;code&gt;.bashrc&lt;/code&gt; 에 alias 를 추가하는 스크립트를 작성하였다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.05.07 : 스크립트 개선 (exec, alias 두 개 함수로 분리)&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>사내 클라우드 제품을 이용해 업무를 보던 중, 계속되는 패치 작업으로 매번 생성하는 컨테이너의 alias 가 사라지는 문제가 발생하였다. 이러한 문제를 해결하고자 패치 이후 새로 생성하는 파드를 검색하고 <code>.bashrc</code> 에 alias 를 추가하는 스크립트를 작성하였다.</p><p><strong>Update Note</strong></p><ul><li>2020.05.07 : 스크립트 개선 (exec, alias 두 개 함수로 분리)</li></ul><a id="more"></a><h1 id="문제-발생"><a href="#문제-발생" class="headerlink" title="문제 발생"></a>문제 발생</h1><p>패치가 진행되면 해당 파드의 이미지를 교체해야 한다. 이 작업을 수행하면 기존 파드를 삭제하고 교체된 이미지로 파드를 재생성하는데, 그럼 기존 파드에서 작업을 하던 alias 들이 사라진다. (당연히 컨테이너가 재기동하면서 <code>.bashrc</code> 초기화)</p><ul><li>기존 사용하는 alias</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">alias dasboot='startDomainAdminServer -u jeus -p jeus'</span><br><span class="line">alias dasdown='stopServer -host localhost:9736 -u jeus -p jeus'</span><br><span class="line"></span><br><span class="line">alias hdstart='startManagedServer -server hyperdata -u jeus -p jeus'</span><br><span class="line">alias hdstop='stopServer -host localhost:19736 -u jeus -p jeus'</span><br><span class="line"></span><br><span class="line">alias pastart='startManagedServer -server ProAuth -u jeus -p jeus'</span><br><span class="line">alias pastop='stopServer -host localhost:29736 -u jeus -p jeus'</span><br><span class="line"></span><br><span class="line">alias polog='tail -100f /hyperdata/proobject7/logs/ProObject.log'</span><br><span class="line">alias slog='tail -100f /db/tibero6/instance/tibero/log/slog/sys.log'</span><br></pre></td></tr></table></figure><h1 id="Script-설계-방안"><a href="#Script-설계-방안" class="headerlink" title="Script 설계 방안"></a>Script 설계 방안</h1><p>우선 고려할 점은 교체한 이미지로 기동한 파드를 찾아야 한다. 이는 <code>grep</code> 과 <code>awk</code> 를 이용해 파드 정보를 조회하여 <strong>파드 이름</strong>을 검색하고 <code>kubectl exec</code> 으로 <code>.bashrc</code> 에 alias 를 추가한다. 당연히 추가만 한다고 적용이 안되므로 마지막에 <code>source ~/.bashrc</code> 명령어를 파드에 넘겨주고 접속하는 방향으로 설계를 하였다.</p><p>정리하면 다음과 같다.</p><ul><li>파드 이름 검색</li><li>alias 를 <code>.bashrc</code> 에 추가</li><li>bash 적용을 위한 <code>source</code> 명령어 전달</li><li>파드 접근</li></ul><blockquote><p><em>사내 클라우드에서는 namespace 가 default 로 정의되어 있다. 이는 바뀌지 않기 때문에 스크립트 안에 default 로 설정하였다.</em></p></blockquote><h1 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> script <span class="keyword">for</span> managing hd container</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> jaejun.lee.1991@gmail.com</span></span><br><span class="line"></span><br><span class="line">namespace=$(kubectl get namespace  | grep hpcd | awk '&#123;print $1&#125;')</span><br><span class="line">pod=$(kubectl describe pod -n hpcd-510fdc58 | grep -B 20 hyperdata8.3_hd | grep "Name:           hpcd" | awk '&#123;print $2&#125;')</span><br><span class="line"></span><br><span class="line">function hd_container_exec() &#123;</span><br><span class="line">echo "[INFO] exec $pod in $namespace" | grep "[INFO]" --color</span><br><span class="line">kubectl exec -ti -n $namespace $pod -- bash</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function append_alias() &#123;</span><br><span class="line">echo "[INFO] append alias to $pod" | grep "[INFO]" --color</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias dasboot="\"startDomainAdminServer -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias dasdown="\"stopServer -host localhost:9736 -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias pastart="\"startManagedServer -server ProAuth -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias pastop="\"stopServer -host localhost:29736 -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias hdstart="\"startManagedServer -server hyperdata -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias hdstop="\"stopServer -host localhost:19736 -u jeus -p jeus"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias polog="\"tail -f /hyperdata/proobject7/logs/ProObject.log"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'echo alias slog="\"tail -f /db/tibero6/instance/tibero/log/slog/sys.log"\" &gt;&gt; ~/.bashrc'</span><br><span class="line">kubectl exec -n $namespace $pod -- bash -c 'source ~/.bashrc'</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function main() &#123;</span><br><span class="line">  case "$&#123;1:-&#125;" in</span><br><span class="line">  exec)</span><br><span class="line">    hd_container_exec</span><br><span class="line">    ;;</span><br><span class="line">  alias)</span><br><span class="line">    append_alias</span><br><span class="line">    ;;</span><br><span class="line">  *)</span><br><span class="line">    set +x</span><br><span class="line">    echo "usage:" &gt;&amp;2</span><br><span class="line">    echo "   $0 exec" &gt;&amp;2</span><br><span class="line">    echo "   $0 alias" &gt;&amp;2</span><br><span class="line">    ;;</span><br><span class="line">  esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main $1</span><br></pre></td></tr></table></figure><ul><li><del>6번째 줄 : alias 를 적용할 파드 이름을 검색</del></li><li><del>9번째 줄 ~ 29번째 줄 : <code>source ~/.bashrc</code> 이전 : alias 를 <code>.bashrc</code> 에 추가</del></li><li><del>30번째 줄 : <code>.bashrc</code> 적용</del></li><li><del>31번째 줄 : 파드 접근</del></li><li>hd_container_exec : 특정 컨테이너<em>(hd)</em> 로 접근하는 함수</li><li>append_alias : 특정 컨테이너<em>(hd)</em> 내 <code>.bashrc</code> 파일에 alias 를 추가하고 적용하는 함수</li><li>main : <code>exec</code> or <code>alias</code> 인자를 받는 메인 함수</li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/shell-append_alias_to_pod/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Shell] 두 docker registry 간 이미지 최신화</title>
      <link>https://jx2lee.github.io/shell-image_updater/</link>
      <guid>https://jx2lee.github.io/shell-image_updater/</guid>
      <pubDate>Wed, 08 Apr 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;최근들어 이미지 패치가 자주 이루어지면서, 이미지를 일일이 풀(pull)하고 울팀 레지스트리에 푸쉬(push)하는 작업이 지속적으로 발생하였다. 최신화가 이루어지는 레지스트리를 daemon / insecure-registry 에 등록해 사용해도 되지만 스크립트 짜는 연습도 할 겸 이미지 최신화 스크립트를 작성하였고 이를 소개하고자 한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>최근들어 이미지 패치가 자주 이루어지면서, 이미지를 일일이 풀(pull)하고 울팀 레지스트리에 푸쉬(push)하는 작업이 지속적으로 발생하였다. 최신화가 이루어지는 레지스트리를 daemon / insecure-registry 에 등록해 사용해도 되지만 스크립트 짜는 연습도 할 겸 이미지 최신화 스크립트를 작성하였고 이를 소개하고자 한다.</p><a id="more"></a><h1 id="상황"><a href="#상황" class="headerlink" title="상황"></a>상황</h1><p>간단히 A팀, B팀(내가 속한)에 대해 간략히 설명하면 다음과 같다.</p><ul><li>A팀 : 이미지를 최신화 하며 이미지 태그는 날짜_v?으로 설정한다. 최신 이미지는 a 레지스트리에 등록한다.</li><li>B팀 : 테스트 작업을 마친 최신 이미지를 사용해 패치하고 이를 다시 테스트 한다. b 레지스트리를 이용한다.</li></ul><p>사실 수작업으로 일일이 이미지 태그를 확인하며 pull&amp;push 해도 된다. docker pull a/이미지:태그, docker tag a/이미지:태그 b/이미지:태그, docker push b/이미지:태그.. 하나의 제품을 정상기동하려면 <strong>4</strong>개의 이미지를 사용하니 굉장히 불편하였다. 이미지 최적화가 안되어서 그런지 한 이미지의 pull&amp;push 가 2분정도 걸리는 경우도 존재한다.</p><p>이를 타파하고자 간단한 쉘 스크립트를 작성하여 모두 update 하던가, 한 이미지만 update 하게끔 만들었다.</p><h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><p>컨피그 파일 하나와 쉘 스크립트 하나가 존재한다. 컨피그 파일(registry.config)은 pull 하기 위한 레지스트리 주소와 push 하기 위한 레지스트리 주소를 작성한다. 이 중 하나라도 작성하지 않으면 ERROR가 발생한다. 간단히 살펴보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ ./updateImage.sh</span><br><span class="line">usage:</span><br><span class="line">   ./updateImage.sh all</span><br><span class="line">   ./updateImage.sh img &#123;image_name&#125;</span><br></pre></td></tr></table></figure><p>쉘 스크립트는 크게 <code>all</code> 과 <code>img</code>가 있다. registry.config 를 모두 작성했다는 가정하에 스크립트를 실행해본다.</p><ul><li><p><strong>all</strong> : 총 4개의 최신 이미지를 pull&amp;push</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">❯ ./updateImage.sh all</span><br><span class="line">[PULL REGISTRY] 192.xxx.xxx.xxx</span><br><span class="line">[PUSH REGISTRY] 192.yyy.yyy.yyy</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p><strong>img</strong> : 4개 중 원하는 이미지를 pull&amp;push</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ ./updateImage.sh img</span><br><span class="line">[PULL REGISTRY] 192.xxx.xxx.xxx</span><br><span class="line">[PUSH REGISTRY] 192.yyy.yyy.yyy</span><br><span class="line">Enter the image name : ???</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ul><li>image name 을 작성하면 그 이미지의 최신 태그를 찾고 이를 pull&amp;push 한다.</li><li><del>최사 제품명이 혹시나 노출되면 안될까 싶어 수행 결과는 작성하지 않았따.</del></li></ul></li></ul><h1 id="Script"><a href="#Script" class="headerlink" title="Script"></a>Script</h1><p>스크립트는 <a href="https://github.com/jx2lee/image-updater" target="_blank" rel="noopener">내 깃헙</a>에 올려두었지만 하기에도 있다. <del>난 착한 편이다.</del></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Thu, 08.04.2020</span></span><br><span class="line"><span class="comment"># jaejun.lee.1991@gmail.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include</span></span><br><span class="line">base_dir=$(dirname <span class="string">"<span class="variable">$0</span>"</span>)</span><br><span class="line">. <span class="variable">$&#123;base_dir&#125;</span>/registry.config</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_env</span></span>()&#123;</span><br><span class="line">    <span class="keyword">if</span> [ -z <span class="variable">$&#123;pull_registry&#125;</span> ] || [ -z <span class="variable">$&#123;push_registry&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"[ERROR] You must set registry variables in registry.config!"</span> | grep <span class="string">"[ERROR]"</span> --color</span><br><span class="line">      <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"[PULL REGISTRY] <span class="variable">$&#123;pull_registry&#125;</span>"</span> | grep <span class="string">"[PULL REGISTRY]"</span> --color</span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"[PUSH REGISTRY] <span class="variable">$&#123;push_registry&#125;</span>"</span> | grep <span class="string">"[PUSH REGISTRY]"</span> --color</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_img</span></span>() &#123;</span><br><span class="line">    image_pattern=<span class="string">'hyperdata8.3_'</span></span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">"Enter the image name : "</span></span><br><span class="line">    <span class="built_in">read</span> name</span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$&#123;name&#125;</span> == *<span class="variable">$&#123;image_pattern&#125;</span>* ]];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Update <span class="variable">$name</span> image.."</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"[ERROR] you must enter the image on hyperdata8.3_&#123;tb, hl, efa, hd&#125;!"</span> | grep <span class="string">"[ERROR]"</span> --color</span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">update_all</span></span>()&#123;</span><br><span class="line">    image_list=( <span class="string">"hyperdata8.3_hd"</span> <span class="string">"hyperdata8.3_tb"</span> <span class="string">"hyperdata8.3_hl"</span> <span class="string">"hyperdata8.3_eda"</span> )</span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;image_list[@]&#125;</span>;<span class="keyword">do</span></span><br><span class="line">        version=$(curl -X GET <span class="variable">$&#123;pull_registry&#125;</span>/v2/<span class="variable">$&#123;image&#125;</span>/tags/list | jq -r <span class="string">'.tags | .[-1]'</span>)</span><br><span class="line">        docker pull <span class="variable">$&#123;pull_registry&#125;</span>/<span class="variable">$&#123;image&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">        docker tag <span class="variable">$&#123;pull_registry&#125;</span>/<span class="variable">$&#123;image&#125;</span>:<span class="variable">$&#123;version&#125;</span> <span class="variable">$&#123;push_registry&#125;</span>/<span class="variable">$&#123;image&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">        docker push <span class="variable">$&#123;push_registry&#125;</span>/<span class="variable">$&#123;image&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">update_once</span></span>()&#123;</span><br><span class="line">    version=$(curl -X GET <span class="variable">$&#123;pull_registry&#125;</span>/v2/<span class="variable">$&#123;name&#125;</span>/tags/list | jq -r <span class="string">'.tags | .[-1]'</span>)</span><br><span class="line">    docker pull <span class="variable">$&#123;pull_registry&#125;</span>/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">    docker tag <span class="variable">$&#123;pull_registry&#125;</span>/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;version&#125;</span> <span class="variable">$&#123;push_registry&#125;</span>/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">    docker push <span class="variable">$&#123;push_registry&#125;</span>/<span class="variable">$&#123;name&#125;</span>:<span class="variable">$&#123;version&#125;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="string">"<span class="variable">$&#123;1:-&#125;</span>"</span> <span class="keyword">in</span></span><br><span class="line">  all)</span><br><span class="line">    check_env</span><br><span class="line">    update_all</span><br><span class="line">    ;;</span><br><span class="line">  img)</span><br><span class="line">    check_env</span><br><span class="line">    check_img</span><br><span class="line">    update_once</span><br><span class="line">    ;;</span><br><span class="line">  *)</span><br><span class="line">    <span class="built_in">set</span> +x</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"usage:"</span> &gt;&amp;2</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   <span class="variable">$0</span> all"</span> &gt;&amp;2</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   <span class="variable">$0</span> img hyperdata8.3_hd"</span> &gt;&amp;2</span><br><span class="line">    ;;</span><br><span class="line">  <span class="keyword">esac</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main <span class="variable">$1</span></span><br></pre></td></tr></table></figure><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/shell-image_updater/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Metallb for Kubernetes 설치</title>
      <link>https://jx2lee.github.io/cloud-install_metallb/</link>
      <guid>https://jx2lee.github.io/cloud-install_metallb/</guid>
      <pubDate>Sun, 05 Apr 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Kubernetes 에 로드밸런서 생성을 위해 설치한 Metallb 설치 과정을 다뤄본다. 서비스를 특정 IP 로 노출하기 위해 Metallb config 설정과 서비스로 노출하는 단계로 설명한다. &lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kubernetes 에 로드밸런서 생성을 위해 설치한 Metallb 설치 과정을 다뤄본다. 서비스를 특정 IP 로 노출하기 위해 Metallb config 설정과 서비스로 노출하는 단계로 설명한다. </p><a id="more"></a><h1 id="Metallb-란"><a href="#Metallb-란" class="headerlink" title="Metallb 란"></a>Metallb 란</h1><h2 id="MetalLB는-표준-라우팅-프로토콜을-사용하여-베어-메탈-깡통-Kubernetes-클러스터에-대한-로드-밸런서-구현-이라고-한다-표준-네트워크-장비와-통합되는-네트워크-LB-구현을-제공하여-베어-메탈-클러스터의-외부-서비스도-가능하게-만들어주는-것을-목표로-한다"><a href="#MetalLB는-표준-라우팅-프로토콜을-사용하여-베어-메탈-깡통-Kubernetes-클러스터에-대한-로드-밸런서-구현-이라고-한다-표준-네트워크-장비와-통합되는-네트워크-LB-구현을-제공하여-베어-메탈-클러스터의-외부-서비스도-가능하게-만들어주는-것을-목표로-한다" class="headerlink" title="MetalLB는 표준 라우팅 프로토콜을 사용하여 베어 메탈 (깡통) Kubernetes 클러스터에 대한 로드 밸런서 구현 이라고 한다. 표준 네트워크 장비와 통합되는 네트워크 LB 구현을 제공하여 베어 메탈 클러스터의 외부 서비스도 가능하게 만들어주는 것을 목표로 한다."></a>MetalLB는 표준 라우팅 프로토콜을 사용하여 베어 메탈 (깡통) Kubernetes 클러스터에 대한 <strong>로드 밸런서 구현</strong> 이라고 한다. 표준 네트워크 장비와 통합되는 네트워크 LB 구현을 제공하여 베어 메탈 클러스터의 외부 서비스도 가능하게 만들어주는 것을 목표로 한다.</h2><blockquote><p><em>프라이빗 클라우드 환경에서 벤더사를 이용하지 않는 kubernetes 운영의 경우, 공유 IP 만 존재한다면 이를 로드밸런서로 활용할 수 있게 만들어주는 장점이 있다.</em></p></blockquote><h1 id="Metallb-설치"><a href="#Metallb-설치" class="headerlink" title="Metallb 설치"></a>Metallb 설치</h1><p><a href="https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml" target="_blank" rel="noopener">github</a> 의 공식 배포 야믈을 특정 디렉토리 <em>(ex. metallb)</em> 에 다운받아 배포한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/jlee/metallb</span><br><span class="line">wget -O metallb.yaml https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml</span><br><span class="line">kubectl apply -f metallb.yaml</span><br></pre></td></tr></table></figure><p>이후 생성하는 metallb-system 네임스페이스에 파드를 정상 배포하였는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node2:/data/jlee<span class="comment"># kubectl get pods -n metallb-system</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">controller-547d466688-25w69   1/1     Running   0          2d21h</span><br><span class="line">speaker-dfhwc                 1/1     Running   0          2d21h</span><br><span class="line">speaker-kpc2n                 1/1     Running   0          2d21h</span><br><span class="line">speaker-lfjv9                 1/1     Running   0          2d21h</span><br><span class="line">speaker-p9qlt                 1/1     Running   0          2d21h</span><br></pre></td></tr></table></figure><h1 id="Metallb-Configmap-배포"><a href="#Metallb-Configmap-배포" class="headerlink" title="Metallb Configmap 배포"></a>Metallb Configmap 배포</h1><p>로드밸런서 생성에 대한 컨피그 맵 야믈을 생성하고 배포한다. 이름은 <code>metallb-Configmap.yaml</code> 로 설정하였다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node2:/data/jlee/metallb<span class="comment"># cat metallb-ConfigMap.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  namespace: metallb-system</span><br><span class="line">  name: config</span><br><span class="line">data:</span><br><span class="line">  config: |</span><br><span class="line">    address-pools:</span><br><span class="line">    - name: my-ip-space</span><br><span class="line">      protocol: layer2</span><br><span class="line">      addresses:</span><br><span class="line">      - 192.168.179.184-192.168.179.195</span><br></pre></td></tr></table></figure><ul><li>adresses 부분은 로드밸런서로 사용할 IP 대역대를 설정한다. 나의 경우, 184-195 까지 여유 IP 가 존재하기 때문에 range 를 추가하였다.<ul><li>만약 하나의 IP 로 설정할 경우 IP 하나만 작성한다.</li></ul></li><li>정상 배포하였는지 configmap 을 출력한다.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-node2:/data/jlee/metallb<span class="comment"># kubectl get configmap -n metallb-system -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">items:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  data:</span><br><span class="line">    config: |</span><br><span class="line">      address-pools:</span><br><span class="line">      - name: my-ip-space</span><br><span class="line">        protocol: layer2</span><br><span class="line">        addresses:</span><br><span class="line">        - 192.168.179.184-192.168.179.195</span><br><span class="line">  kind: ConfigMap</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;<span class="string">"apiVersion"</span>:<span class="string">"v1"</span>,<span class="string">"data"</span>:&#123;<span class="string">"config"</span>:<span class="string">"address-pools:\n- name: my-ip-space\n  protocol: layer2\n  addresses:\n  - 192.168.179.184-192.168.179.195\n"</span>&#125;,<span class="string">"kind"</span>:<span class="string">"ConfigMap"</span>,<span class="string">"metadata"</span>:&#123;<span class="string">"annotations"</span>:&#123;&#125;,<span class="string">"name"</span>:<span class="string">"config"</span>,<span class="string">"namespace"</span>:<span class="string">"metallb-system"</span>&#125;&#125;</span><br><span class="line">    creationTimestamp: <span class="string">"2020-04-03T09:56:44Z"</span></span><br><span class="line">    name: config</span><br><span class="line">    namespace: metallb-system</span><br><span class="line">    resourceVersion: <span class="string">"13110630"</span></span><br><span class="line">    selfLink: /api/v1/namespaces/metallb-system/configmaps/config</span><br><span class="line">    uid: 49765aca-9364-48c2-9f9a-4fa2304651e8</span><br><span class="line">kind: List</span><br><span class="line">metadata:</span><br><span class="line">  resourceVersion: <span class="string">""</span></span><br><span class="line">  selfLink: <span class="string">""</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="서비스-배포-후-확인"><a href="#서비스-배포-후-확인" class="headerlink" title="서비스 배포 후 확인"></a>서비스 배포 후 확인</h1><p>4개 파드 통신을 위한 서비스 야믈 파일에 type 을 로드밸런서로 설정하고 서비스를 배포한다.</p><p><em>loadbalancer.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="string">..</span></span><br><span class="line"><span class="string">..</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">loadBalancerIP:</span> <span class="number">192.168</span><span class="number">.179</span><span class="number">.184</span> <span class="comment"># 이 부분 수정 필요</span></span><br></pre></td></tr></table></figure><ul><li><code>loadBalancerIP</code> 값을 위 <strong>metallb-Configmap.yaml 내 IP 범위에 포함한 하나</strong>로 사용한다.</li><li>이후 배포한 서비스를 확인하면 <code>EXTERNA-IP</code> 에 IP 가 표시될 것이다.<ul><li>반드시 <code>ip 값은 configmap ip range 안</code>에서 사용해야한다.</li><li><code>kubectl get svc</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME       TYPE           CLUSTER-IP    EXTERNAL-IP       PORT(S)                                                                                                                                                                      AGE</span><br><span class="line">hyper-lb   LoadBalancer   10.96.25.50   192.168.179.184   20:31010/TCP,21:31020/TCP,22:31030/TCP,23:31040/TCP,80:31060/TCP,8080:31080/TCP,9736:31085/TCP,8629:31090/TCP,8630:31100/TCP,28080:31160/TCP,1883:31190/TCP,2883:31200/TCP   6h42m</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://metallb.universe.tf" target="_blank" rel="noopener">https://metallb.universe.tf</a></li><li><a href="https://ssup2.github.io/record/Kubernetes_MetalLB_설치_Ubuntu_18.04/" target="_blank" rel="noopener">https://ssup2.github.io/record/Kubernetes_MetalLB_설치_Ubuntu_18.04/</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_metallb/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] kubectl 명령어 수행 시 실행속도 저하 문제</title>
      <link>https://jx2lee.github.io/cloud-kubectl_hang/</link>
      <guid>https://jx2lee.github.io/cloud-kubectl_hang/</guid>
      <pubDate>Mon, 30 Mar 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;도커 루트 디렉토리를 변경하던 도중, k8s 클러스터에서 kubectl 명령어가 느려지는 문제가 발생하였다. 원인을 파악하고 이를 해결하는 과정을 다룬다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>도커 루트 디렉토리를 변경하던 도중, k8s 클러스터에서 kubectl 명령어가 느려지는 문제가 발생하였다. 원인을 파악하고 이를 해결하는 과정을 다룬다.</p><a id="more"></a><h1 id="문제-발생"><a href="#문제-발생" class="headerlink" title="문제 발생"></a>문제 발생</h1><p>kubectl 를 사용하면 결과는 나오지만 엄청 오래 걸리는 문제가 발생하였다. <code>time kubectl get nodes</code> 를 수행하면 다음과 같이 결과가 나왔다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node1    Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node2    Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node3    Ready    &lt;none&gt;   14d   v1.15.3</span><br><span class="line">k8s-node4    Ready    &lt;none&gt;   14d   v1.15.3</span><br><span class="line"></span><br><span class="line">real    2m1.032s</span><br><span class="line">user    2m0.089s</span><br><span class="line">sys    2m0.041s</span><br></pre></td></tr></table></figure><h1 id="원인-파악"><a href="#원인-파악" class="headerlink" title="원인 파악"></a>원인 파악</h1><ul><li><p><code>kube-system</code> 의 파드 상태</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:/data<span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-56cd854695-hvnkl   1/1     Running   0          7d</span><br><span class="line">calico-node-4f2bt                          1/1     Running   0          7d</span><br><span class="line">calico-node-bhk4z                          1/1     Running   0          7d</span><br><span class="line">calico-node-kmvm9                          1/1     Running   0          7d</span><br><span class="line">calico-node-q928k                          1/1     Running   0          7d</span><br><span class="line">calico-node-snf8z                          0/1     Evicted   0          90m</span><br><span class="line">coredns-5c98db65d4-7665n                   1/1     Running   35         10d</span><br><span class="line">coredns-5c98db65d4-7hpxb                   1/1     Running   34         10d</span><br><span class="line">etcd-k8s-master                            1/1     Running   3          14d</span><br><span class="line">etcd-k8s-node1                             1/1     Running   0          14d</span><br><span class="line">etcd-k8s-node2                             1/1     Running   0          14d</span><br><span class="line">kube-apiserver-k8s-master                  1/1     Running   3          5d23h</span><br><span class="line">kube-apiserver-k8s-node1                   1/1     Running   0          5d23h</span><br><span class="line">kube-apiserver-k8s-node2                   1/1     Running   0          5d23h</span><br><span class="line">kube-controller-manager-k8s-master         1/1     Running   3          14d</span><br><span class="line">kube-controller-manager-k8s-node1          1/1     Running   7          14d</span><br><span class="line">kube-controller-manager-k8s-node2          1/1     Running   8          14d</span><br><span class="line">kube-proxy-4dhqc                           1/1     Running   0          14d</span><br><span class="line">kube-proxy-9v87c                           1/1     Running   0          14d</span><br><span class="line">kube-proxy-pfrwf                           1/1     Running   0          14d</span><br><span class="line">kube-proxy-tsdb6                           0/1     Evicted   0          91m</span><br><span class="line">kube-proxy-vsk6r                           1/1     Running   0          14d</span><br><span class="line">kube-scheduler-k8s-master                  1/1     Running   2          14d</span><br><span class="line">kube-scheduler-k8s-node1                   1/1     Running   6          14d</span><br><span class="line">kube-scheduler-k8s-node2                   1/1     Running   8          14d</span><br><span class="line">tiller-deploy-758bcdc94f-c92cw             1/1     Running   0          14d</span><br></pre></td></tr></table></figure><ul><li>Evcited 된 캘리코 노드 파드가 보인다. 분명 k8s-master 노드에서 발생한 것으로 보인다. (미리 캡쳐를 떠놓지 못해 -o wide 옵션을 준 결과는 없다) </li><li><code>calico-node-snf8z</code> 파드를 describe 해보자.</li></ul></li><li><p><code>calico-node-snf8z</code> 캘리코 파드</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:/data<span class="comment"># kd pod -n kube-system calico-node-snf8z</span></span><br><span class="line">Name:                 calico-node-snf8z</span><br><span class="line">Namespace:            kube-system</span><br><span class="line">Priority:             2000001000</span><br><span class="line">Priority Class Name:  system-node-critical</span><br><span class="line">Node:                 k8s-master/</span><br><span class="line">Start Time:           Tue, 31 Mar 2020 14:14:44 +0900</span><br><span class="line">Labels:               controller-revision-hash=5744776c47</span><br><span class="line">                    k8s-app=calico-node</span><br><span class="line">                    pod-template-generation=1</span><br><span class="line">Annotations:          scheduler.alpha.kubernetes.io/critical-pod:</span><br><span class="line">Status:               Failed</span><br><span class="line">Reason:               Evicted</span><br><span class="line">Message:              The node was low on resource: ephemeral-storage.</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ul><li><p><code>The node was low on resource: ephemeral-storage.</code> 메세지가 눈에 띈다.</p></li><li><p>구글링을 통해 알아본 결과, 해당 파드가 배포된 노드 용량이 부족하다 느끼면 파드를 띄우지 못하고 Evicted 상태로 변한다고 한다.</p><ul><li>상태를 보아하니 docker root directory 가 /var/lib 가 default 로 설정되어 있어 이미지 등 데이터가 많이 쌓이는 문제가 발생하였다. <em>(루트 전체 디렉토리의 약 80% 이상을 차지하고 있었다. 이는 full 나지 않아도 kubernetest 가 설정한 적정 용량(?)에서만 파드를 띄우게끔 설계된 것으로 보인다-뇌피셜)</em></li><li>이를 해결하고자 docker root directory 를 변경하였다. <a href="">참고</a></li></ul></li><li><p>이후 <strong>Evicted 된 캘리코 노드 파드를 재기동</strong>하였다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart 7feda4bd2162</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="결과"><a href="#결과" class="headerlink" title="결과"></a>결과</h1><p>해당 컨테이너를 재시작하고 <code>kube-system</code> 파드 상태를 확인한 결과, 모두 정상 작동하고 있으며 kubectl 명령어 실행도 이전처럼 빠르게 복구되었다. 이를 통해 kubectl 명령어어가 느려진 이유는 *”<strong>노드 용량 및 노드 간 통신</strong>일 수도 있다”* 라는 것을 깨달았다. 이외에도 많은 부분에서 명령어 실행 시간이 길어질 수 있는데 그때마다 글에 추가할 예정이다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:/data<span class="comment"># kgpo -n kube-system</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE     IP                NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-56cd854695-hvnkl   1/1     Running   0          7d      10.244.169.130    k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-2wvj8                          1/1     Running   0          54s     192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-4f2bt                          1/1     Running   0          7d      192.168.179.176   k8s-node4    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-bhk4z                          1/1     Running   0          7d      192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-kmvm9                          1/1     Running   0          7d      192.168.179.175   k8s-node3    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-q928k                          1/1     Running   0          7d      192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5c98db65d4-7665n                   1/1     Running   35         10d     10.244.36.71      k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5c98db65d4-7hpxb                   1/1     Running   34         10d     10.244.169.148    k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-master                            1/1     Running   3          14d     192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-node1                             1/1     Running   0          14d     192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-node2                             1/1     Running   0          14d     192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-master                  1/1     Running   3          5d23h   192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-node1                   1/1     Running   0          5d23h   192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-node2                   1/1     Running   0          5d23h   192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-master         1/1     Running   3          14d     192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-node1          1/1     Running   7          14d     192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-node2          1/1     Running   8          14d     192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-4dhqc                           1/1     Running   0          14d     192.168.179.175   k8s-node3    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-8qtnp                           1/1     Running   0          54s     192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-9v87c                           1/1     Running   0          14d     192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-pfrwf                           1/1     Running   0          14d     192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-vsk6r                           1/1     Running   0          14d     192.168.179.176   k8s-node4    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-master                  1/1     Running   2          14d     192.168.179.172   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-node1                   1/1     Running   6          14d     192.168.179.173   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-node2                   1/1     Running   8          14d     192.168.179.174   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">tiller-deploy-758bcdc94f-c92cw             1/1     Running   0          14d     10.244.122.75     k8s-node4    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">root@k8s-node2:/data<span class="comment"># time kubectl get nodes</span></span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node1    Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node2    Ready    master   14d   v1.15.3</span><br><span class="line">k8s-node3    Ready    &lt;none&gt;   14d   v1.15.3</span><br><span class="line">k8s-node4    Ready    &lt;none&gt;   14d   v1.15.3</span><br><span class="line"></span><br><span class="line">real    0m1.032s</span><br><span class="line">user    0m0.089s</span><br><span class="line">sys    0m0.041s</span><br></pre></td></tr></table></figure><hr><p>2020.03.31 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-kubectl_hang/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubeflow 폐쇄망 설치 중 Namespace 생성 화면이 나오지 않는 문제</title>
      <link>https://jx2lee.github.io/cloud-kubeflow_error/</link>
      <guid>https://jx2lee.github.io/cloud-kubeflow_error/</guid>
      <pubDate>Sun, 29 Mar 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Kubeflow 를 폐쇄 환경에서 설치하던 중 Namespace 생성화면이 나오지 않고 심지어 선택할 수 없는 문제가 발생하였다. 문제의 원인을 파악하고 해결하는 과정을 다룬다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.05.19 : Image list 변경&lt;/li&gt;
&lt;li&gt;2020.06.24 : Image List 변경 (kfserving-system 에 필요한 이미지 추가)&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kubeflow 를 폐쇄 환경에서 설치하던 중 Namespace 생성화면이 나오지 않고 심지어 선택할 수 없는 문제가 발생하였다. 문제의 원인을 파악하고 해결하는 과정을 다룬다.</p><p><strong>Update Note</strong>  </p><ul><li>2020.05.19 : Image list 변경</li><li>2020.06.24 : Image List 변경 (kfserving-system 에 필요한 이미지 추가)</li></ul><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><ul><li>UI 접속 후 namespace 생성이 되지 않음<ul><li><code>.cache</code> 폴더 삭제 후 재 배포해도 계속되는 문제 발생</li></ul></li></ul><h2 id="kubectl-get-pod-n-kubeflow"><a href="#kubectl-get-pod-n-kubeflow" class="headerlink" title="kubectl get pod -n kubeflow"></a>kubectl get pod -n kubeflow</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">NAME                                                           READY   STATUS             RESTARTS   AGE</span><br><span class="line">admission-webhook-bootstrap-stateful-set-0                     1/1     Running            0          15m</span><br><span class="line">admission-webhook-deployment-68c6dd4cc5-sgtn6                  1/1     Running            0          14m</span><br><span class="line">application-controller-stateful-set-0                          1/1     Running            0          15m</span><br><span class="line">argo-ui-78bf45b698-2vhm9                                       1/1     Running            0          15m</span><br><span class="line">centraldashboard-fd9549bd5-nv68z                               1/1     Running            0          15m</span><br><span class="line">jupyter-web-app-deployment-7797778d74-5lq9d                    1/1     Running            0          15m</span><br><span class="line">katib-controller-55545cb4c8-8xdtn                              1/1     Running            1          15m</span><br><span class="line">katib-db-d99f776cd-zww8n                                       0/1     Running            1          15m</span><br><span class="line">katib-manager-67d9689545-9j6cf                                 0/1     CrashLoopBackOff   6          15m</span><br><span class="line">katib-ui-889499864-fd4hc                                       1/1     Running            0          15m</span><br><span class="line">metacontroller-0                                               1/1     Running            0          15m</span><br><span class="line">metadata-db-68df96445c-br8vt                                   1/1     Running            0          15m</span><br><span class="line">metadata-deployment-865fddd777-dpkbv                           1/1     Running            0          15m</span><br><span class="line">metadata-envoy-deployment-68f64489cc-ts88j                     1/1     Running            0          15m</span><br><span class="line">metadata-grpc-deployment-7f5d6c8ccb-j99d2                      1/1     Running            1          15m</span><br><span class="line">metadata-ui-84c76df48f-4sxdq                                   1/1     Running            0          15m</span><br><span class="line">minio-75d8cbbb5c-2dsgt                                         1/1     Running            0          15m</span><br><span class="line">ml-pipeline-7f6548ff8-74lh6                                    0/1     ImagePullBackOff   0          15m</span><br><span class="line">ml-pipeline-ml-pipeline-visualizationserver-559c875d6b-9mth7   0/1     ImagePullBackOff   0          15m</span><br><span class="line">ml-pipeline-persistenceagent-796c6c4c75-l8vx2                  0/1     ImagePullBackOff   0          15m</span><br><span class="line">ml-pipeline-scheduledworkflow-f86df57bd-87j5p                  0/1     ImagePullBackOff   0          15m</span><br><span class="line">ml-pipeline-ui-fb8b6778f-zgx59                                 1/1     Running            0          15m</span><br><span class="line">ml-pipeline-viewer-controller-deployment-78bdcc54fc-pf8lb      1/1     Running            0          15m</span><br><span class="line">mysql-6c5ddbd98b-pkqqr                                         1/1     Running            0          15m</span><br><span class="line">notebook-controller-deployment-7694b76c89-fb6g5                1/1     Running            0          15m</span><br><span class="line">profiles-deployment-5c48f8d6d8-kxfx5                           1/2     CrashLoopBackOff   7          15m</span><br><span class="line">pytorch-operator-dfb77d487-92dqx                               1/1     Running            0          15m</span><br><span class="line">seldon-operator-controller-manager-0                           1/1     Running            1          15m</span><br><span class="line">spartakus-volunteer-74f96589f9-g2xd5                           1/1     Running            0          15m</span><br><span class="line">tensorboard-6867797f97-kqxsc                                   1/1     Running            0          15m</span><br><span class="line">tf-job-operator-58d7d7d976-jhpk4                               1/1     Running            0          15m</span><br><span class="line">workflow-controller-66dd745699-9bqcx                           1/1     Running            0          15m</span><br></pre></td></tr></table></figure><h2 id="log"><a href="#log" class="headerlink" title="log"></a>log</h2><h3 id="profiles-deployment-manager"><a href="#profiles-deployment-manager" class="headerlink" title="profiles-deployment manager"></a>profiles-deployment manager</h3><p><code>k logs -n kubeflow profiles-deployment-5c48f8d6d8-kxfx5 -c manager</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">flag provided but not defined: -workload-identity</span><br><span class="line">Usage of /manager:</span><br><span class="line">  -kubeconfig string</span><br><span class="line">        Paths to a kubeconfig. Only required <span class="keyword">if</span> out-of-cluster.</span><br><span class="line">  -master string</span><br><span class="line">        The address of the Kubernetes API server. Overrides any value <span class="keyword">in</span> kubeconfig. Only required <span class="keyword">if</span> out-of-cluster.</span><br><span class="line">  -metrics-addr string</span><br><span class="line">        The address the metric endpoint binds to. (default <span class="string">":8080"</span>)</span><br><span class="line">  -userid-header string</span><br><span class="line">        Key of request header containing user id (default <span class="string">"x-goog-authenticated-user-email"</span>)</span><br><span class="line">  -userid-prefix string</span><br><span class="line">        Request header user id common prefix (default <span class="string">"accounts.google.com:"</span>)</span><br></pre></td></tr></table></figure><h3 id="profiles-deployment-kfam"><a href="#profiles-deployment-kfam" class="headerlink" title="profiles-deployment kfam"></a>profiles-deployment kfam</h3><p><code>k logs -n kubeflow profiles-deployment-5c48f8d6d8-kxfx5 -c kfam</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time=<span class="string">"2020-03-26T06:02:16Z"</span> level=info msg=<span class="string">"Server started"</span></span><br></pre></td></tr></table></figure><h3 id="centraldashboard-pod-logs"><a href="#centraldashboard-pod-logs" class="headerlink" title="centraldashboard pod logs"></a>centraldashboard pod logs</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Initializing Kubernetes configuration</span><br><span class="line">Unable to fetch Nodes &#123; kind: <span class="string">'Status'</span>,</span><br><span class="line">  apiVersion: <span class="string">'v1'</span>,</span><br><span class="line">  metadata: &#123;&#125;,</span><br><span class="line">  status: <span class="string">'Failure'</span>,</span><br><span class="line">  message:</span><br><span class="line">   <span class="string">'nodes is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "nodes" in API group "" at the cluster scope'</span>,</span><br><span class="line">  reason: <span class="string">'Forbidden'</span>,</span><br><span class="line">  details: &#123; kind: <span class="string">'nodes'</span> &#125;,</span><br><span class="line">  code: 403 &#125;</span><br><span class="line">Unable to fetch Application information: &#123; kind: <span class="string">'Status'</span>,</span><br><span class="line">  apiVersion: <span class="string">'v1'</span>,</span><br><span class="line">  metadata: &#123;&#125;,</span><br><span class="line">  status: <span class="string">'Failure'</span>,</span><br><span class="line">  message:</span><br><span class="line">   <span class="string">'applications.app.k8s.io is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "applications" in API group "app.k8s.io" in the namespace "kubeflow"'</span>,</span><br><span class="line">Using Profiles service at http://profiles-kfam.kubeflow:8081/kfam</span><br><span class="line">  reason: <span class="string">'Forbidden'</span>,</span><br><span class="line">  details: &#123; group: <span class="string">'app.k8s.io'</span>, kind: <span class="string">'applications'</span> &#125;,</span><br><span class="line">  code: 403 &#125;</span><br><span class="line">Unable to fetch Nodes &#123; kind: <span class="string">'Status'</span>,</span><br><span class="line">  apiVersion: <span class="string">'v1'</span>,</span><br><span class="line">  metadata: &#123;&#125;,</span><br><span class="line">  status: <span class="string">'Failure'</span>,</span><br><span class="line">  message:</span><br><span class="line">   <span class="string">'nodes is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "nodes" in API group "" at the cluster scope'</span>,</span><br><span class="line">  reason: <span class="string">'Forbidden'</span>,</span><br><span class="line">  details: &#123; kind: <span class="string">'nodes'</span> &#125;,</span><br><span class="line">  code: 403 &#125;</span><br><span class="line"><span class="string">"other"</span> is not a supported platform <span class="keyword">for</span> Metrics</span><br><span class="line">Server listening on port http://localhost:8082 (<span class="keyword">in</span> production mode)</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br><span class="line">Unable to contact Profile Controller [object Object]</span><br></pre></td></tr></table></figure><ul><li><strong>Unable to contact Profile Controller [object Object]</strong><ul><li>centraldashboard 에서 profile controller 요청을 받지 못하는 상황</li><li>각 파드에 접속하여 (centraldashboard, profile controller-manager) 핑을 때려봤는데 모두 통신이 원활하였음</li></ul></li></ul><h1 id="해결-방안"><a href="#해결-방안" class="headerlink" title="해결 방안"></a>해결 방안</h1><ul><li>엄청나게 많은 방법을 시도했다.<ul><li>kfctl verion, 각종 이미지 변경 등..</li><li>시행착오 끝에 centraldashobard 와 profile-deployment 파드에 생성한 컨테이너 이미지 버젼 문제였다.<ul><li><code>gcr.io/kubeflow-images-public/centraldashboard:latest</code></li><li><code>gcr.io/kubeflow-images-public/profile-controller:v20191024-v0.7.0-rc.5-12-g956569ba-e3b0c4</code></li><li><code>gcr.io/kubeflow-images-public/kfam@sha256:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0</code><ul><li>digest 로 이루어진 이미지는 pull 이후에 tag 를 생성하여 레지스트리에 push 하였다. (ex. <code>gcr.io/kubeflow-images-public/kfam:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0</code>)</li></ul></li></ul></li></ul></li><li>최종적으로 kubeflow 0.7.1 버젼에 사용한 이미지 리스트는 다음과 같다.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">argoproj/argoui:v2.3.0</span><br><span class="line">argoproj/workflow-controller:v2.3.0</span><br><span class="line">docker.io/istio/citadel:1.1.6</span><br><span class="line">docker.io/istio/galley:1.1.6</span><br><span class="line">docker.io/istio/kubectl:1.1.6</span><br><span class="line">docker.io/istio/mixer:1.1.6</span><br><span class="line">docker.io/istio/pilot:1.1.6</span><br><span class="line">docker.io/istio/proxy_init:1.1.6</span><br><span class="line">docker.io/istio/proxyv2:1.1.6</span><br><span class="line">docker.io/istio/sidecar_injector:1.1.6</span><br><span class="line">docker.io/jaegertracing/all-in-one:1.9</span><br><span class="line">docker.io/kiali/kiali:v0.16</span><br><span class="line">docker.io/prom/prometheus:v2.3.1</span><br><span class="line">docker.io/seldonio/seldon-core-operator:0.4.1</span><br><span class="line">gcr.io/google_containers/spartakus-amd64:v1.1.0</span><br><span class="line">gcr.io/kfserving/alibi-explainer:0.2.2</span><br><span class="line">gcr.io/kfserving/kfserving-controller:0.2.2</span><br><span class="line">gcr.io/kfserving/logger:0.2.2</span><br><span class="line">gcr.io/kfserving/pytorchserver:0.2.2</span><br><span class="line">gcr.io/kfserving/sklearnserver:0.2.2</span><br><span class="line">gcr.io/kfserving/storage-initializer:0.2.2 </span><br><span class="line">gcr.io/kfserving/xgbserver:0.2.2</span><br><span class="line">gcr.io/kubebuilder/kube-rbac-proxy:v0.4.0</span><br><span class="line">gcr.io/kubeflow-images-public/admission-webhook:v20190520-v0-139-gcee39dbc-dirty-0d8f4c</span><br><span class="line">gcr.io/kubeflow-images-public/ingress-setup:latest</span><br><span class="line">gcr.io/kubeflow-images-public/jupyter-web-app:9419d4d</span><br><span class="line">gcr.io/kubeflow-images-public/katib/v1alpha3/katib-controller:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/katib/v1alpha3/katib-manager:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/katib/v1alpha3/katib-ui:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/kubernetes-sigs/application:1.0-beta</span><br><span class="line">gcr.io/kubeflow-images-public/metadata-frontend:v0.1.8</span><br><span class="line">gcr.io/kubeflow-images-public/metadata:v0.1.11</span><br><span class="line">gcr.io/kubeflow-images-public/pytorch-operator:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v-base-ef41372-1177829795472347138</span><br><span class="line">gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-cpu:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/tensorflow-1.14.0-notebook-gpu:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-cpu:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-gpu:v0.7.0</span><br><span class="line">gcr.io/kubeflow-images-public/tf_operator:kubeflow-tf-operator-postsubmit-v1-5adee6f-6109-a25c</span><br><span class="line">gcr.io/ml-pipeline/api-server:0.1.31</span><br><span class="line">gcr.io/ml-pipeline/envoy:metadata-grpc</span><br><span class="line">gcr.io/ml-pipeline/frontend:0.1.31</span><br><span class="line">gcr.io/ml-pipeline/persistenceagent:0.1.31</span><br><span class="line">gcr.io/ml-pipeline/scheduledworkflow:0.1.31</span><br><span class="line">gcr.io/ml-pipeline/viewer-crd-controller:0.1.31</span><br><span class="line">gcr.io/ml-pipeline/visualization-server:0.1.27</span><br><span class="line">gcr.io/tfx-oss-public/ml_metadata_store_server:0.15.1</span><br><span class="line">grafana/grafana:6.0.2</span><br><span class="line">mcr.microsoft.com/onnxruntime/server:v0.5.1</span><br><span class="line">metacontroller/metacontroller:v0.3.0</span><br><span class="line">minio/minio:RELEASE.2018-02-09T22-40-05Z</span><br><span class="line">mysql:5.6</span><br><span class="line">mysql:8</span><br><span class="line">mysql:8.0.3</span><br><span class="line">nvcr.io/nvidia/tensorrtserver:19.05-py3</span><br><span class="line">tensorflow/serving:1.11.0</span><br><span class="line">tensorflow/serving:1.11.0-gpu</span><br><span class="line">tensorflow/serving:1.12.0</span><br><span class="line">tensorflow/serving:1.12.0-gpu</span><br><span class="line">tensorflow/serving:1.13.0</span><br><span class="line">tensorflow/serving:1.13.0-gpu</span><br><span class="line">tensorflow/serving:1.14.0</span><br><span class="line">tensorflow/serving:1.14.0-gpu</span><br><span class="line">tensorflow/tensorflow:1.8.0</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:88d864eb3c47881cf7ac058479d1c735cc3cf4f07a11aad0621cd36dcd9ae3c6</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa@sha256:a7801c3cf4edecfa51b7bd2068f97941f6714f7922cb4806245377c2b336b723</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:aeaacec4feedee309293ac21da13e71a05a2ad84b1d5fcc01ffecfa6cfbb2870</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:3b096e55fa907cff53d37dadc5d20c29cea9bb18ed9e921a588fee17beb937df</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/networking/istio@sha256:057c999bccfe32e9889616b571dc8d389c742ff66f0b5516bad651f05459b7bc</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:e0654305370cf3bbbd0f56f97789c92cf5215f752b70902eba5d5fc0e88c5aca</span><br><span class="line">gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:c2076674618933df53e90cf9ddd17f5ddbad513b8c95e955e45e37be7ca9e0e8</span><br><span class="line">gcr.io/kubeflow-images-public/centraldashboard@sha256:4299297b8390599854aa8f77e9eb717db684b32ca9a94a0ab0e73f3f73e5d8b5</span><br><span class="line">gcr.io/kubeflow-images-public/kfam@sha256:3b0d4be7e59a3fa5ed1d80dccc832312caa94f3b2d36682524d3afc4e45164f0</span><br><span class="line">gcr.io/kubeflow-images-public/notebook-controller@sha256:6490f737000bd1d2520ac4b8cbde2b09749cdb291b1967ddda95d05131db49db</span><br><span class="line">gcr.io/kubeflow-images-public/profile-controller@sha256:e601b2226e534a4f8e0722cfc44ae4a919a90265c4c6c9e7a7a55fcb57032f25</span><br></pre></td></tr></table></figure><blockquote><p><em>tar 파일로 용량을 계산한 결과 약 30G(no gzip option)</em></p></blockquote><h1 id="추가로-발생한-문제"><a href="#추가로-발생한-문제" class="headerlink" title="추가로 발생한 문제"></a>추가로 발생한 문제</h1><ul><li>Kubeflow 배포 전 istio-system 와 knative-serving 네임스페이스가 존재하여 배포할 때 에러가 발생</li><li>해결 방안<ul><li>배포 전 istio-system / knative-serving 네임스페이스를 삭제 후 재 배포</li></ul></li></ul><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><ul><li><a href="https://github.com/kubeflow/kubeflow/issues/3859" target="_blank" rel="noopener">https://github.com/kubeflow/kubeflow/issues/3859</a></li><li><a href="https://github.com/kubeflow/kubeflow/issues/4788" target="_blank" rel="noopener">https://github.com/kubeflow/kubeflow/issues/4788</a></li><li><a href="https://github.com/kubeflow/kubeflow/issues/4718" target="_blank" rel="noopener">https://github.com/kubeflow/kubeflow/issues/4718</a></li><li><a href="https://github.com/kubeflow/kubeflow/issues/3900" target="_blank" rel="noopener">https://github.com/kubeflow/kubeflow/issues/3900</a></li><li><a href="https://stackoverflow.com/questions/54203646/kubernetes-how-to-increase-ephemeral-storage" target="_blank" rel="noopener">https://stackoverflow.com/questions/54203646/kubernetes-how-to-increase-ephemeral-storage</a></li><li><a href="https://www.kangwoo.kr/2020/02/18/pc에-kubeflow-설치하기-3부-kubeflow-설치하기/" target="_blank" rel="noopener">https://www.kangwoo.kr/2020/02/18/pc에-kubeflow-설치하기-3부-kubeflow-설치하기/</a></li></ul><hr><p>2020.03.30 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-kubeflow_error/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Docker private registry 설정</title>
      <link>https://jx2lee.github.io/cloud-docker_registry/</link>
      <guid>https://jx2lee.github.io/cloud-docker_registry/</guid>
      <pubDate>Tue, 17 Mar 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;docker private registry 를 생성하고, tar 파일로 변환한 이미지를 load 및 registry 에 push 하는 과정을 다룬다. 사이트에 나가게 되면 폐쇄망인 경우가 대부분인데, 이럴 경우를 대비해서 &lt;strong&gt;이미지 리스트를 읽어들여 docker image 를 tar로 변환하고 registry 에 push 하는 쉘 스크립트&lt;/strong&gt;를 작성하였다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.03.30 : docker run 시 mount 방법(-v 옵션) 및 docker image pull / push 스크립트 추가&lt;/li&gt;
&lt;li&gt;2020.04.13 : docker run 시 restart argument 추가&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>docker private registry 를 생성하고, tar 파일로 변환한 이미지를 load 및 registry 에 push 하는 과정을 다룬다. 사이트에 나가게 되면 폐쇄망인 경우가 대부분인데, 이럴 경우를 대비해서 <strong>이미지 리스트를 읽어들여 docker image 를 tar로 변환하고 registry 에 push 하는 쉘 스크립트</strong>를 작성하였다.</p><p><strong>Update Note</strong></p><ul><li>2020.03.30 : docker run 시 mount 방법(-v 옵션) 및 docker image pull / push 스크립트 추가</li><li>2020.04.13 : docker run 시 restart argument 추가</li></ul><a id="more"></a><h1 id="Private-registry-생성"><a href="#Private-registry-생성" class="headerlink" title="Private registry 생성"></a>Private registry 생성</h1><h2 id="registry-이미지를-Pull-하고-container-를-기동한다"><a href="#registry-이미지를-Pull-하고-container-를-기동한다" class="headerlink" title="registry 이미지를 Pull 하고 container 를 기동한다."></a>registry 이미지를 Pull 하고 container 를 기동한다.</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry</span><br><span class="line">docker run -dit --name bips-registry --restart=always -p 5000:5000 -v /data/registry:/var/lib/registry registry:latest</span><br></pre></td></tr></table></figure><blockquote><ul><li><em>-v 플래그를 이용해 레지스트리 저장소를 /data/registry 마운트 시켜 컨테이너를 동작한다. 이는 이미지가 많아질 경우 용량이 큰 디바이스에 직접 설정하여 이미지를 관리할 수 있다.</em></li><li><em><code>--restart=alyways</code> 인자를 추가하여 도커 데몬 재시작 시 기동할 수 있도록 설정한다.</em></li></ul></blockquote><h1 id="Image-push"><a href="#Image-push" class="headerlink" title="Image push"></a>Image push</h1><h2 id="tar-파일로-묶은-이미지를-docker-load-i-tar-name-으로-이미지를-생성하고-이를-registry-에-push-한다"><a href="#tar-파일로-묶은-이미지를-docker-load-i-tar-name-으로-이미지를-생성하고-이를-registry-에-push-한다" class="headerlink" title="tar 파일로 묶은 이미지를 docker load -i {tar_name} 으로 이미지를 생성하고, 이를 registry 에 push 한다."></a>tar 파일로 묶은 이미지를 <code>docker load -i {tar_name}</code> 으로 이미지를 생성하고, 이를 registry 에 push 한다.</h2><ul><li>원래 이미지 : 192.168.17.131:5000/ubuntu_t6:2020303_v2</li><li>태그 변경 후 이미지 : 92.168.179.185:5000/ubuntu_t6:2020303_v2</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker tag 192.168.17.131:5000/ubuntu_t6:2020303_v2 192.168.179.185:5000/ubuntu_t6:2020303_v2</span><br><span class="line">docker push 192.168.179.185:5000/ubuntu_t6:2020303_v2</span><br></pre></td></tr></table></figure><h1 id="Image-확인"><a href="#Image-확인" class="headerlink" title="Image 확인"></a>Image 확인</h1><h2 id="registry-에-해당-이미지가-존재하는지-curl-명령어로-확인한다"><a href="#registry-에-해당-이미지가-존재하는지-curl-명령어로-확인한다" class="headerlink" title="registry 에 해당 이미지가 존재하는지 curl 명령어로 확인한다."></a>registry 에 해당 이미지가 존재하는지 <code>curl</code> 명령어로 확인한다.</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># curl -X GET 192.168.179.185:5000/v2/_catalog</span></span><br><span class="line">&#123;<span class="string">"repositories"</span>:[<span class="string">"dfa-module"</span>,<span class="string">"hd8.3_rel"</span>,<span class="string">"hl_r172919"</span>,<span class="string">"ubuntu_t6"</span>]&#125;</span><br><span class="line">root@k8s-master:~<span class="comment"># curl -X GET 192.168.179.185:5000/v2/ubuntu_t6/tags/list</span></span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"ubuntu_t6"</span>,<span class="string">"tags"</span>:[<span class="string">"2020303_v2"</span>]&#125;</span><br></pre></td></tr></table></figure><blockquote><p>잘~ 등록되었다!</p></blockquote><h1 id="Docker-Image-Pull-amp-Push-스크립트"><a href="#Docker-Image-Pull-amp-Push-스크립트" class="headerlink" title="Docker Image Pull &amp; Push 스크립트"></a>Docker Image Pull &amp; Push 스크립트</h1><p>폐쇄망 환경에서 docker hub 의 이미지를 가져올 수 없는 상황이 발생하였다. 이를 위해 폐쇄망이 아닌 환경에서 이미지를 pull 하고, 이를 폐쇄망 환경에서 특정 registry (private docker registry) 에 push 하는 스크립트를 작성하였다.</p><ul><li><p>기능</p><ul><li><p>pull : docker hub 의 이미지를 가져와 <code>tars</code> 디렉토리에 저장한다.</p></li><li><p>push : <code>tars</code> 디렉토리에 tar 이미지를 특정 registry 에 push 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ ./imageLoader</span><br><span class="line">usage:</span><br><span class="line">  ./imageLoader pull</span><br><span class="line">  ./imageLoader push &#123;registry_endpoint&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>이미지:태그 로 이루어진 <code>.imageList</code> 가 선행으로 준비해야 한다. 또한, <code>.imageListHash</code> 는 태그명이 아닌 해쉬값으로 되어있는 이미지를 받을 때 사용한다. 만약 둘 중 사용하지 않는 이미지가 있다면 선택에 따라 삭제하고 해당 스크립트에 주석을 설정한다.</p><ul><li>첫 번째 pull/push 하는 부분이 <code>이미지:태그</code>, 두 번째가 <code>이미지@해쉬</code></li><li>본인은 Kubeflow 를 폐쇄망 환경에서 설치할 이슈가 생겨 필요한 이미지 리스트를 .imageList / .imageListHash 에 작성하였다.</li><li>참고로 Kubeflow 폐쇄망 설치 시 이미지 버젼 때문에 애를 많이 먹었다..</li></ul></li><li><p><a href="https://github.com/jx2lee/kubeflow-image-loader" target="_blank" rel="noopener">github</a> 에 올려두었다. 허접한 스크립트 이지만, 현 직장에서는 편하게(?) 사용할 수 있을 것 같아 공유한다. <del>많은 별 부탁드립니다.</del></p></li></ul><hr><p>2020.03.18 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-docker_registry/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Orphaned pod found 에러 해결</title>
      <link>https://jx2lee.github.io/cloud_orphaned_pod_error/</link>
      <guid>https://jx2lee.github.io/cloud_orphaned_pod_error/</guid>
      <pubDate>Wed, 11 Mar 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;본 포스트에서는 kubelet log 에 Orphaned pod found , but volume subpaths are still present on disk 로그가 발생하는 문제를 해결한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>본 포스트에서는 kubelet log 에 Orphaned pod found , but volume subpaths are still present on disk 로그가 발생하는 문제를 해결한다.</p><a id="more"></a><h1 id="Kubelet-log"><a href="#Kubelet-log" class="headerlink" title="Kubelet log"></a>Kubelet log</h1><p><code>journalctl -f | grep kubelet</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mar 12 01:31:04 k8s-node2 kubelet[19210]: E0312 01:31:04.964272   19210 kubelet_volumes.go:154] Orphaned pod <span class="string">"1a2f73f1-77a2-4053-975f-57a89fdba1db"</span> found, but volume subpaths are still present on disk : There were a total of 1 errors similar to this. Turn up verbosity to see them.</span><br></pre></td></tr></table></figure><h1 id="문제-원인"><a href="#문제-원인" class="headerlink" title="문제 원인"></a>문제 원인</h1><p>해당 노드를 재부팅했을 때 기존에 남아있던 파드 정보로 인하여 에러가 발생한 것 같다. 사라진 파드의 정보에 volume subpath 도 삭제되지 않은 것이다.</p><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><p>의외로 간단하다. 해당 pod 정보를 삭제하면 되는데, 본인 환경으로는 <code>/var/lib/kubelet/pods/</code> 에 파드 UUID 폴더를 삭제하면 된다. 이후 kubelet 을 재기동하면 위 로그가 삭제됨을 확인할 수 있다.</p><h1 id="이외-문제들"><a href="#이외-문제들" class="headerlink" title="이외 문제들"></a>이외 문제들</h1><p>오늘 있었던 다양한 에러들을 한 번 정리했다 (네트워크 문제로 인해 file stroage 를 배포하는 문제는 더 파악해본 후 포스팅 할 예정이다).</p><h2 id="kubelet-로그에-Unable-to-read-config-path-“-etc-kubernetes-manifests”-path-does-not-exist-ignoring-메세지-발생"><a href="#kubelet-로그에-Unable-to-read-config-path-“-etc-kubernetes-manifests”-path-does-not-exist-ignoring-메세지-발생" class="headerlink" title="kubelet 로그에 Unable to read config path “/etc/kubernetes/manifests”: path does not exist, ignoring 메세지 발생"></a>kubelet 로그에 Unable to read config path “/etc/kubernetes/manifests”: path does not exist, ignoring 메세지 발생</h2><ul><li><code>/etc/kubernets/path</code> 에 <code>manifests</code> 폴더를 생성하여 해결</li></ul><h2 id="노드에-node-kubernetes-io-unreachable-NoSchedule-Taint-가-걸려있는-경우"><a href="#노드에-node-kubernetes-io-unreachable-NoSchedule-Taint-가-걸려있는-경우" class="headerlink" title="노드에 node.kubernetes.io/unreachable:NoSchedule Taint 가 걸려있는 경우"></a>노드에 node.kubernetes.io/unreachable:NoSchedule Taint 가 걸려있는 경우</h2><ul><li>해당 노드가 Not Ready 인 상태</li><li>이런 경우에는 대게 노드가 재부팅 후 스왑 메모리가 켜져 있을 확률이 높다. <code>free</code> 명령어를 통해 확인한 다음 swap off 이후 kubelet 을 재기동 한다.</li></ul><hr><p>2020.03.12 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud_orphaned_pod_error/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] R docker 컨테이너에서 Hadoop HDFS 연동</title>
      <link>https://jx2lee.github.io/cloud-r_hadoop_connection/</link>
      <guid>https://jx2lee.github.io/cloud-r_hadoop_connection/</guid>
      <pubDate>Wed, 19 Feb 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;본 포스트에서는 R Container 에서 Hadoop HDFS 데이터를 연동하는 과정을 다룬다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>본 포스트에서는 R Container 에서 Hadoop HDFS 데이터를 연동하는 과정을 다룬다.</p><a id="more"></a><h1 id="R-Container-기동"><a href="#R-Container-기동" class="headerlink" title="R Container 기동"></a>R Container 기동</h1><h2 id="R-container-image-를-이용해-컨테이너를-기동한다"><a href="#R-container-image-를-이용해-컨테이너를-기동한다" class="headerlink" title="R container image 를 이용해 컨테이너를 기동한다."></a>R container image 를 이용해 컨테이너를 기동한다.</h2><ul><li><p><strong>docker run -d -p 8787:8787 -e PASSWORD=tmaxtmax rocker_with_java:latest</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># docker rename competent_dubinsky r-hadoop-test</span></span><br><span class="line">root@k8s-master:/app<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">aa91a42054dc        rocker_with_java:latest   <span class="string">"/init"</span>                  23 minutes ago      Up 23 minutes       0.0.0.0:8787-&gt;8787/tcp   r-hadoop-test</span><br></pre></td></tr></table></figure></li><li><p>http://{NODE_IP}:8787 로 접속하여 rstudio/tmaxtmax 입력하여 Rstduio 화면으로 이동한다.</p><p><img src="/image/rstudio-login.png" alt=""></p></li></ul><blockquote><p><em>rocker_with_java image 는 rocker-rstudio 이미지 보다 상위 이미지인 rocker/tidyverse 를 사용한 새로운 이미지다. <a href="https://github.com/gadenbuie/docker-tidyverse-rjava/blob/master/Dockerfile" target="_blank" rel="noopener">참고</a></em></p></blockquote><h1 id="R-Container-환경설정"><a href="#R-Container-환경설정" class="headerlink" title="R Container 환경설정"></a>R Container 환경설정</h1><h2 id="Hadoop-연동을-위한-Hadoop-client-와-java-를-설치한다"><a href="#Hadoop-연동을-위한-Hadoop-client-와-java-를-설치한다" class="headerlink" title="Hadoop 연동을 위한 Hadoop client 와 java 를 설치한다."></a>Hadoop 연동을 위한 Hadoop client 와 java 를 설치한다.</h2><ul><li><p>로컬에 있는 hadoop client 와 java tar 파일들을 R container 로 옮긴다.</p><ul><li><strong>docker cp hadoop-client.tar r-hadoop-test:/root</strong></li><li><strong>docker cp jdk.tar r-hadoop-test:/root</strong></li></ul></li><li><p>R container로 접속하여 hadoop client 를 설치한다</p><ul><li><strong>docker exec -it r-hadoop-test /bin/bash</strong> 명령어 이후 hadoop client 설치</li><li>설치 확인</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rstudio@4935816e695d:~$ java -version</span><br><span class="line">java version <span class="string">"1.8.0_241"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_241-b07)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)</span><br><span class="line">rstudio@aa91a42054dc:~$ hdfs version</span><br><span class="line">Hadoop 2.10.0</span><br><span class="line">Subversion ssh://git.corp.linkedin.com:29418/hadoop/hadoop.git -r e2f1f118e465e787d8567dfa6e2f3b72a0eb9194</span><br><span class="line">Compiled by jhung on 2019-10-22T19:10Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 7b2d8877c5ce8c9a2cca5c7e81aa4026</span><br><span class="line">This <span class="built_in">command</span> was run using /app/hadoop/2.10.0/share/hadoop/common/hadoop-common-2.10.0.jar</span><br></pre></td></tr></table></figure><h1 id="Hadoop-연동을-위한-R-package-설치"><a href="#Hadoop-연동을-위한-R-package-설치" class="headerlink" title="Hadoop 연동을 위한 R package 설치"></a>Hadoop 연동을 위한 R package 설치</h1><p>Hadoop 연동을 위한 R 패키지를 설치한다.</p><ul><li><p>R Studio 에서 아래 커맨드를 이용해 패키지를 설치한다. HADOOP_CMD와 JAVA_HOME 은 각 환경에 맞는 PATH 로 변경하여 수행한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(devtools)</span><br><span class="line"><span class="keyword">library</span>(rJava)</span><br><span class="line">install_github(c(<span class="string">"RevolutionAnalytics/rmr2/pkg"</span>, <span class="string">"RevolutionAnalytics/plyrmr2/pkg"</span>))</span><br><span class="line"></span><br><span class="line">Sys.setenv(HADOOP_CMD=<span class="string">"/app/hadoop/2.10.0/bin/hadoop"</span>)</span><br><span class="line">Sys.setenv(JAVA_HOME=<span class="string">"/usr/lib/jvm/java-8-openjdk-amd64"</span>)</span><br><span class="line"></span><br><span class="line">install_github(<span class="string">"RevolutionAnalytics/rhdfs/pkg"</span>)</span><br></pre></td></tr></table></figure></li><li><p>Packeges 관리 화면에 설치가 되었는지 확인한다.</p></li></ul><h1 id="R-Hadoop-연동"><a href="#R-Hadoop-연동" class="headerlink" title="R - Hadoop 연동"></a>R - Hadoop 연동</h1><p>R 환경변수를 설정하고 HDFS 에 접근하여 목록과 데이터 일부를 확인한다.</p><ul><li><p><code>rhdfs / rmr2</code> 패키지를 활성화 시키고 hdfs 객체를 초기화한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(rmr2)</span><br><span class="line"><span class="keyword">library</span>(rhdfs)</span><br><span class="line"></span><br><span class="line">hdfs.init()</span><br></pre></td></tr></table></figure></li><li><p><strong>hdfs.ls / hdfs.cat</strong> 함수를 이용해 디렉토리 목록과 데이터 일부를 확인한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hdfs.ls(<span class="string">"/user/spark"</span>)</span><br><span class="line">hdfs.cat(<span class="string">"/user/spark/test.csv"</span>)</span><br><span class="line"></span><br><span class="line">&gt; hdfs.ls(<span class="string">"/user/spark"</span>)</span><br><span class="line">  permission   owner      group   size          modtime                      file</span><br><span class="line"><span class="number">1</span> drwxr-xr-x   spark supergroup      <span class="number">0</span> <span class="number">2020</span>-<span class="number">02</span>-<span class="number">19</span> <span class="number">05</span>:<span class="number">02</span> /user/spark/.sparkStaging</span><br><span class="line"><span class="number">2</span> -rw-r--r-- rstudio supergroup <span class="number">970491</span> <span class="number">2020</span>-<span class="number">02</span>-<span class="number">19</span> <span class="number">09</span>:<span class="number">52</span>      /user/spark/test.csv</span><br></pre></td></tr></table></figure></li></ul><h1 id="참고-R-Hadoop-연동-REST-API-방식"><a href="#참고-R-Hadoop-연동-REST-API-방식" class="headerlink" title="(참고) R - Hadoop 연동 (REST API 방식)"></a>(참고) R - Hadoop 연동 (REST API 방식)</h1><p>이전의 방법은 R container 에 hadoop client 를 이용해 연동하였다. 또다른 방법으로써 hadoop 에서 제공하는 REST API 를 이용해 R과 연동하는 방법이다.</p><ul><li><p>R package <strong>httr</strong> 을 설치한다.</p><p><code>install.packages(&quot;httr&quot;)</code></p></li><li><p>hadoop URI 변수를 생성한다. 형태는 <code>http://namenodedns:port/webhdfs/v1/user/username/myfile.csv?user.name=MYUSERNAME&amp;op=OPEN</code> 으로 hadoop 설정에 맞게끔 변경한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfsUri=<span class="string">"http://192.168.179.178:50070/webhdfs/v1"</span></span><br><span class="line">fileUri=<span class="string">"/user/spark/test.csv"</span></span><br><span class="line">readParameter=<span class="string">"?user.name="</span></span><br><span class="line">usernameParameter=<span class="string">"spark&amp;"</span></span><br><span class="line">optionnalParameters=<span class="string">"op=OPEN"</span></span><br><span class="line">uri &lt;- paste0(hdfsUri, fileUri, readParameter, usernameParameter, optionnalParameters)</span><br></pre></td></tr></table></figure></li><li><p>URI 형태로 데이터를 불러오고 상단 부분 <em>(head)</em> 을 확인한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = read.csv(uri)</span><br><span class="line">head(data))</span><br></pre></td></tr></table></figure></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://github.com/RevolutionAnalytics/RHadoop/wiki/Installing-RHadoop-on-RHEL" target="_blank" rel="noopener">https://github.com/RevolutionAnalytics/RHadoop/wiki/Installing-RHadoop-on-RHEL</a></li><li><a href="https://niceguy1575.tistory.com/40" target="_blank" rel="noopener">https://niceguy1575.tistory.com/40</a></li><li><a href="https://hub.docker.com/r/rocker/tidyverse" target="_blank" rel="noopener">https://hub.docker.com/r/rocker/tidyverse</a></li><li><a href="https://github.com/gadenbuie/docker-tidyverse-rjava/blob/master/Dockerfile" target="_blank" rel="noopener">https://github.com/gadenbuie/docker-tidyverse-rjava/blob/master/Dockerfile</a></li><li><a href="https://wikidocs.net/52630" target="_blank" rel="noopener">https://wikidocs.net/52630</a></li></ul><hr><p>2020.02.20 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-r_hadoop_connection/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Elasticsearch 배포 on K8s</title>
      <link>https://jx2lee.github.io/cloud-deploy_es/</link>
      <guid>https://jx2lee.github.io/cloud-deploy_es/</guid>
      <pubDate>Thu, 06 Feb 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;toy project를 위해 es를 구축하려던 찰나, 사내에 K8s cluster를 구축하였다. 클라우드 공부 겸 Elasticsearch와 kibana를 K8s에 배포하는 과정을 다룬다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>toy project를 위해 es를 구축하려던 찰나, 사내에 K8s cluster를 구축하였다. 클라우드 공부 겸 Elasticsearch와 kibana를 K8s에 배포하는 과정을 다룬다</p><a id="more"></a><h1 id="Elasticsearch-배포하기"><a href="#Elasticsearch-배포하기" class="headerlink" title="Elasticsearch 배포하기"></a>Elasticsearch 배포하기</h1><h2 id="3-node로-구성된-elasticsearch-클러스터를-배포한다-한-개의-노드로만-구성될-경우-장애가-발생하면-고가용성을-확보할-수-없으므로-이와-같이-3개-노드로-구성된-클러스트를-배포함으로써-split-brain을-피하고자-한다"><a href="#3-node로-구성된-elasticsearch-클러스터를-배포한다-한-개의-노드로만-구성될-경우-장애가-발생하면-고가용성을-확보할-수-없으므로-이와-같이-3개-노드로-구성된-클러스트를-배포함으로써-split-brain을-피하고자-한다" class="headerlink" title="3-node로 구성된 elasticsearch 클러스터를 배포한다. 한 개의 노드로만 구성될 경우 장애가 발생하면 고가용성을 확보할 수 없으므로 이와 같이 3개 노드로 구성된 클러스트를 배포함으로써 split-brain을 피하고자 한다."></a>3-node로 구성된 elasticsearch 클러스터를 배포한다. 한 개의 노드로만 구성될 경우 장애가 발생하면 고가용성을 확보할 수 없으므로 이와 같이 3개 노드로 구성된 클러스트를 배포함으로써 <strong>split-brain</strong>을 피하고자 한다.</h2><h2 id="Namespace-생성"><a href="#Namespace-생성" class="headerlink" title="Namespace 생성"></a>Namespace 생성</h2><p><em>elastic_ns.yaml</em>을 작성하고 namespace를 생성한다</p><p><code>kubectl create -f elastic_ns.yaml</code></p><p><em>elastic_ns.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure><h2 id="Service-생성"><a href="#Service-생성" class="headerlink" title="Service 생성"></a>Service 생성</h2><p><em>elastic_svc.yaml</em>을 작성하고 service를 생성한다</p><p><code>kubectl create -f  elastic_svc.yaml</code></p><p><em>elastic_svc.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">elastic-svc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9200</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">rest</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9300</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">inter-node</span></span><br></pre></td></tr></table></figure><ul><li><p><code>kubectl get service -n {namespace-name}</code>으로 서비스 생성을 확인한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/jlee/elastic<span class="comment"># kg svc -n elastic</span></span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">elastic-svc NodePort 10.96.42.114 &lt;none&gt; 9200:30117/TCP,9300:30395/TCP 56m</span><br></pre></td></tr></table></figure></li></ul><blockquote><p><em>기존 사이트에서 소개한 service와는 조금 다르게 작성하였다. 클러스터에 배보된 es node에 접속하기 위해서는 service의 타입을 NodePort로 설정하였다. NodePort로 설정하지 않는다면 이후에 curl 하는 명령이 connected refused 될 것이다, K8s Service 정리가 필요!</em></p></blockquote><h2 id="StatefulSet-생성"><a href="#StatefulSet-생성" class="headerlink" title="StatefulSet 생성"></a>StatefulSet 생성</h2><p><em>elastic_statefulset.yaml</em>을 작성하고 StatefulSet을 생성한다</p><blockquote><p><em>StatefulSet이란, 상태를 가지고 있는 Pod들을 관리하는 컨트롤러로 순서를 지정하여 Pod를 실행하고 volume을 지정하여 Pod가 내려가도 정보를 잃지 않게 한다</em></p></blockquote><p><code>kubectl create -f elastic_statefulset.yaml</code></p><p><em>elastic_statefulset.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">es-cluster</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">elastic</span> <span class="comment"># namepsace name for elasticsearch</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">elasticsearch</span> <span class="comment"># service name for elasticsearch</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.5.2</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9200</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">rest</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9300</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">inter-node</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">k8s-elastic</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node.name</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">fieldRef:</span></span><br><span class="line">                <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">discovery.seed_hosts</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">"es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch"</span> <span class="comment"># hostname for each container</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster.initial_master_nodes</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">"es-cluster-0,es-cluster-1,es-cluster-2"</span> <span class="comment"># node name in es-cluster</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ES_JAVA_OPTS</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">"-Xms512m -Xmx512m"</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fix-permissions</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"chown -R 1000:1000 /usr/share/elasticsearch/data"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-vm-max-map</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">["sysctl",</span> <span class="string">"-w"</span><span class="string">,</span> <span class="string">"vm.max_map_count=262144"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">increase-fd-ulimit</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"ulimit -n 65536"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">rook-ceph-block</span> <span class="comment"># your storageclass</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">10Gi</span></span><br></pre></td></tr></table></figure><ul><li><p><code>kubectl get pods -n elastic</code>으로 생성한 파드를 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/jlee/elastic<span class="comment"># kgpo -n elastic</span></span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">es-cluster-0 1/1 Running 0 159m</span><br><span class="line">es-cluster-1 1/1 Running 0 158m</span><br><span class="line">es-cluster-2 1/1 Running 0 158m</span><br></pre></td></tr></table></figure></li></ul><h2 id="Check-Status"><a href="#Check-Status" class="headerlink" title="Check Status"></a>Check Status</h2><p>정상적으로 ES 노드가 배포되었는지 <code>kubectl get svc -n elastic</code>을 통해 확인된 포트로 <em>(9200에 포트포워딩 된 포트 확인)</em> curl 명령을 수행한다.</p><p><code>curl http://{ip}:{port}</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/jlee/elastic<span class="comment"># curl http://192.168.179.172:30117</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span> : <span class="string">"es-cluster-2"</span>,</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"k8s-elastic"</span>,</span><br><span class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"GqGwbyKYSfGZoEcqFumVzw"</span>,</span><br><span class="line">  <span class="string">"version"</span> : &#123;</span><br><span class="line">    <span class="string">"number"</span> : <span class="string">"7.2.0"</span>,</span><br><span class="line">    <span class="string">"build_flavor"</span> : <span class="string">"default"</span>,</span><br><span class="line">    <span class="string">"build_type"</span> : <span class="string">"docker"</span>,</span><br><span class="line">    <span class="string">"build_hash"</span> : <span class="string">"508c38a"</span>,</span><br><span class="line">    <span class="string">"build_date"</span> : <span class="string">"2019-06-20T15:54:18.811730Z"</span>,</span><br><span class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"lucene_version"</span> : <span class="string">"8.0.0"</span>,</span><br><span class="line">    <span class="string">"minimum_wire_compatibility_version"</span> : <span class="string">"6.8.0"</span>,</span><br><span class="line">    <span class="string">"minimum_index_compatibility_version"</span> : <span class="string">"6.0.0-beta1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Kibana-배포하기"><a href="#Kibana-배포하기" class="headerlink" title="Kibana 배포하기"></a>Kibana 배포하기</h1><h2 id="Kibana-배포에-경우-Service와-Deployment가-명시된-yaml-파일을-생성하고-배포하면-된다-위와-같은-서비스-방식인-NodePort로-서비스를-배포하고-포트번호-5601만-명시해주면-노드포트-형식의-서비스가-포트-포워딩을-수행하여-웹에서-접속할-수-있다"><a href="#Kibana-배포에-경우-Service와-Deployment가-명시된-yaml-파일을-생성하고-배포하면-된다-위와-같은-서비스-방식인-NodePort로-서비스를-배포하고-포트번호-5601만-명시해주면-노드포트-형식의-서비스가-포트-포워딩을-수행하여-웹에서-접속할-수-있다" class="headerlink" title="Kibana 배포에 경우 Service와 Deployment가 명시된 yaml 파일을 생성하고 배포하면 된다. 위와 같은 서비스 방식인 NodePort로 서비스를 배포하고 포트번호 5601만 명시해주면 노드포트 형식의 서비스가 포트 포워딩을 수행하여 웹에서 접속할 수 있다."></a>Kibana 배포에 경우 Service와 Deployment가 명시된 yaml 파일을 생성하고 배포하면 된다. 위와 같은 서비스 방식인 NodePort로 서비스를 배포하고 포트번호 5601만 명시해주면 노드포트 형식의 서비스가 포트 포워딩을 수행하여 웹에서 접속할 수 있다.</h2><p><code>kubectl create -f kibana.yaml</code></p><p><em>kibana.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">5601</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">kibana</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kibana</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">docker.elastic.co/kibana/kibana:7.2.0</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ELASTICSEARCH_URL</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">http://elasticsearch:9200</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5601</span></span><br></pre></td></tr></table></figure><h2 id="Check-Status-1"><a href="#Check-Status-1" class="headerlink" title="Check Status"></a>Check Status</h2><p>정상적으로 Kibana 가 배포되었는지 <code>kubectl get svc -n elastic</code>을 통해 확인된 포트로 <em>(9200에 포트포워딩 된 포트 확인)</em> curl 명령을 수행한다.</p><p><code>curl http://{ip}:{port}</code></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes" target="_blank" rel="noopener">How To Set Up an Elasticsearch, Fluentd and Kibana (EFK) Logging Stack on Kubernetes</a></li><li><a href="https://blog.voidmainvoid.net/153" target="_blank" rel="noopener">Elasticsearch와 Kibana, filebeat 를 활용한 쿠버네티스 로깅 아키텍쳐</a></li></ul><hr><p>2020.02.06 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-deploy_es/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] rook-ceph을 이용한 Ceph cluster 구성</title>
      <link>https://jx2lee.github.io/cloud-install_rook_ceph/</link>
      <guid>https://jx2lee.github.io/cloud-install_rook_ceph/</guid>
      <pubDate>Wed, 05 Feb 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;K8s 클러스터 내 rook-ceph을 이용한 Ceph cluster를 구성한다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.03.30 : yaml 파일이 포함된 github 주소 추가&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>K8s 클러스터 내 rook-ceph을 이용한 Ceph cluster를 구성한다.</p><p><strong>Update Note</strong></p><ul><li>2020.03.30 : yaml 파일이 포함된 github 주소 추가</li></ul><a id="more"></a><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><img src="https://rook.io/docs/rook/v0.9/media/rook-architecture.png" alt=""></p><p>rook-ceph은 Ceph 클러스터 및 다른 component들을 CRD(Custom Resource Definition)으로 관리하며 CRD의 변경사항을 Rook Operator를 이용해 일괄 적용할 수 있다</p><h1 id="설치-순서"><a href="#설치-순서" class="headerlink" title="설치 순서"></a>설치 순서</h1><h2 id="아래-순서와-같이-설치를-진행"><a href="#아래-순서와-같이-설치를-진행" class="headerlink" title="아래 순서와 같이 설치를 진행"></a>아래 순서와 같이 설치를 진행</h2><ul><li><p>특정 위치에 git repository를 clone 한다. 이후 common.yaml, operator.yaml 을 이용해 rook-ceph에서 제공하는 CRD와 operator를 생성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/rook/rook.git</span><br><span class="line"><span class="built_in">cd</span> /rook/cluster/example/kubenetes/cephfs</span><br><span class="line">kubectl apply -f common.yamlkubectl apply -f operator.yaml</span><br></pre></td></tr></table></figure></li><li><p>ceph_config_override.yaml 과 cluster.yaml 을 이용해 configmap을 생성하고 cluster를 구성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ceph_config_override.yaml</span><br><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure><p><em>ceph_config_override.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-config-override</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">[global]</span></span><br><span class="line">    <span class="string">mon</span> <span class="string">osd</span> <span class="string">down</span> <span class="string">out</span> <span class="string">interval</span> <span class="string">=</span> <span class="string">&#123;osd_down_out_interval&#125;</span></span><br><span class="line">    <span class="string">mon</span> <span class="string">clock</span> <span class="string">drift</span> <span class="string">allowed</span> <span class="string">=</span> <span class="number">0.2</span></span><br></pre></td></tr></table></figure><p><em>cluster.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephCluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">cephVersion:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ceph/ceph:v14.2.4-20190917</span></span><br><span class="line">    <span class="attr">allowUnsupported:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">dataDirHostPath:</span> <span class="string">/var/lib/rook</span></span><br><span class="line">  <span class="attr">skipUpgradeChecks:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">mon:</span></span><br><span class="line">    <span class="attr">count:</span> <span class="number">1</span>    <span class="comment"># Recommendation: Use odd numbers (ex. 3, 5)</span></span><br><span class="line">  <span class="attr">dashboard:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ssl:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">monitoring:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span>  <span class="comment"># Require Prometheus to be pre-installed</span></span><br><span class="line">    <span class="attr">rulesNamespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">hostNetwork:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">rbdMirroring:</span></span><br><span class="line">    <span class="attr">workers:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">mgr:</span></span><br><span class="line">    <span class="attr">modules:</span></span><br><span class="line">    <span class="comment"># The pg_autoscaler is only available on nautilus or newer. remove this if testing mimic.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pg_autoscaler</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">storage:</span></span><br><span class="line">    <span class="attr">useAllNodes:</span> <span class="literal">true</span>      <span class="comment"># Apply ceph-osd to all nodes.</span></span><br><span class="line">    <span class="attr">useAllDevices:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">deviceFilter:</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">journalSizeMB:</span> <span class="string">"1024"</span>  <span class="comment"># This value can be removed for environments with normal sized disks (20 GB or larger)</span></span><br><span class="line">      <span class="attr">osdsPerDevice:</span> <span class="string">"1"</span>   <span class="comment"># This value can be overridden at the node or device level</span></span><br><span class="line">    <span class="attr">directories:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/var/lib/rook</span></span><br></pre></td></tr></table></figure></li><li><p>toolbox.yaml 을 이용해 ceph 클러스터 이용을 위한 client를 설치한다</p><p><code>kubectl apply -f toolbox.yaml</code></p></li><li><p>block_pool.yaml  과 file_system.yaml을 이용해 block / file storage 배포 준비</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f block_pool.yaml</span><br><span class="line">kubectl apply -f file_system.yaml</span><br></pre></td></tr></table></figure><p><em>block_pool.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephBlockPool</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">replicapool</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">failureDomain:</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">replicated:</span></span><br><span class="line">    <span class="attr">size:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p><em>file_system.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephFilesystem</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">metadataPool:</span></span><br><span class="line">  <span class="comment"># failureDomain - values are possible for 'osd' and 'host'</span></span><br><span class="line">    <span class="attr">failureDomain:</span> <span class="string">host</span>  <span class="comment"># ceph-osd must exist equal or more than replicated size</span></span><br><span class="line">    <span class="attr">replicated:</span></span><br><span class="line">      <span class="attr">size:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">dataPools:</span></span><br><span class="line">  <span class="comment"># failureDomain - values are possible for 'osd' and 'host'</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">failureDomain:</span> <span class="string">host</span>  <span class="comment"># ceph-osd must exist equal or more than replicated size</span></span><br><span class="line">      <span class="attr">replicated:</span></span><br><span class="line">        <span class="attr">size:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">metadataServer:</span></span><br><span class="line">    <span class="attr">activeCount:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">activeStandby:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li><li><p>마지막으로 block_sc.yaml 과 file_sc.yaml을 이용해 각 block / file storageclass를 생성한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f block_sc.yaml</span><br><span class="line">kubectl apply -f file_sc.yaml</span><br></pre></td></tr></table></figure><p><em>block_sc.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">rook-ceph-block</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.rbd.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">    <span class="comment"># clusterID is the namespace where the rook cluster is running</span></span><br><span class="line">    <span class="comment"># If you change this namespace, also change the namespace below where the secret namespaces are defined</span></span><br><span class="line">    <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ceph pool into which the RBD image shall be created</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">replicapool</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image format. Defaults to "2".</span></span><br><span class="line">    <span class="attr">imageFormat:</span> <span class="string">"2"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image features. Available for imageFormat: "2". CSI RBD currently supports only `layering` feature.</span></span><br><span class="line">    <span class="attr">imageFeatures:</span> <span class="string">layering</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The secrets contain Ceph admin credentials. These are generated automatically by the operator</span></span><br><span class="line">    <span class="comment"># in the same namespace as the cluster.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-rbd-provisioner</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-rbd-node</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="comment"># Specify the filesystem type of the volume. If not specified, csi-provisioner</span></span><br><span class="line">    <span class="comment"># will set default as `ext4`.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/fstype:</span> <span class="string">ext4</span></span><br><span class="line"><span class="comment"># uncomment the following to use rbd-nbd as mounter on supported nodes</span></span><br></pre></td></tr></table></figure><p><em>file_sc.yaml</em></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">csi-cephfs-sc</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.cephfs.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="comment"># clusterID is the namespace where operator is deployed.</span></span><br><span class="line">  <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># CephFS filesystem name into which the volume shall be created</span></span><br><span class="line">  <span class="attr">fsName:</span> <span class="string">myfs</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Ceph pool into which the volume shall be created</span></span><br><span class="line">  <span class="comment"># Required for provisionVolume: "true"</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">myfs-data0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Root path of an existing CephFS volume</span></span><br><span class="line">  <span class="comment"># Required for provisionVolume: "false"</span></span><br><span class="line">  <span class="comment"># rootPath: /absolute/path</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># The secrets contain Ceph admin credentials. These are generated automatically by the operator</span></span><br><span class="line">  <span class="comment"># in the same namespace as the cluster.</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-cephfs-provisioner</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-cephfs-node</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># (optional) The driver can use either ceph-fuse (fuse) or ceph kernel client (kernel)</span></span><br><span class="line">  <span class="comment"># If omitted, default volume mounter will be used - this is determined by probing for ceph-fuse</span></span><br><span class="line">  <span class="comment"># or by setting the default mounter explicitly via --volumemounter command-line argument.</span></span><br><span class="line">  <span class="comment"># mounter: kernel</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">  <span class="comment"># uncomment the following line for debugging</span></span><br><span class="line">  <span class="comment">#- debug</span></span><br></pre></td></tr></table></figure></li></ul><p>위 단계를 거치고 난 뒤 rook-ceph namespace의 pod와 storageclass 를 확인한다</p><p><code>kubectl get pods -n rook-ceph</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~/jlee/rook-ceph-master<span class="comment"># kubectl get pods -n rook-ceph</span></span><br><span class="line">NAME                                           READY   STATUS      RESTARTS   AGE</span><br><span class="line">csi-cephfsplugin-7kz7v                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-9rt7t                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-dnggh                         3/3     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-provisioner-974b566d9-7k2rb   4/4     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-provisioner-974b566d9-kxg2f   4/4     Running     0          4d19h</span><br><span class="line">csi-cephfsplugin-xzt9b                         3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-2npvg                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-drzkp                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-hhsm5                            3/3     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-provisioner-579c546f5-qprb8      5/5     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-provisioner-579c546f5-svhlw      5/5     Running     0          4d19h</span><br><span class="line">csi-rbdplugin-qhsw6                            3/3     Running     0          4d19h</span><br><span class="line">rook-ceph-mds-myfs<span class="_">-a</span>-58ddc89fc8-s4f44          1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mds-myfs-b-85dc7c7cf4-x68lk          1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mgr<span class="_">-a</span>-69df8d6794-glbjb               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon<span class="_">-a</span>-7b9cb64846-zfbwf               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon-b-7fc7c8fbb4-75j9j               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-mon-c-6c59c89fbc-rn8nv               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-operator-7985c4b57d-8qtht            1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-0-55888686c-pf6wn                1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-1-f56d885d4-tnrmv                1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-2-68f99d999f-zlrl4               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-3-7545f4df9b-ng4tf               1/1     Running     0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node1-msfs9          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node2-z858m          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node3-lwh4c          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-osd-prepare-k8s-node4-w8rfw          0/1     Completed   0          4d19h</span><br><span class="line">rook-ceph-tools-8648fbb998-5q7v2               1/1     Running     0          4d19h</span><br><span class="line">rook-discover-85fzl                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-djj97                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-p7cwx                            1/1     Running     0          4d19h</span><br><span class="line">rook-discover-zvn5f                            1/1     Running     0          4d19h</span><br></pre></td></tr></table></figure><p><code>kubectl get storageclass</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl get storageclass</span></span><br><span class="line">NAME                        PROVISIONER                     AGE</span><br><span class="line">csi-cephfs-sc               rook-ceph.cephfs.csi.ceph.com   16h</span><br><span class="line">rook-ceph-block             rook-ceph.rbd.csi.ceph.com      16h</span><br></pre></td></tr></table></figure><blockquote><p><em>위 언급한 yaml 파일은 github 에 올려 두었다. <a href="https://github.com/jaejuning/rook-ceph-deploy" target="_blank" rel="noopener">https://github.com/jaejuning/rook-ceph-deploy</a></em></p></blockquote><h1 id="Ceph-cluster-상태-확인"><a href="#Ceph-cluster-상태-확인" class="headerlink" title="Ceph cluster 상태 확인"></a>Ceph cluster 상태 확인</h1><h2 id="설치가-완료되었다면-구축한-ceph-cluster가-정상-구동되었는지-확인하여야-한다-toolbox-pod-를-통해-pod-네임을-확인한다"><a href="#설치가-완료되었다면-구축한-ceph-cluster가-정상-구동되었는지-확인하여야-한다-toolbox-pod-를-통해-pod-네임을-확인한다" class="headerlink" title="설치가 완료되었다면 구축한 ceph cluster가 정상 구동되었는지 확인하여야 한다. toolbox pod 를 통해 pod 네임을 확인한다"></a>설치가 완료되었다면 구축한 ceph cluster가 정상 구동되었는지 확인하여야 한다. toolbox pod 를 통해 pod 네임을 확인한다</h2><p><code>kubectl -n rook-ceph get pod -l &quot;app=rook-ceph-tools&quot;</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl -n rook-ceph get pod -l "app=rook-ceph-tools"</span></span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">rook-ceph-tools-8648fbb998-dzbbd   1/1     Running   0          15h</span><br></pre></td></tr></table></figure><ul><li><p>확인된 pod 네임을 통해 exec 명령어로 해당 컨테이너로 접속</p><p><code>kubectl exec -it -n rook-ceph [위 결과로 나온 pod NAME] -- /bin/bash</code></p></li></ul><h2 id="Ceph-cluster-상태-확인-1"><a href="#Ceph-cluster-상태-확인-1" class="headerlink" title="Ceph cluster 상태 확인"></a>Ceph cluster 상태 확인</h2><p><code>ceph -s</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node3 /] ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     9d3a534e-797f-4659-af8d-4bfb5f60f76c</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum a (age 16h)</span><br><span class="line">    mgr: a(active, since 15h)</span><br><span class="line">    mds: myfs:1 &#123;0=myfs<span class="_">-a</span>=up:active&#125; 1 up:standby-replay</span><br><span class="line">    osd: 2 osds: 2 up (since 15h), 2 <span class="keyword">in</span> (since 15h)</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   3 pools, 24 pgs</span><br><span class="line">    objects: 537 objects, 1.4 GiB</span><br><span class="line">    usage:   53 GiB used, 45 GiB / 98 GiB avail</span><br><span class="line">    pgs:     24 active+clean</span><br></pre></td></tr></table></figure><h2 id="Ceph-cluster-disk-확인"><a href="#Ceph-cluster-disk-확인" class="headerlink" title="Ceph cluster disk 확인"></a>Ceph cluster disk 확인</h2><p><code>ceph df</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node3 /] ceph df</span><br><span class="line">RAW STORAGE:</span><br><span class="line">    CLASS     SIZE       AVAIL      USED       RAW USED     %RAW USED </span><br><span class="line">    ssd       98 GiB     45 GiB     53 GiB       53 GiB         53.87 </span><br><span class="line">    TOTAL     98 GiB     45 GiB     53 GiB       53 GiB         53.87 </span><br><span class="line"></span><br><span class="line">POOLS:</span><br><span class="line">    POOL              ID     STORED      OBJECTS     USED        %USED     MAX AVAIL </span><br><span class="line">    replicapool        1     1.4 GiB         509     1.4 GiB      3.50        19 GiB </span><br><span class="line">    myfs-metadata      2     2.2 KiB          28     2.2 KiB         0        19 GiB </span><br><span class="line">    myfs-data0         3         0 B           0         0 B         0        19 GiB</span><br></pre></td></tr></table></figure><h2 id="RBD-image-사용량"><a href="#RBD-image-사용량" class="headerlink" title="RBD image 사용량"></a>RBD image 사용량</h2><p><code>rbd du -p replicapoll</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NAME                                         PROVISIONED USED    </span><br><span class="line">csi-vol-22712573-4815-11ea-9f90-aea9eb69a9f1      10 GiB 344 MiB </span><br><span class="line">csi-vol-6d1536b2-47fc-11ea-9f90-aea9eb69a9f1      10 GiB 300 MiB </span><br><span class="line">csi-vol-d38c964b-4814-11ea-9f90-aea9eb69a9f1      10 GiB 404 MiB </span><br><span class="line">csi-vol-d4745340-4814-11ea-9f90-aea9eb69a9f1      10 GiB 396 MiB </span><br><span class="line">csi-vol-d4937470-4814-11ea-9f90-aea9eb69a9f1      20 GiB 244 MiB </span><br><span class="line">csi-vol-d4a291d9-4814-11ea-9f90-aea9eb69a9f1      20 GiB 400 MiB </span><br><span class="line">&lt;TOTAL&gt;                                           80 GiB 2.0 GiB</span><br></pre></td></tr></table></figure><p>reclaimPolicy를 Retain으로 설정할 경우, pv를 지워도 RBD image가 ceph cluster에 남게 되는데, 이 경우에는 <code>rbd ls</code>, <code>rbd rm</code> 등을 통해 rbd 리스트를 확인하고 삭제해야 한다.</p><h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><p>내 경우 클러스터의 한 노드에서 csi-rbdplugin pod가 생성되지 않고 CrashLoopBack 이 걸리는 현상이 발생하였다. 노드 문제를 해결하지 못하여 우회하는 방안으로 <strong>해당 노드에 파드가 설정되지 않게 taint 조건을 추가</strong>하여 문제를 해결하였다.</p><p><code>kubectl taint nodes {csi-rbdplugin pod를 생성하지 못하는 노드} key=value:NoSchedule-</code></p><p>이후에 rook-ceph cluster를 재 구축하면 csi-rbdplugin이 정상 작동함을 확인할 수 있다.</p><hr><p>2020.02.06 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_rook_ceph/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Terminating State에 빠진 Namespace 삭제</title>
      <link>https://jx2lee.github.io/cloud-delete_ns_at_terminating_state/</link>
      <guid>https://jx2lee.github.io/cloud-delete_ns_at_terminating_state/</guid>
      <pubDate>Mon, 03 Feb 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;K8s namespace를 삭제하다보면 state가 &lt;code&gt;Terminating&lt;/code&gt;이면서 get namespace 결과에 계속 남아있는 문제가 발생하는데, 이를 해결하는 방법을 다룬다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Updata Note&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.03.13 : Advanced 추가 (shell script)&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>K8s namespace를 삭제하다보면 state가 <code>Terminating</code>이면서 get namespace 결과에 계속 남아있는 문제가 발생하는데, 이를 해결하는 방법을 다룬다.</p><p><strong>Updata Note</strong>  </p><ul><li>2020.03.13 : Advanced 추가 (shell script)</li></ul><a id="more"></a><h1 id="문제-발생"><a href="#문제-발생" class="headerlink" title="문제 발생"></a>문제 발생</h1><p><code>rook-ceph</code> 네임스페이스를 생성하다 삭제하면서 아래와 같은 문제가 발생하였다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get ns</span><br><span class="line">NAME              STATUS        AGE</span><br><span class="line">default           Active        2d21h</span><br><span class="line">istio-system      Active        6h40m</span><br><span class="line">knative-serving   Active        6h40m</span><br><span class="line">kube-node-lease   Active        2d21h</span><br><span class="line">kube-public       Active        2d21h</span><br><span class="line">kube-system       Active        2d21h</span><br><span class="line">rook-ceph         Terminating   16m</span><br></pre></td></tr></table></figure><p>Terminating 중인 네임스페이스를 한 번 더 지우는 명령어를 수행하면 에러가 발생한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error from server (Conflict): Operation cannot be fulfilled on namespaces <span class="string">"rook-ceph"</span>: The system is ensuring all content is removed from this namespace.  Upon completion, this namespace will automatically be purged by the system.</span><br></pre></td></tr></table></figure><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><p>해당 Namespace의 yaml 파일을 살펴보면, <code>.spec/finalizers</code>  부분에 Kubernetes라 명시되어 있다. 이를 빈 공백으로 바꾸고 적용하는 순서로 진행한다.</p><ul><li><code>jq</code> 패키지를 설치하고 <em>(apt get install jq)</em> 아래 명령어를 수행한다.<br><code>kubectl get namespace $NAMESPACE -o json |jq &#39;.spec = {&quot;finalizers&quot;:[]}&#39; &gt; temp.json</code></li><li>명령어를 수행한 디렉토리에 <code>temp.json</code>이 생성되는데, 이를 yaml 파일로 적용할 것이다. 이때 필요한 Ip/port를 아래 명령어로 확인한다.<br><code>kubectl proxy &amp;</code></li><li>curl 명령어로 수정사항을 반영한다.<br><code>curl -k -H &quot;Content-Type: application/json&quot; -X PUT --data-binary @temp.json http://127.0.0.1:8001/api/v1/namespaces/{Namespace-name}/finalize</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get namespaces</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   2d21h</span><br><span class="line">istio-system      Active   6h43m</span><br><span class="line">knative-serving   Active   6h43m</span><br><span class="line">kube-node-lease   Active   2d21h</span><br><span class="line">kube-public       Active   2d21h</span><br><span class="line">kube-system       Active   2d21h</span><br></pre></td></tr></table></figure><h1 id="Advanced-Shell-script"><a href="#Advanced-Shell-script" class="headerlink" title="(Advanced) Shell script"></a>(Advanced) Shell script</h1><p>이런 에러가 발생할 때마다 일일이 찾기 귀찮아서 쉘 스크립트 공부도 할 겸 <code>deleteNS.sh</code> 스크립트를 구현하였다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment">#  delete namespaces</span></span><br><span class="line"></span><br><span class="line">NS=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">kubectl get namespace <span class="variable">$NS</span> -o json |jq <span class="string">'.spec = &#123;"finalizers":[]&#125;'</span> &gt; temp.json</span><br><span class="line">kubectl proxy &amp;</span><br><span class="line">curl -k -H <span class="string">"Content-Type: application/json"</span> -X PUT --data-binary @temp.json http://127.0.0.1:8001/api/v1/namespaces/<span class="variable">$NS</span>/finalize</span><br><span class="line"><span class="built_in">kill</span> %1 &amp;&amp; rm tmp.json <span class="comment"># proxy process 를 다운하고 tmp.json 파일을 삭제</span></span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://nasermirzaei89.net/2019/01/27/delete-namespace-stuck-at-terminating-state/" target="_blank" rel="noopener">Delete Namespace Stuck At Terminating State, https://nasermirzaei89.net/2019/01/27/delete-namespace-stuck-at-terminating-state/</a></li></ul><hr><p>2020.02.04 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-delete_ns_at_terminating_state/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] K8s cluster node 추가 및 삭제</title>
      <link>https://jx2lee.github.io/cloud-manage_node/</link>
      <guid>https://jx2lee.github.io/cloud-manage_node/</guid>
      <pubDate>Tue, 28 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;K8s 클러스터에 노드를 추가 및 삭제하는 과정을 다룬다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Node&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.03.10 : kubectl drain 설명 추가&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>K8s 클러스터에 노드를 추가 및 삭제하는 과정을 다룬다.</p><p><strong>Update Node</strong></p><ul><li>2020.03.10 : kubectl drain 설명 추가</li></ul><a id="more"></a><h1 id="상태-확인"><a href="#상태-확인" class="headerlink" title="상태 확인"></a>상태 확인</h1><p><code>kubectl get nodes</code>로 노드 상태를 확인한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME          STATUS     ROLES    AGE     VERSION</span><br><span class="line">ai.bips       NotReady   &lt;none&gt;   11m     v1.15.3</span><br><span class="line">bigdata-svr   Ready      &lt;none&gt;   8m24s   v1.15.3</span><br><span class="line">k8s-master    Ready      master   6d17h   v1.15.3</span><br><span class="line">k8s-node1     Ready      master   6d17h   v1.15.3</span><br><span class="line">k8s-node2     Ready      master   6d17h   v1.15.3</span><br><span class="line">k8s-node3     Ready      &lt;none&gt;   4m14s   v1.15.3</span><br></pre></td></tr></table></figure><p><strong>k8s-node3</strong> 노드를 삭제하고 추가해보도록 하자</p><h1 id="Delete-k8s-master-amp-Reset-k8s-node3"><a href="#Delete-k8s-master-amp-Reset-k8s-node3" class="headerlink" title="Delete (k8s-master) &amp; Reset (k8s-node3)"></a>Delete (k8s-master) &amp; Reset (k8s-node3)</h1><p>마스터 노드에서 <strong>k8s-node3</strong>를 delete 한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete node k8s-node3</span><br><span class="line">node <span class="string">"k8s-node3"</span> deleted</span><br></pre></td></tr></table></figure><blockquote><p><em>kubectl delete 말고 kubectl drain {node_name} 을 수행하면 이미 띄워져있는 해당 노드의 파드들을 클러스터 내 다른 노드로 이동시키는 명령이다. delete 보다 drain을 수행하여 클러스터에서 제외시키는 것이 관리에 더 용이할 것으로 보인다.</em></p></blockquote><p>이후, 삭제한 노드에서 <code>kubeadm</code>을 통해 reset 한다. reset을 하게되면 이후 마스터 노드에서 k8s-node3가 삭제되었음을 확인한다</p><p><code>kubeadm reset</code></p><blockquote><p><em>reset 하지 않으면 이전 정보가 남아있어 추후에 join 수행 시 error 발생</em></p></blockquote><h1 id="In-master-node"><a href="#In-master-node" class="headerlink" title="In master node,"></a>In master node,</h1><p>kubeadm init 을 통해 생성된 토큰을 확인하기 위해서 3개 마스터 중 한 대 노드에서 token 을 확인한다</p><p><code>kubeadm token list</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                           EXTRA GROUPS</span><br><span class="line">4e3bad.gzp017frj86g4ngi   23h         2020-01-30T01:53:56Z   authentication,signing   &lt;none&gt;                                                system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">eo7vb4.3ck3l5ja3ry78bef   &lt;invalid&gt;   2020-01-23T08:03:36Z   authentication,signing   &lt;none&gt;                                                system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">m8470a.r8fo1tbwmdhb39eo   22h         2020-01-30T00:58:34Z   authentication,signing   &lt;none&gt;                                                system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">sds92v.mk937ek75jygtrlo   &lt;invalid&gt;   2020-01-22T10:03:36Z   &lt;none&gt;                   Proxy <span class="keyword">for</span> managing TTL <span class="keyword">for</span> the kubeadm-certs secret   &lt;none&gt;</span><br></pre></td></tr></table></figure><p><em>EXPIERS</em> : invalid 하지 않는 토큰이 없는 경우, <code>kubeadm token create(or generate)</code>로 토큰을 설정한다. 만약 expired 되지 않았다면, join 명렁어의 토큰으로 사용한다</p><p>이후 hash 값이 필요하므로 다음 명령어를 통해 hash 값을 확인한다</p><p><code>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;</code></p><h1 id="In-k8s-node3"><a href="#In-k8s-node3" class="headerlink" title="In k8s-node3,"></a>In k8s-node3,</h1><p><strong>k8s-node3</strong>에서 위 master 노드를 통해 확인한 값으로 join 을 수행한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm join 192.168.179.171:6443 --token 4e3bad.gzp017frj86g4ngi \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:b141f77ea7c5749767bd7a1dfc54f256ef374969b08f660f1c131453ebed7091</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br></pre></td></tr></table></figure><blockquote><p><em>IP는 마스터 IP(주의 : 삼중화를 진행하였으므로, 3개 마스터 통신을 담당하는 VIP로 작성) port는 6443</em></p></blockquote><p>추가를 완료하였다. 이후에 master 노드에서 <code>kubectl get nodes</code> 를 하면 하기 출력을 확인할 수 있다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME          STATUS   ROLES    AGE     VERSION</span><br><span class="line">bigdata-svr   Ready    &lt;none&gt;   23m     v1.15.3</span><br><span class="line">k8s-master    Ready    master   6d18h   v1.15.3</span><br><span class="line">k8s-node1     Ready    master   6d18h   v1.15.3</span><br><span class="line">k8s-node2     Ready    master   6d18h   v1.15.3</span><br><span class="line">k8s-node3     Ready    &lt;none&gt;   3m16s   v1.15.3 <span class="comment"># Check!</span></span><br></pre></td></tr></table></figure><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>K8s cluster에 노드를 추가하고 삭제하는 과정을 다뤘다. 노드를 삭제하고 삭제한 노드에서 리셋을 진행한 다음, 마스터에서의 <code>token 및 hash value</code>를 추가 노드에 join에 이용하였다</p><ul><li><p>노드 삭제</p><p><code>kubectl delete node {node-name}</code></p></li><li><p>노드 리셋</p><p><code>kubeadm reset</code></p></li><li><p>cluster token 확인</p><p><code>kubadm token list</code>, expired 된 토큰 발견 시 <code>kubeadm token create</code>로 새 토큰 생성</p></li><li><p>hash값 확인</p><p><code>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;</code></p></li></ul><hr><p>2020.01.29 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-manage_node/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Shell] .DS_Store 삭제 script</title>
      <link>https://jx2lee.github.io/shell-delete_ds_store/</link>
      <guid>https://jx2lee.github.io/shell-delete_ds_store/</guid>
      <pubDate>Sun, 26 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Mac Finder로 파일을 탐색하다 보면 &lt;code&gt;.DS_Store&lt;/code&gt; 이라는 파일이 생성된다. 성가시다! git을 사용할 때항상 .gitignore로 명시를 해야되며, 모든 폴더에 적용하고 push 한 경험이 있을거다. 쉘 공부하면서 간단한 스크립트를 이번 포스트에서 작성해본다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.04.01 : 스크립트 수정 (변수 입력 및 usage)&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Mac Finder로 파일을 탐색하다 보면 <code>.DS_Store</code> 이라는 파일이 생성된다. 성가시다! git을 사용할 때항상 .gitignore로 명시를 해야되며, 모든 폴더에 적용하고 push 한 경험이 있을거다. 쉘 공부하면서 간단한 스크립트를 이번 포스트에서 작성해본다.</p><p><strong>Update Note</strong></p><ul><li>2020.04.01 : 스크립트 수정 (변수 입력 및 usage)</li></ul><a id="more"></a><h1 id="DS-Store"><a href="#DS-Store" class="headerlink" title=".DS_Store?"></a>.DS_Store?</h1><p>DS_STORE 파일이란 Desktop Services Store의 약자로 애플에서 정의한 파일 포맷이다. 애플의 맥 OS X 시스템이 폴더에 접근할 때 생기는 해당 폴더에 대한 메타데이터를 저장하는 파일이다. 윈도우의 thumb.db 파일과 비슷하다. 분석해보면 해당 디렉토리 크기, 아이콘의 위치, 폴더의 배경에 대한 정보들을 얻을 수 있다. 맥 OS 환경에서만 생성 및 사용되지만,파일을 공유하는 과정에서 이 파일도 같이 공유되는 경우가 있다. <a href="https://chp747.tistory.com/54" target="_blank" rel="noopener">출처</a></p><h1 id="Shell-script"><a href="#Shell-script" class="headerlink" title="Shell script"></a>Shell script</h1><p>간단한 한 줄 짜리 명령으로 루트 디렉토리부터 삭제할 수 있다. 하지만 나는 이게 귀찮았다. 그리고 Finder로는 <code>/</code> 디렉토리까지 갈 일이 없고, <code>/Users/jj</code> 아래 하위 디렉토리에 생성되는 DS_Store 파일이 거슬렸다. hackerrank shell 문제를 푸는 디렉토리에 <code>rm-ds-store.sh</code> 파일을 생성하고 스크립트를 작성하였다</p><p>sudo와 find로 쉽게 작성할 수 있다. 쉘 실행 시 <code>stdin</code>으로 패스워드 입력값을 받아 sudo 명렁을 실행하고, 삭제되는 내역을 print 한다. 내용은 하기와 같다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># delete all .DS_Store file from path</span></span><br><span class="line"><span class="comment"># Wed, 01.04.2020</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>  [ <span class="string">"<span class="variable">$#</span>"</span> -ne 1 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"usage   : <span class="variable">$0</span> &#123;path&#125;"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"example : <span class="variable">$0</span> /Users/jj"</span></span><br><span class="line">        <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">path=<span class="variable">$1</span></span><br><span class="line">sudo --stdin find <span class="variable">$&#123;path&#125;</span> -name <span class="string">".DS_Store"</span> -<span class="built_in">print</span> -delete</span><br><span class="line"><span class="built_in">echo</span> <span class="string">".DS_Store clear in <span class="variable">$&#123;path&#125;</span> !"</span></span><br></pre></td></tr></table></figure><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><p><code>./rm-ds-store.sh</code> 명령어를 실행하면 Usage 를 확인할 수 있다. 정리하고자 하는 디렉토리를 삽입하면 된다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~/shell/custom</span><br><span class="line">❯ ./rm-ds-store.sh</span><br><span class="line">usage   : ./rm-ds-store.sh &#123;path&#125;</span><br><span class="line">example : ./rm-ds-store.sh /Users/jj</span><br><span class="line"></span><br><span class="line">~/shell/custom</span><br><span class="line">❯ ./rm-ds-store.sh /Users/jj</span><br><span class="line">Password:</span><br><span class="line">.DS_Store clear <span class="keyword">in</span> /Users/jj..!</span><br></pre></td></tr></table></figure><p><del>삭제된 위치가 프린트하며 동시에 삭제하여 완료됨을 확인할 수 있다. 원래는 <code>/</code> 하위 디렉토리 모두 검사하였지만 굳이 검사할 필요가 없었다 <em>(이유는 .DS_Store 의 정의를 생각하면 된다)</em>. 쉘 스크립트 공부하면서 실제로 써볼 수 있는 toy project 였고 더 활용할 수 있는 방안을 고민해야겠다.</del> 인자값이 없으면 Usage 를 출력하고 원하는 디렉토리를 추가하여 하위 디렉토리를 모두 검색하는 스크립트로 수정하였다. 조금씩 더 활용할 방안을 생각하면서 수정할 계획이다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://chp747.tistory.com/54" target="_blank" rel="noopener">.DS_STORE 파일이란, https://chp747.tistory.com/54</a></li></ul><hr><p>2020.01.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/shell-delete_ds_store/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubeflow 설치</title>
      <link>https://jx2lee.github.io/cloud-install_kubeflow/</link>
      <guid>https://jx2lee.github.io/cloud-install_kubeflow/</guid>
      <pubDate>Wed, 22 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;K8s cluster 위 Kubeflow를 설치하는 과정을 다룬다. K8s cluster 구축은 &lt;a href=&quot;https://jaejuning.github.io/2020/01/22/2020-01-22-cloud-k8s_cluster/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;포스트&lt;/a&gt; 참고&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.02.25 : Trouble Shooting 추가&lt;/li&gt;
&lt;li&gt;2020.03.13 : Kubeflow 삭제 추가, kfctl 버젼 명시&lt;/li&gt;
&lt;li&gt;2020.03.18 : Dashboard UI 수정&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>K8s cluster 위 Kubeflow를 설치하는 과정을 다룬다. K8s cluster 구축은 <a href="https://jaejuning.github.io/2020/01/22/2020-01-22-cloud-k8s_cluster/" target="_blank" rel="noopener">포스트</a> 참고</p><p><strong>Update Note</strong></p><ul><li>2020.02.25 : Trouble Shooting 추가</li><li>2020.03.13 : Kubeflow 삭제 추가, kfctl 버젼 명시</li><li>2020.03.18 : Dashboard UI 수정</li></ul><a id="more"></a><h1 id="K8s-환경"><a href="#K8s-환경" class="headerlink" title="K8s 환경"></a>K8s 환경</h1><h2 id="Storageclass-default-설정-확인"><a href="#Storageclass-default-설정-확인" class="headerlink" title="Storageclass default 설정 확인"></a>Storageclass default 설정 확인</h2><p>storage class name default 설정을 위해 아래 커맨드라인을 수행</p><p><code>kubectl patch storageclass [storage class 명] -p &#39;{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}&#39;</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get sc <span class="comment">#sc : storageclass</span></span><br><span class="line">NAME                        PROVISIONER                     AGE</span><br><span class="line">csi-cephfs-sc               rook-ceph.cephfs.csi.ceph.com   16h</span><br><span class="line">rook-ceph-block (default)   rook-ceph.rbd.csi.ceph.com      16h</span><br></pre></td></tr></table></figure><h1 id="Kubeflow-설치-파일-다운"><a href="#Kubeflow-설치-파일-다운" class="headerlink" title="Kubeflow 설치 파일 다운"></a>Kubeflow 설치 파일 다운</h1><p><a href="https://github.com/kubeflow/kubeflow/releases" target="_blank" rel="noopener">https://github.com/kubeflow/kubeflow/releases</a>에서 최신 kfctl 바이너리를 다운받아 압축을 해제한다.</p><blockquote><p><em>본인은 v1.0.1-0-gf3edb9b 을 사용하였다.</em></p></blockquote><h1 id="Kubeflow-환경-설정"><a href="#Kubeflow-환경-설정" class="headerlink" title="Kubeflow 환경 설정"></a>Kubeflow 환경 설정</h1><h2 id="bashrc"><a href="#bashrc" class="headerlink" title=".bashrc"></a>.bashrc</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KF_NAME=my-kubeflow</span><br><span class="line"><span class="built_in">export</span> BASE_DIR=/root/kubeflow</span><br><span class="line"><span class="built_in">export</span> KF_DIR=<span class="variable">$&#123;BASE_DIR&#125;</span>/<span class="variable">$&#123;KF_NAME&#125;</span></span><br><span class="line"><span class="built_in">export</span> CONFIG_FILE=<span class="variable">$&#123;KF_DIR&#125;</span>/kfctl_k8s_istio.0.7.0.yaml</span><br><span class="line"><span class="built_in">export</span> CONFIG_URI=<span class="string">"https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_k8s_istio.0.7.0.yaml"</span></span><br></pre></td></tr></table></figure><h2 id="kfctl-k8s-istio-0-7-0-yaml"><a href="#kfctl-k8s-istio-0-7-0-yaml" class="headerlink" title="kfctl_k8s_istio.0.7.0.yaml"></a>kfctl_k8s_istio.0.7.0.yaml</h2><p><code>wget -O kfctl_k8s_istio.0.7.0.yaml $CONFIG_URI</code></p><h1 id="Kubeflow-deploy"><a href="#Kubeflow-deploy" class="headerlink" title="Kubeflow deploy"></a>Kubeflow deploy</h1><h2 id="Binary-이동"><a href="#Binary-이동" class="headerlink" title="Binary 이동"></a>Binary 이동</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;BASE_DIR&#125;</span></span><br><span class="line">chmod 755 kfctl</span><br><span class="line">mv kfctl /usr/bin</span><br></pre></td></tr></table></figure><h2 id="설치"><a href="#설치" class="headerlink" title="설치"></a>설치</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$KF_DIR</span></span><br><span class="line">kfctl apply -V -f <span class="variable">$&#123;CONFIG_FILE&#125;</span></span><br></pre></td></tr></table></figure><h1 id="Access-Kubeflow-UI"><a href="#Access-Kubeflow-UI" class="headerlink" title="Access Kubeflow UI"></a>Access Kubeflow UI</h1><p><code>http://{NODE_IP}:31380</code>로 접속한다</p><p><img src="/image/kubeflow-login.png" alt=""></p><blockquote><p><em><del>Master가 많은 경우에 <strong>centraldashboard</strong> pod 를 확인하여, 해당 host ip를 사용하면 접속이 가능하다 (Master, Worker IP로 접속이 모두 가능)</del></em></p><ul><li>Service 를 NodePort 로 설정하였기때문에 클러스터 내 모든 노드의 IP로 접근이 가능하다.</li></ul></blockquote><h1 id="Truuble-Shooting"><a href="#Truuble-Shooting" class="headerlink" title="Truuble Shooting"></a>Truuble Shooting</h1><h2 id="Artifacts-또는-Executions-탭에서-error-mysql-query-failed-errno-2006"><a href="#Artifacts-또는-Executions-탭에서-error-mysql-query-failed-errno-2006" class="headerlink" title="Artifacts 또는 Executions 탭에서 error mysql_query failed errno 2006"></a>Artifacts 또는 Executions 탭에서 error mysql_query failed errno 2006</h2><p>해당 탭으로 이동하면 mysql_query failed 에러가 발생하는 경우가 있다. 이때에는 metadata-grpc-deployment pod 를 재시작 하면 된다.</p><p><code>kubectl get pod {pod_name} -n kubeflow -o yaml | kubectl replace --force -f-</code> </p><h1 id="Kubeflow-삭제"><a href="#Kubeflow-삭제" class="headerlink" title="Kubeflow 삭제"></a>Kubeflow 삭제</h1><p>Kubeflow 를 삭제하는 방법은 아래 <strong>kfctl delete</strong> 명령어를 사용한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;KF_DIR&#125;</span></span><br><span class="line">kfctl delete -f <span class="variable">$&#123;CONFIG_FILE&#125;</span></span><br></pre></td></tr></table></figure><ul><li><p>명령어 수행 후 <strong>kubectl get all -n kubeflow</strong> 로 모든 내용이 삭제되었는-f 지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  root@k8s-master:~/kubeflow/my-kubeflow<span class="comment"># kubectl get all -n kubeflow</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure></li></ul><hr><p>2020.01.23 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_kubeflow/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] K8s cluster 구축</title>
      <link>https://jx2lee.github.io/cloud-install_k8s/</link>
      <guid>https://jx2lee.github.io/cloud-install_k8s/</guid>
      <pubDate>Tue, 21 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;K8s cluster는 Master 3대&lt;em&gt;(k8s-master/k8s-node1/k8s-node2)&lt;/em&gt; / Worker 2대&lt;em&gt;(k8s-node3/k8s-node4)&lt;/em&gt;로 구성한다.&lt;/p&gt;
&lt;p&gt;k8s는 &lt;code&gt;1.15.3&lt;/code&gt; version 으로 진행하며, 모든 서버는 &lt;code&gt;ubuntu 18.04&lt;/code&gt; 이다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.02.25 : kubeadm init 시 &lt;code&gt;--upload-certs&lt;/code&gt; 옵션 부가 설명&lt;/li&gt;
&lt;li&gt;2020.03.12 : Calico CNI 설정 추가&lt;/li&gt;
&lt;li&gt;2020.03.17 : Trouble shooting 추가 - Calico node not working &lt;/li&gt;
&lt;li&gt;2020.06.04 : Taint NoSchedule 변경 (&lt;code&gt;/ to =&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>K8s cluster는 Master 3대<em>(k8s-master/k8s-node1/k8s-node2)</em> / Worker 2대<em>(k8s-node3/k8s-node4)</em>로 구성한다.</p><p>k8s는 <code>1.15.3</code> version 으로 진행하며, 모든 서버는 <code>ubuntu 18.04</code> 이다.</p><p><strong>Update Note</strong></p><ul><li>2020.02.25 : kubeadm init 시 <code>--upload-certs</code> 옵션 부가 설명</li><li>2020.03.12 : Calico CNI 설정 추가</li><li>2020.03.17 : Trouble shooting 추가 - Calico node not working </li><li>2020.06.04 : Taint NoSchedule 변경 (<code>/ to =</code>)</li></ul><a id="more"></a><h1 id="공통"><a href="#공통" class="headerlink" title="공통"></a>공통</h1><p>모든 노드에 공통으로 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y apt-transport-https curl</span><br><span class="line">apt-get update</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - <span class="comment"># Docker 공식 GPG key</span></span><br><span class="line">sudo apt-key fingerprint 0EBFCD88</span><br><span class="line">sudo add-apt-repository \</span><br><span class="line">    <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">    <span class="variable">$(lsb_release -cs)</span> \</span></span><br><span class="line"><span class="string">    stable"</span></span><br><span class="line">apt-get install -y docker-ce</span><br></pre></td></tr></table></figure><p>1.15.3 버젼에 맞는 kubelet / kubeadm / kubectl 를 설치한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"><span class="built_in">echo</span> deb http://apt.kubernetes.io/ kubernetes-xenial main &gt; /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y kubeadm=1.15.3-00 kubelet=1.15.3-00 kubectl=1.15.3-00</span><br></pre></td></tr></table></figure><p>Kubernets는 swap를 off시켜야 작동하므로 swap 메모리를 끈다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">free</span><br><span class="line">swapoff -a</span><br><span class="line">vi /etc/fstab</span><br><span class="line"><span class="comment"># 재부팅시 자동으로 swapoff 하려면 위 파일에서 swap 부분 주석 처리</span></span><br></pre></td></tr></table></figure><p>방화벽을 내려준다 <em>(ubnut : ufw)</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop ufw </span><br><span class="line">systemctl <span class="built_in">disable</span> ufw</span><br></pre></td></tr></table></figure><p><code>/etc/docker/daemon.json</code> 의 파일을 수정하고 도커 데몬을 재실행한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>], <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line"><span class="string">"log-opts"</span>: &#123;</span><br><span class="line"><span class="string">"max-size"</span>: <span class="string">"100m"</span> &#125;,</span><br><span class="line"><span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>, <span class="string">"insecure-registries"</span>: [<span class="string">"192.168.179.185:5000"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><blockquote><p><em>insecure-registries 는 VIP(virtual ip)를 나타내는데, 삼중화 했을 때 마스터 간 통신을 위한 ip. 뒤에 포트 5000은 후에 마스터 부분에 설치할 keepalived 에서 사용한다</em><br>Q. VIP의 포트는 아무렇게 지정해도 되는가?</p></blockquote><p>위 커맨드 라인을 정리한 script는 다음과 같다. 해당 스크립트를 작성하여 5개 노드에서 모두 실행한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># install basic package &amp; docker-ce &amp; k8s utils</span></span><br><span class="line"></span><br><span class="line">apt-get install -y apt-transport-https curl</span><br><span class="line">apt-get update</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - <span class="comment"># Docker 공식 GPG key</span></span><br><span class="line">sudo apt-key fingerprint 0EBFCD88</span><br><span class="line">sudo add-apt-repository \</span><br><span class="line">  <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">  <span class="variable">$(lsb_release -cs)</span> \</span></span><br><span class="line"><span class="string">  stable"</span></span><br><span class="line">apt-get install -y docker-ce</span><br><span class="line"></span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"><span class="built_in">echo</span> deb http://apt.kubernetes.io/ kubernetes-xenial main &gt; /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y kubeadm=1.15.3-00 kubelet=1.15.3-00 kubectl=1.15.3-00</span><br><span class="line"></span><br><span class="line">free</span><br><span class="line">swapoff -a</span><br><span class="line"></span><br><span class="line">ufw <span class="built_in">disable</span></span><br><span class="line">ufw status</span><br><span class="line"></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>], <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line"><span class="string">"log-opts"</span>: &#123;</span><br><span class="line"><span class="string">"max-size"</span>: <span class="string">"100m"</span> &#125;,</span><br><span class="line"><span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>, <span class="string">"insecure-registries"</span>: [<span class="string">"192.168.179.185:5000"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload &amp;&amp; <span class="built_in">echo</span> <span class="string">"restart docker-daemon"</span></span><br><span class="line">systemctl restart docker &amp;&amp; <span class="built_in">echo</span> <span class="string">"restart docker"</span></span><br></pre></td></tr></table></figure><h1 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h1><p>마스터 노드에서만 진행하는 부분을 다룬다</p><h2 id="Keepalived-설치"><a href="#Keepalived-설치" class="headerlink" title="Keepalived 설치"></a>Keepalived 설치</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y keepalived</span><br><span class="line">vi /etc/keepalived/keepalived.conf</span><br></pre></td></tr></table></figure><p><code>keepalived.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface enp0s8</span><br><span class="line">    virtual_router_id 50</span><br><span class="line">    priority 100 <span class="comment"># 이후 마스터부터 1씩 감소하여 수정</span></span><br><span class="line">    advert_int 1</span><br><span class="line">    nopreempt</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass $ place secure password here.</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.179.185</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>interface : ifconfig -a로 확인</li><li>priority : master 마다 다른 값 설정<ul><li>priority 값이 높으면 최우선적으로 master 역할 수행</li><li>100, 99, 98 로 설정</li></ul></li><li>virtual_ipaddress : 앞전에 docker daemon의 vip 주소 기입<ul><li>VIP 이어도 아무 ip나 사용하면 혹여나 충돌이 일어날까봐 할당받은 ip 사용</li></ul></li></ul><p>keepalived 서비스 재시작 후 상태(<code>ip a</code>)를 확인한다</p><p><code>systemctl restart keepalived &amp;&amp; systemctl status keepalived</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">3: enp6s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether 64:e5:99:fa:52:c1 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.179.172/24 brd 192.168.179.255 scope global enp6s0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.179.185/32 scope global enp6s0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::66e5:99ff:fefa:52c1/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><blockquote><p><em>VIP로 설정한 192.168.179.171 이 보이는 것을 확인 // 하나의 master에만 보임 (나머지는 stand by)</em></p></blockquote><h2 id="K8s-설치"><a href="#K8s-설치" class="headerlink" title="K8s 설치"></a>K8s 설치</h2><p><code>kubeadm-config.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: <span class="string">"v1.15.3"</span></span><br><span class="line">controlPlaneEndpoint: <span class="string">"192.168.179.185:6443"</span></span><br><span class="line">networking:</span><br><span class="line">    serviceSubnet: <span class="string">"10.96.0.0/16"</span></span><br><span class="line">    podSubnet: <span class="string">"10.244.0.0/16"</span></span><br><span class="line">apiServer:</span><br><span class="line">    extraArgs:</span><br><span class="line">        advertise-address: <span class="string">"192.168.179.185”</span></span><br></pre></td></tr></table></figure><ul><li>위 Yaml 파일은 첫 번째 master에서만 작성 후 init 을 수행한다.</li><li>v1.15.3으로 작성한다.</li></ul><blockquote><p><em>controlPlaneEndpoint와 advertise-address 는 VIP이고 포트로 6443으로 지정</em></p></blockquote><p>Yaml 파일을 이용해 클러스터 초기화를 진행한다.</p><p><code>kubeadm init --config=kubeadm-config.yaml --upload-certs</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following <span class="built_in">command</span> on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 \</span><br><span class="line">    --control-plane --certificate-key 553c75881e6825bf9e5f3887b2100de4a3d979777a313b70281c5bbe5ddeef80</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted <span class="keyword">in</span> two hours; If necessary, you can use </span><br><span class="line"><span class="string">"kubeadm init phase upload-certs --upload-certs"</span> to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0</span><br></pre></td></tr></table></figure><blockquote><p><em><code>--upload-certs</code> 옵션은 Master 이중화 시 key 인증을 init 명령과 수행해주는 역할을 한다. 이 옵션을 주지 않으면 이중화 대상 Master 에 key 인증을 수행해야 한다.</em></p></blockquote><p>서버 주소 및 인증서를 복사하는 단계로 아래 명령어를 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p><code>kubectl get pods --all-namespaces</code> 명령어로 아래와 같은 파드가 생성되기 기다린다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kgpo --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-5c98db65d4-9fpzf             0/1     Pending   0          3m2s</span><br><span class="line">kube-system   coredns-5c98db65d4-vn8d5             0/1     Pending   0          3m2s</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          119s</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          2m14s</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          2m21s</span><br><span class="line">kube-system   kube-proxy-c4cnn                     1/1     Running   0          3m1s</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          2m7s</span><br></pre></td></tr></table></figure><blockquote><p><em>coredns 는 CNI를 설치해야 Running 상태가 된다.</em></p></blockquote><p><a href="https://docs.projectcalico.org/v3.9/manifests/calico.yaml" target="_blank" rel="noopener">calico yaml</a>을 다운받아 <code>CALICO_IPV4POOL_CIDR</code> 값을 10.244.0.0/16 으로 변경한 후 CNI 를 설치한다.</p><p><code>kubectl apply -f kube-calico.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">        - name: calico-node</span><br><span class="line">          image: calico/node:v3.9.5</span><br><span class="line">          env:</span><br><span class="line">            <span class="comment"># Use Kubernetes API as the backing datastore.</span></span><br><span class="line">            - name: DATASTORE_TYPE</span><br><span class="line">              value: <span class="string">"kubernetes"</span></span><br><span class="line">            <span class="comment"># Wait for the datastore.</span></span><br><span class="line">            - name: WAIT_FOR_DATASTORE</span><br><span class="line">              value: <span class="string">"true"</span></span><br><span class="line">            <span class="comment"># Set based on the k8s node name.</span></span><br><span class="line">            - name: NODENAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: spec.nodeName</span><br><span class="line">            <span class="comment"># Choose the backend to use.</span></span><br><span class="line">            - name: CALICO_NETWORKING_BACKEND</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: calico_backend</span><br><span class="line">            <span class="comment"># Cluster type to identify the deployment type</span></span><br><span class="line">            - name: CLUSTER_TYPE</span><br><span class="line">              value: <span class="string">"k8s,bgp"</span></span><br><span class="line">            <span class="comment"># Auto-detect the BGP IP address.</span></span><br><span class="line">            - name: IP</span><br><span class="line">              value: <span class="string">"autodetect"</span></span><br><span class="line">            <span class="comment"># Enable IPIP</span></span><br><span class="line">            - name: CALICO_IPV4POOL_IPIP</span><br><span class="line">              value: <span class="string">"Always"</span></span><br><span class="line">            <span class="comment"># Set MTU for tunnel device used if ipip is enabled</span></span><br><span class="line">            - name: FELIX_IPINIPMTU</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: veth_mtu</span><br><span class="line">            <span class="comment"># The default IPv4 pool to create on startup if none exists. Pod IPs will be</span></span><br><span class="line">            <span class="comment"># chosen from this range. Changing this value after installation will have</span></span><br><span class="line">            <span class="comment"># no effect. This should fall within `--cluster-cidr`.</span></span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: <span class="string">"10.244.0.0/16"</span> <span class="comment">######################## 변경 ########################</span></span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p><em>CALICO_IPV4POOL_CIDR 값을 10.244.0.0/16 으로 변경되어있는지 확인한 후 배포한다. 클러스터 구성한 노드 IP 대역과 같으면 충돌이 일어난다고 한다.</em></p></blockquote><p>calico 파드가 띄워졌는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~<span class="comment"># kgpo --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-56cd854695-65j42   1/1     Running   0          89s</span><br><span class="line">kube-system   calico-node-ptq8x                          1/1     Running   0          89s</span><br><span class="line">kube-system   coredns-5c98db65d4-9fpzf                   1/1     Running   0          7m29s</span><br><span class="line">kube-system   coredns-5c98db65d4-vn8d5                   1/1     Running   0          7m29s</span><br><span class="line">kube-system   etcd-k8s-master                            1/1     Running   0          6m26s</span><br><span class="line">kube-system   kube-apiserver-k8s-master                  1/1     Running   0          6m41s</span><br><span class="line">kube-system   kube-controller-manager-k8s-master         1/1     Running   0          6m48s</span><br><span class="line">kube-system   kube-proxy-c4cnn                           1/1     Running   0          7m28s</span><br><span class="line">kube-system   kube-scheduler-k8s-master                  1/1     Running   0          6m34s</span><br></pre></td></tr></table></figure><p>나머지 master node에서 init 시 생성된 커맨드를 실행하여 클러스터에 Join 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \</span><br><span class="line"> --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0 \</span><br><span class="line"> --control-plane --certificate-key 553c75881e6825bf9e5f3887b2100de4a3d979777a313b70281c5bbe5ddeef80</span><br></pre></td></tr></table></figure><p>마찬가지로 서버 주소 및 인증서를 복사하는 명령어를 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h1 id="Worker-Node"><a href="#Worker-Node" class="headerlink" title="Worker Node"></a>Worker Node</h1><p>kubeadm init 시 나온 토큰과 해쉬값으로 각 워커 노드에서 Join 한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.179.185:6443 --token iicz2g.0a8b07vasikwuthz \</span><br><span class="line"> --discovery-token-ca-cert-hash sha256:249ee21a200d807f21dad0102eb638e50904102c7e7ae8f6388c1654f60ae1a0</span><br></pre></td></tr></table></figure><h1 id="설치-확인"><a href="#설치-확인" class="headerlink" title="설치 확인"></a>설치 확인</h1><h2 id="Kubectl-get-nodes"><a href="#Kubectl-get-nodes" class="headerlink" title="Kubectl get nodes"></a>Kubectl get nodes</h2><p><code>kubectl get nodes -o wide</code><br>master node에서 확인하면 클러스터에 포함된 노드들을 확인할 수 있다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME</span><br><span class="line">k8s-master   Ready    master   44m   v1.15.3   192.168.179.172   &lt;none&gt;        Ubuntu 18.04.4 LTS   5.3.0-28-generic    docker://19.3.8</span><br><span class="line">k8s-node1    Ready    master   41m   v1.15.3   192.168.179.173   &lt;none&gt;        Ubuntu 18.04.3 LTS   4.15.0-88-generic   docker://19.3.6</span><br><span class="line">k8s-node2    Ready    master   40m   v1.15.3   192.168.179.174   &lt;none&gt;        Ubuntu 18.04.3 LTS   4.15.0-88-generic   docker://19.3.6</span><br><span class="line">k8s-node3    Ready    &lt;none&gt;   40m   v1.15.3   192.168.179.175   &lt;none&gt;        Ubuntu 18.04.3 LTS   4.15.0-88-generic   docker://19.3.8</span><br><span class="line">k8s-node4    Ready    &lt;none&gt;   40m   v1.15.3   192.168.179.176   &lt;none&gt;        Ubuntu 18.04.3 LTS   4.15.0-88-generic   docker://19.3.8</span><br></pre></td></tr></table></figure><h2 id="선택사항-Master-node에도-pod-배포가-가능한-상태로-변환"><a href="#선택사항-Master-node에도-pod-배포가-가능한-상태로-변환" class="headerlink" title="(선택사항) Master node에도 pod 배포가 가능한 상태로 변환"></a>(선택사항) Master node에도 pod 배포가 가능한 상태로 변환</h2><p>master에 Pod를 배포할 수 있는 상태로 변환하기 위해 taint 조건을 해제한다.</p><p><code>kubectl taint nodes {node-name} node-role.kubernetes.io=master:NoSchedule-</code></p><blockquote><p><em>만약 노드를 리스케쥴 되지 않게 복구하려면 kubectl taint nodes {node-name} node-role.kubernetes.io/master:NoSchedule</em></p></blockquote><h1 id="Trouble-Shooting"><a href="#Trouble-Shooting" class="headerlink" title="Trouble-Shooting"></a>Trouble-Shooting</h1><h2 id="calico-node-가-Running-상태이지만-Unhealthy-문제"><a href="#calico-node-가-Running-상태이지만-Unhealthy-문제" class="headerlink" title="calico node 가 Running 상태이지만 Unhealthy 문제"></a>calico node 가 Running 상태이지만 Unhealthy 문제</h2><p><a href="https://github.com/projectcalico/calico/issues/2904" target="_blank" rel="noopener">https://github.com/projectcalico/calico/issues/2904</a> 문제와 같다. calico-node 가 클러스터 내 노드 수만큼 기동하지만 0/1 Running 상태였다. 문제가 있는 파드를 describe 해본 결과 다음과 같다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason          Age                   From                 Message</span><br><span class="line">  ----     ------          ----                  ----                 -------</span><br><span class="line">  Normal   Pulled          45m                   kubelet, k8s-master  Container image <span class="string">"calico/cni:v3.9.5"</span> already present on machine</span><br><span class="line">  Normal   Created         45m                   kubelet, k8s-master  Created container upgrade-ipam</span><br><span class="line">  Normal   Started         45m                   kubelet, k8s-master  Started container upgrade-ipam</span><br><span class="line">  Normal   Scheduled       45m                   default-scheduler    Successfully assigned kube-system/calico-node-v5rgk to k8s-master</span><br><span class="line">  Normal   Started         45m                   kubelet, k8s-master  Started container install-cni</span><br><span class="line">  Normal   Pulled          45m                   kubelet, k8s-master  Container image <span class="string">"calico/cni:v3.9.5"</span> already present on machine</span><br><span class="line">  Normal   Created         45m                   kubelet, k8s-master  Created container install-cni</span><br><span class="line">  Normal   Started         45m                   kubelet, k8s-master  Started container flexvol-driver</span><br><span class="line">  Normal   Pulled          45m                   kubelet, k8s-master  Container image <span class="string">"calico/pod2daemon-flexvol:v3.9.5"</span> already present on machine</span><br><span class="line">  Normal   Created         45m                   kubelet, k8s-master  Created container flexvol-driver</span><br><span class="line">  Normal   Pulled          45m                   kubelet, k8s-master  Container image <span class="string">"calico/node:v3.9.5"</span> already present on machine</span><br><span class="line">  Normal   Created         45m                   kubelet, k8s-master  Created container calico-node</span><br><span class="line">  Normal   Started         45m                   kubelet, k8s-master  Started container calico-node</span><br><span class="line">  Warning  Unhealthy       30m (x34 over 45m)    kubelet, k8s-master  Readiness probe failed: calico/node is not ready: felix is not ready: readiness probe reporting 503</span><br><span class="line">  Warning  Unhealthy       25m (x76 over 45m)    kubelet, k8s-master  Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused</span><br><span class="line">  Warning  Unhealthy       15m (x116 over 45m)   kubelet, k8s-master  Liveness probe failed: calico/node is not ready: Felix is not live: Get http://localhost:9099/liveness: dial tcp 127.0.0.1:9099: connect: connection refused</span><br><span class="line">  Warning  FailedMount     12m                   kubelet, k8s-master  MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">"calico-node-token-9j8gt"</span> : couldn<span class="string">'t propagate object cache: timed out waiting for the condition</span></span><br><span class="line"><span class="string">  Normal   SandboxChanged  12m                   kubelet, k8s-master  Pod sandbox changed, it will be killed and re-created.</span></span><br><span class="line"><span class="string">  Normal   Pulled          12m                   kubelet, k8s-master  Container image "calico/cni:v3.9.5" already present on machine</span></span><br><span class="line"><span class="string">  Normal   Started         12m                   kubelet, k8s-master  Started container upgrade-ipam</span></span><br><span class="line"><span class="string">  Normal   Created         12m                   kubelet, k8s-master  Created container upgrade-ipam</span></span><br><span class="line"><span class="string">  Normal   Started         12m (x2 over 12m)     kubelet, k8s-master  Started container install-cni</span></span><br><span class="line"><span class="string">  Normal   Pulled          12m (x2 over 12m)     kubelet, k8s-master  Container image "calico/cni:v3.9.5" already present on machine</span></span><br><span class="line"><span class="string">  Normal   Created         12m (x2 over 12m)     kubelet, k8s-master  Created container install-cni</span></span><br><span class="line"><span class="string">  Normal   Started         12m                   kubelet, k8s-master  Started container flexvol-driver</span></span><br><span class="line"><span class="string">  Normal   Pulled          12m                   kubelet, k8s-master  Container image "calico/pod2daemon-flexvol:v3.9.5" already present on machine</span></span><br><span class="line"><span class="string">  Normal   Created         12m                   kubelet, k8s-master  Created container flexvol-driver</span></span><br><span class="line"><span class="string">  Normal   Pulled          12m                   kubelet, k8s-master  Container image "calico/node:v3.9.5" already present on machine</span></span><br><span class="line"><span class="string">  Normal   Created         12m                   kubelet, k8s-master  Created container calico-node</span></span><br><span class="line"><span class="string">  Normal   Started         12m                   kubelet, k8s-master  Started container calico-node</span></span><br><span class="line"><span class="string">  Warning  Unhealthy       11m (x2 over 12m)     kubelet, k8s-master  Readiness probe failed: calico/node is not ready: felix is not ready: readiness probe reporting 503</span></span><br><span class="line"><span class="string">  Warning  Unhealthy       7m34s (x19 over 12m)  kubelet, k8s-master  Liveness probe failed: calico/node is not ready: Felix is not live: Get http://localhost:9099/liveness: dial tcp 127.0.0.1:9099: connect: connection refused</span></span><br><span class="line"><span class="string">  Warning  Unhealthy       2m30s (x38 over 12m)  kubelet, k8s-master  Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused</span></span><br></pre></td></tr></table></figure><blockquote><p><em>너무 길어 Event 부분만 작성하였다.</em></p></blockquote><p>좀 더 deep 한 로그를 찾고자 해당 파드 log 를 찾아본 결과 다음과 같다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-10-03 04:34:38.296 [WARNING][16449] int_dataplane.go 781: failed to wipe the XDP state error=failed to load BPF program (/tmp/felix-bpf-824808941): <span class="built_in">stat</span> /sys/fs/bpf/calico/xdp/prefilter_v1_calico_tmp_A: no such file or directory</span><br><span class="line">libbpf: Error <span class="keyword">in</span> bpf_object__probe_name():Operation not permitted(1). Couldn<span class="string">'t load basic '</span>r0 = 0<span class="string">' BPF program.</span></span><br><span class="line"><span class="string">libbpf: failed to load object '</span>/tmp/felix-bpf-824808941<span class="string">'</span></span><br><span class="line"><span class="string">Error: failed to load object file</span></span><br></pre></td></tr></table></figure><p>위 깃헙 이슈 링크를 확인해보면 OS 커널단에서 BPF 관련 오브젝트를 읽어드리지 못한 상태였다. 이슈 내용들을 살펴보니 OS secure boot 한 경우 생길 수 있다하며 <code>mokutil --disable-validation</code> 명령어로 안전 모드로 부팅하지 못하게 설정하고 재부팅 하였다. 재부팅 시 명령어로 설정한 패스워드로 secure-mode boot 을 disabled 로 설정하고 재부팅 하니 calico node 가 문제없이 기동됨을 확인하였다.</p><hr><p>2020.01.22 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_k8s/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubeflow overview</title>
      <link>https://jx2lee.github.io/cloud-introduction_to_kubeflow/</link>
      <guid>https://jx2lee.github.io/cloud-introduction_to_kubeflow/</guid>
      <pubDate>Sun, 12 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Kubeflow 는 &lt;em&gt;Kubernetes 위에서 동작하는 ML toolkit&lt;/em&gt; 이자, ML 파이프 라인을 구축하고 실험하는 data scientist를 위한 플랫폼이다. 머신러닝 시스템 개발, 테스트 및 프로덕션 수준의 서비스를 위해 다양한 환경에 배포하려는 &lt;em&gt;머신러닝 엔지니어&lt;/em&gt; 및 &lt;em&gt;운영 팀&lt;/em&gt;을 위한 것이다. 포스트는 Conceptual overview, ML workflow, Kuberflow Components, interface, example 순서로 작성하였다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;kubeflow 0.7.0 version 기준으로 작성하였다&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Kubeflow 는 <em>Kubernetes 위에서 동작하는 ML toolkit</em> 이자, ML 파이프 라인을 구축하고 실험하는 data scientist를 위한 플랫폼이다. 머신러닝 시스템 개발, 테스트 및 프로덕션 수준의 서비스를 위해 다양한 환경에 배포하려는 <em>머신러닝 엔지니어</em> 및 <em>운영 팀</em>을 위한 것이다. 포스트는 Conceptual overview, ML workflow, Kuberflow Components, interface, example 순서로 작성하였다.</p><blockquote><p><em>kubeflow 0.7.0 version 기준으로 작성하였다</em></p></blockquote><a id="more"></a><h1 id="Conceptual-overview"><a href="#Conceptual-overview" class="headerlink" title="Conceptual overview"></a>Conceptual overview</h1><p>Kubernetes 위 ML 시스템의 구성 요소를 배치한 그림은 다음과 같다.</p><p><img src="https://www.kubeflow.org/docs/images/kubeflow-overview-platform-diagram.svg" alt=""></p><p>Kubeflow는 ML 시스템을 배포, 확장 및 관리하기 위한 플랫폼으로 Kubernetes 기반으로 구성한다. Kubeflow interface 를 통해 ML tools을 지정할 수 있고 클라우드 뿐 아니라 on-premise 에 동일한 worflow를 배포할 수 있어 특정 플랫폼에 종속되지 않는다. 각 구성 요소들이 어떤 역할을 하는지는 뒤 kubeflow Components에서 살펴본다.</p><h1 id="ML-workflow"><a href="#ML-workflow" class="headerlink" title="ML workflow"></a>ML workflow</h1><p>많은 사람들의 선입견 중 하나가 머신러닝 모델 개발이 ML 시스템의 대부분을 차지할 것이라 생각한다. 하지만, 실제 모델을 개발하는 시간 보다 데이터 탐색부터 데이터 분석, 그리고 개발된 모델을 반복적으로 학습하며 튜닝하는 시간이 훨씬 길다. </p><p>즉, ML 시스템 개발은 반복적인 프로세스로, workflow의 각 단계를 평가하고 최고의 퍼포먼스를 낼 수 있게 모델 및 파라미터 변경 사항을 적용해야 한다. 아래는 실험 및 생산<em>(실제 배포)</em> 관점에서의 workflow를 나타낸다.</p><p><img src="https://www.kubeflow.org/docs/images/kubeflow-overview-workflow-diagram-1.svg" alt=""></p><p>각 단계별 내용은 다음과 같다.</p><ul><li>Experimental phase : 실험 단계<ul><li>Identify problem and collect and analyse data : ML 시스템으로 해결하고자 하는 문제를 식별하고 학습 훈련을 위한 데이터를 수집하고 분석한다</li><li>Choose an ML algorithm and code your model : 사용하고자 하는 ML Framework 및 알고리즘을 선별하고 모델 초기 버젼을 코딩한다</li><li>Experiment with data and model training : 앞서 준비된 데이터와 모델 코드를 통해 학습을 진행한다</li><li>Tune the model hyperparameters : 모델 결과에 영향을 주는 hyperparameter를 조정하며 학습을 반복적으로 진행한다 <em>(이후에는 반복적인 parameter 튜닝과 학습을 진행한다)</em></li></ul></li><li>Production phase : 생산 단계<em>(배포 단계)</em><ul><li>Transform data : 학습과 예측에 필요한 데이터를 변환한다. 이때, 모델 정합성을 위해 위 실험 단계에서 진행한 데이터와 같은 형태로 변환해야 함을 주의한다</li><li>Train model : 모델을 학습한다</li><li>Serve the model for online/batch prediction : 온라인 또는 배치 모드를 위한 모델을 제공한다</li><li>Monitor the model’s performance : 모델 성능을 모니터링한다. 이를 통해 모델을 수정하고 재 학습을 진행하여 모델 성능을 높여간다</li></ul></li></ul><h1 id="Kubeflow-components-in-the-ML-workflow"><a href="#Kubeflow-components-in-the-ML-workflow" class="headerlink" title="Kubeflow components in the ML workflow"></a>Kubeflow components in the ML workflow</h1><p>위에 설명한 ML workflow에 Kubeflow 컴포넌트를 대입한 그림이다.</p><p><img src="https://www.kubeflow.org/docs/images/kubeflow-overview-workflow-diagram-2.svg" alt=""></p><p>각 컴포넌트들을 experiment/production 별 나누어 설명한다.</p><p><code>Experiment</code></p><ul><li>Pytorch / scikit-learn / Tensorflow / XGBoost : ML 알고리즘을 제공하는 패키지. 가장 유명한 Tensorflow 부터 손쉽게 ML 모델을 생성할 수 있는 scikit-learn 까지, 현재 진행형으로 다양한 ML 알고리즘 패키지를 지원하고 있다.</li><li>Jupyter notebook / Fairing / pipelines<ul><li>Jupyter notebook : web 기반 파이선 인터프리터로, 인터렉티브한 환경을 제공하며 데이터 분석에 많이 사용하는 tool</li><li><a href="https://www.kubeflow.org/docs/fairing/fairing-overview/" target="_blank" rel="noopener">Fairing</a> : Kubeflow에서 ML 모델을 쉽게 학습하고 배포할 수 있는 Python 패키지</li><li><a href="https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/" target="_blank" rel="noopener">pipelines</a> : Kubeflow의 pipeline은 ML workflow의 모든 구성 요소를 설명하는 개념이다. 헷갈릴 수 있겠지만, ML workflow의 모든 과정을 담은 것으로 인지하고 workflow를 실행하는데 필요한 입력값 &amp; 구성 요소의 모든 입출력에 대한 정의를 포함하고 있다 <em>(공식 Doc에는 pipeline을 Kubeflow 안의 플랫폼이라 표현한다)</em>. pipeline은 다음 기능들을 포함하고 있다.<ul><li>ML workflow을 추적하고 관리하는 UI</li><li>다중 ML workflow scheduling</li><li>ML workflow를 정의하고 실행하기 위한 SDK <em>(python)</em></li><li>SDK를 이용해 ML system과 연결하는 Notebook</li></ul></li></ul></li></ul><p><img src="https://www.kubeflow.org/docs/images/pipelines-architecture.png" alt=""></p><p>[참고 - <a href="https://www.kubeflow.org/docs/images/pipelines-architecture.png" target="_blank" rel="noopener">pipeline architecture</a>]</p><ul><li><a href="">Katib</a> : ML 모델의 Hyper parameter 및 아키텍쳐를 자동으로 튜닝하는 kubeflow의 컴포넌트 <em>(Hyperparameter란, 모델 학습 과정을 제어하는 변수로 learning rate / neural network의 layer 수 / layer 내 node 수 등이 있다)</em></li></ul><p><code>Prodiction</code></p><ul><li>Chainer / MPI MXNet / PyTorch / TFJob<ul><li><a href="https://v0-6.kubeflow.org/docs/components/training/chainer/" target="_blank" rel="noopener">Chainer</a> : CUDA<em>(GPU)</em>, 다양한 딥러닝 아키텍쳐를 지원하는 유연한 딥러닝 프레임워크 </li><li>MPI : ?</li><li>MXNet / Pytorch / TFJob : 오픈소스 딥러닝 소프트웨어 프레임워크로 Deep Neural Network를 학습 및 배포</li></ul></li><li>KFServing / NVDIA TensorRT / PyTorch / TFServing / Seldon : 학습된 모델을 실제 배포할 때 사용하는 컴포넌트로, 크게 KFServing 과 Seldon 을 이용해 프레임워크를 배포. 각 컴포넌트들에 대한 내용은 방대하여 <a href="https://www.kubeflow.org/docs/components/serving/" target="_blank" rel="noopener">공식 Doc</a> 참조</li><li>Metadata / TensorBoard<ul><li><a href="https://www.kubeflow.org/docs/components/misc/metadata/" target="_blank" rel="noopener">Metadata</a> : 모델, 모델 실행, 데이터 셋 등 기타 Artifact에 대한 정보를 의미하는 컴포넌트 <em>(Artifact란, ML workflow 구성 요소의 input / output을 형성하는 file 또는 오브젝트)</em></li><li><a href="https://www.kubeflow.org/docs/pipelines/sdk/output-viewer/#tensorboard" target="_blank" rel="noopener">TensorBoard</a> : Tensorflow가 포함하는 graph visualization tool</li></ul></li></ul><p>#Kubeflow interface</p><p>Kubeflow는 사용자 인터페이스와 커맨드라인 인터페이스를 모두 제공한다.</p><ul><li><p>User interface</p><p><img src="https://www.kubeflow.org/docs/images/central-ui.png" alt=""></p><p>배포된 컴포넌트에 액세스하는데 사용할 수 있는 대시 보드를 제공한다. <a href="https://www.kubeflow.org/docs/other-guides/accessing-uis/" target="_blank" rel="noopener"><em>(참고)</em></a></p></li><li><p>Command line interface</p><p><code>Kfctl</code> 은 Kubeflow를 설치 및 구성하는데 사용할 수 있는 Kubeflow CLI. <a href="https://www.kubeflow.org/docs/other-guides/kustomize/" target="_blank" rel="noopener"><em>(참고)</em></a></p></li></ul><p>공식 도큐먼트를 참고해 전체적인 개념을 살펴보았다. 다음 포스트에는 Kubernetes 클러스터에 Kubeflow를 설치하는 과정을 다룬다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p><a href="https://www.kubeflow.org/docs/about/kubeflow/" target="_blank" rel="noopener">Kubeflow org, https://www.kubeflow.org/docs/about/kubeflow/</a></p></li><li><p><a href="https://bcho.tistory.com/1301" target="_blank" rel="noopener">쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개, https://bcho.tistory.com/1301</a></p></li></ul><hr><p>2020.01.13 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-introduction_to_kubeflow/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Database] Install ElasticSearch using Docker</title>
      <link>https://jx2lee.github.io/cloud-install_elasticsearch/</link>
      <guid>https://jx2lee.github.io/cloud-install_elasticsearch/</guid>
      <pubDate>Tue, 07 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;데이터 마트를 구축하고 이를 시각화하는 파이프라인 구축 pilot을 수행하기 위해 ElasticSearch를 설치하고자 한다. 단일 서버에 싱글 노드로 구축하고 binary 설치를 하려고 했지만 요즘 추세에 맞게(?) Container 기반으로 구축하고자 Docker를 이용한다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Docker 가 이미 설치되어 있는 상태에서 진행한다&lt;/em&gt;  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Updata Note&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2020.05.10 : Elasticsearch 용어 정리&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>데이터 마트를 구축하고 이를 시각화하는 파이프라인 구축 pilot을 수행하기 위해 ElasticSearch를 설치하고자 한다. 단일 서버에 싱글 노드로 구축하고 binary 설치를 하려고 했지만 요즘 추세에 맞게(?) Container 기반으로 구축하고자 Docker를 이용한다.</p><blockquote><p><em>Docker 가 이미 설치되어 있는 상태에서 진행한다</em>  </p></blockquote><p><strong>Updata Note</strong>  </p><ul><li>2020.05.10 : Elasticsearch 용어 정리</li></ul><a id="more"></a><h1 id="Elasticsearch-용어"><a href="#Elasticsearch-용어" class="headerlink" title="Elasticsearch 용어"></a>Elasticsearch 용어</h1><h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h2><p>elasticsearch 내 데이ㅓ 저장소로 RDBMS 의 데이터베이스와 유사  </p><ul><li>하나 또는 여러 개 Document</li><li>포괄적인 의미의 색인 또는 색인 파일 <em>(범용적인 의미로 사용)</em><ul><li><code>indice</code>: elasticsearch 내 물리적으로 사용하는 색인 또는 색인 파일</li></ul></li></ul><h2 id="Shard"><a href="#Shard" class="headerlink" title="Shard"></a>Shard</h2><p>Lucene 을 기준으로 검색의 기본 데이터베이스가 되는 인덱스  </p><ul><li>분산 처리를 위한 개념</li><li>큰 크기의 인덱스 -&gt; 여러 개 작은 인덱스로 나누어 저장하는 것을 의미</li><li>단일 노드에서는 저장소 서능에 대한 한계를 해결, 클러스터에서는 분산 처리를 수행하며 빠른 결과 생성</li></ul><p><strong>Primary Shard</strong>:<br>색인 시 가장 먼저 생성되는 인덱스로 복제의 기본 소스<br><strong>Replica Shard</strong>:<br>레플리카 설정값에 따라 Primary Shard 을 복제하여 생성한 샤드를 일컫음</p><h2 id="Replica"><a href="#Replica" class="headerlink" title="Replica"></a>Replica</h2><p>단어 뜻대로 복제본으로, 장애 발생 시 지속성 보장과 검색 효율성을 위해 사용  </p><ul><li>분산된 다른 노드에 Shard 와 같은 데이터를 복제 <em>(복제된 Shard 를 Replica 라 생각하자)</em></li><li>생성 절차<ul><li>Primary Shard 색인</li><li>각 노드에서 async 하게 Shard 복제<ul><li>검색 성능 저하 최소화</li></ul></li></ul></li></ul><h2 id="Document"><a href="#Document" class="headerlink" title="Document"></a>Document</h2><p>elasticsearch 에서 가장 기본이 되는 데이터 단위  </p><ul><li>하나의 item 또는 article</li><li>RDBMS 의 테이블 내 하나의 row 에 해당<ul><li><code>Type</code> 은 RDBMS 테이블</li><li><code>Field</code> 는 RDBMS 테이블의 하나의 column</li></ul></li></ul><h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2><p>elasticsearch 를 구성하는 하나의 서버 또는 데몬  </p><ul><li>독립적으로 동작 가능한 서버</li></ul><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p>standalone 하게 동작하는 여러 노드를 하나의 그룹으로 묶어 데이터의 분산과 공유를 할 수 있도록 서비스를 구성한 것</p><h1 id="pull-Docker-Image-for-ElasticSearch"><a href="#pull-Docker-Image-for-ElasticSearch" class="headerlink" title="pull Docker-Image for ElasticSearch"></a>pull Docker-Image for ElasticSearch</h1><p>ElasticSearch docker image를 서버로 가져오는 작업을 수행한다. 현재 포스팅 기준 최신 버젼은 7.5.1 이다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.elastic.co/elasticsearch/elasticsearch:7.5.1</span><br><span class="line"></span><br><span class="line">Trying to pull repository docker.elastic.co/elasticsearch/elasticsearch ... </span><br><span class="line">7.5.1: Pulling from docker.elastic.co/elasticsearch/elasticsearch</span><br><span class="line">c808caf183b6: Pull complete </span><br><span class="line">05ff3f896999: Pull complete </span><br><span class="line">82fb7fb0a94e: Pull complete </span><br><span class="line">c4d0024708f4: Pull complete </span><br><span class="line">136650a16cfe: Pull complete </span><br><span class="line">968db096c092: Pull complete </span><br><span class="line">42547e91692f: Pull complete </span><br><span class="line">Digest: sha256:b0960105e830085acbb1f9c8001f58626506ce118f33816ea5d38c772bfc7e6c</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> docker.elastic.co/elasticsearch/elasticsearch:7.5.1</span><br></pre></td></tr></table></figure><h1 id="Run-single-node-cluster"><a href="#Run-single-node-cluster" class="headerlink" title="Run single-node cluster"></a>Run single-node cluster</h1><p><code>docker run -i -t -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.5.1</code></p><blockquote><p><em>docker container 실행 시 외부 접근을 허용하기 위해서 <strong>-p</strong> 인자를 추가하여 port forwarding 하게끔 설정한다. 또한, 인터렉티브한 컨테이너를 생성하기 위해 -i -p 인자를 추가하였다.</em></p></blockquote><h1 id="Check"><a href="#Check" class="headerlink" title="Check"></a>Check</h1><p>curl 을 이용해 elasticsearch 가 실행되고 있는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET [설치한 서버 ip]:9200</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span> : <span class="string">"294fb8043230"</span>,</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"docker-cluster"</span>,</span><br><span class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"UOT6i7eIRjuan8ot89zNHw"</span>,</span><br><span class="line">  <span class="string">"version"</span> : &#123;</span><br><span class="line">    <span class="string">"number"</span> : <span class="string">"7.5.1"</span>,</span><br><span class="line">    <span class="string">"build_flavor"</span> : <span class="string">"default"</span>,</span><br><span class="line">    <span class="string">"build_type"</span> : <span class="string">"docker"</span>,</span><br><span class="line">    <span class="string">"build_hash"</span> : <span class="string">"3ae9ac9a93c95bd0cdc054951cf95d88e1e18d96"</span>,</span><br><span class="line">    <span class="string">"build_date"</span> : <span class="string">"2019-12-16T22:57:37.835892Z"</span>,</span><br><span class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"lucene_version"</span> : <span class="string">"8.3.0"</span>,</span><br><span class="line">    <span class="string">"minimum_wire_compatibility_version"</span> : <span class="string">"6.8.0"</span>,</span><br><span class="line">    <span class="string">"minimum_index_compatibility_version"</span> : <span class="string">"6.0.0-beta1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></span><br></pre></td></tr></table></figure><p>설치를 완료하였다.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://velog.io/@pa324/elasticsearch-설치-도커-2bk2h3gh7d" target="_blank" rel="noopener">elasticsearch 설치 (도커), https://velog.io/@pa324/elasticsearch-설치-도커-2bk2h3gh7d</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html" target="_blank" rel="noopener">elasticsearch document, https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html</a></li></ul><hr><p>2020.01.08 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_elasticsearch/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[BI] Superset 설치</title>
      <link>https://jx2lee.github.io/bi-install_superset/</link>
      <guid>https://jx2lee.github.io/bi-install_superset/</guid>
      <pubDate>Mon, 06 Jan 2020 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Superset은 Web 기반 BI 툴로써 Python으로 개발되었고 수집-저장-처리를 거친 데이터를 마트에서 추출하여 그래프로 시각화하는데 사용한다.&lt;/p&gt;
&lt;p&gt;제공 기능으로는 EDA, Dashboard 생성 및 공유, 보안, 권한과 다양한 소스 연결을 지원한다. 이번 포스트에는 Superset을 설치해본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Superset은 Web 기반 BI 툴로써 Python으로 개발되었고 수집-저장-처리를 거친 데이터를 마트에서 추출하여 그래프로 시각화하는데 사용한다.</p><p>제공 기능으로는 EDA, Dashboard 생성 및 공유, 보안, 권한과 다양한 소스 연결을 지원한다. 이번 포스트에는 Superset을 설치해본다.</p><a id="more"></a><h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><h2 id="VirtualenvWrapper"><a href="#VirtualenvWrapper" class="headerlink" title="VirtualenvWrapper"></a>VirtualenvWrapper</h2><p>python 가상환경을 관리하는 <code>VirtualenvWrapper</code>을 설치하고 <code>superset</code> 환경을 셋팅한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkvirtualenv superset</span><br><span class="line">$ workon superset</span><br></pre></td></tr></table></figure><h2 id="Install-Superset-and-Initialization"><a href="#Install-Superset-and-Initialization" class="headerlink" title="Install Superset and Initialization"></a>Install Superset and Initialization</h2><p>virtualenv 환경에서 pip 명령어를 이용해 설치한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install apache-superset</span><br></pre></td></tr></table></figure><p>superset의 database를 초기화 하고 admin user를 생성한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ superset db upgrade</span><br><span class="line">$ flask fab create-admin</span><br><span class="line">Username [admin]: flask fab create-admin</span><br><span class="line">User first name [admin]: admin</span><br><span class="line">User last name [user]:</span><br><span class="line">Email [admin@fab.org]:</span><br><span class="line">Password:</span><br><span class="line">Repeat <span class="keyword">for</span> confirmation:</span><br><span class="line">2020-01-07 10:51:24,272:INFO:root:Configured event logger of <span class="built_in">type</span> &lt;class <span class="string">'superset.utils.log.DBEventLogger'</span>&gt;</span><br><span class="line">Recognized Database Authentications.</span><br><span class="line">Admin User flask fab create-admin created.</span><br></pre></td></tr></table></figure><p>이후 테스트 할 데이터를 import한다. 이후 권한/허가등을 초기화하고 마지막으로 UI 화면을 띄운다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ superset load_examples</span><br><span class="line">$ superset init</span><br><span class="line">$ superset run -p 8088 --with-threads --reload --debugger</span><br></pre></td></tr></table></figure><h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><p>설치 중 발생한 에러를 살펴본다.</p><h2 id="install-error-python-geohash"><a href="#install-error-python-geohash" class="headerlink" title="install error : python-geohash"></a>install error : python-geohash</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Command errored out with <span class="built_in">exit</span> status 1:</span><br><span class="line">     <span class="built_in">command</span>: /home/supset/.virtualenvs/superset/bin/python3 -u -c <span class="string">'import sys, setuptools, tokenize; sys.argv[0] = '</span><span class="string">"'"</span><span class="string">'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'</span><span class="string">"'"</span><span class="string">'; __file__='</span><span class="string">"'"</span><span class="string">'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'</span><span class="string">"'"</span><span class="string">';f=getattr(tokenize, '</span><span class="string">"'"</span><span class="string">'open'</span><span class="string">"'"</span><span class="string">', open)(__file__);code=f.read().replace('</span><span class="string">"'"</span><span class="string">'\r\n'</span><span class="string">"'"</span><span class="string">', '</span><span class="string">"'"</span><span class="string">'\n'</span><span class="string">"'"</span><span class="string">');f.close();exec(compile(code, __file__, '</span><span class="string">"'"</span><span class="string">'exec'</span><span class="string">"'"</span><span class="string">'))'</span> install --record /tmp/pip-record-oy48mkll/install-record.txt --single-version-externally-managed --compile --install-headers /home/supset/.virtualenvs/superset/include/site/python3.6/python-geohash</span><br><span class="line">         cwd: /tmp/pip-install-onzf3pi1/python-geohash/</span><br><span class="line">    Complete output (19 lines):</span><br><span class="line">    running install</span><br><span class="line">    running build</span><br><span class="line">    running build_py</span><br><span class="line">    creating build</span><br><span class="line">    creating build/lib.linux-x86_64-3.6</span><br><span class="line">    copying geohash.py -&gt; build/lib.linux-x86_64-3.6</span><br><span class="line">    copying quadtree.py -&gt; build/lib.linux-x86_64-3.6</span><br><span class="line">    copying jpgrid.py -&gt; build/lib.linux-x86_64-3.6</span><br><span class="line">    copying jpiarea.py -&gt; build/lib.linux-x86_64-3.6</span><br><span class="line">    running build_ext</span><br><span class="line">    building <span class="string">'_geohash'</span> extension</span><br><span class="line">    creating build/temp.linux-x86_64-3.6</span><br><span class="line">    creating build/temp.linux-x86_64-3.6/src</span><br><span class="line">    gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DPYTHON_MODULE=1 -I/usr/include/python3.6m -c src/geohash.cpp -o build/temp.linux-x86_64-3.6/src/geohash.o</span><br><span class="line">    src/geohash.cpp:538:20: fatal error: Python.h: No such file or directory</span><br><span class="line">     <span class="comment">#include &lt;Python.h&gt;</span></span><br><span class="line">                        ^</span><br><span class="line">    compilation terminated.</span><br><span class="line">    error: <span class="built_in">command</span> <span class="string">'gcc'</span> failed with <span class="built_in">exit</span> status 1</span><br><span class="line">    ----------------------------------------</span><br><span class="line">ERROR: Command errored out with <span class="built_in">exit</span> status 1: /home/supset/.virtualenvs/superset/bin/python3 -u -c <span class="string">'import sys, setuptools, tokenize; sys.argv[0] = '</span><span class="string">"'"</span><span class="string">'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'</span><span class="string">"'"</span><span class="string">'; __file__='</span><span class="string">"'"</span><span class="string">'/tmp/pip-install-onzf3pi1/python-geohash/setup.py'</span><span class="string">"'"</span><span class="string">';f=getattr(tokenize, '</span><span class="string">"'"</span><span class="string">'open'</span><span class="string">"'"</span><span class="string">', open)(__file__);code=f.read().replace('</span><span class="string">"'"</span><span class="string">'\r\n'</span><span class="string">"'"</span><span class="string">', '</span><span class="string">"'"</span><span class="string">'\n'</span><span class="string">"'"</span><span class="string">');f.close();exec(compile(code, __file__, '</span><span class="string">"'"</span><span class="string">'exec'</span><span class="string">"'"</span><span class="string">'))'</span> install --record /tmp/pip-record-oy48mkll/install-record.txt --single-version-externally-managed --compile --install-headers /home/supset/.virtualenvs/superset/include/site/python3.6/python-geohash Check the logs <span class="keyword">for</span> full <span class="built_in">command</span> output.</span><br></pre></td></tr></table></figure><p>python-geohash package 설치 시 에러가 발생하였다. 이는 설치 시 필요한 시스템 패키지가 미설치되어 발생한 에러로, <code>sudo yum install gcc gcc-c++ python3-devel cyrus-sasl-devel</code> 을 통해 해결할 수 있다. 프로그램 설치 시 환경 설정이 꼭 필요하니 <a href="https://superset.incubator.apache.org/index.html#" target="_blank" rel="noopener">공식 documents</a>를 참고하자.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://superset.incubator.apache.org/installation.html" target="_blank" rel="noopener">Superset Document, https://superset.incubator.apache.org/installation.html</a></li></ul><hr><p>2020.01.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/bi-install_superset/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 큰 수 만들기</title>
      <link>https://jx2lee.github.io/programmers-large_number/</link>
      <guid>https://jx2lee.github.io/programmers-large_number/</guid>
      <pubDate>Mon, 16 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;주어진 숫자에서 특정 갯수의 숫자만으로 가장 큰 수를 만드는 문제를 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>주어진 숫자에서 특정 갯수의 숫자만으로 가장 큰 수를 만드는 문제를 풀어본다</p><a id="more"></a><h1 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h1><p>어떤 숫자에서 k개의 수를 제거했을 때 얻을 수 있는 가장 큰 숫자를 구하려 합니다. 예를 들어, 숫자 1924에서 수 두 개를 제거하면 [19, 12, 14, 92, 94, 24] 를 만들 수 있습니다. 이 중 가장 큰 숫자는 94 입니다.</p><p>문자열 형식으로 숫자 number와 제거할 수의 개수 k가 solution 함수의 매개변수로 주어집니다. number에서 k 개의 수를 제거했을 때 만들 수 있는 수 중 가장 큰 숫자를 문자열 형태로 return 하도록 solution 함수를 완성하세요.</p><h2 id="제한-조건"><a href="#제한-조건" class="headerlink" title="제한 조건"></a>제한 조건</h2><p>number는 1자리 이상, 1,000,000자리 이하인 숫자입니다. k는 1 이상 number의 자릿수 미만인 자연수입니다.</p><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><table><thead><tr><th>number</th><th>k</th><th>return</th></tr></thead><tbody><tr><td>1924</td><td>2</td><td>94</td></tr><tr><td>1231234</td><td>3</td><td>3234</td></tr><tr><td>4177252841</td><td>4</td><td>775841</td></tr></tbody></table><h1 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h1><p>탐욕법으로 풀 수 있는 문제로, 우선 collected 라는 결과물 저장 List를 선언한다. number의 숫자를 for문으로 돌면서 <u>collected 길이 &gt; 0</u> / <u>collected의 마지막 숫자 비교</u> / <u>k &gt; 0</u> 조건을 만족하면, 원소 하나를 빼주고 k를 차감한다.</p><p>이후 k가 0이면 빈 리스트를 반환하는 걸 방지하고자 index i이상 만큼의 number를 담는다. for문의 마지막으로 조건에 안걸리는 num은 collected에 담는다. 이후 k가 음수일 경우를 대비해 -k 까지 slice를 수행하고 결과물이 담긴 collected List를 join하여 숫자로 변환한다.</p><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(number, k)</span>:</span></span><br><span class="line">    collected = []</span><br><span class="line">    <span class="keyword">for</span> i, num <span class="keyword">in</span> enumerate(number):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> len(collected) &gt; <span class="number">0</span> <span class="keyword">and</span> collected[<span class="number">-1</span>] &lt; num <span class="keyword">and</span> k &gt; <span class="number">0</span>:</span><br><span class="line">            collected.pop()</span><br><span class="line">            k -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            collected += list(number[i:])</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        collected.append(num)</span><br><span class="line"></span><br><span class="line">    collected = collected[:-k] <span class="keyword">if</span> k &gt; <span class="number">0</span> <span class="keyword">else</span> collected</span><br><span class="line">    answer = <span class="string">''</span>.join(collected)</span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><hr><p>2019.12.17 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-large_number/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] 이동평균 - Moving Average</title>
      <link>https://jx2lee.github.io/sql-moving_average/</link>
      <guid>https://jx2lee.github.io/sql-moving_average/</guid>
      <pubDate>Sun, 15 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;모 기업 코딩테스트에 나온 이동 평균, Moving Average 를 SQL로 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>모 기업 코딩테스트에 나온 이동 평균, Moving Average 를 SQL로 풀어본다</p><a id="more"></a><p>코딩테스트를 Hackerrank 플랫폼을 이용했던터라 문제 복원을 할 수 없었다. 이에 <a href="https://www.sqlteam.com/articles/calculating-running-totals" target="_blank" rel="noopener">(https://www.sqlteam.com/articles/calculating-running-totals)</a> 에서 제공한 create database script를 활용해 생성한 데이터로 이동 평균을 구해보고자 한다.</p><p>사용한 쿼리와 결과는 아래와 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">delimiter //</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> insert_row()</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">DECLARE</span> DayCount <span class="built_in">smallint</span> <span class="keyword">default</span> <span class="number">5</span>;</span><br><span class="line">    <span class="keyword">DECLARE</span> Sales <span class="built_in">bigint</span> <span class="keyword">default</span> <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    WHILE DayCount &lt;= 5000 DO</span><br><span class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> Sales <span class="keyword">values</span> (DayCount, Sales);</span><br><span class="line">        <span class="keyword">SET</span> DayCount = DayCount + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">SET</span> Sales = Sales + <span class="number">15</span>;</span><br><span class="line">    <span class="keyword">END</span> <span class="keyword">WHILE</span>;</span><br><span class="line"><span class="keyword">END</span>//</span><br><span class="line"></span><br><span class="line">delimiter;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql root@localhost:practice&gt; select count(*) from Sales;                                                                                                                                                      </span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| count(*) |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">| 5000     |</span><br><span class="line">+<span class="comment">----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span></span><br><span class="line"><span class="built_in">Time</span>: <span class="number">0.010</span>s</span><br></pre></td></tr></table></figure><h1 id="이동평균-구하기"><a href="#이동평균-구하기" class="headerlink" title="이동평균 구하기"></a>이동평균 구하기</h1><p><code>스칼라 서브쿼리</code>를 이용해 문제를 해결하였다. average 함수를 이용해 평균 Sales 값을 구하는데, 스칼라 서브쿼리 내 서브쿼리<em>(Count 절)</em>를 작성하여 count가 1과 3사이에 있을때 평균을 구하는 칼럼(MvAvg)을 조회하였다.</p><blockquote><p><em>문제를 풀다보니 SQL 실행순서나 계획 등에 대한 지식이 부족한 것 같다. 책을 한 권 구비하여 공부하는게 좋을 듯 하다.</em></p></blockquote><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    DayCount,</span><br><span class="line">    Sales,</span><br><span class="line">    (<span class="keyword">select</span></span><br><span class="line">        <span class="keyword">avg</span>(Sales) <span class="keyword">as</span> moving_average</span><br><span class="line">     <span class="keyword">from</span> Sales b</span><br><span class="line">     <span class="keyword">where</span> (<span class="keyword">select</span></span><br><span class="line">                <span class="keyword">count</span>(*)</span><br><span class="line">            <span class="keyword">from</span> Sales c</span><br><span class="line">            <span class="keyword">where</span> DayCount <span class="keyword">between</span> b.DayCount <span class="keyword">and</span> a.DayCount</span><br><span class="line">            ) <span class="keyword">between</span> <span class="number">1</span> <span class="keyword">and</span> <span class="number">3</span> </span><br><span class="line">    ) <span class="keyword">as</span> MvAvg </span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    Sales a</span><br><span class="line">;</span><br></pre></td></tr></table></figure><hr><p>2019.12.16 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/sql-moving_average/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Install Spark</title>
      <link>https://jx2lee.github.io/hadoop-install_spark/</link>
      <guid>https://jx2lee.github.io/hadoop-install_spark/</guid>
      <pubDate>Thu, 12 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Spark를 설치하는 과정을 다룬다. binary를 다운받아 풀고 config를 수정하면 쉽게 설치하고 실행할 수 있다. 이 포스트에는 standalone 모드로 spark를 실행한다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Spark를 설치하는 과정을 다룬다. binary를 다운받아 풀고 config를 수정하면 쉽게 설치하고 실행할 수 있다. 이 포스트에는 standalone 모드로 spark를 실행한다</p><a id="more"></a><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="Hadoop-Version"><a href="#Hadoop-Version" class="headerlink" title="Hadoop Version"></a>Hadoop Version</h2><p><code>hadoop version</code> 명령어를 통해 Hadoop의 버젼을 체크한다. 이 말인 즉슨, Hadoop Client가 Spark를 사용할 계정에 준비되어 있어야 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Hadoop 2.9.2</span><br><span class="line">Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704</span><br><span class="line">Compiled by ajisaka on 2018-11-13T12:42Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 3a9939967262218aa556c684d107985</span><br><span class="line">This <span class="built_in">command</span> was run using /app/hadoop/2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar</span><br></pre></td></tr></table></figure><blockquote><p><em>Hadoop Client는 설치가 필요없고 이미 구축된 하둡 클러스터에서 hadoop 바이너리만 가져와 사용하는 것을 말한다. 즉, 다른 서버에서 하둡을 사용할 수 있게끔만 설정해놓자.</em></p></blockquote><h2 id="Download-binary"><a href="#Download-binary" class="headerlink" title="Download binary"></a>Download binary</h2><p><a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">Spark Documents</a>로 접속하여 binary를 다운로드 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 app]<span class="comment"># wget http://mirror.apache-kr.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz</span></span><br><span class="line">--2019-12-10 17:41:49--  http://mirror.apache-kr.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz</span><br><span class="line">Resolving mirror.apache-kr.org (mirror.apache-kr.org)... 1.201.139.179</span><br><span class="line">Connecting to mirror.apache-kr.org (mirror.apache-kr.org)|1.201.139.179|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 230091034 (219M) [application/x-gzip]</span><br><span class="line">Saving to: ‘spark-2.4.4-bin-hadoop2.7.tgz’</span><br></pre></td></tr></table></figure><p>Spark 유저를 생성하고 Spark Home 디렉토리에 다운받은 binary를 풀어준다.</p><h1 id="Set-config"><a href="#Set-config" class="headerlink" title="Set config"></a>Set config</h1><h2 id="bash-profile"><a href="#bash-profile" class="headerlink" title="~/.bash_profile"></a>~/.bash_profile</h2><p>JAVA, HADOOP 환경변수를 설정하고 SPARK 환경변수를 새로 작성하고 update 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#JAVA ENV</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/app/java/jdk1.8.0_181</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#SPARK ENV</span></span><br><span class="line">SPARK_HOME=/app/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP ENV</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/app/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><h1 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h1><p><code>$SPARK_HOME/bin</code> 폴더에 <code>pypark</code>를 실행한다.</p><blockquote><p>*</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[spark@node2 bin]$ ./pyspark </span><br><span class="line">Python 3.6.8 (default, Aug  7 2019, 17:28:10) </span><br><span class="line">[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux</span><br><span class="line">Type <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> or <span class="string">"license"</span> <span class="keyword">for</span> more information.</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">'_/</span></span><br><span class="line"><span class="string">   /__ / .__/\_,_/_/ /_/\_\   version 2.4.4</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Using Python version 3.6.8 (default, Aug  7 2019 17:28:10)</span></span><br><span class="line"><span class="string">SparkSession available as '</span>spark<span class="string">'.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span></span><br></pre></td></tr></table></figure><p>간단한 RDD를 생성하여 README.md 에 포함한 라인을 세보도록 한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; lines &#x3D; sc.textFile(&#39;README.md&#39;)</span><br><span class="line">&gt;&gt;&gt; lines.count()</span><br><span class="line">105</span><br></pre></td></tr></table></figure><blockquote><p><em>sc.textFile로 경로를 무시하게되면 자동으로 hdfs 경로를 읽어들인다. 만약에 로컬 파일을 읽고 싶다면, <code>file://[file path]/[file name]</code>으로 작성하면 로컬 파일을 읽어들인다.</em></p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://spark.apache.org/docs/latest/index.html" target="_blank" rel="noopener">Spark Documents</a></li></ul><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-install_spark/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 다리를 지나는 트럭</title>
      <link>https://jx2lee.github.io/programmers-truck/</link>
      <guid>https://jx2lee.github.io/programmers-truck/</guid>
      <pubDate>Mon, 02 Dec 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;최대 용량을 가진 다리를 트럭이 모두 지나는 시간을 구하는 문제를 풀어본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>최대 용량을 가진 다리를 트럭이 모두 지나는 시간을 구하는 문제를 풀어본다.</p><a id="more"></a><h1 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h1><p>트럭 여러 대가 강을 가로지르는 일 차선 다리를 정해진 순으로 건너려 합니다. 모든 트럭이 다리를 건너려면 최소 몇 초가 걸리는지 알아내야 합니다. 트럭은 1초에 1만큼 움직이며, 다리 길이는 bridge_length이고 다리는 무게 weight까지 견딥니다.<br>※ 트럭이 다리에 완전히 오르지 않은 경우, 이 트럭의 무게는 고려하지 않습니다.</p><p>예를 들어, 길이가 2이고 10kg 무게를 견디는 다리가 있습니다. 무게가 [7, 4, 5, 6]kg인 트럭이 순서대로 최단 시간 안에 다리를 건너려면 다음과 같이 건너야 합니다.</p><table><thead><tr><th>경과 시간</th><th>다리를 지난 트럭</th><th>다리를 건너는 트럭</th><th>대기 트럭</th></tr></thead><tbody><tr><td>0</td><td>[]</td><td>[]</td><td>[7,4,5,6]</td></tr><tr><td>1~2</td><td>[]</td><td>[7]</td><td>[4,5,6]</td></tr><tr><td>3</td><td>[7]</td><td>[4]</td><td>[5,6]</td></tr><tr><td>4</td><td>[7]</td><td>[4,5]</td><td>[6]</td></tr><tr><td>5</td><td>[7,4]</td><td>[5]</td><td>[6]</td></tr><tr><td>6~7</td><td>[7,4,5]</td><td>[6]</td><td>[]</td></tr><tr><td>8</td><td>[7,4,5,6]</td><td>[]</td><td>[]</td></tr></tbody></table><p>따라서, 모든 트럭이 다리를 지나려면 최소 8초가 걸립니다.</p><p>solution 함수의 매개변수로 다리 길이 bridge_length, 다리가 견딜 수 있는 무게 weight, 트럭별 무게 truck_weights가 주어집니다. 이때 모든 트럭이 다리를 건너려면 최소 몇 초가 걸리는지 return 하도록 solution 함수를 완성하세요.</p><h2 id="제한-조건"><a href="#제한-조건" class="headerlink" title="제한 조건"></a>제한 조건</h2><ul><li>bridge_length는 1 이상 10,000 이하입니다.</li><li>weight는 1 이상 10,000 이하입니다.</li><li>truck_weights의 길이는 1 이상 10,000 이하입니다.</li><li>모든 트럭의 무게는 1 이상 weight 이하입니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><table><thead><tr><th>bridge_length</th><th>weight</th><th>truck_weights</th><th>return</th></tr></thead><tbody><tr><td>2</td><td>10</td><td>[7,4,5,6]</td><td>8</td></tr><tr><td>100</td><td>100</td><td>[10]</td><td>101</td></tr><tr><td>100</td><td>100</td><td>[10,10,10,10,10,10,10,10,10,10]</td><td>110</td></tr></tbody></table><h1 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h1><p>배열을 list로 풀면 하나의 케이스가 시간초과가 발생한다. pop와 append 시 index를 재배열하므로 이를 방지하기 위해, <code>collections</code> 패키지의 <code>deque</code> 배열을 사용하여 해결하였다.</p><p><code>queue</code> 변수는 다리를 지나가고 있는 트럭들을 나타낸다. truck_weights 의 모든 트럭들을 하나씩 뽑아 while 문을 실행한다.</p><p>queue 배열 길이가 bridge_length와 같다면 queue에서 pop을 실행하고, 만약 선택된 트럭의 무게를 더해도 버틸 수 있다면 <em>(sum(queue) + truck &lt;= weight)</em> queue에 트럭을 추가하고 while문을 빠져나온다. 만약 그렇지 않다면 queue에 0을 왼쪽에 추가하고 시간을 +1 한다.</p><p>위를 반복하고 마지막에 들어간 트럭의 소요시간을 구하기 위해 bridge_length를 더하고 문제를 마무리한다.</p><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(bridge_length, weight, truck_weights)</span>:</span></span><br><span class="line"></span><br><span class="line">    answer = <span class="number">0</span></span><br><span class="line">    queue = deque([])</span><br><span class="line">    truck_weights = deque(truck_weights)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> truck <span class="keyword">in</span> truck_weights:</span><br><span class="line">        <span class="keyword">while</span> truck:</span><br><span class="line">            <span class="keyword">if</span> len(queue) == bridge_length:</span><br><span class="line">                queue.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> sum(queue) + truck &lt;= weight:</span><br><span class="line">                queue.appendleft(truck)</span><br><span class="line">                truck = <span class="number">0</span></span><br><span class="line">                answer += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                queue.appendleft(<span class="number">0</span>)</span><br><span class="line">                answer += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">    answer += bridge_length    </span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><blockquote><p><em>Python 의 List 타입의 경우 pop(0)을 수행할 때 인덱스를 재배열하는 것을 깨달았다. 즉, queue를 구현하기 위해서는 List보다 Collections 패키지의 deque를 사용하는 것이 시간초과를 피할 수 있다</em> </p></blockquote><hr><p>2019.12.03 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-truck/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Tibero 계정의 모든 table을 HDFS로 저장</title>
      <link>https://jx2lee.github.io/hadoop-tables_to_hdfs_using_sqoop/</link>
      <guid>https://jx2lee.github.io/hadoop-tables_to_hdfs_using_sqoop/</guid>
      <pubDate>Tue, 26 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;Sqoop&lt;/code&gt;을 이용해 RDB 특정 계정의 모든 Table을 Import 하는 과정을 다룬다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>Sqoop</code>을 이용해 RDB 특정 계정의 모든 Table을 Import 하는 과정을 다룬다</p><a id="more"></a><p>Tibero의 ERP 계정의 모든 Table을 HDFS로 저장하고 동시에 Hive Table로 생성한다. <code>sqoop import-all-tables</code>을 이용하며 특정 스키마가 없는 테이블은 제외하였다. 구문은 다음과 같다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sqoop import-all-tables \</span><br><span class="line">--connect jdbc:tibero:thin:@[ip]:[port]:[DB SID] \</span><br><span class="line">--driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">--username [user] --password [passowrd] \</span><br><span class="line">--warehouse-dir [hdfs dir] \</span><br><span class="line">--hive-import --hive-overwrite --hive-database [metastore db name] \</span><br><span class="line">--exclude-tables SM_GROUP,SM_GROUP_PERMISSION,SM_PERMISSION,SM_PROJECT_GROUP_AUTH,SM_ROLE,SM_USER,SM_USER_GROUP \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure><ul><li><em>–connect</em> : 접속할 DB 정보</li><li><em>–driver</em> : 접속할 DB Driver</li><li><em>–username &amp; –password</em> : 계정 ID/Password</li><li><em>–warehouse-dir</em> : HDFS 위치</li><li><em>–hive-import –hive-overwrite –hive-database</em> : HDFS로 저장함과 동시에 Hive table로 import. hive-database는 MetaStore의 database</li><li><em>–exclude-table</em> : Import 시 제외할 Table</li><li><em>–m</em> : number of mappers</li></ul><blockquote><p><em>제외할 테이블 명을 명시할 떄 콤마 이후에 무조건 붙여줘야 argument를 인식한다</em></p></blockquote><p>생각보다 시간이 오래걸렸다. 결과를 확인해보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ beeline</span><br><span class="line">$ !connect jdbc:hive2://[ip]:[port] user password</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> tims;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">tables</span>;</span><br><span class="line"></span><br><span class="line">+<span class="comment">-----------------------+</span></span><br><span class="line">|       tab_name        |</span><br><span class="line">+<span class="comment">-----------------------+</span></span><br><span class="line">| aactv00t              |</span><br><span class="line">| aactv01t              |</span><br><span class="line">| aactv10t              |</span><br><span class="line">| aactv20t              |</span><br><span class="line">| aactv24t              |</span><br><span class="line">| aactv25t              |</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">| satch00t_03           |</span><br><span class="line">| sbms_common_code      |</span><br><span class="line">| sbms_document_data    |</span><br><span class="line">| sbms_error_log        |</span><br><span class="line">+<span class="comment">-----------------------+</span></span><br><span class="line">595 rows selected (0.183 seconds)</span><br></pre></td></tr></table></figure><hr><p>2019.11.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-tables_to_hdfs_using_sqoop/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 문자열 압축</title>
      <link>https://jx2lee.github.io/programmers-compress_char/</link>
      <guid>https://jx2lee.github.io/programmers-compress_char/</guid>
      <pubDate>Mon, 25 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;주어진 문자열을 가장 짧게 압축하는 문제를 풀어본다 (2020 카카오 1차 코딩테스트)&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>주어진 문자열을 가장 짧게 압축하는 문제를 풀어본다 (2020 카카오 1차 코딩테스트)</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>데이터 처리 전문가가 되고 싶은 “어피치”는 문자열을 압축하는 방법에 대해 공부를 하고 있습니다. 최근에 대량의 데이터 처리를 위한 간단한 비손실 압축 방법에 대해 공부를 하고 있는데, 문자열에서 같은 값이 연속해서 나타나는 것을 그 문자의 개수와 반복되는 값으로 표현하여 더 짧은 문자열로 줄여서 표현하는 알고리즘을 공부하고 있습니다.<br>간단한 예로 “aabbaccc”의 경우 “2a2ba3c”(문자가 반복되지 않아 한번만 나타난 경우 1은 생략함)와 같이 표현할 수 있는데, 이러한 방식은 반복되는 문자가 적은 경우 압축률이 낮다는 단점이 있습니다. 예를 들면, “abcabcdede”와 같은 문자열은 전혀 압축되지 않습니다. “어피치”는 이러한 단점을 해결하기 위해 문자열을 1개 이상의 단위로 잘라서 압축하여 더 짧은 문자열로 표현할 수 있는지 방법을 찾아보려고 합니다.<br><br>예를 들어, “ababcdcdababcdcd”의 경우 문자를 1개 단위로 자르면 전혀 압축되지 않지만, 2개 단위로 잘라서 압축한다면 “2ab2cd2ab2cd”로 표현할 수 있습니다. 다른 방법으로 8개 단위로 잘라서 압축한다면 “2ababcdcd”로 표현할 수 있으며, 이때가 가장 짧게 압축하여 표현할 수 있는 방법입니다.<br>다른 예로, “abcabcdede”와 같은 경우, 문자를 2개 단위로 잘라서 압축하면 “abcabc2de”가 되지만, 3개 단위로 자른다면 “2abcdede”가 되어 3개 단위가 가장 짧은 압축 방법이 됩니다. 이때 3개 단위로 자르고 마지막에 남는 문자열은 그대로 붙여주면 됩니다.<br>압축할 문자열 s가 매개변수로 주어질 때, 위에 설명한 방법으로 1개 이상 단위로 문자열을 잘라 압축하여 표현한 문자열 중 가장 짧은 것의 길이를 return 하도록 solution 함수를 완성해주세요.<br></p><h2 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h2><ul><li>s의 길이는 1 이상 1,000 이하입니다.</li><li>s는 알파벳 소문자로만 이루어져 있습니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">     s                       result</span><br><span class="line">&quot;aabbaccc&quot;                     7</span><br><span class="line">&quot;ababcdcdababcdcd&quot;             9</span><br><span class="line">&quot;abcabcdede&quot;                   8</span><br><span class="line">&quot;abcabcabcabcdededededede&quot;    14</span><br><span class="line">&quot;xababcdcdababcdcd&quot;           17</span><br></pre></td></tr></table></figure><h2 id="입출력-예에-대한-설명"><a href="#입출력-예에-대한-설명" class="headerlink" title="입출력 예에 대한 설명"></a>입출력 예에 대한 설명</h2><ul><li>입출력 예 #1<ul><li>문자열을 1개 단위로 잘라 압축했을 때 가장 짧습니다.</li></ul></li><li>입출력 예 #2<ul><li>문자열을 8개 단위로 잘라 압축했을 때 가장 짧습니다.</li></ul></li><li>입출력 예 #3<ul><li>문자열을 3개 단위로 잘라 압축했을 때 가장 짧습니다.</li></ul></li><li>입출력 예 #4<ul><li>문자열을 2개 단위로 자르면 “abcabcabcabc6de” 가 됩니다.</li><li>문자열을 3개 단위로 자르면 “4abcdededededede” 가 됩니다.</li><li>문자열을 4개 단위로 자르면 “abcabcabcabc3dede” 가 됩니다.</li><li>문자열을 6개 단위로 자를 경우 “2abcabc2dedede”가 되며, 이때의 길이가 14로 가장 짧습니다.</li></ul></li><li>입출력 예 #5<ul><li>문자열은 제일 앞부터 정해진 길이만큼 잘라야 합니다. 따라서 주어진 문자열을 x / ababcdcd / ababcdcd 로 자르는 것은 불가능 합니다. 이 경우 어떻게 문자열을 잘라도 압축되지 않으므로 가장 짧은 길이는 이 됩니다.</li></ul></li></ul><h1 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h1><p>딱히 사용한 알고리즘은 없는 것 같다 <del>(굳이 선택하면 브루트포스?)</del>. 반복하는 문자열 길이에 따라 모든 문자열을 압축하고, 이에 대한 길이를 res 리스트에 담아 최솟값을 출력해낸다.</p><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(s)</span>:</span></span><br><span class="line">    result = <span class="string">''</span></span><br><span class="line">    cnt = <span class="number">1</span></span><br><span class="line">    res = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>, len(s)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(s), n):</span><br><span class="line">            <span class="keyword">if</span> s[i:i+n] == s[i+n:i+<span class="number">2</span>*n]:</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> cnt &gt; <span class="number">1</span>:</span><br><span class="line">                    result += str(cnt) + s[i:i+n]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    result += s[i:i+n]</span><br><span class="line">                cnt = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i == len(s) - n:</span><br><span class="line">                <span class="keyword">if</span> cnt &gt; <span class="number">1</span>:</span><br><span class="line">                    result += str(cnt) + s[i+n:i+<span class="number">2</span>*n]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    result += s[i+n:i+<span class="number">2</span>*n]</span><br><span class="line"></span><br><span class="line">        res.append(len(result))</span><br><span class="line">        result = <span class="string">''</span></span><br><span class="line">        cnt = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> min(res)</span><br></pre></td></tr></table></figure><hr><p>2019.11.26 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-compress_char/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 자물쇠와 열쇠</title>
      <link>https://jx2lee.github.io/programmers-unlock/</link>
      <guid>https://jx2lee.github.io/programmers-unlock/</guid>
      <pubDate>Mon, 25 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;key를 이용해 자물쇠를 여는 문제를 풀어본다 (2020 카카오 1차 코딩테스트)&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>key를 이용해 자물쇠를 여는 문제를 풀어본다 (2020 카카오 1차 코딩테스트)</p><a id="more"></a><h1 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h1><p>고고학자인 튜브는 고대 유적지에서 보물과 유적이 가득할 것으로 추정되는 비밀의 문을 발견하였습니다. 그런데 문을 열려고 살펴보니 특이한 형태의 자물쇠로 잠겨 있었고 문 앞에는 특이한 형태의 열쇠와 함께 자물쇠를 푸는 방법에 대해 다음과 같이 설명해 주는 종이가 발견되었습니다.</p><p>잠겨있는 자물쇠는 격자 한 칸의 크기가 1 x 1인 N x N 크기의 정사각 격자 형태이고 특이한 모양의 열쇠는 M x M 크기인 정사각 격자 형태로 되어 있습니다.</p><p>자물쇠에는 홈이 파여 있고 열쇠 또한 홈과 돌기 부분이 있습니다. 열쇠는 회전과 이동이 가능하며 열쇠의 돌기 부분을 자물쇠의 홈 부분에 딱 맞게 채우면 자물쇠가 열리게 되는 구조입니다. 자물쇠 영역을 벗어난 부분에 있는 열쇠의 홈과 돌기는 자물쇠를 여는 데 영향을 주지 않지만, 자물쇠 영역 내에서는 열쇠의 돌기 부분과 자물쇠의 홈 부분이 정확히 일치해야 하며 열쇠의 돌기와 자물쇠의 돌기가 만나서는 안됩니다. 또한 자물쇠의 모든 홈을 채워 비어있는 곳이 없어야 자물쇠를 열 수 있습니다.</p><p>열쇠를 나타내는 2차원 배열 key와 자물쇠를 나타내는 2차원 배열 lock이 매개변수로 주어질 때, 열쇠로 자물쇠를 열수 있으면 true를, 열 수 없으면 false를 return 하도록 solution 함수를 완성해주세요.</p><h2 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h2><ul><li>key는 M x M(3 ≤ M ≤ 20, M은 자연수)크기 2차원 배열입니다.</li><li>lock은 N x N(3 ≤ N ≤ 20, N은 자연수)크기 2차원 배열입니다.</li><li>M은 항상 N 이하입니다.</li><li>key와 lock의 원소는 0 또는 1로 이루어져 있습니다.</li><li>0은 홈 부분, 1은 돌기 부분을 나타냅니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><p>| key | lock | result |<br>| —– | —— | —————————— | —— |<br>| [[0, 0, 0], [1, 0, 0], [0, 1, 1]]   | [[1, 1, 1], [1, 1, 0], [1, 0, 1]]    | true |</p><h2 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h2><p><img src="https://grepp-programmers.s3.amazonaws.com/files/production/469703690b/79f2f473-5d13-47b9-96e0-a10e17b7d49a.jpg" alt="https://grepp-programmers.s3.amazonaws.com/files/production/469703690b/79f2f473-5d13-47b9-96e0-a10e17b7d49a.jpg"></p><p>key를 시계 방향으로 90도 회전하고, 오른쪽으로 한 칸, 아래로 한 칸 이동하면 lock의 홈 부분을 정확히 모두 채울 수 있습니다.</p><h1 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h1><p>한 줄로 문제를 풀어보면, <strong>lock을 확대하고 key를 하나씩 대입해보면서 모든 부분이 1인 경우</strong>를 찾으면 된다. 크게 세 가지 함수로 구현하였다.</p><p><code>rotate_key</code>는 말그래도 입력한 key 를 시계 방향 90도로 회전하는 함수이다. 입력은 key와 key의 길이</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_key</span><span class="params">(key, M)</span>:</span></span><br><span class="line">    res = [[<span class="number">0</span> * n <span class="keyword">for</span> n <span class="keyword">in</span> range(M)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(M)]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(M):</span><br><span class="line">            res[x][M - y - <span class="number">1</span>] = key[y][x]</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p><code>expand_lock</code>은 lock을 key와 대조하기 위해 확장하는 함수이다. <em>n+2 X (m-1)</em> 만큼 확장한다. N은 lock의 길이, M은 열쇠의 길이</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_lock</span><span class="params">(lock, N, M, K)</span>:</span></span><br><span class="line">    res = [[<span class="number">0</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> range(K)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(K)]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(N):</span><br><span class="line">            res[y + M - <span class="number">1</span>][x + M - <span class="number">1</span>] = lock[y][x]</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p><code>is_open</code>은 확장된 lock과 key를 이용해 각 구멍 value를 더해 1이 아니면 경우는 False, 1인 경우에는 True를 반환하는 함수이다. 이 함수는 확장된 lock을 겹치는 부분부터 끝까지 key를 for문으로 돌려가며 확인한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_open</span><span class="params">(_y, _x, key, lock, N, M)</span>:</span></span><br><span class="line">    _lock = copy.deepcopy(lock)</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(M):</span><br><span class="line">            _lock[_y + y][_x + x] += key[y][x]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(N):</span><br><span class="line">            <span class="keyword">if</span> _lock[y + M - <span class="number">1</span>][x + M - <span class="number">1</span>] != <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>마지막 <code>solution</code>함수는 하나하나 키를 돌려가며 모든 값들이 1인지를 판단하고, 아니면 key를 돌려가며 확인하는 함수이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(key, lock)</span>:</span></span><br><span class="line"></span><br><span class="line">    n, m = len(lock), len(key)</span><br><span class="line">    k = n + <span class="number">2</span> * (m - <span class="number">1</span>)</span><br><span class="line">    lock = expand_lock(lock, n, m, k)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(k - m +<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(k - m +<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">                <span class="keyword">if</span> is_open(y, x, key, lock, n, m):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                key = rotate_key(key, m)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_key</span><span class="params">(key, M)</span>:</span></span><br><span class="line">    res = [[<span class="number">0</span> * n <span class="keyword">for</span> n <span class="keyword">in</span> range(M)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(M)]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(M):</span><br><span class="line">            res[x][M - y - <span class="number">1</span>] = key[y][x]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_lock</span><span class="params">(lock, N, M, K)</span>:</span></span><br><span class="line">    res = [[<span class="number">0</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> range(K)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(K)]</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(N):</span><br><span class="line">            res[y + M - <span class="number">1</span>][x + M - <span class="number">1</span>] = lock[y][x]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_open</span><span class="params">(_y, _x, key, lock, N, M)</span>:</span></span><br><span class="line">    _lock = copy.deepcopy(lock)</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(M):</span><br><span class="line">            _lock[_y + y][_x + x] += key[y][x]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(N):</span><br><span class="line">            <span class="keyword">if</span> _lock[y + M - <span class="number">1</span>][x + M - <span class="number">1</span>] != <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(key, lock)</span>:</span></span><br><span class="line">    answer = <span class="literal">True</span></span><br><span class="line">    n, m = len(lock), len(key)</span><br><span class="line">    k = n + <span class="number">2</span> * (m - <span class="number">1</span>)</span><br><span class="line">    lock = expand_lock(lock, n, m, k)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(k - m +<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(k - m +<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">                <span class="keyword">if</span> is_open(y, x, key, lock, n, m):</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                key = rotate_key(key, m)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><hr><p>2019.11.26 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-unlock/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Database] MySQL 유저 관리</title>
      <link>https://jx2lee.github.io/database-manage_user_in_mysql/</link>
      <guid>https://jx2lee.github.io/database-manage_user_in_mysql/</guid>
      <pubDate>Sun, 24 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;MySQL의 유저를 관리해본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>MySQL의 유저를 관리해본다</p><a id="more"></a><h1 id="User-table"><a href="#User-table" class="headerlink" title="User table"></a>User table</h1><p>MySQL에서 관리하는 유저를 조회해보자. 우선, 기본적으로 mysql database에 user 테이블에서 관리한다. mysql database를 선택하고 user table의 host, user를 조회해보자.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show databases;</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| Database           |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| hive               |</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">use</span> mysql;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; select host, user from user;</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| host      | user             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| %         | hive             |</span><br><span class="line">| localhost | mysql.infoschema |</span><br><span class="line">| localhost | mysql.session    |</span><br><span class="line">| localhost | mysql.sys        |</span><br><span class="line">| localhost | root             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><h1 id="Create-User-amp-Database"><a href="#Create-User-amp-Database" class="headerlink" title="Create User &amp; Database"></a>Create User &amp; Database</h1><h2 id="User"><a href="#User" class="headerlink" title="User"></a>User</h2><p>Sqoop를 이용해 hdfs 데이터를 MySQL table을 저장하기 위한 계정을 생성한다. <del>(Sqoop export를 위해서는 해당 RDB에 테이블이 존재해야한다. 굳이 이관하는 것 까진 필요없을 것 같아, 이번 포스팅에는 유저를 생성하고 관리하는 방법만 다룬다)</del></p><p><code>create user [user name]@[ip] identified by [password];</code></p><ul><li>user name : 생성할 계정명</li><li>ip : 접속가능 ip로 로컬 계정에서만 접속을 허용할 것이면 localhost, 본인과 같이 모든 외부 IP에서 접근이 가능하게 하려면 <strong>%</strong></li><li>password : 생성할 계정의 비밀번호</li></ul><blockquote><p><em>ip의 경우, grant 명령어로 수정이 가능함</em></p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create user 'tims'@'%' identified by '****';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select host, user from user;</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| host      | user             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| %         | hive             |</span><br><span class="line">| %         | tims             |</span><br><span class="line">| localhost | mysql.infoschema |</span><br><span class="line">| localhost | mysql.session    |</span><br><span class="line">| localhost | mysql.sys        |</span><br><span class="line">| localhost | root             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">6 rows in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure><h2 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h2><p>생성한 tims계정에서 사용할 database를 생성한다.</p><p><code>create database [database name]</code></p><ul><li>database name : 생성할 database 이름</li></ul><p><code>grank all privileges on [database name].[schema] to [user name]@[ip]</code></p><ul><li>database naem : 생성한 database 이름</li><li>schema : 생성한 database 내 스키마</li><li>user name : 권한을 줄 계정명</li><li>ip : 접속 ip</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database tims;</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; grant all privileges on tims.* to 'tims'@'%';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><p>테스트해보자. <code>show tables</code> 를 치게되면 아무 테이블이 표시되지 않을 것이다. <em>(당연)</em></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[mysql@node2 ~]$ mysql -u tims -p</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands <span class="keyword">end</span> <span class="keyword">with</span> ; or \g.</span><br><span class="line">Your MySQL connection id is 6820</span><br><span class="line">Server version: 8.0.18 Source distribution</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type '<span class="keyword">help</span>;' or '\h' for help. <span class="keyword">Type</span> <span class="string">'\c'</span> <span class="keyword">to</span> <span class="keyword">clear</span> the <span class="keyword">current</span> <span class="keyword">input</span> statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">show</span> <span class="keyword">databases</span>;</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| Database           |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| information_schema |</span><br><span class="line">| tims               |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">use</span> tims;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">Empty <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><blockquote><p><em>ERROR 1045 (28000): Access denied for user ‘hive’@’localhost’ (using password: NO) 에러가 발생하는 경우가 있다. 이때는 해당 계정으로 Login 할 때 -p opiton을 붙여준다</em></p></blockquote><hr><p>2019.11.25 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/database-manage_user_in_mysql/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Install Zeppelin and Connect to RDBMS &amp; Hive</title>
      <link>https://jx2lee.github.io/hadoop-install_zeppelin/</link>
      <guid>https://jx2lee.github.io/hadoop-install_zeppelin/</guid>
      <pubDate>Sun, 17 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;Apache Zeppelin&lt;/code&gt;을 설치하고 &lt;code&gt;Tibero&lt;/code&gt;와 &lt;code&gt;Hive&lt;/code&gt;에 연동하는 과정을 살펴본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>Apache Zeppelin</code>을 설치하고 <code>Tibero</code>와 <code>Hive</code>에 연동하는 과정을 살펴본다</p><a id="more"></a><h1 id="Install-Apache-Zeppelin"><a href="#Install-Apache-Zeppelin" class="headerlink" title="Install Apache Zeppelin"></a>Install Apache Zeppelin</h1><p><code>Zeppelin</code> user를 생성하고 설치파일을 다운로드한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ adduser zepp --gid 1000 <span class="comment"># bigdata</span></span><br><span class="line">$ wget http://apache.mirror.cdnetworks.com/zeppelin/zeppelin-0.8.2/zeppelin-0.8.2-bin-all.tgz</span><br><span class="line">$ <span class="built_in">cd</span> /app &amp;&amp; tar -xvzf zeppelin-0.8.2-bin-all.tgz</span><br></pre></td></tr></table></figure><p><code>$ZEPPELIN_HOME/conf/zeppelin-site.xml</code> 파일을 수정한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.server.addr&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;192.xxx.xxx.xx&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Server binding address, Server IP&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.server.port&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;8001&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Server port.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.server.ssl.port&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;8443&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Server ssl port. (used when ssl property is <span class="built_in">set</span> to <span class="literal">true</span>)&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.server.context.path&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/&lt;/value&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.server.context.path&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Context Path of the Web Application&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.war.tempdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;webapps&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Location of jetty temporary directory&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.notebook.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;notebook&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;path or URI <span class="keyword">for</span> notebook persist&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.notebook.homescreen&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;id of notebook to be displayed <span class="keyword">in</span> homescreen. ex) 2A94M5J1Z Empty value displays default home screen&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;zeppelin.notebook.homescreen.hide&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;hide homescreen notebook from list when this value <span class="built_in">set</span> to <span class="literal">true</span>&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><blockquote><p><em>이미 8080포트가 사용중이므로 port를 8001로 수정하였다.</em></p></blockquote><p>zeppelin 폴더 이용 권한을 <code>zepp</code>에게 주고 daemon을 실행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ chown -R zepp:bigdata zeppelin/</span><br><span class="line">$ su - zepp</span><br><span class="line">$ bin/zeppelin-daemon.sh start</span><br><span class="line">Zeppelin start                                             [  OK  ]</span><br></pre></td></tr></table></figure><p><a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 으로 접속한다.</p><p><img src="/image/zeppelin-home.png" alt=""></p><h1 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h1><h2 id="Tibero-Connection"><a href="#Tibero-Connection" class="headerlink" title="Tibero Connection"></a>Tibero Connection</h2><p>Tibero와 연동하는 방법은 간단하다. <code>$ZEPPELIN_HOME/interpreter/jdbc</code> 안에 <code>tibero6-jdbc.jar</code> 파일을 복사한다</p><p><code>$ cp tibero6-jdbc.jar $ZEPPELIN_HOME/interpreter/jdbc/tibero6-jdbc.jar</code></p><p>이후 <code>$ZEPPELIN/conf/interpreter.json</code> 내 <code>jdbc</code> 부분에 import할 DB 정보를 작성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"jdbc"</span>: &#123;</span><br><span class="line">  <span class="string">"id"</span>: <span class="string">"jdbc"</span>,</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"jdbc"</span>,</span><br><span class="line">  <span class="string">"group"</span>: <span class="string">"jdbc"</span>,</span><br><span class="line">  <span class="string">"properties"</span>: &#123;</span><br><span class="line">    <span class="string">"default.url"</span>: &#123;</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"default.url"</span>,</span><br><span class="line">      <span class="string">"value"</span>: <span class="string">"jdbc:tibero:thin:@192.168.xxx.xxx:xxxx:tibero"</span>,</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"string"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"default.driver"</span>: &#123;</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"default.driver"</span>,</span><br><span class="line">      <span class="string">"value"</span>: <span class="string">"com.tmax.tibero.jdbc.TbDriver"</span>,</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"string"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"default.password"</span>: &#123;</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"default.password"</span>,</span><br><span class="line">      <span class="string">"value"</span>: <span class="string">"xxxxx"</span>,</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"password"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"default.user"</span>: &#123;</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"default.user"</span>,</span><br><span class="line">      <span class="string">"value"</span>: <span class="string">"xxx"</span>,</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"string"</span></span><br></pre></td></tr></table></figure><blockquote><p><em><code>properties</code> 안에 default.url, default.driver, default.password/user 를 해당 DB 정보를 작성한다. 나머지는 세부적인 사항이므로 <a href="https://zeppelin.apache.org/docs/0.8.0/interpreter/jdbc.html" target="_blank" rel="noopener">https://zeppelin.apache.org/docs/0.8.0/interpreter/jdbc.html</a>를 확인해 필요하면 수정하도록 한다.</em></p></blockquote><p><code>Zeppelin</code>을 재실행한다. Notebook을 생성하고 <code>%jdbc \n select * from tab</code>을 실행하여 정상적으로 연결되었는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="variable">$ZEPPELIN_HOME</span>/bin/zeppelin-daemon.sh restart</span><br><span class="line"></span><br><span class="line">%jdbc</span><br><span class="line">select * from tab</span><br></pre></td></tr></table></figure><p><img src="/image/zeppelin-jdbc.png" alt=""></p><h2 id="Hive-Connection"><a href="#Hive-Connection" class="headerlink" title="Hive Connection"></a>Hive Connection</h2><p><code>Hive</code>와의 연동도 마찬가지로 <code>$ZEPPELIN/conf/interpreter.json</code> 내 <code>interpreterSettings</code> 부분에 Hive 정보를 작성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"interpreterSettings"</span>: &#123;</span><br><span class="line">    <span class="string">"hive"</span>: &#123;</span><br><span class="line">      <span class="string">"id"</span>: <span class="string">"hive"</span>,</span><br><span class="line">      <span class="string">"name"</span>: <span class="string">"hive"</span>,</span><br><span class="line">      <span class="string">"group"</span>: <span class="string">"jdbc"</span>,</span><br><span class="line">      <span class="string">"properties"</span>: &#123;</span><br><span class="line">        <span class="string">"default.url"</span>: &#123;</span><br><span class="line">          <span class="string">"name"</span>: <span class="string">"default.url"</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="string">"jdbc:hive2://localhost:10000/project"</span>,</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"default.driver"</span>: &#123;</span><br><span class="line">          <span class="string">"name"</span>: <span class="string">"default.driver"</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="string">"org.apache.hive.jdbc.HiveDriver"</span>,</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"string"</span></span><br><span class="line">        &#125;,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">        <span class="string">"default.password"</span>: &#123;</span><br><span class="line">          <span class="string">"name"</span>: <span class="string">"default.password"</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="string">"hive"</span>,</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"password"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"default.user"</span>: &#123;</span><br><span class="line">          <span class="string">"name"</span>: <span class="string">"default.user"</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="string">"hive"</span>,</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"string"</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">      <span class="string">"dependencies"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"groupArtifactVersion"</span>: <span class="string">"org.apache.hive:hive-jdbc:2.3.6"</span>,</span><br><span class="line">          <span class="string">"local"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"groupArtifactVersion"</span>: <span class="string">"org.apache.hadoop:hadoop-common:2.6.0"</span>,</span><br><span class="line">          <span class="string">"local"</span>: <span class="literal">false</span>,</span><br><span class="line">          <span class="string">"exclusions"</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="string">"option"</span>: &#123;</span><br><span class="line">        <span class="string">"remote"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"port"</span>: -1,</span><br></pre></td></tr></table></figure><blockquote><p><em>templete을 이용해 굳이 모든 정보를 입력하지 않아도 된다. Zeppelin 웹에서 interpreter를 생성한 후 <strong>default.driver, default.password, default.url, default.user, Dependencies 2개</strong>를 작성한 후 생성하면 자동으로 interpreter.json에 추가된다. 주의할 점은, HiveServer2 로 접근이 가능한 상태임을 체크해주어야 한다.</em></p></blockquote><p><code>Zeppelin</code>을 재실행한다. Notebook을 생성하고 <code>%jdbc \n show tables</code>을 실행하여 정상적으로 연결되었는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="variable">$ZEPPELIN_HOME</span>/bin/zeppelin-daemon.sh restart</span><br><span class="line"></span><br><span class="line">%hive</span><br><span class="line">show tables</span><br></pre></td></tr></table></figure><p><img src="/image/zeppelin-hive.png" alt=""></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zeppelin.apache.org/docs/0.8.0/interpreter/hive.html#dependencies" target="_blank" rel="noopener">Zeppelin Documents, https://zeppelin.apache.org/docs/0.8.0/interpreter/hive.html#dependencies </a></li></ol><hr><p>2019.11.18 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-install_zeppelin/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Install Presto</title>
      <link>https://jx2lee.github.io/hadoop-install_presto/</link>
      <guid>https://jx2lee.github.io/hadoop-install_presto/</guid>
      <pubDate>Mon, 11 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;Presto&lt;/code&gt;를 설치하는 과정을 살펴본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>Presto</code>를 설치하는 과정을 살펴본다</p><a id="more"></a><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="Add-user-amp-Download"><a href="#Add-user-amp-Download" class="headerlink" title="Add user &amp; Download"></a>Add user &amp; Download</h2><p><code>Presto</code> user를 생성하고 hdclient 그룹에 포함한다. 이후 설치파일을 다운로드한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ adduser presto --gid 8630 <span class="comment"># hdclient</span></span><br><span class="line">$ wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.228/presto-server-0.228.tar.gz</span><br></pre></td></tr></table></figure><h2 id="bash-profile"><a href="#bash-profile" class="headerlink" title=".bash_profile"></a>.bash_profile</h2><p><code>.bash_profile</code>에 <code>Hadoop</code> 및 <code>Presto</code> Env를 추가한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hadoop Env</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/app/jdk</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/app/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:\</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin:\</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/app/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_YARN_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=<span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># Presto Env</span></span><br><span class="line"><span class="built_in">export</span> PRESTO_HOME=/app/presto</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h1 id="Configuring-Presto"><a href="#Configuring-Presto" class="headerlink" title="Configuring Presto"></a>Configuring Presto</h1><p>세 개의 설정파일을 <code>$PRESTO_HOME/etc</code> 폴더에 생성한다.</p><h2 id="etc-node-properties"><a href="#etc-node-properties" class="headerlink" title="/etc/node.properties"></a>/etc/node.properties</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.environment=production</span><br><span class="line">node.id=ffffffff-ffff-ffff-ffff-ffffffffffff</span><br><span class="line">node.data-dir=/app/presto/data</span><br></pre></td></tr></table></figure><h2 id="etc-jvm-confing"><a href="#etc-jvm-confing" class="headerlink" title="/etc/jvm.confing"></a>/etc/jvm.confing</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xmx16G</span><br><span class="line">-XX:+UseG1GC</span><br><span class="line">-XX:G1HeapRegionSize=32M</span><br><span class="line">-XX:+UseGCOverheadLimit</span><br><span class="line">-XX:+ExplicitGCInvokesConcurrent</span><br><span class="line">-XX:+HeapDumpOnOutOfMemoryError</span><br><span class="line">-XX:+ExitOnOutOfMemoryError</span><br></pre></td></tr></table></figure><h2 id="etc-config-properties"><a href="#etc-config-properties" class="headerlink" title="/etc/config.properties"></a>/etc/config.properties</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">coordinator=<span class="literal">true</span></span><br><span class="line">node-scheduler.include-coordinator=<span class="literal">true</span></span><br><span class="line">http-server.http.port=8000</span><br><span class="line">query.max-memory=5GB</span><br><span class="line">query.max-memory-per-node=1GB</span><br><span class="line">query.max-total-memory-per-node=2GB</span><br><span class="line">discovery-server.enabled=<span class="literal">true</span></span><br><span class="line">discovery.uri=http://192.168.xxx.xxx:8000</span><br></pre></td></tr></table></figure><blockquote><ul><li><code>http-server.htt.port</code> : <em>Presto는 내부 및 외부 모든 통신에 HTTP를 사용하며, 내 경우 8000번 포트를 open, 이를 통해 통신</em></li><li><code>discovery.uri</code> : <em>Presto instance는 시작 시 Discovery service에 등록되는 URI로 Presto 구동 서버의 IP와 port (위와 같은 경우는 8000 port) 로 작성</em></li></ul></blockquote><h2 id="etc-catalog-hive-properties"><a href="#etc-catalog-hive-properties" class="headerlink" title="/etc/catalog/hive.properties"></a>/etc/catalog/hive.properties</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">connector.name=hive-hadoop2</span><br><span class="line">hive.metastore.uri=thrift://localhost:9083</span><br></pre></td></tr></table></figure><blockquote><p><em>Hive MetaStore 의 default port는 *</em>9083***</p></blockquote><p>위에 생성한 파일들을 tree로 표현하면 다음과 같다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">├── catalog</span><br><span class="line">│   └── hive.properties</span><br><span class="line">├── config.properties</span><br><span class="line">├── jvm.config</span><br><span class="line">└── node.properties</span><br><span class="line"></span><br><span class="line">1 directory, 4 files</span><br></pre></td></tr></table></figure><h1 id="Start-Presto-Server"><a href="#Start-Presto-Server" class="headerlink" title="Start Presto Server"></a>Start Presto Server</h1><p><code>$PRESTO_HOME/bin</code> 폴더에 <code>launcher</code> 파일을 실행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ./launcher start</span><br><span class="line">Started as 25072</span><br><span class="line"><span class="comment"># $PRESTO_HOME/data/var/log/launcher.log</span></span><br><span class="line">2019-11-12T14:56:02.306+0900INFOmainio.airlift.log.LoggingLogging to stderr</span><br><span class="line">2019-11-12T14:56:02.308+0900INFOmainBootstrapLoading configuration</span><br><span class="line">2019-11-12T14:56:02.404+0900INFOmainBootstrapInitializing logging</span><br><span class="line">2019-11-12T14:56:02.447+0900INFOmainio.airlift.log.LoggingLogging to /app/presto/data/var/<span class="built_in">log</span>/server.log</span><br><span class="line">2019-11-12T14:56:02.497+0900INFOmainio.airlift.log.LoggingDisabling stderr output</span><br></pre></td></tr></table></figure><p>Presto CLI 을 <code>wget</code>을 이용해 다운로드 한다. 이후 실행권한을 주고 CLI 를 실행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.228/presto-cli-0.228-executable.jar &amp;&amp; mv presto-cli-0.228-executable.jar presto</span><br><span class="line">$ chmod +x presto</span><br><span class="line">$ ./presto --server 192.168.154.156:8000 --catalog hive --schema project</span><br></pre></td></tr></table></figure><blockquote><p><em>Presto CLI 명령어 arguments</em></p><ul><li><code>server</code> : <em>discovery.uri</em></li><li><code>catalog</code> : <em>Hive MetaStore</em></li><li><code>schema</code> : <em>Hive metaStore</em> 중 <em>project db **</em></li></ul></blockquote><p>테이블을 조회해보자.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">presto:project&gt; show tables;</span><br><span class="line">  Table   </span><br><span class="line"><span class="comment">----------</span></span><br><span class="line"> binvt00t </span><br><span class="line"> bprjt00t </span><br><span class="line"> ccomp00t </span><br><span class="line"> iprsn00t </span><br><span class="line">(4 rows)</span><br><span class="line"></span><br><span class="line">Query 20191112_060524_00002_bgi94, FINISHED, 1 node</span><br><span class="line">Splits: 19 total, 19 done (100.00%)</span><br><span class="line">0:02 [4 rows, 100B] [1 rows/s, 43B/s]</span><br></pre></td></tr></table></figure><p><strong>구축 완료!</strong></p><h1 id="Query-속도-비교"><a href="#Query-속도-비교" class="headerlink" title="Query 속도 비교"></a>Query 속도 비교</h1><p>테이블의 row 수를 반환하는 쿼리문을 <code>Presto</code>와 <code>Hive</code>에서 수행해본다.</p><ul><li><code>Presto</code></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">presto:project&gt; select count(*) from bprjt00t;</span><br><span class="line"> _col0 </span><br><span class="line"><span class="comment">-------</span></span><br><span class="line"> 65355 </span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">Query 20191112_061041_00004_bgi94, FINISHED, 1 node</span><br><span class="line">Splits: 23 total, 23 done (100.00%)</span><br><span class="line">0:04 [65.4K rows, 9.29MB] [15.9K rows/s, 2.26MB/s]</span><br></pre></td></tr></table></figure><ul><li><code>Hive</code></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select count(*)</span><br><span class="line">    &gt; from bprjt00t;</span><br><span class="line">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Query ID = hive_20191112151209_8598d146-fed8-4b55-8a2b-e1ed186a82d0</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to <span class="keyword">change</span> the average <span class="keyword">load</span> <span class="keyword">for</span> a reducer (<span class="keyword">in</span> <span class="keyword">bytes</span>):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;<span class="built_in">number</span>&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">limit</span> the maximum <span class="built_in">number</span> <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;<span class="built_in">number</span>&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a <span class="keyword">constant</span> <span class="built_in">number</span> <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;<span class="built_in">number</span>&gt;</span><br><span class="line"><span class="keyword">Starting</span> Job = job_1567153359966_0111, <span class="keyword">Tracking</span> <span class="keyword">URL</span> = <span class="keyword">http</span>://node5.dat:<span class="number">8088</span>/proxy/application_1567153359966_0111/</span><br><span class="line"><span class="keyword">Kill</span> Command = /app/hadoop/<span class="keyword">bin</span>/hadoop job  -<span class="keyword">kill</span> job_1567153359966_0111</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: <span class="built_in">number</span> <span class="keyword">of</span> mappers: <span class="number">2</span>; number of reducers: 1</span><br><span class="line">2019-11-12 15:12:19,615 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2019-11-12 15:12:23,860 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.1 sec</span><br><span class="line">2019-11-12 15:12:27,986 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 5 seconds 980 msec</span><br><span class="line">Ended Job = job_1567153359966_0111</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 5.98 sec   HDFS Read: 9754283 HDFS Write: 105 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 5 seconds 980 msec</span><br><span class="line">OK</span><br><span class="line">65355</span><br><span class="line">Time taken: 20.718 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><blockquote><p><em>대략 Presto가 Hive 대비 쿼리속도가 *</em>20배 가량 빠르다***</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://prestodb.io/docs/current/index.html" target="_blank" rel="noopener">Presto Documents</a></li><li><a href="https://medium.com/@nil.me/a-single-node-installation-of-presto-and-simple-benchmarks-3271bc738ed1" target="_blank" rel="noopener">A Single-node Installation of Presto and Simple Benchmarks</a></li></ol><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-install_presto/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Sqoop을 이용한 Table 조회</title>
      <link>https://jx2lee.github.io/hadoop-sqoop_example/</link>
      <guid>https://jx2lee.github.io/hadoop-sqoop_example/</guid>
      <pubDate>Wed, 06 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Tibero Table을 &lt;code&gt;Sqoop&lt;/code&gt; 을 이용해 HDFS에 저장함과 동시에, &lt;code&gt;Hive&lt;/code&gt; 로 조회하는 예제를 살펴본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Tibero Table을 <code>Sqoop</code> 을 이용해 HDFS에 저장함과 동시에, <code>Hive</code> 로 조회하는 예제를 살펴본다.</p><a id="more"></a><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="RDBMS-Table"><a href="#RDBMS-Table" class="headerlink" title="RDBMS Table"></a>RDBMS Table</h2><p>BPRJT00T 테이블을 확인한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">$ DESC BPRJT00T;</span><br><span class="line">COLUMN_NAME                              TYPE               CONSTRAINT          </span><br><span class="line"><span class="comment">---------------------------------------- ------------------ --------------------</span></span><br><span class="line">PRJT_CD                                  VARCHAR(10)        PRIMARY KEY</span><br><span class="line">PRJT_NM                                  VARCHAR(1000)      </span><br><span class="line">COMP_CD                                  VARCHAR(10)        </span><br><span class="line">CUST_CD                                  VARCHAR(10)        </span><br><span class="line">PRJT_ENV                                 VARCHAR(3000)      </span><br><span class="line">BUSI_AMT                                 NUMBER(13)         </span><br><span class="line">ATTACH_NO_ORG                            VARCHAR(20)        </span><br><span class="line">IMPORTANT_CLS                            VARCHAR(1)         NOT NULL</span><br><span class="line">MA_PRJT_CLS                              VARCHAR(1)         NOT NULL</span><br><span class="line">REPORT_CLS                               VARCHAR(4)         NOT NULL</span><br><span class="line">PRIORITY_CD                              VARCHAR(4)         NOT NULL</span><br><span class="line">PRJT_STATUS                              VARCHAR(4)         NOT NULL</span><br><span class="line">SALE_EMP                                 VARCHAR(7)         </span><br><span class="line">REMARK                                   VARCHAR(4000)      </span><br><span class="line">REG_EMP                                  VARCHAR(7)         </span><br><span class="line">REG_DATE                                 VARCHAR(8)         </span><br><span class="line">MOD_EMP                                  VARCHAR(7)         </span><br><span class="line">MOD_DATE                                 VARCHAR(8)         </span><br><span class="line">LOSS_PROD                                VARCHAR(200)       </span><br><span class="line">CURRENCY_KIND                            VARCHAR(4)         NOT NULL</span><br><span class="line">RECNTR_YN                                VARCHAR(1)         NOT NULL</span><br><span class="line">RECNTR_STATUS                            VARCHAR(4)         </span><br><span class="line">DIST_PATH                                VARCHAR(100)       </span><br><span class="line">DISTRIB_YN                               VARCHAR(1)         NOT NULL</span><br><span class="line">DISTRIB_PRJTCD                           VARCHAR(10)        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">INDEX_NAME                       TYPE                     COLUMN_NAME           </span><br><span class="line"><span class="comment">-------------------------------- ------------------------ ----------------------</span></span><br><span class="line">BPRJT00T_IDX01                   NORMAL                   SALE_EMP</span><br><span class="line">BPRJT00T_IDX02                   NORMAL                   COMP_CD</span><br><span class="line">BPRJT00T_PK                      NORMAL                   PRJT_CD</span><br><span class="line">$ <span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> BPRJT00T;</span><br><span class="line">  COUNT(*)</span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">     56125</span><br></pre></td></tr></table></figure><h2 id="Sqoop-eval"><a href="#Sqoop-eval" class="headerlink" title="Sqoop eval"></a>Sqoop eval</h2><p><code>Sqoop</code>을 이용해 테이블 접근이 가능한지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sqoop <span class="built_in">eval</span> \</span><br><span class="line">-connect jdbc:tibero:thin:@[ip]:[port]:[DB SID]] \</span><br><span class="line">-driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">-username XXX -password XXX \</span><br><span class="line">-e <span class="string">"select * from BPRJT00T where rownum &lt; 10"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p><em>보안상 조회 결과는 생략하였다</em></p></blockquote><h1 id="RDMBS-to-HDFS"><a href="#RDMBS-to-HDFS" class="headerlink" title="RDMBS to HDFS"></a>RDMBS to HDFS</h1><p>확인이 끝났다면, 아래 명령어를 통해 <code>Sqoop</code>으로 HDFS에 저장하고 동시에 <code>Hive</code>로 Import 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sqoop import <span class="string">"-Dorg.apache.sqoop.splitter.allow_text_splitter=true"</span> \</span><br><span class="line">--connect jdbc:tibero:thin:@[ip]:[port]:[DB SID] \</span><br><span class="line">--driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">--target-dir /project/BPRJT00T \</span><br><span class="line">--username XXX --password XXX \</span><br><span class="line">--table BPRJT00T \</span><br><span class="line">--fields-terminated-by <span class="string">","</span> \</span><br><span class="line">--hive-import \</span><br><span class="line">--create-hive-table \</span><br><span class="line">--hive-table project.BPRJT00T</span><br></pre></td></tr></table></figure><blockquote><p><em>Hive로 Import 하기 위해서는 미리 Database가 구성되어 있어야 한다. (나의 경우 DB Name은 project)</em></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">19/11/07 16:28:43 INFO hive.HiveImport: OK</span><br><span class="line">19/11/07 16:28:43 INFO hive.HiveImport: Time taken: 4.162 seconds</span><br><span class="line">19/11/07 16:28:44 INFO hive.HiveImport: Loading data to table project.bprjt00t</span><br><span class="line">19/11/07 16:28:44 INFO hive.HiveImport: OK</span><br><span class="line">19/11/07 16:28:44 INFO hive.HiveImport: Time taken: 0.611 seconds</span><br><span class="line">19/11/07 16:28:45 INFO hive.HiveImport: Hive import complete.</span><br><span class="line">19/11/07 16:28:45 INFO hive.HiveImport: Export directory is contains the _SUCCESS file only, removing the directory.</span><br></pre></td></tr></table></figure><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><p>우선, <code>Hive</code>로 Import 한 테이블을 hdfs 명렁어로 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -ls /user/hive/warehouse</span><br><span class="line">Found 1 items</span><br><span class="line">drwxrwxrwx   - hive supergroup          0 2019-11-07 16:27 /user/hive/warehouse/project.db</span><br><span class="line">$ hdfs dfs -ls /user/hive/warehouse/project.db/</span><br><span class="line">Found 1 items</span><br><span class="line">drwxrwxrwx   - hive supergroup          0 2019-11-07 16:28 /user/hive/warehouse/project.db/bprjt00t</span><br></pre></td></tr></table></figure><blockquote><p><em>잘 들어갔다.</em></p></blockquote><p>그럼 <code>Hive</code> 콘솔로 접속하여 BPRJT00T 테이블을 조회해보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ hive</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/app/hive/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">hive&gt; $ use project;</span><br><span class="line">OK</span><br><span class="line">Time taken: 2.963 seconds</span><br><span class="line">hive&gt; $ select * from bprjt00t <span class="built_in">limit</span> 10;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><blockquote><p><em>이또한, 조회결과는 생략</em></p></blockquote><hr><p>2019.11.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-sqoop_example/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Hive Import 시 Could not initialize class org.apache.derby.jdbc.EmbeddedDriver 문제해결</title>
      <link>https://jx2lee.github.io/hadoop-sqoop_import_error/</link>
      <guid>https://jx2lee.github.io/hadoop-sqoop_import_error/</guid>
      <pubDate>Wed, 06 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;Hive&lt;/code&gt; 에 RDMS 테이블을 import 하는 과정에서 발생한 문제를 해결한다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>Hive</code> 에 RDMS 테이블을 import 하는 과정에서 발생한 문제를 해결한다</p><a id="more"></a><h1 id="Status"><a href="#Status" class="headerlink" title="Status"></a>Status</h1><p>아래와 같은 명령어를 통해 Tibero 테이블 <em>BPRJT00T</em>를 <code>Sqoop</code>으로 땡겨오고 <code>Hive</code>로 Import 하고자 했다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sqoop import <span class="string">"-Dorg.apache.sqoop.splitter.allow_text_splitter=true"</span> \</span><br><span class="line">--connect jdbc:tibero:thin:@192.168.154.xxx:xxxx:tibero \</span><br><span class="line">--driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">--target-dir /project/BPRJT00T \</span><br><span class="line">--username ERP --password xxxx \</span><br><span class="line">--table BPRJT00T \</span><br><span class="line">--fields-terminated-by <span class="string">","</span> \</span><br><span class="line">--hive-import \</span><br><span class="line">--create-hive-table \</span><br><span class="line">--hive-table project.BPRJT00T</span><br></pre></td></tr></table></figure><h1 id="Error-Message"><a href="#Error-Message" class="headerlink" title="Error Message"></a>Error Message</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Could not initialize class org.apache.derby.jdbc.EmbeddedDriver...</span><br><span class="line">...</span><br><span class="line">... 12 more</span><br></pre></td></tr></table></figure><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>분명 <code>Hive</code>의 MetaStore를 <strong>MySQL</strong>로 설정하였는데<em>(초기화까지 완료한 상태)</em> 자꾸 Derby Driver를 못찾았다는 에러가 발생하였다. 이는, <strong>hive-site.xml이 Hive가 인식을 못해 Default Database로 Derby</strong>를 사용했기 때문이다. 이는 <strong>.bash_profile 또는 .profile 내 HADOOP_CLASSPATH를 추가</strong>하여 해결할 수 있다.</p><blockquote><p><em>만약 나처럼 MetaStore를 MySQL이 아닌 Derby로 설정했는데 에러가 발생한다면, $HIVE_HOME/lib 안에 connector 파일이 있는지 확인하고 없다면 copy &amp; paste 하자</em></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.profile</span><br><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=<span class="variable">$HIVE_HOME</span>/conf:<span class="variable">$HIVE_HOME</span>/lib</span><br><span class="line">$ . ~/.profile</span><br></pre></td></tr></table></figure><p>이후 Status에서 작성한 커맨드를 실행하면 <code>Hive</code>에 미리 생성해놓은 Database에 테이블이 생성한 것을 확인할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -ls /user/hive/warehouse</span><br><span class="line">Found 1 items</span><br><span class="line">drwxrwxrwx   - hive supergroup          0 2019-11-07 15:41 /user/hive/warehouse/project.db</span><br></pre></td></tr></table></figure><blockquote><p><em>MySQL hive 유저의 proejct DB에 bprjt00t 테이블이 들어가 있음을 확인</em></p></blockquote><hr><p>2019.11.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-sqoop_import_error/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Database] Install MySQL 8.0</title>
      <link>https://jx2lee.github.io/database-install_mysql/</link>
      <guid>https://jx2lee.github.io/database-install_mysql/</guid>
      <pubDate>Tue, 05 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Hive의 Meta Store로 MySQL를 사용하기 위해 설치하고, 이를 정리한다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Hive의 Meta Store로 MySQL를 사용하기 위해 설치하고, 이를 정리한다</p><a id="more"></a><h1 id="Setting-Environment"><a href="#Setting-Environment" class="headerlink" title="Setting Environment"></a>Setting Environment</h1><p>설치에 필요한 라이브러리 version을 맞춰줄 필요가 있다.</p><h2 id="Version-Up-CMake"><a href="#Version-Up-CMake" class="headerlink" title="Version Up CMake"></a>Version Up CMake</h2><p><code>CMake</code> 이 하위 version이라면 올려보도록 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xvzf cmake-3.16.0-rc3.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> cmake-3.16.0-rc3.tar.gz</span><br><span class="line">$ ./bootstrap</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure><h2 id="Version-up-gcc"><a href="#Version-up-gcc" class="headerlink" title="Version up gcc"></a>Version up gcc</h2><p>마찬가지로 <code>gcc</code> version이 하위 버젼이면 올려보도록 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install centos-release-scl</span><br><span class="line">$ sudo yum install devtoolset-7-gcc*</span><br><span class="line">$ scl <span class="built_in">enable</span> devtoolset-7 bash</span><br><span class="line">$ <span class="built_in">which</span> gcc</span><br><span class="line">$ gcc --version</span><br><span class="line">gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)</span><br><span class="line">Copyright (C) 2015 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the <span class="built_in">source</span> <span class="keyword">for</span> copying conditions.  There is NO</span><br><span class="line">warranty; not even <span class="keyword">for</span> MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure><h1 id="Make"><a href="#Make" class="headerlink" title="Make"></a>Make</h1><p><code>wget</code>을 이용해 binary 파일을 다운받고 <code>CMake</code>을 이용해 설치한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /app/</span><br><span class="line">$ wget https://dev.mysql.com/get/Downloads/MySQL-8.0/mysql-8.0.18.tar.gz</span><br><span class="line">$ tar xvfz mysql-8.0.18.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> mysql-8.0.18</span><br><span class="line">$ cmake \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX=/app/mysql \</span><br><span class="line">-DMYSQL_DATADIR=/home/mysql/data \</span><br><span class="line">-DSYSCONFDIR=/app/mysql \</span><br><span class="line">-DMYSQL_USER=mysql \</span><br><span class="line">-DWITH_MYISAM_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_INNOBASE_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_PARTITION_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_FEDERATED_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_MEMORY_STORAGE_ENGINE=1 \</span><br><span class="line">-DWITH_READLINE=1 \</span><br><span class="line">-DMYSQL_UNIX_ADDR=/app/mysql/mysql.sock \</span><br><span class="line">-DMYSOL_TCP_PORT=3306 \</span><br><span class="line">-DENABLED_LOCAL_INFILE=1 \</span><br><span class="line">-DENABLE_DOWNLOADS=1 \</span><br><span class="line">-DWITH_EXTRA_CHARSETS=all \</span><br><span class="line">-DDEFAULT_CHARSET=utf8 \</span><br><span class="line">-DDEFAULT_COLLATION=utf8_general_ci \</span><br><span class="line">-DWITH_DEBUG=0 \</span><br><span class="line">-DMYSQL_MAINTAINER_MODE=0 \</span><br><span class="line">-DDOWNLOAD_BOOST=1 \</span><br><span class="line">-DDOWNLOAD_BOOST=1 -DWITH_BOOST=/app/mysql-8.0.18</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure><h1 id="Add-Servcie"><a href="#Add-Servcie" class="headerlink" title="Add Servcie"></a>Add Servcie</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cp mysql.server /etc/rc.d/init.d/mysql</span><br><span class="line">$ ln -s /etc/rc.d/init.d/mysql /etc/rc.d/rc3.d/S97mysql </span><br><span class="line">$ vi /usr/lib/systemd/system/mysql.service</span><br></pre></td></tr></table></figure><h1 id="etc-my-cnf"><a href="#etc-my-cnf" class="headerlink" title="/etc/my.cnf"></a>/etc/my.cnf</h1><p>/etc 에 <code>my.cnf</code> config 파일을 생성한다. <code>my.cnf</code>는 <strong>MySQL</strong>의 config를 설정하는 파일이며, 본 설치에서는 DB Engine으로 <strong>InnoDB</strong>를 사용한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">default-character-set &#x3D; utf8</span><br><span class="line">port &#x3D; 3306</span><br><span class="line">socket &#x3D; &#x2F;tmp&#x2F;mysql.sock</span><br><span class="line">default-character-set &#x3D; utf8</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[mysqld]</span><br><span class="line">socket&#x3D;&#x2F;app&#x2F;mysql&#x2F;mysql.sock</span><br><span class="line">datadir&#x3D;&#x2F;home&#x2F;mysql&#x2F;data</span><br><span class="line">basedir &#x3D; &#x2F;app&#x2F;mysql</span><br><span class="line">#user &#x3D; mysql</span><br><span class="line">#bind-address &#x3D; 0.0.0.0</span><br><span class="line"></span><br><span class="line">skip-external-locking</span><br><span class="line">key_buffer_size &#x3D; 384M</span><br><span class="line">max_allowed_packet &#x3D; 16M</span><br><span class="line">table_open_cache &#x3D; 2048</span><br><span class="line">sort_buffer_size &#x3D; 2M</span><br><span class="line">read_buffer_size &#x3D; 2M</span><br><span class="line">read_rnd_buffer_size &#x3D; 8M</span><br><span class="line">myisam_sort_buffer_size &#x3D; 64M</span><br><span class="line">thread_cache_size &#x3D; 8</span><br><span class="line"> </span><br><span class="line">#dns query</span><br><span class="line">skip-name-resolve</span><br><span class="line"> </span><br><span class="line">#connection</span><br><span class="line">max_connections &#x3D; 1000</span><br><span class="line">max_connect_errors &#x3D; 1000</span><br><span class="line">wait_timeout&#x3D; 60</span><br><span class="line"> </span><br><span class="line">#slow-queries</span><br><span class="line">#slow_query_log &#x3D; &#x2F;home&#x2F;mysql_data&#x2F;slow-queries.log</span><br><span class="line">#long_query_time &#x3D; 3</span><br><span class="line">#log-slow-queries &#x3D; &#x2F;home&#x2F;mysql_data&#x2F;mysql-slow-queries.log</span><br><span class="line"> </span><br><span class="line">##timestamp</span><br><span class="line">explicit_defaults_for_timestamp</span><br><span class="line">symbolic-links&#x3D;0</span><br><span class="line"></span><br><span class="line">### log</span><br><span class="line">log-error&#x3D;&#x2F;home&#x2F;mysql&#x2F;data&#x2F;mysqld.log</span><br><span class="line">pid-file&#x3D;&#x2F;home&#x2F;mysql&#x2F;mysqld.pid</span><br><span class="line"> </span><br><span class="line">###chracter</span><br><span class="line">character-set-client-handshake&#x3D;FALSE</span><br><span class="line">init_connect &#x3D; SET collation_connection &#x3D; utf8_general_ci</span><br><span class="line">init_connect &#x3D; SET NAMES utf8</span><br><span class="line">character-set-server &#x3D; utf8</span><br><span class="line">collation-server &#x3D; utf8_general_ci</span><br><span class="line">symbolic-links&#x3D;0</span><br><span class="line"></span><br><span class="line">##Password Policy</span><br><span class="line">#validate_password_policy&#x3D;LOW</span><br><span class="line">#validate_password_policy&#x3D;MEDIUM</span><br><span class="line"> </span><br><span class="line">### MyISAM Spectific options</span><br><span class="line">#default-storage-engine &#x3D; myisam</span><br><span class="line">key_buffer_size &#x3D; 32M</span><br><span class="line">bulk_insert_buffer_size &#x3D; 64M</span><br><span class="line">myisam_sort_buffer_size &#x3D; 128M</span><br><span class="line">myisam_max_sort_file_size &#x3D; 10G</span><br><span class="line">myisam_repair_threads &#x3D; 1</span><br><span class="line"> </span><br><span class="line">### INNODB Spectific options</span><br><span class="line">default-storage-engine &#x3D; InnoDB</span><br><span class="line">#skip-innodb</span><br><span class="line">#innodb_additional_mem_pool_size &#x3D; 16M</span><br><span class="line">innodb_buffer_pool_size &#x3D; 1024MB</span><br><span class="line">innodb_data_file_path &#x3D; ibdata1:10M:autoextend</span><br><span class="line">innodb_write_io_threads &#x3D; 8</span><br><span class="line">innodb_read_io_threads &#x3D; 8</span><br><span class="line">innodb_thread_concurrency &#x3D; 16</span><br><span class="line">innodb_flush_log_at_trx_commit &#x3D; 1</span><br><span class="line">innodb_log_buffer_size &#x3D; 8M</span><br><span class="line">innodb_log_file_size &#x3D; 128M</span><br><span class="line">innodb_log_files_in_group &#x3D; 3</span><br><span class="line">innodb_max_dirty_pages_pct &#x3D; 90</span><br><span class="line">innodb_lock_wait_timeout &#x3D; 120</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[mysqldump]</span><br><span class="line">default-character-set &#x3D; utf8</span><br><span class="line">max_allowed_packet &#x3D; 512M</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[mysql]</span><br><span class="line">#no-auto-rehash</span><br><span class="line">default-character-set &#x3D; utf8</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">[myisamchk]</span><br><span class="line">key_buffer_size &#x3D; 512M</span><br><span class="line">sort_buffer_size &#x3D; 512M</span><br><span class="line">read_buffer &#x3D; 8M</span><br><span class="line">write_buffer &#x3D; 8M</span><br></pre></td></tr></table></figure><h1 id="Initialize-Database"><a href="#Initialize-Database" class="headerlink" title="Initialize Database"></a>Initialize Database</h1><p>Database를 mysql user로 초기화 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ /app/mysql/bin/mysqld --initialize-insecure --basedir=/app/mysql --datadir=/home/mysql/data --user=mysql</span><br><span class="line">$ ll /home/mysql/data/</span><br><span class="line">total 448572</span><br><span class="line">-rw-r----- 1 mysql mysql        56 Nov  5 17:19 auto.cnf</span><br><span class="line">-rw------- 1 mysql mysql      1680 Nov  5 17:19 ca-key.pem</span><br><span class="line">-rw-r--r-- 1 mysql mysql      1112 Nov  5 17:19 ca.pem</span><br><span class="line">-rw-r--r-- 1 mysql mysql      1112 Nov  5 17:19 client-cert.pem</span><br><span class="line">-rw------- 1 mysql mysql      1676 Nov  5 17:19 client-key.pem</span><br><span class="line">-rw-r----- 1 mysql mysql      6100 Nov  5 17:19 ib_buffer_pool</span><br><span class="line">-rw-r----- 1 mysql mysql  10485760 Nov  5 17:19 ibdata1</span><br><span class="line">-rw-r----- 1 mysql mysql 134217728 Nov  5 17:19 ib_logfile0</span><br><span class="line">-rw-r----- 1 mysql mysql 134217728 Nov  5 17:19 ib_logfile1</span><br><span class="line">-rw-r----- 1 mysql mysql 134217728 Nov  5 17:19 ib_logfile2</span><br><span class="line">drwxr-x--- 2 mysql mysql         6 Nov  5 17:19 <span class="comment">#innodb_temp</span></span><br><span class="line">drwxr-x--- 2 mysql mysql       143 Nov  5 17:19 mysql</span><br><span class="line">-rw-r----- 1 mysql mysql      1301 Nov  5 17:19 mysqld.log</span><br><span class="line">-rw-r----- 1 mysql mysql  25165824 Nov  5 17:19 mysql.ibd</span><br><span class="line">drwxr-x--- 2 mysql mysql      8192 Nov  5 17:19 performance_schema</span><br><span class="line">-rw------- 1 mysql mysql      1680 Nov  5 17:19 private_key.pem</span><br><span class="line">-rw-r--r-- 1 mysql mysql       452 Nov  5 17:19 public_key.pem</span><br><span class="line">-rw-r--r-- 1 mysql mysql      1112 Nov  5 17:19 server-cert.pem</span><br><span class="line">-rw------- 1 mysql mysql      1676 Nov  5 17:19 server-key.pem</span><br><span class="line">drwxr-x--- 2 mysql mysql        28 Nov  5 17:19 sys</span><br><span class="line">-rw-r----- 1 mysql mysql  10485760 Nov  5 17:19 undo_001</span><br><span class="line">-rw-r----- 1 mysql mysql  10485760 Nov  5 17:19 undo_002</span><br></pre></td></tr></table></figure><h1 id="Restart-Service-amp-Checking"><a href="#Restart-Service-amp-Checking" class="headerlink" title="Restart Service &amp; Checking"></a>Restart Service &amp; Checking</h1><p>Service 재기동 후 <strong>MySQL</strong>이 제대로 설치되었는지 확인한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop mysql</span><br><span class="line">$ systemctl start mysql</span><br><span class="line">$ /app/mysql/bin/mysql -u root -p</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 8</span><br><span class="line">Server version: 8.0.18 Source distribution</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; </span><br><span class="line">mysql&gt; </span><br><span class="line">mysql&gt; </span><br><span class="line">mysql&gt; \s</span><br><span class="line">--------------</span><br><span class="line">/app/mysql/bin/mysql  Ver 8.0.18 <span class="keyword">for</span> Linux on x86_64 (Source distribution)</span><br><span class="line"></span><br><span class="line">Connection id:8</span><br><span class="line">Current database:</span><br><span class="line">Current user:root@localhost</span><br><span class="line">SSL:Not <span class="keyword">in</span> use</span><br><span class="line">Current pager:stdout</span><br><span class="line">Using outfile:<span class="string">''</span></span><br><span class="line">Using delimiter:;</span><br><span class="line">Server version:8.0.18 Source distribution</span><br><span class="line">Protocol version:10</span><br><span class="line">Connection:Localhost via UNIX socket</span><br><span class="line">Server characterset:utf8</span><br><span class="line">Db     characterset:utf8</span><br><span class="line">Client characterset:utf8</span><br><span class="line">Conn.  characterset:utf8</span><br><span class="line">UNIX socket:/tmp/mysql.sock</span><br><span class="line">Uptime:17 min 25 sec</span><br><span class="line"></span><br><span class="line">Threads: 2  Questions: 6  Slow queries: 0  Opens: 115  Flush tables: 3  Open tables: 35  Queries per second avg: 0.005</span><br><span class="line">--------------</span><br></pre></td></tr></table></figure><blockquote><p><em>MySQL 시작 시 /tmp/mysql.sock 이 없다고 fail이 날 수 있다. 이때는 tmp 폴더안에 mysql.sock이 있는 path로 링크를 생성하면된다. (초기 설정부터 /tmp에 안들어가게끔 어떻게 설정하지..? 이건 내일하자!)</em></p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://xinet.kr/?p=2149" target="_blank" rel="noopener">MYSQL 8.0 INSTALL ( mysql 8.0.17 ) / Centos 7</a></li><li><a href="https://idchowto.com/?p=43760" target="_blank" rel="noopener">CentOS7에서 Mysql 8.0 소스 설치</a></li><li><a href="https://dev.mysql.com/doc/refman/8.0/en/installing.html" target="_blank" rel="noopener">MySQL Documents</a></li></ol><hr><p>2019.11.06 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/database-install_mysql/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Install Hive</title>
      <link>https://jx2lee.github.io/hadoop-install_hive/</link>
      <guid>https://jx2lee.github.io/hadoop-install_hive/</guid>
      <pubDate>Tue, 05 Nov 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Hive를 설치하는 과정을 살펴본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Hive를 설치하는 과정을 살펴본다</p><a id="more"></a><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="Add-user-amp-group"><a href="#Add-user-amp-group" class="headerlink" title="Add user &amp; group"></a>Add user &amp; group</h2><p><code>Hive</code> user를 생성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ groupadd hdclient</span><br><span class="line">$ usermod -g hdclient sqoop </span><br><span class="line">$ adduser hive --gid 8630 <span class="comment"># hdclient</span></span><br></pre></td></tr></table></figure><h2 id="bash-profile"><a href="#bash-profile" class="headerlink" title=".bash_profile"></a>.bash_profile</h2><p><code>.bash_profile</code>에 <code>Hadoop</code> 및 <code>Hive</code> ENV를 추가한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hadoop</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/app/jdk</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/app/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:\</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin:\</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/app/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_YARN_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=<span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/app/hive</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h2 id="Setting-MySQL-for-Hive-MetaStore"><a href="#Setting-MySQL-for-Hive-MetaStore" class="headerlink" title="Setting MySQL for Hive MetaStore"></a>Setting MySQL for Hive MetaStore</h2><p><code>Hive</code> MetaStore를 MySQL로 사용하기위해 새로운 database와 <code>hive</code> user를 생성한다</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">create</span> <span class="keyword">database</span> hive;</span><br><span class="line">$ <span class="keyword">create</span> <span class="keyword">user</span> hive@<span class="string">'%'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'hive'</span>;</span><br><span class="line">$ <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> hive.* <span class="keyword">to</span> hive@<span class="string">'%'</span>;</span><br><span class="line">$ <span class="keyword">use</span> mysql;</span><br><span class="line">$ <span class="keyword">select</span> host, <span class="keyword">user</span> <span class="keyword">from</span> <span class="keyword">user</span>;</span><br><span class="line"></span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| host      | user             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">| %         | hive             |</span><br><span class="line">| localhost | mysql.infoschema |</span><br><span class="line">| localhost | mysql.session    |</span><br><span class="line">| localhost | mysql.sys        |</span><br><span class="line">| localhost | root             |</span><br><span class="line">+<span class="comment">-----------+------------------+</span></span><br><span class="line">5 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><blockquote><p><em>user를 생성할 때 골뱅이 뒤 %는 모든 외부 ip의 접근을 허용한다는 뜻이다.</em></p></blockquote><h2 id="jdbc-to-HIVE-HOME-lib"><a href="#jdbc-to-HIVE-HOME-lib" class="headerlink" title="jdbc to $HIVE_HOME/lib/"></a>jdbc to $HIVE_HOME/lib/</h2><p>MySQL Driver를 해당 PATH로 복사한다.</p><p><code>$ cp tibero6-jdbc.jar /app/hive/lib/</code></p><blockquote><p><em>Driver URL : <a href="https://dev.mysql.com/downloads/connector/j/8.0.html" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/8.0.html</a></em></p></blockquote><h1 id="Hive-Configurations"><a href="#Hive-Configurations" class="headerlink" title="Hive Configurations"></a>Hive Configurations</h1><h2 id="hive-env-sh"><a href="#hive-env-sh" class="headerlink" title="hive-env.sh"></a>hive-env.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cp <span class="variable">$HIVE_HOME</span>/conf/hive-env.sh.template <span class="variable">$HIVE_HOME</span>/conf/hive-env.sh`</span><br><span class="line">$ vi <span class="variable">$HIVE_HOME</span>/conf/hive-env.sh</span><br><span class="line">HADOOP_HOME=/app/hadoop</span><br></pre></td></tr></table></figure><h2 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h2><p><code>hive-site.xml</code>을 아래와 같이 작성한다. <code>Hive</code>의 MetaStore를 외부 서버의 MySQL를 이용할 예정이다. <em>(Hive 설치된 서버와 별개의 서버이다. 만약 같은 서버라면, javax.jdo.option.ConnectionURL의 ip:port값은 localhost:port로 작성한다.)</em></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://ip:port/hive?serverTimezone=UTC<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.urls<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node5.dat:10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p><em>javax.jdo.option.ConnectionURL의 port 뒤 hive는 MetaStore로 사용하기 위한 MySQL DB name이다. 뒤에 serverTimezone arg를 추가한 이유는 추가하지 않으면 SchemaTool 초기화 시 에러 메세지가 뜬다. 결국엔 시간 형식이 맞지 않아 생기는 문제이므로 arg를 추가한다</em></p></blockquote><h2 id="Create-MetaStore-Schema"><a href="#Create-MetaStore-Schema" class="headerlink" title="Create MetaStore Schema"></a>Create MetaStore Schema</h2><p><code>schematool -initSchema -dbType mysql --verbose</code> 을 통해 <code>Hive</code>의 MetaStore를 초기화 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ schematool -initSchema -dbType mysql --verbose</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">beeline&gt; Initialization script completed</span><br><span class="line">schemaTool completed</span><br><span class="line">$ mysql -u hive -p</span><br><span class="line">mysql&gt; use hive;</span><br><span class="line">Reading table information <span class="keyword">for</span> completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------------------+</span><br><span class="line">| Tables_in_hive            |</span><br><span class="line">+---------------------------+</span><br><span class="line">| AUX_TABLE                 |</span><br><span class="line">| BUCKETING_COLS            |</span><br><span class="line">| CDS                       |</span><br><span class="line">| COLUMNS_V2                |</span><br><span class="line">| COMPACTION_QUEUE          |</span><br><span class="line">| COMPLETED_COMPACTIONS     |</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">| SERDE_PARAMS              |</span><br><span class="line">| TYPES                     |</span><br><span class="line">| TYPE_FIELDS               |</span><br><span class="line">| VERSION                   |</span><br><span class="line">| WRITE_SET                 |</span><br><span class="line">+---------------------------+</span><br><span class="line">57 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="Run-HiveServer-amp-MetaStore"><a href="#Run-HiveServer-amp-MetaStore" class="headerlink" title="Run HiveServer &amp; MetaStore"></a>Run HiveServer &amp; MetaStore</h1><p><code>hiveserver2</code>와 <code>metastore</code>를 기동해주면 완료.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ hive --service hiveserver2 &amp;</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br><span class="line">$ hive --service metastore &amp;</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/app/hadoop/2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is of <span class="built_in">type</span> [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br></pre></td></tr></table></figure><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-install_hive/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] Mappers and Reducers</title>
      <link>https://jx2lee.github.io/python-map_reduce/</link>
      <guid>https://jx2lee.github.io/python-map_reduce/</guid>
      <pubDate>Wed, 30 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;hackerrank에서 제공하는 Database 카테고리의 MapReduce 문제를 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>hackerrank에서 제공하는 Database 카테고리의 MapReduce 문제를 풀어본다</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p><strong>Mappers and Reducers</strong></p><p><a href="http://www.slideshare.net/rantav/introduction-to-map-reduce" target="_blank" rel="noopener">Here’s</a> a quick but comprehensive introduction to the idea of splitting tasks into a MapReduce model. The four important functions involved are:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Map (the mapper function)  </span><br><span class="line">EmitIntermediate(the intermediate key,value pairs emitted by the mapper functions)  </span><br><span class="line">Reduce (the reducer function)  </span><br><span class="line">Emit (the final output, after summarization from the Reduce functions)</span><br></pre></td></tr></table></figure><p>We provide you with a single system, single thread version of a basic MapReduce implementation.</p><p><strong>Task</strong></p><p>Joins are</p><p>The input is a number of lines with pairs of name of friends, in the form:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Friend1] [Friend2]</span><br></pre></td></tr></table></figure><p>The required output is to print the number of friends of each person, in the format shown. The code for the MapReduce class, parts related to IO etc. has already been provided. However, the mapper and reducer functions are incomplete. Your task is to fill up the mapper and reducer functions appropriately, such that the program works, and outputs the list of number of friends of each person , in lexicographical order.</p><p>Also, this program outputs certain information to the error stream. This information has been logged to help beginners gain a better understanding of the the intermediate steps in a map-reduce process.</p><p><strong>Languages Supported</strong></p><p>Currently, we provide the base code in Python.</p><p><strong>Input Format</strong></p><p>A list of single space separated pairs of friend names. We have already written the input handling code to read in this data.</p><p><strong>Output Format</strong></p><p>Again, the output handling part has already been provided in the template code. The Key contains [Person name] and the value contains the number of friends, sorted in lexicographical order. The entities in this list, will naturally be confined to only those people provided in the input data.</p><p><strong>Sample Input</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Joe Sue</span><br><span class="line">Sue Phi</span><br><span class="line">Phi Joe</span><br><span class="line">Phi Alice</span><br></pre></td></tr></table></figure><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;key&quot;:&quot;Alice&quot;,&quot;value&quot;:&quot;1&quot;&#125;</span><br><span class="line">&#123;&quot;key&quot;:&quot;Joe&quot;,&quot;value&quot;:&quot;2&quot;&#125;</span><br><span class="line">&#123;&quot;key&quot;:&quot;Phi&quot;,&quot;value&quot;:&quot;3&quot;&#125;</span><br><span class="line">&#123;&quot;key&quot;:&quot;Sue&quot;,&quot;value&quot;:&quot;2&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>We have computed the number of friends for each person via the Mapper and Reducer functions.</p><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p>full code 는 아래와 같다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MapReduce</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.intermediate = OrderedDict()</span><br><span class="line">        self.result = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">emitIntermediate</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        self.intermediate.setdefault(key, [])</span><br><span class="line">        self.intermediate[key].append(value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">emit</span><span class="params">(self, value)</span>:</span></span><br><span class="line">        self.result.append(value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self, data, mapper, reducer)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> data:</span><br><span class="line">            mapper(record)</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> self.intermediate:</span><br><span class="line">            reducer(key, self.intermediate[key])</span><br><span class="line"></span><br><span class="line">        self.result.sort()</span><br><span class="line">        print(self.result)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.result:</span><br><span class="line">            print(<span class="string">"&#123;\"key\":\""</span> + item[<span class="number">0</span>] + <span class="string">"\",\"value\":\""</span> + str(item[<span class="number">1</span>]) + <span class="string">"\"&#125;"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mapReducer = MapReduce()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(record)</span>:</span></span><br><span class="line">    <span class="comment"># Start writing the Map code here</span></span><br><span class="line">    words = record.split()</span><br><span class="line">    mapReducer.emitIntermediate(words[<span class="number">0</span>], words[<span class="number">1</span>])</span><br><span class="line">    mapReducer.emitIntermediate(words[<span class="number">1</span>], words[<span class="number">0</span>])</span><br><span class="line">    print(mapReducer.intermediate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer</span><span class="params">(key, list_of_values)</span>:</span></span><br><span class="line">    <span class="comment"># Start writing the Reduce code here</span></span><br><span class="line">    mapReducer.emit((key, len(list_of_values)))</span><br><span class="line">    print(mapReducer.result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># inputData = ['Joe Sue', 'Sue Phi', 'Phi Joe', 'Phi Alice']</span></span><br><span class="line">    inputData = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        inputData.append(line)</span><br><span class="line">    mapReducer.execute(inputData, mapper, reducer)</span><br></pre></td></tr></table></figure><p>우선, <code>mapReduce</code> class를 살펴본다.</p><h2 id="Class-mapReduce"><a href="#Class-mapReduce" class="headerlink" title="Class : mapReduce"></a>Class : mapReduce</h2><p>clss <code>mapReduce</code>는 <code>init</code> 함수를 포함 총 세 개의 함수를 갖는다.</p><h3 id="Func-init"><a href="#Func-init" class="headerlink" title="Func : init"></a>Func : init</h3><p><strong>init</strong>`함수로 인해 <strong>intermediate, result</strong> 변수를 갖는다. 이는 각각 <u>key-value로 이루어진 dictionary <em>(문제에서 원하는 단어 : 단어 출현 횟수를 의미)</em></u>와 <u>문제 정답에 맞는 형식의 Return</u> 값이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.intermediate = OrderedDict()</span><br><span class="line">    self.result = []</span><br></pre></td></tr></table></figure><h3 id="Func-emitIntermediate"><a href="#Func-emitIntermediate" class="headerlink" title="Func : emitIntermediate"></a>Func : emitIntermediate</h3><p>key-value 를 입력받아 dictionary에 추가하는 함수이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">emitIntermediate</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">    self.intermediate.setdefault(key, [])</span><br><span class="line">    self.intermediate[key].append(value)</span><br></pre></td></tr></table></figure><h3 id="Func-emit"><a href="#Func-emit" class="headerlink" title="Func : emit"></a>Func : emit</h3><p>각 단어의 출현 횟수를 집계한 후 결과값에 담는 함수이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">emit</span><span class="params">(self, value)</span>:</span></span><br><span class="line">    self.result.append(value)</span><br></pre></td></tr></table></figure><h3 id="Func-execute"><a href="#Func-execute" class="headerlink" title="Func : execute"></a>Func : execute</h3><p>입력받은 데이터를 읽어들여 나중에 우리가 작성해야할 <code>mapper / reducer</code>함수를 이용해 최종 결과값을 알맞는 형태로 출력하는 함수이다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self, data, mapper, reducer)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> data:</span><br><span class="line">        mapper(record)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> self.intermediate:</span><br><span class="line">        reducer(key, self.intermediate[key])</span><br><span class="line"></span><br><span class="line">    self.result.sort()</span><br><span class="line">    print(self.result)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> self.result:</span><br><span class="line">        print(<span class="string">"&#123;\"key\":\""</span> + item[<span class="number">0</span>] + <span class="string">"\",\"value\":\""</span> + str(item[<span class="number">1</span>]) + <span class="string">"\"&#125;"</span>)</span><br></pre></td></tr></table></figure><blockquote><p><em>실행함수(excutable fucntion)라 생각하자</em></p></blockquote><h2 id="Func-mapper"><a href="#Func-mapper" class="headerlink" title="Func : mapper"></a>Func : mapper</h2><p>이제 <code>mapper</code> 를 살펴본다. 입력받은 한 문장은 <code>split</code> 함수를 통해 두 단어로 나누어주고, 첫 번째 단어만 key로 인식하면 안되기 때문에 <code>mapReducer</code> 클래스에서 만든 emitIntermediate 함수를 <strong>두 번</strong> 수행한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(record)</span>:</span></span><br><span class="line">    <span class="comment"># Start writing the Map code here</span></span><br><span class="line">    words = record.split()</span><br><span class="line">    mapReducer.emitIntermediate(words[<span class="number">0</span>], words[<span class="number">1</span>])</span><br><span class="line">    mapReducer.emitIntermediate(words[<span class="number">1</span>], words[<span class="number">0</span>])</span><br><span class="line">    print(mapReducer.intermediate)</span><br></pre></td></tr></table></figure><p>과연 이 mapper 함수가 어떻게 작동되는지 문제에서 제공한 test case를 바탕으로 print 해보면 다음과 같이 출력된다. 즉, 같은 key값을 가지면 value로 append 해나간다. <em>(value값으로 계속해서 단어를 추가하는데 이는 나중에 <code>reducer</code> 함수에서 집계를 할 때 사용한다)</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;])])</span><br><span class="line">OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;])])</span><br><span class="line">OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;, &#39;Phi&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;, &#39;Joe&#39;])])</span><br><span class="line">OrderedDict([(&#39;Joe&#39;, [&#39;Sue&#39;, &#39;Phi&#39;]), (&#39;Sue&#39;, [&#39;Joe&#39;, &#39;Phi&#39;]), (&#39;Phi&#39;, [&#39;Sue&#39;, &#39;Joe&#39;, &#39;Alice&#39;]), (&#39;Alice&#39;, [&#39;Phi&#39;])])</span><br></pre></td></tr></table></figure><h2 id="Func-reducer"><a href="#Func-reducer" class="headerlink" title="Func : reducer"></a>Func : reducer</h2><p>key-value로 이루어진 dictionary를 집계해주는 reducer 함수이다. <code>mapReducer</code> 클래스의 <code>emit</code>함수를 통해 <em>result</em> 변수에 결과값을 저장한다. <strong>이때, 위 <code>mapper</code>함수를 통해 각 key에 대한 value들</strong>의 길이를 <u>key와 함께 append 한다.</u></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer</span><span class="params">(key, list_of_values)</span>:</span></span><br><span class="line">    <span class="comment"># Start writing the Reduce code here</span></span><br><span class="line">    mapReducer.emit((key, len(list_of_values)))</span><br><span class="line">    print(mapReducer.result)</span><br></pre></td></tr></table></figure><h2 id="Main"><a href="#Main" class="headerlink" title="Main"></a>Main</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># inputData = ['Joe Sue', 'Sue Phi', 'Phi Joe', 'Phi Alice']</span></span><br><span class="line">    inputData = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        inputData.append(line)</span><br><span class="line">    mapReducer.execute(inputData, mapper, reducer)</span><br></pre></td></tr></table></figure><blockquote><p><em>이렇게 class 및 function을 직접 짜보면서 설계하는 단계의 중요성을 깨달았다. Python을 이런 방식으로 코딩을 해보는 연습을 해야겠다</em></p></blockquote><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><ol><li><a href="https://github.com/cielavenir/procon/blob/master/hackerrank/map-reduce-advanced-count-number-of-friends.py" target="_blank" rel="noopener"> https://github.com/cielavenir/procon/blob/master/hackerrank/map-reduce-advanced-count-number-of-friends.py </a></li><li><a href="https://jayzzz.tistory.com/44" target="_blank" rel="noopener">하둡 맵리듀스(MapReduce) 알아보자,  https://jayzzz.tistory.com/44</a></li></ol><hr><p>2019.10.31 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-map_reduce/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Sqoop import 시 JDBC-90401:Connection refused by the server Error 발생</title>
      <link>https://jx2lee.github.io/hadoop-sqoop_jdbc_error/</link>
      <guid>https://jx2lee.github.io/hadoop-sqoop_jdbc_error/</guid>
      <pubDate>Tue, 29 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;상황&quot;&gt;&lt;a href=&quot;#상황&quot; class=&quot;headerlink&quot; title=&quot;상황&quot;&gt;&lt;/a&gt;상황&lt;/h1&gt;&lt;p&gt;Sqoop을 이용해 Tibero Table을 hdfs 형태로 변환하는 import 과정에서 ERROR가 발생하였다. 상황을 간단히 설명하면, 정보시스템 개발기 DB&lt;em&gt;(Tibero)&lt;/em&gt; Tabel을 팀 서버에 구축한 Hadoop 에&lt;em&gt;(51, 52 : DataNode, 53 : NameNode로 이하 숫자로 표현)&lt;/em&gt; 저장하고자 했다.
      
      </description>
      
      
      <content:encoded><![CDATA[<h1 id="상황"><a href="#상황" class="headerlink" title="상황"></a>상황</h1><p>Sqoop을 이용해 Tibero Table을 hdfs 형태로 변환하는 import 과정에서 ERROR가 발생하였다. 상황을 간단히 설명하면, 정보시스템 개발기 DB<em>(Tibero)</em> Tabel을 팀 서버에 구축한 Hadoop 에<em>(51, 52 : DataNode, 53 : NameNode로 이하 숫자로 표현)</em> 저장하고자 했다.<a id="more"></a>정보시스템에서 허용한 IP는 총 4개였고 그 중 하나인 69<em>(편하게 숫자로.. 대체하겠다)</em>에 <code>Sqoop</code>을 설치하여 Hadoop에 저장하려는 계획이었다. 간략히 각 서버와 현황을 나타내면 아래와 같다.</p><ul><li>Hadoop<ul><li>51, 52 : DataNode</li><li>53 : NameNode</li><li><strong>정보시스템 개발기 DB에 접근이 허용되지 않음</strong></li></ul></li><li>Sqoop<ul><li>69</li><li><strong>정보시스템 개발기 DB에 접근이 허용되지 않음</strong></li></ul></li></ul><p><code>Sqoop import</code> 명령어 <em>(sqoop import –connect jdbc:tibero:thin:@192.168.xx.xx:8629:tibero –driver com.tmax.tibero.jdbc.TbDriver –username xxxx –password xxxx –table PROJECT_INFO –delete-target-dir -m 1)</em> 를 날리면 아래와 같은 에러가 발생하였다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">sqoop@bips:/app/sqoop/sqoop$ sqoop import --connect jdbc:tibero:thin:@192.168.10.84:8629:tibero --driver com.tmax.tibero.jdbc.TbDriver --username tody -P --table PROJECT_INFO --delete-target-dir -m 1</span><br><span class="line">Warning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HBASE_HOME</span> to the root of your HBase installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog <span class="built_in">jobs</span> will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HCAT_HOME</span> to the root of your HCatalog installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ZOOKEEPER_HOME</span> to the root of your Zookeeper installation.</span><br><span class="line">19/10/30 09:32:49 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7</span><br><span class="line">Enter password: </span><br><span class="line">19/10/30 09:33:01 WARN sqoop.ConnFactory: Parameter --driver is <span class="built_in">set</span> to an explicit driver however appropriate connection manager is not being <span class="built_in">set</span> (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly <span class="built_in">which</span> connection manager should be used next time.</span><br><span class="line">19/10/30 09:33:01 INFO manager.SqlManager: Using default fetchSize of 1000</span><br><span class="line">19/10/30 09:33:01 INFO tool.CodeGenTool: Beginning code generation</span><br><span class="line">19/10/30 09:33:01 ERROR manager.SqlManager: Error executing statement: java.sql.SQLException: JDBC-90401:Connection refused by the server. - Connection refused (Connection refused)</span><br><span class="line">java.sql.SQLException: JDBC-90401:Connection refused by the server. - Connection refused (Connection refused)</span><br><span class="line">at com.tmax.tibero.jdbc.err.TbError.makeSQLException(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.err.TbError.newSQLException(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.comm.TbStream.&lt;init&gt;(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.comm.TbCommType4.createStream(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.driver.TbConnection.openConnection(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.TbDriver.connectInternal(Unknown Source)</span><br><span class="line">at com.tmax.tibero.jdbc.TbDriver.connect(Unknown Source)</span><br><span class="line">at java.sql.DriverManager.getConnection(DriverManager.java:664)</span><br><span class="line">at java.sql.DriverManager.getConnection(DriverManager.java:247)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.makeConnection(SqlManager.java:904)</span><br><span class="line">at org.apache.sqoop.manager.GenericJdbcManager.getConnection(GenericJdbcManager.java:59)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:763)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:786)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.getColumnInfoForRawQuery(SqlManager.java:289)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.getColumnTypesForRawQuery(SqlManager.java:260)</span><br><span class="line">at org.apache.sqoop.manager.SqlManager.getColumnTypes(SqlManager.java:246)</span><br><span class="line">at org.apache.sqoop.manager.ConnManager.getColumnTypes(ConnManager.java:327)</span><br><span class="line">at org.apache.sqoop.orm.ClassWriter.getColumnTypes(ClassWriter.java:1872)</span><br><span class="line">at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1671)</span><br><span class="line">at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:106)</span><br><span class="line">at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:501)</span><br><span class="line">at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628)</span><br><span class="line">at org.apache.sqoop.Sqoop.run(Sqoop.java:147)</span><br><span class="line">at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)</span><br><span class="line">at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)</span><br><span class="line">at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234)</span><br><span class="line">at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243)</span><br><span class="line">at org.apache.sqoop.Sqoop.main(Sqoop.java:252)</span><br><span class="line">19/10/30 09:33:01 ERROR tool.ImportTool: Import failed: java.io.IOException: No columns to generate <span class="keyword">for</span> ClassWriter</span><br><span class="line">at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1677)</span><br><span class="line">at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:106)</span><br><span class="line">at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:501)</span><br><span class="line">at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:628)</span><br><span class="line">at org.apache.sqoop.Sqoop.run(Sqoop.java:147)</span><br><span class="line">at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)</span><br><span class="line">at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:183)</span><br><span class="line">at org.apache.sqoop.Sqoop.runTool(Sqoop.java:234)</span><br><span class="line">at org.apache.sqoop.Sqoop.runTool(Sqoop.java:243)</span><br><span class="line">at org.apache.sqoop.Sqoop.main(Sqoop.java:252)</span><br></pre></td></tr></table></figure><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p><strong>결론부터 말하면 해결하지 못하는 문제</strong>이다. Hadoop이 JDBC를 통해 정보시스템 개발기 Tibero에 접근해야 하는데 <code>Sqoop</code>이 아래와 같은 구조를 갖는다.</p><p><img src="https://t1.daumcdn.net/cfile/tistory/255AAE415527751E16" alt=""></p><p><a href="https://t1.daumcdn.net/cfile/tistory/255AAE415527751E16" target="_blank" rel="noopener">참고 : https://t1.daumcdn.net/cfile/tistory/255AAE415527751E16</a></p><p>사진은 <code>Sqoop 1</code>의 Architecture이지만, 결국에 Sqoop이 Hadoop의 Map Task에게 태스크를 넘기면 Hadoop이 Database에 접근하는 형태이다. 즉, <strong>정보시스템 DB 접근이 허용되지 않는 Hadoop 환경</strong>에서는 Connection을 허용하지 않는다. 때문에 우리팀이 원래 시도하려던 했던 HDFS 형태로 파일을 떨구고 이를 불러오는 과정을 <em>아예 다른 식으로 접근하거나</em>, <em>우회 방안</em> 을 생각해야 한다. </p><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><p>Connection ERROR 해결 방안은 <strong>Hadoop이 Database에 접근 가능</strong>하게 환경을 구성해주면 된다. 하지만, 우리팀의 프로젝트는 이렇게 환경을 재구성하는 것이 쉽지 않다. 이에대해 다음 두 가지 방안이 있는데 구체적이지 않다. <del>(어떠한 방법이 더 효율적인지 더 고민해봐야겠다)</del></p><ul><li>If using Hadoop,<ul><li>Hadoop을 정보시스템 DB에 접근할 수 있는 환경에 설치</li><li>정보시스템 쪽에 접근 가능한 IP 추가 요청</li></ul></li><li>else,<ul><li>자사 제품 사용..</li></ul></li></ul><blockquote><p> <em>역량 강화를 위해서는 Hadoop system을 이용하는 것이 좋다는 개인적인 바람이 있다.</em></p></blockquote><hr><p>2019.10.30 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-sqoop_jdbc_error/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] 15 Days of Learning</title>
      <link>https://jx2lee.github.io/hackerrank-15_days_of_learning/</link>
      <guid>https://jx2lee.github.io/hackerrank-15_days_of_learning/</guid>
      <pubDate>Tue, 29 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;15 Days of Learning&lt;/code&gt; 를 SELECT sub query을 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>15 Days of Learning</code> 를 SELECT sub query을 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Julia conducted a days of learning SQL contest. The start date of the contest was <em>March 01, 2016</em> and the end date was <em>March 15, 2016</em>.</p><p>Write a query to print total number of unique hackers who made at least submission each day (starting on the first day of the contest), and find the <em>hacker_id</em> and <em>name</em> of the hacker who made maximum number of submissions each day. If more than one such hacker has a maximum number of submissions, print the lowest <em>hacker_id</em>. The query should print this information for each day of the contest, sorted by the date.</p><hr><p><strong>Input Format</strong></p><p>The following tables hold contest data:</p><ul><li><em>Hackers:</em> The <em>hacker_id</em> is the id of the hacker, and <em>name</em> is the name of the hacker.<img src="https://s3.amazonaws.com/hr-challenge-images/19597/1458511164-12adec3b8b-ScreenShot2016-03-21at3.26.47AM.png" alt="img"></li><li><em>Submissions:</em> The <em>submission_date</em> is the date of the submission, <em>submission_id</em> is the id of the submission, <em>hacker_id</em> is the id of the hacker who made the submission, and <em>score</em> is the score of the submission. <img src="https://s3.amazonaws.com/hr-challenge-images/19597/1458511251-0b534030b9-ScreenShot2016-03-21at3.26.56AM.png" alt="img"></li></ul><p><strong>Sample Input</strong></p><p>For the following sample input, assume that the end date of the contest was <em>March 06, 2016</em>.</p><p><em>Hackers</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19597/1458511957-814a2c7bf2-ScreenShot2016-03-21at3.27.06AM.png" alt="img"> <em>Submissions</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19597/1458512015-ff6a708164-ScreenShot2016-03-21at3.27.21AM.png" alt="img"></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2016-03-01 4 20703 Angela</span><br><span class="line">2016-03-02 2 79722 Michael</span><br><span class="line">2016-03-03 2 20703 Angela</span><br><span class="line">2016-03-04 2 20703 Angela</span><br><span class="line">2016-03-05 1 36396 Frank</span><br><span class="line">2016-03-06 1 20703 Angela</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>On <em>March 01, 2016</em> hackers , , , and made submissions. There are unique hackers who made at least one submission each day. As each hacker made one submission, is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is <em>Angela</em>.</p><p>On <em>March 02, 2016</em> hackers , , and made submissions. Now and were the only ones to submit every day, so there are unique hackers who made at least one submission each day. made submissions, and name of the hacker is <em>Michael</em>.</p><p>On <em>March 03, 2016</em> hackers , , and made submissions. Now and were the only ones, so there are unique hackers who made at least one submission each day. As each hacker made one submission so is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is <em>Angela</em>.</p><p>On <em>March 04, 2016</em> hackers , , , and made submissions. Now and only submitted each day, so there are unique hackers who made at least one submission each day. As each hacker made one submission so is considered to be the hacker who made maximum number of submissions on this day. The name of the hacker is <em>Angela</em>.</p><p>On <em>March 05, 2016</em> hackers , , and made submissions. Now only submitted each day, so there is only unique hacker who made at least one submission each day. made submissions and name of the hacker is <em>Frank</em>.</p><p>On <em>March 06, 2016</em> only made submission, so there is only unique hacker who made at least one submission each day. made submission and name of the hacker is <em>Angela</em>.</p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>Join</code>을 이용해 문제를 풀려다 실패하였다. 이에 제공되는 Table이 2개인 점을 활용하여 SELECT 절 내 Sub query를 작성하는 것으로 접근하였다.</p><p>우선, 유일한 제출 날짜 Table로 부터 <em>제출 날짜가 같고 제출 마감일까지 날짜 차이가 같은 유일한 hacker_id</em> 를 조회하는 SELECT 문을 작성한다. 이때, 최종 결과물은 날짜를 기준으로 group화 시킨다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    submission_date,</span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> hacker_id)</span><br><span class="line">     <span class="keyword">from</span> submissions <span class="keyword">as</span> s2</span><br><span class="line">     <span class="keyword">where</span> s2.submission_date = s1.submission_date <span class="keyword">and</span></span><br><span class="line">     (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> s3.submission_date)</span><br><span class="line">      <span class="keyword">from</span> submissions <span class="keyword">as</span> s3</span><br><span class="line">      <span class="keyword">where</span> s3.hacker_id = s2.hacker_id <span class="keyword">and</span> s3.submission_date &lt; s1.submission_date) = <span class="keyword">datediff</span>(s1.submission_date, <span class="string">'2016-03-01'</span>)),</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">distinct</span> submission_date <span class="keyword">from</span> submissions) <span class="keyword">as</span> s1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> submission_date;</span><br></pre></td></tr></table></figure><p>이후, <em>제출을 가장 많이 한 hacker의 id를 조회한 id table</em> 과 <em>id table을 이용해 hacker 이름을 조회</em> 하는 SELECT Sub query를 추가한다. 이때, id table의 경우 가장 많이 제출한 hacker만 뽑아야 하기 때문에 중복을 피하고자 <code>LIMIT 1</code>을 추가한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    submission_date,</span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> hacker_id)</span><br><span class="line">     <span class="keyword">from</span> submissions <span class="keyword">as</span> s2</span><br><span class="line">     <span class="keyword">where</span> s2.submission_date = s1.submission_date <span class="keyword">and</span></span><br><span class="line">     (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> s3.submission_date)</span><br><span class="line">      <span class="keyword">from</span> submissions <span class="keyword">as</span> s3</span><br><span class="line">      <span class="keyword">where</span> s3.hacker_id = s2.hacker_id <span class="keyword">and</span> s3.submission_date &lt; s1.submission_date) = <span class="keyword">datediff</span>(s1.submission_date, <span class="string">'2016-03-01'</span>)),</span><br><span class="line">    <span class="comment">--append</span></span><br><span class="line">    (<span class="keyword">select</span> hacker_id</span><br><span class="line">     <span class="keyword">from</span> submissions <span class="keyword">as</span> s2</span><br><span class="line">     <span class="keyword">where</span> s2.submission_date = s1.submission_date</span><br><span class="line">     <span class="keyword">group</span> <span class="keyword">by</span> hacker_id</span><br><span class="line">     <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">count</span>(submission_id) <span class="keyword">desc</span>, hacker_id <span class="keyword">limit</span> <span class="number">1</span>) <span class="keyword">as</span> <span class="keyword">id</span>,</span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">name</span> <span class="keyword">from</span> hackers <span class="keyword">where</span> hacker_id = <span class="keyword">id</span>)</span><br><span class="line">    <span class="comment">--/append</span></span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">distinct</span> submission_date <span class="keyword">from</span> submissions) <span class="keyword">as</span> s1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> submission_date;</span><br></pre></td></tr></table></figure><blockquote><p><em>문제 접근할 때 Join만 바라보지 않고 SELECT / FROM / WHERE 절에서 Sub query를 작성하는 안목을 키워보자. (물론 hackerrank의 문제는 끝났다..)</em></p></blockquote><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    submission_date,</span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> hacker_id)</span><br><span class="line">     <span class="keyword">from</span> submissions <span class="keyword">as</span> s2</span><br><span class="line">     <span class="keyword">where</span> s2.submission_date = s1.submission_date <span class="keyword">and</span></span><br><span class="line">     (<span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> s3.submission_date)</span><br><span class="line">      <span class="keyword">from</span> submissions <span class="keyword">as</span> s3</span><br><span class="line">      <span class="keyword">where</span> s3.hacker_id = s2.hacker_id <span class="keyword">and</span> s3.submission_date &lt; s1.submission_date) = <span class="keyword">datediff</span>(s1.submission_date, <span class="string">'2016-03-01'</span>)),</span><br><span class="line">    (<span class="keyword">select</span> hacker_id</span><br><span class="line">     <span class="keyword">from</span> submissions <span class="keyword">as</span> s2</span><br><span class="line">     <span class="keyword">where</span> s2.submission_date = s1.submission_date</span><br><span class="line">     <span class="keyword">group</span> <span class="keyword">by</span> hacker_id</span><br><span class="line">     <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">count</span>(submission_id) <span class="keyword">desc</span>, hacker_id <span class="keyword">limit</span> <span class="number">1</span>) <span class="keyword">as</span> <span class="keyword">id</span>,</span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">name</span> <span class="keyword">from</span> hackers <span class="keyword">where</span> hacker_id = <span class="keyword">id</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">distinct</span> submission_date <span class="keyword">from</span> submissions) <span class="keyword">as</span> s1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> submission_date;</span><br></pre></td></tr></table></figure><hr><p>2019.10.30 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-15_days_of_learning/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Sqoop import/export with Tibero</title>
      <link>https://jx2lee.github.io/hadoop-sqoop_with_tibero/</link>
      <guid>https://jx2lee.github.io/hadoop-sqoop_with_tibero/</guid>
      <pubDate>Tue, 29 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;Sqoop&lt;/code&gt;을 이용해 Tibero table을 HDFS로 저장하고 이를 다시 table로 변환하는 테스트를 진행한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>Sqoop</code>을 이용해 Tibero table을 HDFS로 저장하고 이를 다시 table로 변환하는 테스트를 진행한다.</p><a id="more"></a><h1 id="Create-Test-table"><a href="#Create-Test-table" class="headerlink" title="Create Test table"></a>Create Test table</h1><p>우선, <code>Import</code>하려는 table을 생성한다. 중요한 것은 <strong>export하기 위한 table도 생성</strong>해야 한다는 점이다.</p><ul><li>Import table : RECIPES</li><li>Export table : RECIPES_EXP</li></ul><h2 id="Import-table"><a href="#Import-table" class="headerlink" title="Import table"></a>Import table</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">USERS</span>(</span><br><span class="line">USERNO <span class="built_in">NUMBER</span>,</span><br><span class="line">EMAIL <span class="built_in">VARCHAR2</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">PWD <span class="built_in">VARCHAR2</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line"><span class="keyword">NAME</span> <span class="built_in">VARCHAR2</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">PNO <span class="built_in">VARCHAR2</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">ADDRESS <span class="built_in">VARCHAR2</span>(<span class="number">255</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> recipes (recipe_id, recipe_name) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">'Tacos'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> recipes (recipe_id, recipe_name) <span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">'Tomato Soup'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> recipes (recipe_id, recipe_name) <span class="keyword">VALUES</span> (<span class="number">3</span>,<span class="string">'Grilled Cheese'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- checking table</span></span><br><span class="line">SQL&gt; SELECT * FROM RECIPES;</span><br><span class="line"> RECIPE_ID RECIPE_NAME                   </span><br><span class="line"><span class="comment">---------- ------------------------------</span></span><br><span class="line">         3 Grilled Cheese</span><br><span class="line">         1 Tacos</span><br><span class="line">         2 Tomato Soup</span><br><span class="line">3 rows selected.</span><br></pre></td></tr></table></figure><h2 id="Export-table"><a href="#Export-table" class="headerlink" title="Export table"></a>Export table</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> recipes_exp (</span><br><span class="line">  recipe_id <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  recipe_name <span class="built_in">VARCHAR</span>(<span class="number">30</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (recipe_id),</span><br><span class="line">  <span class="keyword">UNIQUE</span> (recipe_name)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h1 id="Sqoop-Import"><a href="#Sqoop-Import" class="headerlink" title="Sqoop Import"></a>Sqoop Import</h1><p>table이 준비되었다면 <code>Sqoop</code>을 이용해 HDFS 형태로 Hadoop에 저장해본다. 명령어와 수행결과는 아래와 같다.</p><h2 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero \</span><br><span class="line">--driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">--username tibero --password [password] \</span><br><span class="line">--table RECIPES \</span><br><span class="line">--target-dir /t1/input</span><br></pre></td></tr></table></figure><blockquote><p><em>Tibero 접속을 위한 string은 위와 같이 작성하고, MySQL/PostgreSQL의 경우 driver를 지정하지 않아도 되지만 Oracle/Tibero는 driver를 설정해야 한다. (MySQL/PostgreSQL : direct connect 지원이라고 document에 명시)</em></p></blockquote><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">sqoop@bips:~$ sqoop import --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero \</span><br><span class="line">&gt; --driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">&gt; --username tibero --password tmax \</span><br><span class="line">&gt; --table RECIPES \</span><br><span class="line">&gt; --target-dir /t1/input</span><br><span class="line">Warning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HBASE_HOME</span> to the root of your HBase installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog <span class="built_in">jobs</span> will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HCAT_HOME</span> to the root of your HCatalog installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ZOOKEEPER_HOME</span> to the root of your Zookeeper installation.</span><br><span class="line">19/10/30 10:09:24 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7</span><br><span class="line">19/10/30 10:09:24 WARN tool.BaseSqoopTool: Setting your password on the <span class="built_in">command</span>-line is insecure. Consider using -P instead.</span><br><span class="line">19/10/30 10:09:24 WARN sqoop.ConnFactory: Parameter --driver is <span class="built_in">set</span> to an explicit driver however appropriate connection manager is not being <span class="built_in">set</span> (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly <span class="built_in">which</span> connection manager should be used next time.</span><br><span class="line">19/10/30 10:09:24 INFO manager.SqlManager: Using default fetchSize of 1000</span><br><span class="line">19/10/30 10:09:24 INFO tool.CodeGenTool: Beginning code generation</span><br><span class="line">19/10/30 10:09:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=0</span><br><span class="line">19/10/30 10:09:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=0</span><br><span class="line">19/10/30 10:09:25 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /app/hadoop</span><br><span class="line">Note: /tmp/sqoop-sqoop/compile/905c294a54718643bcf983498f8878ba/RECIPES.java uses or overrides a deprecated API.</span><br><span class="line">Note: Recompile with -Xlint:deprecation <span class="keyword">for</span> details.</span><br><span class="line">19/10/30 10:09:26 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-sqoop/compile/905c294a54718643bcf983498f8878ba/RECIPES.jar</span><br><span class="line">19/10/30 10:09:26 INFO mapreduce.ImportJobBase: Beginning import of RECIPES</span><br><span class="line">19/10/30 10:09:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar</span><br><span class="line">19/10/30 10:09:26 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES AS t WHERE 1=0</span><br><span class="line">19/10/30 10:09:27 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps</span><br><span class="line">19/10/30 10:09:27 INFO client.RMProxy: Connecting to ResourceManager at node5.dat/192.168.158.53:8050</span><br><span class="line">19/10/30 10:09:31 INFO db.DBInputFormat: Using <span class="built_in">read</span> commited transaction isolation</span><br><span class="line">19/10/30 10:09:31 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(RECIPE_ID), MAX(RECIPE_ID) FROM RECIPES</span><br><span class="line">19/10/30 10:09:31 INFO mapreduce.JobSubmitter: number of splits:4</span><br><span class="line">19/10/30 10:09:31 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled</span><br><span class="line">19/10/30 10:09:31 INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_1567153359966_0069</span><br><span class="line">19/10/30 10:09:31 INFO impl.YarnClientImpl: Submitted application application_1567153359966_0069</span><br><span class="line">19/10/30 10:09:31 INFO mapreduce.Job: The url to track the job: http://node5.dat:8088/proxy/application_1567153359966_0069/</span><br><span class="line">19/10/30 10:09:31 INFO mapreduce.Job: Running job: job_1567153359966_0069</span><br><span class="line">19/10/30 10:09:35 INFO mapreduce.Job: Job job_1567153359966_0069 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span><br><span class="line">19/10/30 10:09:35 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">19/10/30 10:09:39 INFO mapreduce.Job:  map 50% reduce 0%</span><br><span class="line">19/10/30 10:09:40 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">19/10/30 10:09:41 INFO mapreduce.Job: Job job_1567153359966_0069 completed successfully</span><br><span class="line">19/10/30 10:09:41 INFO mapreduce.Job: Counters: 30</span><br><span class="line">File System Counters</span><br><span class="line">FILE: Number of bytes <span class="built_in">read</span>=0</span><br><span class="line">FILE: Number of bytes written=830592</span><br><span class="line">FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">FILE: Number of write operations=0</span><br><span class="line">HDFS: Number of bytes <span class="built_in">read</span>=447</span><br><span class="line">HDFS: Number of bytes written=39</span><br><span class="line">HDFS: Number of <span class="built_in">read</span> operations=16</span><br><span class="line">HDFS: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">HDFS: Number of write operations=8</span><br><span class="line">Job Counters </span><br><span class="line">Launched map tasks=4</span><br><span class="line">Other <span class="built_in">local</span> map tasks=4</span><br><span class="line">Total time spent by all maps <span class="keyword">in</span> occupied slots (ms)=8334</span><br><span class="line">Total time spent by all reduces <span class="keyword">in</span> occupied slots (ms)=0</span><br><span class="line">Total time spent by all map tasks (ms)=8334</span><br><span class="line">Total vcore-milliseconds taken by all map tasks=8334</span><br><span class="line">Total megabyte-milliseconds taken by all map tasks=8534016</span><br><span class="line">Map-Reduce Framework</span><br><span class="line">Map input records=3</span><br><span class="line">Map output records=3</span><br><span class="line">Input split bytes=447</span><br><span class="line">Spilled Records=0</span><br><span class="line">Failed Shuffles=0</span><br><span class="line">Merged Map outputs=0</span><br><span class="line">GC time elapsed (ms)=162</span><br><span class="line">CPU time spent (ms)=3530</span><br><span class="line">Physical memory (bytes) snapshot=827170816</span><br><span class="line">Virtual memory (bytes) snapshot=8600104960</span><br><span class="line">Total committed heap usage (bytes)=585629696</span><br><span class="line">File Input Format Counters </span><br><span class="line">Bytes Read=0</span><br><span class="line">File Output Format Counters </span><br><span class="line">Bytes Written=39</span><br><span class="line">19/10/30 10:09:41 INFO mapreduce.ImportJobBase: Transferred 39 bytes <span class="keyword">in</span> 14.9856 seconds (2.6025 bytes/sec)</span><br><span class="line">19/10/30 10:09:41 INFO mapreduce.ImportJobBase: Retrieved 3 records.</span><br></pre></td></tr></table></figure><h2 id="Checking"><a href="#Checking" class="headerlink" title="Checking"></a>Checking</h2><p>제대로 hadoop에 저장되어있는지 확인해본다. <code>hdfs</code>명령어를 이용해 파일이 정상적으로 저장되었는지 확인한다.</p><p><code>hdfs dfs -cat /t1/input/*</code> or <code>hdfs dfs -ls /t1/input</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sqoop@bips:~$ hdfs dfs -cat /t1/input/*</span><br><span class="line">1,Tacos</span><br><span class="line">2,Tomato Soup</span><br><span class="line">3,Grilled Cheese</span><br><span class="line">sqoop@bips:~$ hdfs dfs -ls /t1/input</span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   2 sqoop supergroup          0 2019-10-30 10:09 /t1/input/_SUCCESS</span><br><span class="line">-rw-r--r--   2 sqoop supergroup          8 2019-10-30 10:09 /t1/input/part-m-00000</span><br><span class="line">-rw-r--r--   2 sqoop supergroup          0 2019-10-30 10:09 /t1/input/part-m-00001</span><br><span class="line">-rw-r--r--   2 sqoop supergroup         14 2019-10-30 10:09 /t1/input/part-m-00002</span><br><span class="line">-rw-r--r--   2 sqoop supergroup         17 2019-10-30 10:09 /t1/input/part-m-00003</span><br></pre></td></tr></table></figure><h1 id="Sqoop-Export"><a href="#Sqoop-Export" class="headerlink" title="Sqoop Export"></a>Sqoop Export</h1><p>이번엔 HDFS를 Tibero table로 다시 변환하는 작업을 진행한다. 명령어와 수행결과는 다음과 같다.</p><h2 id="CMD-1"><a href="#CMD-1" class="headerlink" title="CMD"></a>CMD</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:tibero:thin:@192.168.xxx.xx:xxx:tibero \</span><br><span class="line">--driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">--username tibero --password ?? \</span><br><span class="line">--table RECIPES_EXP \</span><br><span class="line">--<span class="built_in">export</span>-dir /t1/input</span><br></pre></td></tr></table></figure><blockquote><p><em>위에서도 언급했듯이 export table이 Tibero에 이미 존재해야 한다.</em></p></blockquote><h2 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">sqoop@bips:~$ sqoop <span class="built_in">export</span> --connect jdbc:tibero:thin:@192.168.158.53:8729:tibero \</span><br><span class="line">&gt; --driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">&gt; --username tibero --password tmax \</span><br><span class="line">&gt; --table RECIPES_EXP \</span><br><span class="line">&gt; --<span class="built_in">export</span>-dir /t1/input</span><br><span class="line">Warning: /app/sqoop/sqoop/../hbase does not exist! HBase imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HBASE_HOME</span> to the root of your HBase installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../hcatalog does not exist! HCatalog <span class="built_in">jobs</span> will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$HCAT_HOME</span> to the root of your HCatalog installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../accumulo does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.</span><br><span class="line">Warning: /app/sqoop/sqoop/../zookeeper does not exist! Accumulo imports will fail.</span><br><span class="line">Please <span class="built_in">set</span> <span class="variable">$ZOOKEEPER_HOME</span> to the root of your Zookeeper installation.</span><br><span class="line">19/10/30 10:40:23 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7</span><br><span class="line">19/10/30 10:40:23 WARN tool.BaseSqoopTool: Setting your password on the <span class="built_in">command</span>-line is insecure. Consider using -P instead.</span><br><span class="line">19/10/30 10:40:23 WARN sqoop.ConnFactory: Parameter --driver is <span class="built_in">set</span> to an explicit driver however appropriate connection manager is not being <span class="built_in">set</span> (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly <span class="built_in">which</span> connection manager should be used next time.</span><br><span class="line">19/10/30 10:40:23 INFO manager.SqlManager: Using default fetchSize of 1000</span><br><span class="line">19/10/30 10:40:23 INFO tool.CodeGenTool: Beginning code generation</span><br><span class="line">19/10/30 10:40:24 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=0</span><br><span class="line">19/10/30 10:40:24 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=0</span><br><span class="line">19/10/30 10:40:24 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /app/hadoop</span><br><span class="line">Note: /tmp/sqoop-sqoop/compile/bc292d345cc3a16972516454f904b6df/RECIPES_EXP.java uses or overrides a deprecated API.</span><br><span class="line">Note: Recompile with -Xlint:deprecation <span class="keyword">for</span> details.</span><br><span class="line">19/10/30 10:40:25 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-sqoop/compile/bc292d345cc3a16972516454f904b6df/RECIPES_EXP.jar</span><br><span class="line">19/10/30 10:40:25 INFO mapreduce.ExportJobBase: Beginning <span class="built_in">export</span> of RECIPES_EXP</span><br><span class="line">19/10/30 10:40:25 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar</span><br><span class="line">19/10/30 10:40:25 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM RECIPES_EXP AS t WHERE 1=0</span><br><span class="line">19/10/30 10:40:25 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative</span><br><span class="line">19/10/30 10:40:25 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative</span><br><span class="line">19/10/30 10:40:25 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps</span><br><span class="line">19/10/30 10:40:25 INFO client.RMProxy: Connecting to ResourceManager at node5.dat/192.168.158.53:8050</span><br><span class="line">19/10/30 10:40:29 INFO input.FileInputFormat: Total input files to process : 4</span><br><span class="line">19/10/30 10:40:29 INFO input.FileInputFormat: Total input files to process : 4</span><br><span class="line">19/10/30 10:40:29 INFO mapreduce.JobSubmitter: number of splits:4</span><br><span class="line">19/10/30 10:40:29 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative</span><br><span class="line">19/10/30 10:40:29 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled</span><br><span class="line">19/10/30 10:40:29 INFO mapreduce.JobSubmitter: Submitting tokens <span class="keyword">for</span> job: job_1567153359966_0071</span><br><span class="line">19/10/30 10:40:30 INFO impl.YarnClientImpl: Submitted application application_1567153359966_0071</span><br><span class="line">19/10/30 10:40:30 INFO mapreduce.Job: The url to track the job: http://node5.dat:8088/proxy/application_1567153359966_0071/</span><br><span class="line">19/10/30 10:40:30 INFO mapreduce.Job: Running job: job_1567153359966_0071</span><br><span class="line">19/10/30 10:40:35 INFO mapreduce.Job: Job job_1567153359966_0071 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span><br><span class="line">19/10/30 10:40:35 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">19/10/30 10:40:40 INFO mapreduce.Job:  map 75% reduce 0%</span><br><span class="line">19/10/30 10:40:41 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">19/10/30 10:40:41 INFO mapreduce.Job: Job job_1567153359966_0071 completed successfully</span><br><span class="line">19/10/30 10:40:41 INFO mapreduce.Job: Counters: 31</span><br><span class="line">File System Counters</span><br><span class="line">FILE: Number of bytes <span class="built_in">read</span>=0</span><br><span class="line">FILE: Number of bytes written=829388</span><br><span class="line">FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">FILE: Number of write operations=0</span><br><span class="line">HDFS: Number of bytes <span class="built_in">read</span>=656</span><br><span class="line">HDFS: Number of bytes written=0</span><br><span class="line">HDFS: Number of <span class="built_in">read</span> operations=22</span><br><span class="line">HDFS: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">HDFS: Number of write operations=0</span><br><span class="line">Job Counters </span><br><span class="line">Launched map tasks=4</span><br><span class="line">Other <span class="built_in">local</span> map tasks=1</span><br><span class="line">Data-local map tasks=3</span><br><span class="line">Total time spent by all maps <span class="keyword">in</span> occupied slots (ms)=14227</span><br><span class="line">Total time spent by all reduces <span class="keyword">in</span> occupied slots (ms)=0</span><br><span class="line">Total time spent by all map tasks (ms)=14227</span><br><span class="line">Total vcore-milliseconds taken by all map tasks=14227</span><br><span class="line">Total megabyte-milliseconds taken by all map tasks=14568448</span><br><span class="line">Map-Reduce Framework</span><br><span class="line">Map input records=3</span><br><span class="line">Map output records=3</span><br><span class="line">Input split bytes=586</span><br><span class="line">Spilled Records=0</span><br><span class="line">Failed Shuffles=0</span><br><span class="line">Merged Map outputs=0</span><br><span class="line">GC time elapsed (ms)=425</span><br><span class="line">CPU time spent (ms)=4140</span><br><span class="line">Physical memory (bytes) snapshot=811102208</span><br><span class="line">Virtual memory (bytes) snapshot=8589045760</span><br><span class="line">Total committed heap usage (bytes)=606601216</span><br><span class="line">File Input Format Counters </span><br><span class="line">Bytes Read=0</span><br><span class="line">File Output Format Counters </span><br><span class="line">Bytes Written=0</span><br><span class="line">19/10/30 10:40:41 INFO mapreduce.ExportJobBase: Transferred 656 bytes <span class="keyword">in</span> 15.7366 seconds (41.6862 bytes/sec)</span><br><span class="line">19/10/30 10:40:41 INFO mapreduce.ExportJobBase: Exported 3 records.</span><br><span class="line">​</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Checking</span><br><span class="line"></span><br><span class="line">제대로 테이블로 데이터가 들어갔는지 확인해본다. &#96;Sqoop&#96;에서 &#96;--query&#96; argument를 주어 &#96;RECIPES_EXP&#96;를 조회해보자</span><br><span class="line"></span><br><span class="line">&#96;sqoop eval --connect jdbc:tibero:thin:@192.168.xxx.xx:xxxx:tibero --driver com.tmax.tibero.jdbc.TbDriver --username tibero --password ?? --query &#39;SELECT * FROM RECIPES_EXP&#39;&#96;</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;bash</span><br><span class="line">sqoop@bips:~$ sqoop eval --connect jdbc:tibero:thin:@192.168.158.53:8729:tibero \</span><br><span class="line">&gt; --driver com.tmax.tibero.jdbc.TbDriver \</span><br><span class="line">&gt; --username tibero --password tmax --query &#39;SELECT * FROM RECIPES_EXP&#39;</span><br><span class="line">Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;hbase does not exist! HBase imports will fail.</span><br><span class="line">Please set $HBASE_HOME to the root of your HBase installation.</span><br><span class="line">Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;hcatalog does not exist! HCatalog jobs will fail.</span><br><span class="line">Please set $HCAT_HOME to the root of your HCatalog installation.</span><br><span class="line">Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;accumulo does not exist! Accumulo imports will fail.</span><br><span class="line">Please set $ACCUMULO_HOME to the root of your Accumulo installation.</span><br><span class="line">Warning: &#x2F;app&#x2F;sqoop&#x2F;sqoop&#x2F;..&#x2F;zookeeper does not exist! Accumulo imports will fail.</span><br><span class="line">Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.</span><br><span class="line">19&#x2F;10&#x2F;30 10:41:54 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7</span><br><span class="line">19&#x2F;10&#x2F;30 10:41:54 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.</span><br><span class="line">19&#x2F;10&#x2F;30 10:41:54 WARN sqoop.ConnFactory: Parameter --driver is set to an explicit driver however appropriate connection manager is not being set (via --connection-manager). Sqoop is going to fall back to org.apache.sqoop.manager.GenericJdbcManager. Please specify explicitly which connection manager should be used next time.</span><br><span class="line">19&#x2F;10&#x2F;30 10:41:54 INFO manager.SqlManager: Using default fetchSize of 1000</span><br><span class="line">-----------------------------------------------</span><br><span class="line">| RECIPE_ID            | RECIPE_NAME          | </span><br><span class="line">-----------------------------------------------</span><br><span class="line">| 3                    | Grilled Cheese       | </span><br><span class="line">| 1                    | Tacos                | </span><br><span class="line">| 2                    | Tomato Soup          | </span><br><span class="line">-----------------------------------------------</span><br></pre></td></tr></table></figure><p><strong>export 가 정상 작동됐음을 확인할 수 있다</strong></p><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><ol><li><a href="https://dlwjdcks5343.tistory.com/116" target="_blank" rel="noopener">플밍장군님 블로그 :  https://dlwjdcks5343.tistory.com/116 </a></li><li><a href="https://blog.voidmainvoid.net/175" target="_blank" rel="noopener">AndersonChoi 님 블로그 :  https://blog.voidmainvoid.net/175 </a></li><li><a href="https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_free_form_query_imports" target="_blank" rel="noopener">Sqoop Documents :  https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_free_form_query_imports</a></li></ol><hr><p>2019.10.30 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-sqoop_with_tibero/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Interviews</title>
      <link>https://jx2lee.github.io/hackerrank-interviews/</link>
      <guid>https://jx2lee.github.io/hackerrank-interviews/</guid>
      <pubDate>Sun, 27 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Interviews&lt;/code&gt; 문제를 multiple join 및 group by를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Interviews</code> 문제를 multiple join 및 group by를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Samantha interviews many candidates from different colleges using coding challenges and contests. Write a query to print the <em>contest_id</em>, <em>hacker_id</em>, <em>name</em>, and the sums of <em>total_submissions</em>, <em>total_accepted_submissions</em>, <em>total_views</em>, and <em>total_unique_views</em> for each contest sorted by <em>contest_id</em>. Exclude the contest from the result if all four sums are .</p><p><strong>Note:</strong> A specific contest can be used to screen candidates at more than one college, but each college only holds  screening contest.</p><hr><p><strong>Input Format</strong></p><p>The following tables hold interview data:</p><ul><li><em>Contests:</em> The <em>contest_id</em> is the id of the contest, <em>hacker_id</em> is the id of the hacker who created the contest, and <em>name</em> is the name of the hacker. <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458517426-e017c3460e-ScreenShot2016-03-21at4.57.47AM.png" alt="img"></li><li><em>Colleges:</em> The <em>college_id</em> is the id of the college, and <em>contest_id</em> is the id of the contest that Samantha used to screen the candidates. <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458517503-fd4aa63111-ScreenShot2016-03-21at4.57.56AM.png" alt="img"></li><li><em>Challenges:</em> The <em>challenge_id</em> is the id of the challenge that belongs to one of the contests whose contest_id Samantha forgot, and <em>college_id</em> is the id of the college where the challenge was given to candidates. <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458517661-a642f750ce-ScreenShot2016-03-21at4.58.04AM.png" alt="img"></li><li><em>View_Stats:</em> The <em>challenge_id</em> is the id of the challenge, <em>total_views</em> is the number of times the challenge was viewed by candidates, and <em>total_unique_views</em> is the number of times the challenge was viewed by unique candidates. <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458517983-b4302286a8-ScreenShot2016-03-21at4.58.15AM.png" alt="img"></li><li><em>Submission_Stats:</em> The <em>challenge_id</em> is the id of the challenge, <em>total_submissions</em> is the number of submissions for the challenge, and <em>total_accepted_submission</em> is the number of submissions that achieved full scores. <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458518090-80983c916a-ScreenShot2016-03-21at4.58.27AM.png" alt="img"></li></ul><hr><p><strong>Sample Input</strong></p><p><em>Contests</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458519044-d788f8a6ee-ScreenShot2016-03-21at4.58.39AM.png" alt="img"> <em>Colleges</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458519098-912836d6ac-ScreenShot2016-03-21at4.59.22AM.png" alt="img"> <em>Challenges*Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458519120-c531743caf-ScreenShot2016-03-21at4.59.32AM.png" alt="img"> *View_Stats</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458519152-107a67866b-ScreenShot2016-03-21at4.59.43AM.png" alt="img"><em>Submission_Stats</em> Table: <img src="https://s3.amazonaws.com/hr-challenge-images/19596/1458519173-091aba871a-ScreenShot2016-03-21at4.59.55AM.png" alt="img"></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">66406 17973 Rose 111 39 156 56</span><br><span class="line">66556 79153 Angela 0 0 11 10</span><br><span class="line">94828 80275 Frank 150 38 41 15</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>The contest  is used in the college . In this college , challenges  and  are asked, so from the <em>view</em> and <em>submission</em> stats:</p><ul><li>Sum of total submissions </li><li>Sum of total accepted submissions </li><li>Sum of total views </li><li>Sum of total unique views </li></ul><p>Similarly, we can find the sums for contests  and .</p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p>Join 유형 중 <code>Left Join</code>을 활용하여 해결하였다. 다수의 table을 특정 키를 기준으로 <code>Join</code>하는 것이 다소 헷갈릴 수 있지만 차근차근 <code>Join</code>하면 문제를 쉽게 해결할 수 있다.</p><p>우선, <code>contests</code> table을 기준으로 <code>colleges</code>, <code>challenges</code> table과 <code>Left Join</code>을 수행한다. 각 key는 <em>contest_id 와 college_id</em> 이다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.contest_id, a.hacker_id, a.name,</span><br><span class="line"><span class="keyword">from</span> contests <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> colleges <span class="keyword">as</span> b <span class="keyword">on</span> a.contest_id = b.contest_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> challenges <span class="keyword">as</span> c <span class="keyword">on</span> b.college_id = c.college_id;</span><br></pre></td></tr></table></figure><p>다음 <em>total_views<em>와 *total_unique_views</em>를 구하기 위해 <code>view_stats</code> table을 *challenge_id</em> 기준으로 group by 한다. 이후 결과 테이블과 <code>Left Join</code>을 수행한다. 단, key는 <em>challenge_id</em>이다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.contest_id, a.hacker_id, a.name,</span><br><span class="line">    <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views,</span><br><span class="line">    <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line"><span class="keyword">from</span> contests <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> colleges <span class="keyword">as</span> b <span class="keyword">on</span> a.contest_id = b.contest_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> challenges <span class="keyword">as</span> c <span class="keyword">on</span> b.college_id = c.college_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views, <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line">            <span class="keyword">from</span> view_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> d <span class="keyword">on</span> c.challenge_id = d.challenge_id;</span><br></pre></td></tr></table></figure><p><code>view_stats</code> table Join과 같은 방법으로 <code>submission_stats</code> table을 정제한 후 <code>Left Join</code>을 수행한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.contest_id, a.hacker_id, a.name,</span><br><span class="line">    <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views,</span><br><span class="line">    <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line"><span class="keyword">from</span> contests <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> colleges <span class="keyword">as</span> b <span class="keyword">on</span> a.contest_id = b.contest_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> challenges <span class="keyword">as</span> c <span class="keyword">on</span> b.college_id = c.college_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views, <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line">            <span class="keyword">from</span> view_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> d <span class="keyword">on</span> c.challenge_id = d.challenge_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions, <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions</span><br><span class="line">            <span class="keyword">from</span> submission_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> e <span class="keyword">on</span> c.challenge_id = e.challenge_id;</span><br></pre></td></tr></table></figure><p>마지막으로 <em>contest_id, hacker_id, name</em>을 기준으로 group by를 수행하고, 문제의 조건인 네 가지 summation이 0보다 큰 경우만 조회하는  <code>having</code>을 추가하여 완성한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.contest_id, a.hacker_id, a.name,</span><br><span class="line">    <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views,</span><br><span class="line">    <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line"><span class="keyword">from</span> contests <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> colleges <span class="keyword">as</span> b <span class="keyword">on</span> a.contest_id = b.contest_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> challenges <span class="keyword">as</span> c <span class="keyword">on</span> b.college_id = c.college_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views, <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line">            <span class="keyword">from</span> view_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> d <span class="keyword">on</span> c.challenge_id = d.challenge_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions, <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions</span><br><span class="line">            <span class="keyword">from</span> submission_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> e <span class="keyword">on</span> c.challenge_id = e.challenge_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.contest_id, a.hacker_id, a.name</span><br><span class="line"><span class="keyword">having</span> (total_submissions + total_accepted_submissions + total_views + total_unique_views) &gt; <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><p><a href="https://github.com/BlakeBrown/HackerRank-Solutions/blob/master/SQL/5_Advanced%20Join/4_Interviews/Interviews.mysql" target="_blank" rel="noopener">참고</a></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.contest_id, a.hacker_id, a.name,</span><br><span class="line">    <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions,</span><br><span class="line">    <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views,</span><br><span class="line">    <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line"><span class="keyword">from</span> contests <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> colleges <span class="keyword">as</span> b <span class="keyword">on</span> a.contest_id = b.contest_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> challenges <span class="keyword">as</span> c <span class="keyword">on</span> b.college_id = c.college_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_views) <span class="keyword">as</span> total_views, <span class="keyword">sum</span>(total_unique_views) <span class="keyword">as</span> total_unique_views</span><br><span class="line">            <span class="keyword">from</span> view_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> d <span class="keyword">on</span> c.challenge_id = d.challenge_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> ( <span class="keyword">select</span> challenge_id, <span class="keyword">sum</span>(total_submissions) <span class="keyword">as</span> total_submissions, <span class="keyword">sum</span>(total_accepted_submissions) <span class="keyword">as</span> total_accepted_submissions</span><br><span class="line">            <span class="keyword">from</span> submission_stats</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span> challenge_id ) <span class="keyword">as</span> e <span class="keyword">on</span> c.challenge_id = e.challenge_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a.contest_id, a.hacker_id, a.name</span><br><span class="line"><span class="keyword">having</span> (total_submissions + total_accepted_submissions + total_views + total_unique_views) &gt; <span class="number">0</span>;</span><br></pre></td></tr></table></figure><hr><p>2019.10.28 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-interviews/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Install Hadoop using Docker</title>
      <link>https://jx2lee.github.io/hadoop-install_hadoop_using_docker/</link>
      <guid>https://jx2lee.github.io/hadoop-install_hadoop_using_docker/</guid>
      <pubDate>Thu, 24 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;strong&gt;Hadoop&lt;/strong&gt; 환경을 구성해보자!&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><strong>Hadoop</strong> 환경을 구성해보자!</p><a id="more"></a><p>드디어 엔지니어로써의 능력을 배양할 수 있는 <code>환경 구성</code>이다. 우선, 회사에서 지급받은 서버로 이미 하둡 환경이 구축되어 있지만, 개인 할당받은 서버에서 <code>Docker</code>를 이용해 실습 환경을 구축하고자 한다.</p><blockquote><p><em>Docker Hub 에서 스타가 가장 많은 이미지를 이용할 것이다. Docker를 이용하는 것은 <code>혹여나 나중에도 써먹을 경우</code>를 대비한 것이다.</em></p></blockquote><h1 id="PLAN"><a href="#PLAN" class="headerlink" title="PLAN"></a>PLAN</h1><p>3개의 DataNode와 1개의 NameNode로 구성된 하둡 환경을 구축한다. 여러 개 서버를 연결하는 구조 대신, 쉽게 환경을 바꾸고 입맛대로 수정이 가능한 <strong>docker</strong>를 이용해 구성한다. docker를 공부해보자는 의미도 있고 새롭게 환경을 재구성할 때 유용할 것 같다.</p><h1 id="ENVIRONMENT"><a href="#ENVIRONMENT" class="headerlink" title="ENVIRONMENT"></a>ENVIRONMENT</h1><p>hadoop 폴더를 생성하여 아래와 같은 구조를 갖는다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ tree .</span><br><span class="line">.</span><br><span class="line">├── base</span><br><span class="line">│   ├── core-site.xml</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── data-node</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   ├── hdfs-site.xml</span><br><span class="line">│   └── install.sh</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">└── name-node</span><br><span class="line">    ├── Dockerfile</span><br><span class="line">    ├── hdfs-site.xml</span><br><span class="line">    └── install.sh</span><br><span class="line"></span><br><span class="line">3 directories, 9 files</span><br></pre></td></tr></table></figure><p>hadoop의 기본 환경을 구성하는 <code>base</code>와 이를 활용해 <code>name / data -node</code> 폴더를 구성하였고, Dockerfile을 작성하여 직접 image를 build하고 <code>docker-compose</code>를 활용해 배포한다. </p><h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>각 component의 밑바당이 되는 이미지를 구성하는 단계이다. 이는 <code>base</code> 폴더에서 수행하며, 고려사항은 다음과 같다.</p><ul><li>Hadoop 설치를 위한 binary</li><li>Java</li></ul><p>이미지 빌드를 위해 <code>Dockerfile</code>, <code>core-site.xml</code>을 작성해보도록 한다.</p><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p><blockquote><p><em>Dockerfile 작성을 많이 해버릇 해야겠다. 참고한 블로그에서 사용한 내용을 복사 붙여넣지 않고 직접 작성하니 어느정도 흐름은 파악하였다</em></p></blockquote><ul><li><p>환경변수 설정</p><ul><li><code>HADOOP_VERSION</code> : hadoop version을 의미</li><li><code>HADOOP_URL</code> : hadoop 설치 binary 다운을 위한 url</li></ul></li><li><p>환경변수를 이용해 download 및 압축해제</p></li><li><p>링크파일 생성</p></li><li><p>호스트(in base directory) 파일을 container에 추가</p></li><li><p>hadoop 실행을 위한 환경변수 설정</p><ul><li><code>HADOOP_PREFIX</code> : hadoop root directory</li><li><code>HADOOP_CONF_DIR</code> : hadoop config directory</li><li><code>JAVA_HOME</code> : Java directory</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ENV for installation</span></span><br><span class="line">ENV HADOOP_VERSION=2.9.2</span><br><span class="line">ENV HADOOP_URL=http://mirror.apache-kr.org/hadoop/common/hadoop-<span class="variable">$HADOOP_VERSION</span>/hadoop-<span class="variable">$HADOOP_VERSION</span>.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">## Download Hadoop on /app/hadoop</span></span><br><span class="line">RUN curl -fSL <span class="string">"<span class="variable">$HADOOP_URL</span>"</span> -o /tmp/hadoop.tar.gz \</span><br><span class="line">&amp;&amp; tar -xvf /tmp/hadoop.tar.gz -C /opt/ \</span><br><span class="line">&amp;&amp; rm /tmp/hadoop.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># make directory &amp; symbolic link</span></span><br><span class="line">RUN ln -s /opt/hadoop-<span class="variable">$HADOOP_VERSION</span> /opt/hadoop \</span><br><span class="line">&amp;&amp; mkdir /opt/hadoop/dfs \</span><br><span class="line">&amp;&amp; ln -s /opt/hadoop-<span class="variable">$HADOOP_VERSION</span>/etc/hadoop /etc/hadoop \</span><br><span class="line">&amp;&amp; rm -rf /opt/hadoop/share/doc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># copy local-site.xml file to container</span></span><br><span class="line">ADD core-site.xml /etc/hadoop/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ENV for run</span></span><br><span class="line">ENV HADOOP_PREFIX /opt/hadoop</span><br><span class="line">ENV HADOOP_CONF_DIR /etc/hadoop</span><br><span class="line">ENV PATH <span class="variable">$HADOOP_PREFIX</span>/bin/:<span class="variable">$PATH</span></span><br><span class="line">ENV JAVA_HOME /usr/lib/jvm/zulu-8-amd64</span><br></pre></td></tr></table></figure><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><p><code>core-site.xml</code>은 아래와 같이 작성한다.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">connfiguration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://namenode:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>NameNode URI</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">connfiguration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p><code>fs.defaultFS</code> : NameNode의 위치를 찾는 설정으로 읽기/쓰기 요청을 할 때 사용되는 항목</p></li><li><p>URI hostname 은 namenode라 설정하였는데, NameNode container의 host name을 지정한 것</p></li></ul><blockquote><p><em><code>connfiguration</code> tag 명을 제대로 확인하도록 하자. (내 경우 connfiguration -&gt; configuration으로 이미지를 빌드 후 실행하였더니 container가 정상적으로 작동하지 않았다)</em></p></blockquote><h3 id="Build-hadoop-base-2-9-2"><a href="#Build-hadoop-base-2-9-2" class="headerlink" title="Build hadoop-base:2.9.2"></a>Build hadoop-base:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>base</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> base/</span><br><span class="line">[kuber@node2 base]$ docker build -t hadoop-base:2.9.2 .</span><br></pre></td></tr></table></figure><h2 id="NAMENODE"><a href="#NAMENODE" class="headerlink" title="NAMENODE"></a>NAMENODE</h2><p>base image를 생성하였다면, 이를 이용해 NameNode Container를 빌드하기 위한 환경을 구성한다. 고려 사항은 다음과 같다.</p><ul><li>NameNode 용 <code>hdfs-site.xml</code></li><li>FsImage, EditLog 저장을 위한 로컬 파일 시스템 경로</li><li>NameNode의 첫 구동 확인 <em>(첫 구동이 아니라면 포맷 후 구동 필요)</em></li></ul><p>NameNode 이미지 빌드를 위해 <code>Dockerfile</code>, <code>hdfs-site.xml</code>, <code>install.sh</code>를 작성해보도록 한다.</p><h3 id="Dockerfile-1"><a href="#Dockerfile-1" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p><ul><li>이전에 만든 hadoop-base:2.9.2 image를 불러온다</li><li>Web UI 응답 여부 확인을 위한 HEALTHCHECK</li><li>호스트(in name-node directory) 파일을 container에 추가</li><li>FSIMage, EditLog 파일 경로 연결</li><li>포트 노출</li><li>명령어 등록</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">FROM hadoop-base:2.9.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># CON NameNode Web UI</span></span><br><span class="line">HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50070/ || <span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY hdfs-site.xml</span></span><br><span class="line">ADD hdfs-site.xml /etc/hadoop/</span><br><span class="line"></span><br><span class="line"><span class="comment"># FSImage/EditLog path -&gt; volume</span></span><br><span class="line">RUN mkdir /opt/hadoop/dfs/name</span><br><span class="line">VOLUME /opt/hadoop/dfs/name</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY shell scrip</span></span><br><span class="line">ADD install.sh /install.sh</span><br><span class="line">RUN chmod a+x /install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># EXPOSE Port</span></span><br><span class="line">EXPOSE 50070 9000</span><br><span class="line"></span><br><span class="line"><span class="comment"># ADD command line for run</span></span><br><span class="line">CMD [<span class="string">"/install.sh"</span>, <span class="string">"opt/hadoop/dfs/name"</span>]</span><br></pre></td></tr></table></figure><h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p><code>hdfs-site.xml</code>은 아래와 같이 작성한다.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.use.datanode.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.servicerpc-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.https-bind-host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p><code>dfs.namenode.name.dir</code> : FSImage / EditLog 파일을 저장하는 경로</p></li><li><p><code>dfs.blocksize</code> : HDFS 파일 블록의 크기로 본 환경에서는 10MB로 설정하였다<em>(default : 128MB)</em></p><p>(기타 항목들은 ( <a href="https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/" target="_blank" rel="noopener">https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/</a> ) 확인)</p></li></ul><h3 id="install-sh"><a href="#install-sh" class="headerlink" title="install.sh"></a>install.sh</h3><p> <code>install.sh</code>은 NameNode의 네임스페이스의 포맷 여부를 확인하는 쉘 스크립트이다. 만약 네임스페이스가 포맷되어 있다면 NameNode를 구동하고, 포맷되어있지 않다면 포맷을 진행한 후 구동한다.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> SET namespace directory</span></span><br><span class="line">NAME_DIR=$1</span><br><span class="line">echo $NAME_DIR</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> CHECK <span class="keyword">if</span> dir is empty</span></span><br><span class="line">if [ "$(ls -A $NAME_DIR)" ]; then</span><br><span class="line">echo "NameNode is already formatted !!"</span><br><span class="line">else</span><br><span class="line">echo "Format NameNode.."</span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_PREFIX/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> namenode -format</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> RUN</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_PREFIX/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> namenode</span></span><br></pre></td></tr></table></figure><h3 id="Build-hadoop-namenode-2-9-2"><a href="#Build-hadoop-namenode-2-9-2" class="headerlink" title="Build hadoop-namenode:2.9.2"></a>Build hadoop-namenode:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>name-node</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> name-node/</span><br><span class="line">[kuber@node2 name-node]$ docker build -t hadoop-namenode:2.9.2 .</span><br></pre></td></tr></table></figure><h2 id="DATANODE"><a href="#DATANODE" class="headerlink" title="DATANODE"></a>DATANODE</h2><p>NameNode 이미지 생성과 마찬가지로, base image를 이용해 DataNode image를 생성해본다. 고려사항은 아래와 같다.</p><ul><li>DataNode 용 <code>hdfs-site.xml</code></li><li>파일 블록 저장을 위한 경로</li></ul><p>DataNode 이미지 빌드를 위해 <code>Dockerfile</code>, <code>hdfs-site.xml</code>, <code>install.sh</code>를 작성해보도록 한다.</p><h3 id="Dockerfile-2"><a href="#Dockerfile-2" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>Dockerfile</code>은 아래와 같은 순서로 작성하였다.</p><ul><li>이전에 만든 hadoop-base:2.9.2 image를 불러온다</li><li>Web UI 응답 여부 확인을 위한 HEALTHCHECK</li><li>host(in name-node directory) 파일을 container에 추가</li><li>FSIMage, EditLog 파일 경로 연결</li><li>port 노출</li><li>cmd 등록</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">FROM hadoop-base:2.9.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># CONN NameNode Web UI</span></span><br><span class="line">HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || <span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">RUN mkdir /opt/hadoop/dfs/data</span><br><span class="line">VOLUME /opt/hadoop/dfs/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># COPY shell scrip</span></span><br><span class="line">ADD install.sh /install.sh</span><br><span class="line">RUN chmod a+x /install.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># EXPOSE Port</span></span><br><span class="line">EXPOSE 50075 50010</span><br><span class="line"></span><br><span class="line"><span class="comment"># ADD command line for run</span></span><br><span class="line">CMD [<span class="string">"/install.sh"</span>]</span><br></pre></td></tr></table></figure><h3 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p><code>hdfs-site.xml</code> 아래와 같이 작성한다. container 에 datanode의 dir path와 blocksize를 지정한다.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.use.datanode.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="install-sh-1"><a href="#install-sh-1" class="headerlink" title="install.sh"></a>install.sh</h3><p>DataNode의 <code>install.sh</code> 은 별거 없다. DataNode를 구동하는 명령어를 추가하여 작성한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP_PREFIX</span>/bin/hdfs --config <span class="variable">$HADOOP_CONF_DIR</span> datanode</span><br></pre></td></tr></table></figure><h3 id="Build-hadoop-datanode-2-9-2"><a href="#Build-hadoop-datanode-2-9-2" class="headerlink" title="Build hadoop-datanode:2.9.2"></a>Build hadoop-datanode:2.9.2</h3><p>이제 Docker image로 빌드할 차례이다. <code>data-node</code> 폴더로 접근 후 아래와 같은 명령어를 통해 build를 수행한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ <span class="built_in">cd</span> data-node/</span><br><span class="line">[kuber@node2 data-node]$ docker build -t hadoop-datanode:2.9.2 .</span><br><span class="line">Sending build context to Docker daemon 4.096 kB</span><br><span class="line">Step 1/8 : FROM hadoop-base:2.9.2</span><br><span class="line"> ---&gt; 765c9acb59fd</span><br><span class="line">Step 2/8 : HEALTHCHECK --interval=30s --timeout=30s --retries=3 CMD curl -f http://localhost:50075/ || <span class="built_in">exit</span> 1</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> e2b20d7d5fd1</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Successfully built 3f1372bf4fdb</span><br></pre></td></tr></table></figure><p><strong>container 구동을 위한 준비가 거의 끝나간다</strong></p><h1 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h1><p>빌드된 이미지를 하나하나 실행<em>(ex. docker run ~)</em>해도 되지만, <code>docker compose</code>라는 툴을 이용해 한꺼번에 배포해보도록 한다. yml 형식의 스크립트를 작성하여 NadeNode와 DataNode를 한 번에 배포할 것이다.</p><h2 id="Install-docker-compose"><a href="#Install-docker-compose" class="headerlink" title="Install docker-compose"></a>Install <code>docker-compose</code></h2><p>docker 설치 시 자동으로 설치된 줄 알았는데, 설치가 안되있었다. 아래 명령어를 통해 <code>docker-compose</code>를 설치한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100   617    0   617    0     0   1382      0 --:--:-- --:--:-- --:--:--  1380</span><br><span class="line">100 15.4M  100 15.4M    0     0  2327k      0  0:00:06  0:00:06 --:--:-- 3535k</span><br><span class="line">[kuber@node2 hadoop]$ sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">[kuber@node2 hadoop]$ sudo ln -s /usr/<span class="built_in">local</span>/bin/docker-compose /usr/bin/docker-compose</span><br></pre></td></tr></table></figure><h2 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h2><p><code>docker-compose.yml</code>은 docker 실행 옵션들을 미리 적어둔 파일이다. <em>services`</em> 부분은 우리가 구동할 NameNode 및 DataNode에 관련된 옵션들을 작성하고, 계획에서 언급한 것처럼 DataNode 3개 구동을 위해 01/02/03으로 구분하여 작성한다.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">version: "3.4"</span><br><span class="line"></span><br><span class="line">x-datanode_base: &amp;datanode_base</span><br><span class="line">  image: hadoop-datanode:2.9.2</span><br><span class="line">  networks:</span><br><span class="line">    - bridge</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  namenode:</span><br><span class="line">    image: hadoop-namenode:2.9.2</span><br><span class="line">    container_name: namenode</span><br><span class="line">    hostname: namenode</span><br><span class="line">    ports:</span><br><span class="line">      - "50070:50070"</span><br><span class="line">      - "9000:9000"</span><br><span class="line">    volumes:</span><br><span class="line">      - namenode:/opt/hadoop/dfs/name</span><br><span class="line">      - /tmp:/tmp</span><br><span class="line">    networks:</span><br><span class="line">      - bridge</span><br><span class="line"></span><br><span class="line">  datanode01:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode01</span><br><span class="line">    hostname: datanode01</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode01:/opt/hadoop/dfs/data</span><br><span class="line">  datanode02:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode02</span><br><span class="line">    hostname: datanode02</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode02:/opt/hadoop/dfs/data</span><br><span class="line">  datanode03:</span><br><span class="line">    &lt;&lt;: *datanode_base</span><br><span class="line">    container_name: datanode03</span><br><span class="line">    hostname: datanode03</span><br><span class="line">    volumes:</span><br><span class="line">      - datanode03:/opt/hadoop/dfs/data</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  namenode:</span><br><span class="line">  datanode01:</span><br><span class="line">  datanode02:</span><br><span class="line">  datanode03:</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  bridge:</span><br></pre></td></tr></table></figure><blockquote><p><em>version의 경우, 자신의 서버에 설치된 docker engine release에 따라 format이 정해져있으므로 이 <a href="https://docs.docker.com/compose/compose-file/compose-versioning/" target="_blank" rel="noopener">문서</a>를 참고</em></p></blockquote><h2 id="Run-Container-using-docker-compose"><a href="#Run-Container-using-docker-compose" class="headerlink" title="Run Container using docker-compose"></a>Run Container using docker-compose</h2><p>docker-compose를 이용해 배포해 보도록 하자. 볼륨을 생성하고 NameNode / DataNode가 구동되었다는 메세지가 보일 것이다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ docker-compose up -d</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode01"</span> with default driver</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode02"</span> with default driver</span><br><span class="line">Creating volume <span class="string">"hadoop_datanode03"</span> with default driver</span><br><span class="line">namenode is up-to-date</span><br><span class="line">Creating datanode01 ... <span class="keyword">done</span></span><br><span class="line">Creating datanode02 ... <span class="keyword">done</span></span><br><span class="line">Creating datanode03 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure><h1 id="Installation-Check"><a href="#Installation-Check" class="headerlink" title="Installation Check"></a>Installation Check</h1><p>노드들이 정상 작동하는지 확인해보는 단계이다. 구동을 했으면 제대로 되는지 확인하는게 중요하겠죠? 아래 순서와 같이 설치 확인을 진행한다.</p><h2 id="NameNode-컨테이너의-hadoop-client-실행-확인"><a href="#NameNode-컨테이너의-hadoop-client-실행-확인" class="headerlink" title="NameNode 컨테이너의 hadoop client 실행 확인"></a>NameNode 컨테이너의 hadoop client 실행 확인</h2><p>NameNode의 컨테이너에 접속해 커맨드라인을 확인하는 명령어<em>(docker exec)</em>를 통해 확인해본다. 그러면 아래와 같이 Usage가 출력되는 것을 확인할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ docker <span class="built_in">exec</span> namenode /opt/hadoop/bin/hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use <span class="string">"yarn jar"</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">  daemonlog            get/<span class="built_in">set</span> the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure><p>이처럼 매 번 docker exec 명령어를 작성하는 건 정말 귀찮을 것이다. alias를 등록해 간편하게 명령어를 날려보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ vi ~/.bash_profile </span><br><span class="line"><span class="comment"># bash_profile</span></span><br><span class="line"><span class="built_in">alias</span> hadoop=<span class="string">"docker exec namenode /opt/hadoop/bin/hadoop"</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">[kuber@node2 hadoop]$ <span class="built_in">source</span> ~/.bash_profile </span><br><span class="line">[kuber@node2 hadoop]$ hadoop</span><br><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  <span class="built_in">where</span> COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              <span class="built_in">print</span> the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use <span class="string">"yarn jar"</span> to launch</span><br><span class="line">                             YARN applications, not this <span class="built_in">command</span>.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">  daemonlog            get/<span class="built_in">set</span> the <span class="built_in">log</span> level <span class="keyword">for</span> each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands <span class="built_in">print</span> <span class="built_in">help</span> when invoked w/o parameters.</span><br></pre></td></tr></table></figure><h2 id="폴더-생성-조회-삭제-확인"><a href="#폴더-생성-조회-삭제-확인" class="headerlink" title="폴더 생성/조회/삭제 확인"></a>폴더 생성/조회/삭제 확인</h2><p>hadoop 명령어를 통해 폴더를 생성하고 조회하며 마지막으로 삭제하는 작업을 해본다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 hadoop]$ hadoop fs -mkdir -p /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -ls -R /tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:15 /tmp/<span class="built_in">test</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:15 /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -rm -r /tmp/<span class="built_in">test</span>/app</span><br><span class="line">Deleted /tmp/<span class="built_in">test</span>/app</span><br><span class="line">[kuber@node2 hadoop]$ hadoop fs -ls -R /tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-10-25 05:16 /tmp/<span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="Web-UI"><a href="#Web-UI" class="headerlink" title="Web UI"></a>Web UI</h2><p>NameNode와 DataNode 상태를 Web에서 확인할 수 있다. container 실행을 위해 작성한 <code>docker-compose.yml</code> 안에 NameNode의 port<em>(50070)</em>를 이용해 접속을 하면 아래와 같은 화면이 보일 것이다.</p><ul><li><p><code>NameNode</code> overview</p><p><img src="/image/namenode-web.png" alt=""></p></li><li><p><code>DataNode</code> overview</p><p><img src="/image/datanode-web.png" alt=""></p></li></ul><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref."></a>Ref.</h1><ol><li><a href="https://blog.geunho.dev/posts/hadoop-docker-test-env-hdfs/" target="_blank" rel="noopener">김근호님 블로그 : Docker로 Hadoop 테스트 환경 구축하기 - HDFS</a></li><li><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">Docker documenst</a></li></ol><hr><p>made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-install_hadoop_using_docker/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Database] OLAP</title>
      <link>https://jx2lee.github.io/hackerrank-olap/</link>
      <guid>https://jx2lee.github.io/hackerrank-olap/</guid>
      <pubDate>Tue, 22 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;hackerrank에서 제공하는 Database 카테고리의 OLAP 문제를 풀어보고 개념을 정리한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>hackerrank에서 제공하는 Database 카테고리의 OLAP 문제를 풀어보고 개념을 정리한다.</p><a id="more"></a><h1 id="OLAP-The-Total-view"><a href="#OLAP-The-Total-view" class="headerlink" title="OLAP - The Total view"></a>OLAP - The Total view</h1><h2 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h2><p>Which of these provides a total view of the organization?</p><p>1) OLAP<br>2) OLTP<br><strong>3) Data Warehousing</strong><br>4) Database</p><h2 id="풀이"><a href="#풀이" class="headerlink" title="풀이"></a>풀이</h2><p>왜 틀렸는지를 모르겠는 문제이다. <code>1번, 2번, 4번</code>이 결국 <code>3번 : Data Warehousing</code>에 포함된 내용이다. 각각의 개념을 간단히 정리해보면 아래와 같다. <em>(4번의 경우 <code>PASS</code>)</em></p><blockquote><p><strong>OLAP</strong><br>데이터 집계를 효율화하는 접근 방법 중 하나로, <code>다차원 모델</code>구조를 <code>MDX (Multidimensional expressions)</code> 등의 쿼리 언어로 집계한다. 다차원 모델 구조를 <em>OLAP 큐브</em>라 하며 이러한 큐브를 이용해 크로스 집계하는 구조가 <strong>OLAP</strong>이다.</p><p><strong>OLTP (Online Transaction Processing)</strong><br>정의는 <code>실시간으로 서버(DB)가 자료를 처리하는 과정</code> 인데, 사실 OLAP vs OLTP를 비교하는 것을 주로 보았는데 정확한 의미를 모르겠다. OLAP은 하나의 기술로 보는것인지, OLTP는 <code>기술이 아닌 실시간성 처리 과정</code>으로 봐야하는지는 좀 더 살펴본 이후에 자세히 정리해야겠다.</p><p> <strong>Data Warehousing</strong><br> Data Warehouse를 설계하고 사용하는 과정을 뜻하는 단어이다. <code>Data Warehouse</code> 특징을 살펴보면 다음과 같다.</p><ul><li>Web Server 또는 RDB와 달리 <code>대량 데이터 장기 보존</code> 최적화</li><li>정리된 데이터 전송 기능은 뛰어나지만, 소량 데이터의 경우 적합하지 않음</li><li>업무 처리에 있어 함부로 사용해 시스템 과부하 초래는 위험함, 이러한 문제로 필요한 데이터만을 추출하여 <code>데이터 마트 (Data Mart)</code>를 구성함</li></ul></blockquote><p>[참고] : 빅데이터를 지탱하는 기술, Wikipedia</p><h1 id="OLAP-OLAP-Operation-Types"><a href="#OLAP-OLAP-Operation-Types" class="headerlink" title="OLAP - OLAP Operation Types"></a>OLAP - OLAP Operation Types</h1><h2 id="문제-1"><a href="#문제-1" class="headerlink" title="문제"></a>문제</h2><p>Consider a fact table DataPoints(D1,D2,D3,x), and the following three queries:</p><p>Q1: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3<br>Q2: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3 WITH CUBE<br>Q3: Select D1,D2,D3,Sum(x) From DataPoints Group By D1,D2,D3 WITH ROLLUP</p><p>Suppose attributes D1, D2, and D3 have n1, n2, and n3 different values respectively, and assume that each possible combination of values appears at least once in the table DataPoints. The number of tuples in the result of each of the three queries above can be specified as an arithmetic formula involving n1, n2, and n3. Pick the one tuple (a,b,c,d,e,f) in the list below such that when n1=a, n2=b, and n3=c, then the result sizes of queries Q1, Q2, and Q3 are d, e, and f respectively.</p><p>1) (2, 2, 2, 6, 18, 8)<br>2) (2, 2, 2, 8, 64, 15)<br>3) (5, 10, 10, 500, 1000, 550)<br><strong>4) (4, 7, 3, 84, 160, 117)</strong></p><h2 id="풀이-1"><a href="#풀이-1" class="headerlink" title="풀이"></a>풀이</h2><p>문제를 잘못 이해해 푸는데 오래 걸렸다. 주어진 보기 4개 tuple의 앞에 3개는 각각 D1, D2, D3칼럼의 value 들이었다. 따라서, 각 지문의 3개 숫자 <em>(ex. 1번 보기는 2,2,2 -&gt; D1, D2, D3)</em> 로 operation <code>CUBE</code> 및 <code>ROLL UP</code> 을 수행한 후 조회되는 행의 갯수를 맞추는 문제이다. <strong>Q1</strong>은 쉽게 구할 수 있었고 <code>CUBE</code> 및 <code>ROLLUP</code> 연산을 구글을 통해 살펴보았다.</p><p>우선 <code>CUBE</code> operation은  모든 차원에서 모든 속성 조합을 사용한다. 이는 곧, <code>NULL</code> 구문을 사용하기 때문에 group by로 조회수와는 다르게 아래와 같이 계산된다.</p><p><code>(n1 + 1) * (n2 + 1) * (n3 + 1)</code></p><p>마지막으로 <code>ROLLUP</code> operation은 <code>NULL</code>이 있는 속성을 포함하여 속성 tuple을 생성한다. 이에 기존 <code>CUBE</code> 연산을 통해 나온 수와 <code>ROLLUP</code>연산을 통해 계산되는 tuple 수를 더해준다. 식은 아래와 같다.</p><p><code>[기존 CUBE로 계산된 수] + n1 * (n2 + 1) + 1</code></p><blockquote><p>ROLLUP 이라 함은 Drill Down (operation 중 하나)과 달리 작은 범위에서 큰 범위의 단계적 접근 분석 방법을 말한다 <em>(ex. 번지 -&gt; 동 -&gt; 구 -&gt; 시도 -&gt; 광역)</em>. 위에 기존 CUBE 연산을 통한 값과 그 뒤에 새로운 추가된 수를 더하는 내용이 확실히 이해가 가지 않아 나중에 정리해야할 것 같다.</p></blockquote><hr><p>2019.10.23 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-olap/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Hadoop] Hadoop Overview</title>
      <link>https://jx2lee.github.io/hadoop-introduction_to_hadoop/</link>
      <guid>https://jx2lee.github.io/hadoop-introduction_to_hadoop/</guid>
      <pubDate>Mon, 21 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;strong&gt;Hadoop&lt;/strong&gt; 관련 책을 읽으며 개념을 간단히 정리한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><strong>Hadoop</strong> 관련 책을 읽으며 개념을 간단히 정리한다.</p><a id="more"></a><p>맨날 하둡 공부해야지.. 공부해야지 하다가 <a href="http://www.yes24.com/Product/goods/66277191" target="_blank" rel="noopener"><em>빅데이터를 지탱하는 기술</em></a> 책을 읽으며 정리하고자 한다. 무작정 실습부터 하기 보다는, 기본적인 개념을 익히고 <strong>Hadoop</strong> 환경을 구성할 것이다.</p><blockquote><p><em>우선 내용 전체적으로 도서를 참고해 작성하고 추가적인 부분은 구글 서치를 통해 채워넣을 예정이다.  최대한 책을 기반으로 개념을 정리하는 것을 목표로 한다.</em></p></blockquote><p><strong>Contents</strong>:  </p><ul><li><a href="#introductions">Hadoop 이란</a></li><li><a href="#components">Hadoop 기본 구성 요소</a><ul><li><a href="#hdfsyarn">분산 파일 시스템 (HDFS) 과 리소스 관리자 (YARN)</a></li><li><a href="#mrhive">분산 데이터 처리 (MapReduce) 및 쿼리 엔진 (Hive)</a></li><li><a href="#hive">Hive on Tez</a></li><li><a href="#queryengine">대화형 쿼리 엔진 (Impala &amp; Presto)</a></li></ul></li></ul><h1 id="Hadoop-이란"><a href="#Hadoop-이란" class="headerlink" title=" Hadoop 이란"></a><a name="introductions"></a> Hadoop 이란</h1><p>개념을 배우는데 있어서 역사는 크게 중요하지 않다고 생각한다. 책에서는 역사가 기술되어있지만 나는 정의<u><em>(수학과 아니랄까봐)</em></u> 부터 짚어보고자 한다. <code>Hadoop</code>은 단일 소프트웨어가 아닌, <strong>분산 시스템</strong> 을 구성하는 다수의 소프트웨어로 이루어진 <strong>집합체</strong> 이다. <code>Wiki</code>백과에 의하면, <code>대량의 자료를 처리할 수 있는 큰 컴퓨터 클러스터에서 동작하는 분산 응용 프로그램을 지원하는 프레임워크</code>라고 소개한다. 일맥 상통한다.</p><blockquote><p><em>좀 더 자세히 어떠한 언어로 작성되었는지를 표현하였지, 의미는 같다</em></p></blockquote><p>2013년 <code>Hadoop2</code>부터  <code>YARN</code>이라는 <code>리소트관리자</code> 상에서 분산 애플리케이션이 동작하는 구성으로 설계되어, <strong>대규모 분산시스템을 구축하기 위한 플랫폼</strong> 역할을 맡고 있다.</p><p><img src="/image/hadoop-ecosystem.png" alt="그림 - 빅데이터 관련 Apache 프로젝트"></p><p>[그림] - 빅데이터 관련 Apache 프로젝트 (참고 : 빅데이터를 지탱하는 기술)</p><h1 id="Hadoop-기본-구성-요소"><a href="#Hadoop-기본-구성-요소" class="headerlink" title=" Hadoop 기본 구성 요소"></a><a name="components"></a> Hadoop 기본 구성 요소</h1><p>기본 구성 요소로는 <strong>분산 파일 시스템</strong> <em>(distributed file system)<em>인 <code>HDFS(Hadoop Distributed File System)</code>, *</em>리소스 관리자** *(resource manager)</em> 인 <code>YARN(Yet Another Resource Negotiator)</code>, <strong>분산 데이터 처리</strong> <em>(distributed data processing)</em> 기반 <code>MapReduce</code> 3가지다. 이외 구성요소<em>(프로젝트라고 표현하기도 함)</em>는 Hadoop과 독립적으로 개발되어 분산 애플리케이션으로 동작한다.</p><p>즉, 위에서 소개한 프로젝트에서 분산 파일 시스템으로는 <code>HDFS</code>를 사용하고 resource manager로는 <code>Mesos</code>를, 분산 데이터 처리에는 <code>Spark</code>를 사용할 수 있다. 자신에게 맞고 상황에 맞는 프로젝트를 구성하는 것이 Hadoop을 중심으로 하는 데이터 처리의 특징이다.</p><h2 id="분산-파일-시스템-HDFS-과-리소스-관리자-YARN"><a href="#분산-파일-시스템-HDFS-과-리소스-관리자-YARN" class="headerlink" title=" 분산 파일 시스템 (HDFS) 과 리소스 관리자 (YARN)"></a><a name="hdfsyarn"></a> 분산 파일 시스템 (HDFS) 과 리소스 관리자 (YARN)</h2><p>Hadoop에서 처리되는 데이터는 대부분 <code>HDFS</code>에 저장된다. 보통 파일 서버와 비슷한 개념이지만, <code>다수 컴퓨터에 파일을 복사하여 중복성을 높인다</code>는 특징이 있다.</p><blockquote><p>HDFS는 <strong>블록 구조의 file system</strong>이다. 파일을 특정 크기 블록으로 나누어 분산된 서버에 저장한다. 크기는 64MB 에서 Hadoop2 부터는 128M로 증가하였다(<a href="https://yookeun.github.io/java/2015/05/24/hadoop-hdfs/" target="_blank" rel="noopener">참고</a>)</p></blockquote><p>한편, CPU나 메모리 등의 계산 리소스는 resource manager인 <code>YARN</code>에 의해 관리된다. <code>YARN</code>은 CPU 코어와 메모리를 <strong>컨테이너 (Container)</strong> 단위로 관리한다 <em>(여기서 Container는 Docker Container와는 다르다. 어떤 호스트에서 어떤 프로세스를 실행시킬 것인지 결정하는 앱 수준의 기술)</em>. Hadoop에서  분산 앱을 실행하면 <code>YARN</code>이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당한다.</p><blockquote><p>즉, 리소스 관리자인 <code>YARN</code>은 어느 애플리케이션에 얼마만큼의 리소스를 할당할 지 관리함으로써 모든 애플리케이션이 <strong>차질없이 실행되도록 제어</strong> 한다</p></blockquote><h2 id="분산-데이터-처리-MapReduce-및-쿼리-엔진-Hive"><a href="#분산-데이터-처리-MapReduce-및-쿼리-엔진-Hive" class="headerlink" title=" 분산 데이터 처리 (MapReduce) 및 쿼리 엔진 (Hive)"></a><a name="mrhive"></a> 분산 데이터 처리 (MapReduce) 및 쿼리 엔진 (Hive)</h2><ul><li><code>MapReduce</code><br>YARN 상에서 동작하는 분산 애플리케이션 중 하나로 데이터 처리를 실행하는 데 사용한다. 임의의 java 프로그램을 실행할 수 있기 때문에 <em>비구조화 데이터 (Unstructured Data)</em> 가공에 적합하다. 초기 목적은 대량의 데이터를 <em>Batch*처리하기 위함이었다. 한 번 실행하면 대량의 데이터를 읽을 수 있지만, 작은 프로그램을 *(작은 데이터가 존재하는)</em> 을 실행하면 과한 오버헤드로 몇 초 안에 끝나버리는 쿼리에는 어울리지 않다.</li></ul><p><img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2017/04/apache-hadoop-outputformat-introduction-1024x536-1-1.jpg" alt="MapReduce Process"><br>[그림] - MapReduce Process</p><ul><li><code>쿼리 엔진 (Hive)</code><br>Hive는 SQL 등 쿼리 언어에 의한 데이터 집계가 목적으로 설계된 쿼리 엔진 중 하나이다. 이는 SQL 쿼리를 자동으로 MapReduce 프로그램으로 변환시킨다. 실행 특성 상 MapReduce에 의존하고 있다. </li></ul><blockquote><p>쿼리 엔진 Hive도 결국 MapReduce에 의존하고 있기 때문에, 시간이 오래 걸리는 대량의 데이터를 처리하는 <strong>배치 처리에는 적합</strong>하나, <strong>애드 훅 분석을 위한 쿼리<em>(간단하고 바로바로 볼 수 있는)</em>를 여러 번 수행하는 데 적절하지 않다</strong></p></blockquote><center><img src="https://miro.medium.com/max/560/1*ncMKJ3Mdg-QKJQ21zavJeQ.png"></center><p>[그림] - Hive Architecture (<a href="https://medium.com/@yigiterbas/apache-hive-and-applications-1-31735b8823c7" target="_blank" rel="noopener">https://medium.com/@yigiterbas/apache-hive-and-applications-1-31735b8823c7</a>)</p><h2 id="Hive-on-Tez"><a href="#Hive-on-Tez" class="headerlink" title=" Hive on Tez"></a><a name="hive"></a> Hive on Tez</h2><p>Hive 가속화를 위해 개발된 것으로 MapReduce에서 보인 몇 가지 단점을 해결하고 고속화를 실현하고 있다.</p><blockquote><p>예를 들어, MapReduce의 경우 하나의 stage가 끝날 때 까지 다음의 처리를 진행할 수 없었다. 이에 <code>Tez</code>는 stage 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속 처리로 넘겨 전체 쿼리 시간의 단축을 실현했다.</p></blockquote><p>현재의 Hive는 MapReduce 뿐 아니라 Tez를 사용해도 동작하므로 Hive를 <code>Hive on Tez</code> 와 <code>Hive on MR</code>로 구분한다. <em>(MR은 MapReduce 줄임말)</em></p><p><img src="https://t1.daumcdn.net/cfile/tistory/2616EF345874E63A0C" alt="Hive on MR &amp; Hive on Tez Process"><br>[그림] - Hive on MR &amp; Hive on Tez Process</p><h2 id="대화형-쿼리-엔진-Impala-amp-Presto"><a href="#대화형-쿼리-엔진-Impala-amp-Presto" class="headerlink" title=" 대화형 쿼리 엔진 (Impala &amp; Presto)"></a><a name="queryengine"></a> 대화형 쿼리 엔진 (Impala &amp; Presto)</h2><p>Hive 고속화가 아닌 대화형 쿼리 실행만을 위한 엔진도 있다. 그 중 <code>Impala</code>와 <code>Presto</code>가 대표적이다. <code>Imapala</code>와 <code>Presto</code>를 간단히 살펴보면 다음과 같다.</p><ul><li><p><strong>Impala</strong></p><p>Impala는 크게 <code>impalad</code>와 <code>impala state store</code> 프로세스로 구성한다.</p><ul><li><code>impalad</code>는 분산 질의 엔진 역할을 담당하는 프로세스로, Hadoop 클러스터 내 데이터노드 위에서 질의에 대한 plan 설계와 질의 처리 작업을 수행한다.</li><li><code>impala state store</code> 는 각 데이터 노드에서 수행되는 <code>impalad</code>에 대한 메타데이터를 유지하는 역할을 담당한다. <code>impalad</code> 프로세스가 클러스터 내에 추가 또는 제거될 때 <code>impala state store</code> 프로세스를 통해 메타데이터가 업데이트된다.</li></ul><blockquote><p><code>impalad</code> : 분산 질의 엔진, <code>impala state store</code> : Impalad의 메타데이터 관리</p></blockquote></li></ul><p><img src="https://d2.naver.com/content/images/2015/06/helloworld-246342-1.png" alt=""></p><p>[그림] - impala high-level architecture (<a href="http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/" target="_blank" rel="noopener">원본출처</a>)</p><ul><li><p><strong>Presto</strong></p><p>Presto는 크게 <code>Coordinator</code>와 <code>Worker</code>로 구성된다.</p><ul><li><code>Coordinator</code>는 SQL query 분석, query 계획과 Presto Worker 노드 (worker)를 관리한다. REST API를 사용하여 Worker 및 Client와 통신한다.</li><li><code>Worker</code>는 작업을 실행하고 데이터를 처리한다. Worker가 수행한 결과를 Coordinator를 거쳐 Client에게 전달하며 Coordinator와 마찬가지로 REST API를 사용해 통신한다.</li></ul></li></ul><p><img src="http://labs.gree.jp/blog/wp-content/uploads/2014/12/presto_arch-600x372.png" alt=""></p><p>[그림] - Presto architecture (<a href="http://labs.gree.jp/blog/2014/12/12838/" target="_blank" rel="noopener">출처</a>)</p><p>이러한 대화형 쿼리 엔진은 Hive 와는 달리 순간 최대 속도를 높이기 위해 모든 오버헤드를 제거하여, 리소스를 최대한 활용하여 쿼리를 실행한다 <em>(이는 Hive의 단점으로 언급한 부분을 해결한다)</em> . 그 결과, 대화형 쿼리 엔진은 MPP DB와 비교해도 손색없는 응답 시간을 얻을 수 있다. </p><blockquote><p>Hadoop에서는 쿼리 엔진을 목적에 따라 구분한다. 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에는 높은 처리량으로 리소스를 활용할 수 있는 <code>Hive</code>를, 구조화 및 완성된 데이터를 대화식으로 집계를 원할 땐 지연이 적은 <code>Impala</code>와 <code>Presto</code>가 적합하다.</p></blockquote><hr><p>2019.10.22 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hadoop-introduction_to_hadoop/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 등굣길</title>
      <link>https://jx2lee.github.io/programmers-tortoise/</link>
      <guid>https://jx2lee.github.io/programmers-tortoise/</guid>
      <pubDate>Thu, 17 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;등교하는데 가능한 루트의 최솟값을 구하는 문제를 풀어본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>등교하는데 가능한 루트의 최솟값을 구하는 문제를 풀어본다.</p><a id="more"></a><h1 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h1><h2 id="문제-설명-1"><a href="#문제-설명-1" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>계속되는 폭우로 일부 지역이 물에 잠겼습니다. 물에 잠기지 않은 지역을 통해 학교를 가려고 합니다. 집에서 학교까지 가는 길은 m x n 크기의 격자모양으로 나타낼 수 있습니다.</p><p>아래 그림은 m = 4, n = 3 인 경우입니다.</p><p><img src="https://grepp-programmers.s3.amazonaws.com/files/ybm/056f54e618/f167a3bc-e140-4fa8-a8f8-326a99e0f567.png" alt="image0.png"></p><p>가장 왼쪽 위, 즉 집이 있는 곳의 좌표는 (1, 1)로 나타내고 가장 오른쪽 아래, 즉 학교가 있는 곳의 좌표는 (m, n)으로 나타냅니다.</p><p>격자의 크기 m, n과 물이 잠긴 지역의 좌표를 담은 2차원 배열 puddles이 매개변수로 주어집니다. 집에서 학교까지 갈 수 있는 최단경로의 개수를 1,000,000,007로 나눈 나머지를 return 하도록 solution 함수를 작성해주세요.</p><h2 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h2><ul><li>격자의 크기 m, n은 1 이상 100 이하인 자연수입니다.<ul><li>m과 n이 모두 1인 경우는 입력으로 주어지지 않습니다.</li></ul></li><li>물에 잠긴 지역은 0개 이상 10개 이하입니다.</li><li>집과 학교가 물에 잠긴 경우는 입력으로 주어지지 않습니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><table><thead><tr><th>m</th><th>n</th><th>puddles</th><th>return</th></tr></thead><tbody><tr><td>4</td><td>3</td><td>[[2, 2]]</td><td>4</td></tr></tbody></table><h2 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h2><p><img src="https://grepp-programmers.s3.amazonaws.com/files/ybm/32c67958d5/729216f3-f305-4ad1-b3b0-04c2ba0b379a.png" alt="image1.png"></p><h1 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h1><p>Dynamic Programming 문제. 오랜만에 파이썬 알고리즘 문제를 풀었다. 쉬운 레벨이라 생각해 도전하였지만 역시나 구글검색행.. 우선 코드에 사용한 변수들을 살펴보자</p><blockquote><p> <code>grid</code> : 격자 <em>(index error를 방지하기 위해 +1 만큼 더 생성)</em></p></blockquote><p>여기서 조심해야 할 것은, 문제에서 제공하는 m,n이 행과 열이라고 생각할 수 있는데 그 반대이다. 이 점을 명심하고 문제를 풀어야 index error를 방지하고 문제를 해결할 수 있다.</p><p>물이 고여있는 좌표에는 <code>-1</code>로 대체한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> puddles:</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> puddles:</span><br><span class="line">grid[y][x] = <span class="number">-1</span></span><br></pre></td></tr></table></figure><p>이제 (a,b) = (a-1, b) + (a, b-1) 식을 구현하는데 위에 언급한 것 처럼 행과 열을 조심해서 <code>for</code>문을 수행해야 한다. 행을 기준으로 열을 채워나가는 구조로 (1,1) 인 부분은 <code>continue</code>로 수정하지 않게 설정한다. 또한, 물이 있는 경우는 0으로 바꿔 횟수가 커지기 않게 방지하고 마지막으로 위 식을 작성하면 grid 변수는 원하는 대로 채워질 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line"><span class="keyword">if</span> i == j == <span class="number">1</span>:</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> grid[j][i] == <span class="number">-1</span>:</span><br><span class="line">            grid[j][i] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">grid[j][i] = (grid[j][i<span class="number">-1</span>] + grid[j<span class="number">-1</span>][i])%<span class="number">1000000007</span></span><br></pre></td></tr></table></figure><p>행과 열 순서가 바꿔 있기 때문에 마지막 return 값도 [m][n]이 아닌 [n][m]으로 <code>return</code> 해야한다.</p><p><code>return grid[n][m]</code></p><p>full code는 하기와 같다</p><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(m, n, puddles)</span>:</span></span><br><span class="line">    grid = [[<span class="number">0</span>] * (m+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n+<span class="number">1</span>)]</span><br><span class="line">    grid[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> puddles:</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> puddles:</span><br><span class="line">            grid[y][x] = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> i == j == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> grid[j][i] == <span class="number">-1</span>:</span><br><span class="line">                grid[j][i] = <span class="number">0</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            grid[j][i] = (grid[j][i<span class="number">-1</span>] + grid[j<span class="number">-1</span>][i])%<span class="number">1000000007</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grid[n][m]</span><br></pre></td></tr></table></figure><hr><p>2019.10.18 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-tortoise/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Print Prime Number</title>
      <link>https://jx2lee.github.io/hackerrank-print_prime_number/</link>
      <guid>https://jx2lee.github.io/hackerrank-print_prime_number/</guid>
      <pubDate>Mon, 14 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Print Prime Number&lt;/code&gt; 문제를 사용자 변수를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Print Prime Number</code> 문제를 사용자 변수를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Write a query to print all  <em>prime numbers</em>  less than or equal to  1000. Print your result on a single line, and use the ampersand () character as your separator (instead of a space).</p><p>For example, the output for all prime numbers  &lt;= 10 would be:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2&amp;3&amp;5&amp;7</span><br></pre></td></tr></table></figure><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p>1000 이하의 소수를 구하는 문제로, sql query로는 처음 풀어본다. 아래와 같은 순서로 풀어볼 수 있다. (참고한 자료는 url을 잃어버렸다. 죄송합니다)</p><p><strong>첫 번째</strong>, <code>prime number</code>를 구하기 위한 <code>num</code> 변수를 2 이상 1000이하 까지 조회하는 부분이다. <code>information_schema</code>의 테이블을 이용해 <code>num := num + 1</code> 을 조회하면 아래와 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    @num1 :=@num1 + <span class="number">1</span> <span class="keyword">as</span> num1</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    information_schema.tables t1,</span><br><span class="line">    information_schema.tables t2,</span><br><span class="line">    (<span class="keyword">select</span> @num1 := <span class="number">1</span>) tmp</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p><strong>두 번째</strong>, 소수가 아닌 수를 걸러내기 위해 <code>exists</code> 문을 작성한다. <code>div</code> 변수를 <code>num</code> 변수와 같이 조회하는 문을 이용해 소수<em>(약수는 나와 그 수 밖에 없는 특징 : floor(num / div) != num / div )</em>를 구한다. 이때, <code>where</code>절에 속해야 한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">where</span><br><span class="line">    num1 &lt;= 1000</span><br><span class="line">and not exists (</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        *</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        (</span><br><span class="line">            <span class="keyword">select</span></span><br><span class="line">                @num2 :=@num2 + <span class="number">1</span> <span class="keyword">as</span> num2</span><br><span class="line">            <span class="keyword">from</span></span><br><span class="line">                information_schema.tables <span class="keyword">as</span> t1,</span><br><span class="line">                information_schema.tables <span class="keyword">as</span> t2,</span><br><span class="line">                (<span class="keyword">select</span> @num2 := <span class="number">1</span>) tmp2</span><br><span class="line">            <span class="keyword">limit</span> <span class="number">1000</span></span><br><span class="line">        ) t2</span><br><span class="line">    <span class="keyword">where</span></span><br><span class="line">        <span class="keyword">floor</span>(num1 / num2) = (num1 / num2)</span><br><span class="line">    <span class="keyword">and</span> num2 * num2 &lt;= num1</span><br><span class="line">    <span class="keyword">and</span> num2 &gt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>이제 적절히 두 sql 문을 합쳐주면 된다. 테이블명이 중복되지 않게, 이미 사용한 사용자 변수 또한 중복되지 않게 두 query를 섞어주면 문제를 해결할 수 있다.</p><blockquote><p>특히, 사용자 변수 num1, num2 를 같은 것으로 실행하니 오류가 발생하였다. 앞으로 주의할 것! 사용자 변수는 <strong>모두 다르게</strong></p></blockquote><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">group_concat</span>(num1 separator <span class="string">'&amp;'</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            @num1 :=@num1 + <span class="number">1</span> <span class="keyword">as</span> num1</span><br><span class="line">        <span class="keyword">from</span></span><br><span class="line">            information_schema.tables <span class="keyword">as</span> t1,</span><br><span class="line">            information_schema.tables <span class="keyword">as</span> t2,</span><br><span class="line">            (<span class="keyword">select</span> @num1 := <span class="number">1</span>) tmp1</span><br><span class="line">    ) t1</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    num1 &lt;= <span class="number">1000</span></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">not</span> <span class="keyword">exists</span> (</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        *</span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        (</span><br><span class="line">            <span class="keyword">select</span></span><br><span class="line">                @num2 :=@num2 + <span class="number">1</span> <span class="keyword">as</span> num2</span><br><span class="line">            <span class="keyword">from</span></span><br><span class="line">                information_schema.tables <span class="keyword">as</span> t1,</span><br><span class="line">                information_schema.tables <span class="keyword">as</span> t2,</span><br><span class="line">                (<span class="keyword">select</span> @num2 := <span class="number">1</span>) tmp2</span><br><span class="line">            <span class="keyword">limit</span> <span class="number">1000</span></span><br><span class="line">        ) t2</span><br><span class="line">    <span class="keyword">where</span></span><br><span class="line">        <span class="keyword">floor</span>(num1 / num2) = (num1 / num2)</span><br><span class="line">    <span class="keyword">and</span> num2 * num2 &lt;= num1</span><br><span class="line">    <span class="keyword">and</span> num2 &gt; <span class="number">1</span>);</span><br></pre></td></tr></table></figure><hr><p>2019.10.15 made by <em>jaejun.lee</em></p><!--stackedit_data:eyJoaXN0b3J5IjpbLTEyOTA5NzU5MTgsMTI0NjM5MjY2MCwtNDA2MDA4Nzc5LDQxOTEwMjYxLDEwNTE0NzkxNzYsLTE1NDYzMzA1NDcsLTM5NjczNjYzMSwtOTg3ODQ3ODA4LC0xMjE0MzMzNTUyLC0xNDI4Nzk5NDAsMTYyNTQ1NTc4LDM2ODE5MDkwOCwtODg3NjM2NTgwLDIwODcxODE4NDEsNzQ1MjIyMDhdfQ==-->]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-print_prime_number/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Symmetric Pairs &amp; Draw The Triangle 1</title>
      <link>https://jx2lee.github.io/hackerrank-symmetric_pairs_draw_triangle_1/</link>
      <guid>https://jx2lee.github.io/hackerrank-symmetric_pairs_draw_triangle_1/</guid>
      <pubDate>Sun, 13 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Symmetric Pairs &amp;amp; Draw The Triangle 1&lt;/code&gt; 문제를 정리한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Symmetric Pairs &amp; Draw The Triangle 1</code> 문제를 정리한다.</p><a id="more"></a><h1 id="Symmetric-Pairs"><a href="#Symmetric-Pairs" class="headerlink" title="Symmetric Pairs"></a>Symmetric Pairs</h1><h2 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h2><p>You are given a table,  <em>Functions</em>, containing two columns:  <em>X</em> and  <em>Y</em>.</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12892/1443818798-51909e977d-1.png" alt=""></p><p>Two pairs  <em>(X1, Y1)</em>  and  <em>(X2, Y2)</em>  are said to be  <em>symmetric</em>  <em>pairs</em>  if <em>X1  = Y2</em>  and  <em>X2  = Y1</em>.</p><p>Write a query to output all such  <em>symmetric</em>  <em>pairs</em>  in ascending order by the value of  <em>X</em>.</p><p><strong>Sample Input</strong></p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12892/1443818693-b384c24e35-2.png" alt=""></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">20 20</span><br><span class="line">20 21</span><br><span class="line">22 23</span><br></pre></td></tr></table></figure><h2 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h2><p>문제는 <code>1) x = y</code>인 짝들과 <code>2) x != y</code> 인 짝들의 <em>union</em>으로 접근하였다.<br>우선, <code>1) x = y</code>인 경우는 아래 쿼리로 표현할 수 있다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> x, y</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">as</span> f1</span><br><span class="line"><span class="keyword">where</span> x = y <span class="keyword">and</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> functions <span class="keyword">where</span> x = f1.x <span class="keyword">and</span> y = f1.x) &gt; <span class="number">1</span></span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string">*count(*)  &gt; 1*인 이유는 나온 갯수가 2개 이상인 짝들만 뽑아줘야 하므로 `</span><span class="keyword">where</span><span class="string">`절에 조건을 추가한 것이다. 이후 `</span><span class="number">2</span>) x != y<span class="string">` 는 아래와 같다.</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span><span class="keyword">sql</span></span><br><span class="line"><span class="keyword">select</span> f1.x, f1.y</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">as</span> f1, functions <span class="keyword">as</span> f2</span><br><span class="line"><span class="keyword">where</span> f1.x = f2.y <span class="keyword">and</span> f1.y = f2.x <span class="keyword">and</span> f1.x &lt; f1.y</span><br></pre></td></tr></table></figure><p>주목해야하는 부분은 <code>f1.x &lt; f1.y</code>인 부분으로, 뽑아내는 짝들의 <code>x</code>값이 <code>y</code>보다 작은 짝들만 찾아주게 되면 <code>1) x = y</code>인 부분은 제외할 수 있다. 이와 같은 두 쿼리를 <code>union</code>으로 묶어주고 마지막 <code>order by</code>를 통해 정렬만 하면 문제가 해결된다.</p><h2 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> x, y</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">as</span> f1</span><br><span class="line"><span class="keyword">where</span> x = y <span class="keyword">and</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> functions <span class="keyword">where</span> x = f1.x <span class="keyword">and</span> y = f1.x) &gt; <span class="number">1</span></span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> f1.x, f1.y</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">as</span> f1, functions <span class="keyword">as</span> f2</span><br><span class="line"><span class="keyword">where</span> f1.x = f2.y <span class="keyword">and</span> f1.y = f2.x <span class="keyword">and</span> f1.x &lt; f1.y</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> x;</span><br></pre></td></tr></table></figure><h1 id="Draw-The-Triangle-1"><a href="#Draw-The-Triangle-1" class="headerlink" title="Draw The Triangle 1"></a>Draw The Triangle 1</h1><h2 id="문제-1"><a href="#문제-1" class="headerlink" title="문제"></a>문제</h2><p><em>P(R)</em>  represents a pattern drawn by Julia in  <em>R</em>  rows. The following pattern represents  <em>P(5)</em>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* * * * * </span><br><span class="line">* * * * </span><br><span class="line">* * * </span><br><span class="line">* * </span><br><span class="line">*</span><br></pre></td></tr></table></figure><p>Write a query to print the pattern  <em>P(20)</em>.</p><h2 id="접근-1"><a href="#접근-1" class="headerlink" title="접근"></a>접근</h2><p><em>사용자 정의 변수</em>를 이용해 접근하였다.<br><code>i</code>라는 변수를 21로 선언하고, <code>repeat</code>함수를 이용해 <code>i &gt; 0</code>일 때까지 반복하는 쿼리를 작성하였다. 4문장으로 쉽게 풀리는 문제인데, <em>사용자 정의 변수</em>에 대해 다시 한 번 생각해보자는 의미로 정리하였고 다음에는 꼭 틀리지 말자.</p><h2 id="해결-1"><a href="#해결-1" class="headerlink" title="해결"></a>해결</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> @i = <span class="number">21</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">repeat</span>(<span class="string">'* '</span>, @i := @i - <span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> information_schema.tables</span><br><span class="line"><span class="keyword">where</span> @i &gt; <span class="number">0</span>;</span><br></pre></td></tr></table></figure><hr><p>2019.10.14 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-symmetric_pairs_draw_triangle_1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Contest Leaderboard</title>
      <link>https://jx2lee.github.io/hackerrank-contest_leaderboard/</link>
      <guid>https://jx2lee.github.io/hackerrank-contest_leaderboard/</guid>
      <pubDate>Wed, 09 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Contest Leaderboard&lt;/code&gt; 문제를 &lt;code&gt;Group by&lt;/code&gt;를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Contest Leaderboard</code> 문제를 <code>Group by</code>를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>You did such a great job helping Julia with her last coding contest challenge that she wants you to work on this one, too!</p><p>The total score of a hacker is the sum of their maximum scores for all of the challenges. Write a query to print the  <em>hacker_id</em>,  <em>name</em>, and total score of the hackers ordered by the descending score. If more than one hacker achieved the same total score, then sort the result by ascending  <em>hacker_id</em>. Exclude all hackers with a total score of  from your result.</p><p><strong>Input Format</strong></p><p>The following tables contain contest data:</p><ul><li><p><em>Hackers:</em>  The  <em>hacker_id</em>  is the id of the hacker, and  <em>name</em>  is the name of the hacker.  <img src="https://s3.amazonaws.com/hr-challenge-images/19503/1458522826-a9ddd28469-ScreenShot2016-03-21at6.40.27AM.png" alt=""></p></li><li><p><em>Submissions:</em>  The  <em>submission_id</em>  is the id of the submission,  <em>hacker_id</em>  is the id of the hacker who made the submission,  <em>challenge_id</em>  is the id of the challenge for which the submission belongs to, and  <em>score</em>  is the score of the submission.  <img src="https://s3.amazonaws.com/hr-challenge-images/19503/1458523022-771511df90-ScreenShot2016-03-21at6.40.37AM.png" alt=""></p></li></ul><p><strong>Sample Input</strong></p><p><em>Hackers</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19503/1458523374-7ecc39010f-ScreenShot2016-03-21at6.51.56AM.png" alt=""></p><p><em>Submissions</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19503/1458523388-0896218137-ScreenShot2016-03-21at6.51.45AM.png" alt=""></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">4071 Rose 191</span><br><span class="line">74842 Lisa 174</span><br><span class="line">84072 Bonnie 100</span><br><span class="line">4806 Angela 89</span><br><span class="line">26071 Frank 85</span><br><span class="line">80305 Kimberly 67</span><br><span class="line">49438 Patrick 43</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>Hacker  <em>4071</em>  submitted solutions for challenges  <em>19797</em>  and  <em>49593</em>, so the total score  .</p><p>Hacker  <em>74842</em>  submitted solutions for challenges  <em>19797</em>  and  <em>63132</em>, so the total score</p><p>Hacker  <em>84072</em>  submitted solutions for challenges  <em>49593</em>  and  <em>63132</em>, so the total score  .</p><p>The total scores for hackers  <em>4806</em>,  <em>26071</em>,  <em>80305</em>, and  <em>49438</em>  can be similarly calculated.</p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p>우선은, <code>challenge_id / hacker_id 별 score의 최댓값</code>을 구하고 이를 <code>hackers</code> 테이블과 조인한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> h.hacker_id, h.name, <span class="keyword">sum</span>(m.score) <span class="keyword">as</span> total_score</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> hacker_id, challenge_id, <span class="keyword">max</span>(score) <span class="keyword">as</span> score</span><br><span class="line">    <span class="keyword">from</span> submissions</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> challenge_id, hacker_id) <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">join</span> hackers <span class="keyword">as</span> h <span class="keyword">on</span> h.hacker_id = m.hacker_id</span><br></pre></td></tr></table></figure><p>이후 <code>max score</code>들의 <code>total_score</code>를 구하기 위해 <code>hacker_id / name 을 key로 하여 group by</code> 한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> h.hacker_id, h.name, <span class="keyword">sum</span>(m.score) <span class="keyword">as</span> total_score</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> hacker_id, challenge_id, <span class="keyword">max</span>(score) <span class="keyword">as</span> score</span><br><span class="line">    <span class="keyword">from</span> submissions</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> challenge_id, hacker_id) <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">join</span> hackers <span class="keyword">as</span> h <span class="keyword">on</span> h.hacker_id = m.hacker_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> h.hacker_id, h.name</span><br></pre></td></tr></table></figure><p>마지막으로 문제에 따라 정렬만 하면 된다.</p><blockquote><p><em>(total_score &gt; 0인 조건도 추가)</em></p></blockquote><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> h.hacker_id, h.name, <span class="keyword">sum</span>(m.score) <span class="keyword">as</span> total_score</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> hacker_id, challenge_id, <span class="keyword">max</span>(score) <span class="keyword">as</span> score</span><br><span class="line">    <span class="keyword">from</span> submissions</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> challenge_id, hacker_id) <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">join</span> hackers <span class="keyword">as</span> h <span class="keyword">on</span> h.hacker_id = m.hacker_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> h.hacker_id, h.name</span><br><span class="line"><span class="keyword">having</span> total_score &gt; <span class="number">0</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> total_score <span class="keyword">desc</span>, h.hacker_id;</span><br></pre></td></tr></table></figure><hr><p>2019.10.10 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-contest_leaderboard/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] SQL Project Planning</title>
      <link>https://jx2lee.github.io/hackerrank-project_planning/</link>
      <guid>https://jx2lee.github.io/hackerrank-project_planning/</guid>
      <pubDate>Wed, 09 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;SQL Project Planning&lt;/code&gt; 문제를 정리한다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>SQL Project Planning</code> 문제를 정리한다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>You are given a table,  <em>Projects</em>, containing three columns:  <em>Task_ID</em>,  <em>Start_Date</em>  and  <em>End_Date</em>. It is guaranteed that the difference between the  <em>End_Date</em>  and the  <em>Start_Date</em>  is equal to  <em>1</em>  day for each row in the table.</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12894/1443819551-639948acc0-1.png" alt=""></p><p>If the  <em>End_Date</em>  of the tasks are consecutive, then they are part of the same project. Samantha is interested in finding the total number of different projects completed.</p><p>Write a query to output the start and end dates of projects listed by the number of days it took to complete the project in ascending order. If there is more than one project that have the same number of completion days, then order by the start date of the project.</p><p><strong>Sample Input</strong></p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12894/1443819440-1c40e943a1-2.png" alt=""></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2015-10-28 2015-10-29</span><br><span class="line">2015-10-30 2015-10-31</span><br><span class="line">2015-10-13 2015-10-15</span><br><span class="line">2015-10-01 2015-10-04</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>The example describes following  <em>four</em>  projects:</p><ul><li><em>Project 1</em>: Tasks  <em>1</em>,  <em>2</em>  and  <em>3</em>  are completed on consecutive days, so these are part of the project. Thus start date of project is  <em>2015-10-01</em>  and end date is  <em>2015-10-04</em>, so it took  <em>3 days</em>  to complete the project.</li><li><em>Project 2</em>: Tasks  <em>4</em> and <em>5</em> are completed on consecutive days, so these are part of the project. Thus, the start date of project is <em>2015-10-13</em> and end date is <em>2015-10-15</em>, so it took <em>2 days</em> to complete the project.</li><li><em>Project 3</em>: Only task  <em>6</em> is part of the project. Thus, the start date of project is <em>2015-10-28</em> and end date is <em>2015-10-29</em>, so it took <em>1 day</em> to complete the project.</li><li><em>Project 4</em>: Only task <em>7</em> is part of the project. Thus, the start date of project is <em>2015-10-30</em> and end date is <em>2015-10-31</em>, so it took <em>1 day</em> to complete the project.</li></ul><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p>프로젝트의 시작과 끝 날짜를 출력하는 문제. 테이블에는 각각의 <code>task</code>들이 <code>start_date, end_date</code>로 구성되었고 같은 프로젝트는 각 <code>task</code>가 이어질 수 있다. 처음 접근했을 때 <code>join</code>을 이용해 <code>p1, p2</code> 테이블로부터 <code>p1.end_date=p2.start_date</code>를 이용하였지만 실패하여 <a href="https://nifannn.github.io/2017/10/24/SQL-Notes-Hackerrank-Projects/" target="_blank" rel="noopener">블로그</a>를 참고하였다.</p><p>우선 <code>start_date</code>가 <code>end_date</code>에 포함되지 않는 날짜를 확인한다. 이는 프로젝트의 시작일 것이다</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> start_date</span><br><span class="line"><span class="keyword">from</span> projects</span><br><span class="line"><span class="keyword">where</span> start_date <span class="keyword">not</span> <span class="keyword">in</span></span><br><span class="line">(<span class="keyword">select</span> end_date <span class="keyword">from</span> projects);</span><br></pre></td></tr></table></figure><p>마찬가지로 <code>end_date</code>가 <code>start_date</code>에 포함되지 않는 날짜를 확인한다. 이는 프로젝트이 끝일 것이다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> end_date</span><br><span class="line"><span class="keyword">from</span> projects</span><br><span class="line"><span class="keyword">where</span> end_date <span class="keyword">not</span> <span class="keyword">in</span></span><br><span class="line">(<span class="keyword">select</span> start_date <span class="keyword">from</span> projects);</span><br></pre></td></tr></table></figure><p>그런 다음 각 프로젝트에 대해 (시작 날짜, 종료 날짜) 쌍을 찾아야한다. 그 전에 프로젝트의 시작 날짜와 종료 날짜를 <code>교차</code>시켜 <code>모든 잠재적 쌍</code>을 생성한다. 또한, 동일한 프로젝트의 경우 종료 날짜는 프로젝트 시작 날짜보다 큰 프로젝트의 모든 종료 날짜 중 가장 작아야한다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> start_date, <span class="keyword">min</span>(end_date)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> start_date <span class="keyword">from</span> projects <span class="keyword">where</span> start_date <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> end_date <span class="keyword">from</span> projects)) <span class="keyword">as</span> t1,</span><br><span class="line">    (<span class="keyword">select</span> end_date <span class="keyword">from</span> projects <span class="keyword">where</span> end_date <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> start_date <span class="keyword">from</span> projects)) <span class="keyword">as</span> t2</span><br><span class="line"><span class="keyword">where</span> start_date &lt; end_date</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> start_date</span><br></pre></td></tr></table></figure><p>마지막 문제 조건 중 프로젝트 수행 기간이 짧은 순서로, 수행 기간이 같다면 시작 날짜를 기준으로 정렬하면 해결할 수 있다. <em>(datediff 함수 이용 - 두 날짜 데이터 차이값 생성)</em></p><ul><li>ADD <code>order by datediff(min(end_date), start_date), start_date</code></li></ul><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> start_date, <span class="keyword">min</span>(end_date)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> start_date <span class="keyword">from</span> projects <span class="keyword">where</span> start_date <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> end_date <span class="keyword">from</span> projects)) <span class="keyword">as</span> t1,</span><br><span class="line">    (<span class="keyword">select</span> end_date <span class="keyword">from</span> projects <span class="keyword">where</span> end_date <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> start_date <span class="keyword">from</span> projects)) <span class="keyword">as</span> t2</span><br><span class="line"><span class="keyword">where</span> start_date &lt; end_date</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> start_date</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">datediff</span>(<span class="keyword">min</span>(end_date), start_date), start_date;</span><br></pre></td></tr></table></figure><hr><p>2019.10.10 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-project_planning/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Challenges</title>
      <link>https://jx2lee.github.io/hackerrank-challenges/</link>
      <guid>https://jx2lee.github.io/hackerrank-challenges/</guid>
      <pubDate>Sun, 06 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Challenges&lt;/code&gt; 문제를 &lt;code&gt;Join&lt;/code&gt;을 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Challenges</code> 문제를 <code>Join</code>을 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Julia asked her students to create some coding challenges. Write a query to print the  <em>hacker_id</em>,  <em>name</em>, and the total number of challenges created by each student. Sort your results by the total number of challenges in descending order. If more than one student created the same number of challenges, then sort the result by  <em>hacker_id</em>. If more than one student created the same number of challenges and the count is less than the maximum number of challenges created, then exclude those students from the result.</p><p><strong>Input Format</strong></p><p>The following tables contain challenge data:</p><ul><li><p><em>Hackers:</em>  The  <em>hacker_id</em>  is the id of the hacker, and  <em>name</em>  is the name of the hacker.  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521004-cb4c077dd3-ScreenShot2016-03-21at6.06.54AM.png" alt=""></p></li><li><p><em>Challenges:</em>  The  <em>challenge_id</em>  is the id of the challenge, and  <em>hacker_id</em>  is the id of the student who created the challenge.  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521079-549341d9ec-ScreenShot2016-03-21at6.07.03AM.png" alt=""></p></li></ul><hr><p><strong>Sample Input 0</strong></p><p><em>Hackers</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521384-34c6866dae-ScreenShot2016-03-21at6.07.15AM.png" alt="">  <em>Challenges</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521410-befa8e1cd9-ScreenShot2016-03-21at6.07.25AM.png" alt=""></p><p><strong>Sample Output 0</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">21283 Angela 6</span><br><span class="line">88255 Patrick 5</span><br><span class="line">96196 Lisa 1</span><br></pre></td></tr></table></figure><p><strong>Sample Input 1</strong></p><p><em>Hackers</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521469-87036deea3-ScreenShot2016-03-21at6.07.48AM.png" alt="">  <em>Challenges</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521490-358215cf0b-ScreenShot2016-03-21at6.07.58AM.png" alt=""></p><p><strong>Sample Output 1</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">12299 Rose 6</span><br><span class="line">34856 Angela 6</span><br><span class="line">79345 Frank 4</span><br><span class="line">80491 Patrick 3</span><br><span class="line">81041 Lisa 1</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>For  <em>Sample Case 0</em>, we can get the following details:<br><img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521677-fd04c384c0-ScreenShot2016-03-21at6.07.38AM.png" alt=""><br>Students  and  both created  challenges, but the maximum number of challenges created is  so these students are excluded from the result.</p><p>For  <em>Sample Case 1</em>, we can get the following details:<br><img src="https://s3.amazonaws.com/hr-challenge-images/19506/1458521836-24039e7523-ScreenShot2016-03-21at6.08.08AM.png" alt=""><br>Students  and  both created  challenges. Because  is the maximum number of challenges created, these students are included in the result.</p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>group by</code> 조건 중 <code>1) 최댓값이 하나여야하고</code>, <code>2) 최댓값 아래로 중복되는 횟수를 가지면 안된다</code> 를 만족하는 것이 어려웠다. <code>count</code> 값을 <code>OR</code>을 이용해 만족하는 범위로 <code>having</code>절을 작성하여 해결할 수 있었다. 순서는 아래와 같이 풀었다.</p><ul><li><code>hackers</code> 테이블과 <code>challenges</code> 테이블을 <code>join</code> 및 <code>group by</code> <em>(group by key는 id / name)</em></li><li><code>having</code> 절 <code>cnt</code> 조건을 <code>OR</code>로 작성 <em>(1. max value, 2. not duplicated)</em> </li><li>문제 조건에 맞는 <code>order by</code> 추가</li></ul><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    c.hacker_id, h.name, <span class="keyword">count</span>(c.challenge_id) <span class="keyword">as</span> cnt</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    challenges <span class="keyword">as</span> c</span><br><span class="line"><span class="keyword">join</span> hackers <span class="keyword">as</span> h <span class="keyword">on</span> c.hacker_id = h.hacker_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    c.hacker_id, h.name</span><br><span class="line"><span class="keyword">having</span></span><br><span class="line">    cnt =  (<span class="keyword">select</span></span><br><span class="line">                <span class="keyword">count</span>(c1.challenge_id)</span><br><span class="line">            <span class="keyword">from</span></span><br><span class="line">                challenges <span class="keyword">as</span> c1</span><br><span class="line">            <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">                c1.hacker_id</span><br><span class="line">            <span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">                <span class="keyword">count</span>(c1.challenge_id) <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">1</span>) <span class="keyword">or</span></span><br><span class="line">    cnt <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span></span><br><span class="line">                    <span class="keyword">count</span>(c2.challenge_id)</span><br><span class="line">                <span class="keyword">from</span></span><br><span class="line">                    challenges <span class="keyword">as</span> c2</span><br><span class="line">                <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">                    c2.hacker_id</span><br><span class="line">                <span class="keyword">having</span></span><br><span class="line">                    c2.hacker_id &lt;&gt; c.hacker_id)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    cnt <span class="keyword">desc</span>, c.hacker_id;</span><br></pre></td></tr></table></figure><hr><p>2019.10.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-challenges/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 단어 변환</title>
      <link>https://jx2lee.github.io/programmers-disk_controller/</link>
      <guid>https://jx2lee.github.io/programmers-disk_controller/</guid>
      <pubDate>Sun, 06 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;특정 기준을 가지고 단어를 변환할 때 최소 횟수를 구하는 문제를 풀어본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>특정 기준을 가지고 단어를 변환할 때 최소 횟수를 구하는 문제를 풀어본다.</p><a id="more"></a><h1 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h1><p>하드디스크는 한 번에 하나의 작업만 수행할 수 있습니다. 디스크 컨트롤러를 구현하는 방법은 여러 가지가 있습니다. 가장 일반적인 방법은 요청이 들어온 순서대로 처리하는 것입니다.<br>예를들어</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 0ms 시점에 3ms가 소요되는 A작업 요청</span><br><span class="line">- 1ms 시점에 9ms가 소요되는 B작업 요청</span><br><span class="line">- 2ms 시점에 6ms가 소요되는 C작업 요청</span><br></pre></td></tr></table></figure><p>와 같은 요청이 들어왔습니다. 이를 그림으로 표현하면 아래와 같습니다.<br><img src="https://grepp-programmers.s3.amazonaws.com/files/production/b68eb5cec6/38dc6a53-2d21-4c72-90ac-f059729c51d5.png" alt="Screen Shot 2018-09-13 at 6.34.58 PM.png"></p><p>한 번에 하나의 요청만을 수행할 수 있기 때문에 각각의 작업을 요청받은 순서대로 처리하면 다음과 같이 처리 됩니다.<br><img src="https://grepp-programmers.s3.amazonaws.com/files/production/5e677b4646/90b91fde-cac4-42c1-98b8-8f8431c52dcf.png" alt="Screen Shot 2018-09-13 at 6.38.52 PM.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- A: 3ms 시점에 작업 완료 (요청에서 종료까지 : 3ms)</span><br><span class="line">- B: 1ms부터 대기하다가, 3ms 시점에 작업을 시작해서 12ms 시점에 작업 완료(요청에서 종료까지 : 11ms)</span><br><span class="line">- C: 2ms부터 대기하다가, 12ms 시점에 작업을 시작해서 18ms 시점에 작업 완료(요청에서 종료까지 : 16ms)</span><br></pre></td></tr></table></figure><p>이 때 각 작업의 요청부터 종료까지 걸린 시간의 평균은 10ms(= (3 + 11 + 16) / 3)가 됩니다.</p><p>하지만 A → C → B 순서대로 처리하면<br><img src="https://grepp-programmers.s3.amazonaws.com/files/production/9eb7c5a6f1/a6cff04d-86bb-4b5b-98bf-6359158940ac.png" alt="Screen Shot 2018-09-13 at 6.41.42 PM.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- A: 3ms 시점에 작업 완료(요청에서 종료까지 : 3ms)</span><br><span class="line">- C: 2ms부터 대기하다가, 3ms 시점에 작업을 시작해서 9ms 시점에 작업 완료(요청에서 종료까지 : 7ms)</span><br><span class="line">- B: 1ms부터 대기하다가, 9ms 시점에 작업을 시작해서 18ms 시점에 작업 완료(요청에서 종료까지 : 17ms)</span><br></pre></td></tr></table></figure><p>이렇게 A → C → B의 순서로 처리하면 각 작업의 요청부터 종료까지 걸린 시간의 평균은 9ms(= (3 + 7 + 17) / 3)가 됩니다.</p><p>각 작업에 대해 [작업이 요청되는 시점, 작업의 소요시간]을 담은 2차원 배열 jobs가 매개변수로 주어질 때, 작업의 요청부터 종료까지 걸린 시간의 평균을 가장 줄이는 방법으로 처리하면 평균이 얼마가 되는지 return 하도록 solution 함수를 작성해주세요. (단, 소수점 이하의 수는 버립니다)</p><h2 id="제한-사항"><a href="#제한-사항" class="headerlink" title="제한 사항"></a>제한 사항</h2><ul><li>jobs의 길이는 1 이상 500 이하입니다.</li><li>jobs의 각 행은 하나의 작업에 대한 [작업이 요청되는 시점, 작업의 소요시간] 입니다.</li><li>각 작업에 대해 작업이 요청되는 시간은 0 이상 1,000 이하입니다.</li><li>각 작업에 대해 작업의 소요시간은 1 이상 1,000 이하입니다.</li><li>하드디스크가 작업을 수행하고 있지 않을 때에는 먼저 요청이 들어온 작업부터 처리합니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><p>jobs</p><p>return</p><p>[[0, 3], [1, 9], [2, 6]]</p><p>9</p><h2 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h2><p>문제에 주어진 예와 같습니다.</p><ul><li>0ms 시점에 3ms 걸리는 작업 요청이 들어옵니다.</li><li>1ms 시점에 9ms 걸리는 작업 요청이 들어옵니다.</li><li>2ms 시점에 6ms 걸리는 작업 요청이 들어옵니다.</li></ul><h1 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h1><p><code>heap</code> 을 이용해야 하는 문제. 사실 이에 대한 개념이 부족하여 공부하려 했지만 방대하길래 우선 패쓰하고 블로그를 참고하였다. 시간이 된다면 <code>heap</code> 에 대해 글을 정리하고 우선 아래와 같은 변수를 통해 해결하였다.</p><ul><li>변수<ul><li><code>in_</code>, <code>out_</code> : 작업을 시작/종료한 시간</li><li><code>ans&#39;</code> : 총 작업 시간</li><li><code>n</code> : 총 작업의 갯수</li><li><code>cnt</code> : <code>heap</code> 구조에서 자료가 빠져나간 횟수로 while문에 사용</li><li><code>wt</code> : <code>heap</code>구조로 작업의 종료 시간을 담는다.</li></ul></li></ul><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><p><a href="https://codedrive.tistory.com/129" target="_blank" rel="noopener">참고 블로그</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(jobs)</span>:</span></span><br><span class="line">    in_, out_, ans, cnt = <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    wt = []</span><br><span class="line">    n = len(jobs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> cnt &lt; n:</span><br><span class="line">        <span class="keyword">for</span> job <span class="keyword">in</span> jobs:</span><br><span class="line">            <span class="keyword">if</span> in_ &lt; job[<span class="number">0</span>] &lt;= out_ :</span><br><span class="line">                ans += (out_ - job[<span class="number">0</span>])</span><br><span class="line">                heapq.heappush(wt, job[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(wt) &gt; <span class="number">0</span>:</span><br><span class="line">            ans += len(wt) * wt[<span class="number">0</span>] <span class="comment">#len(wt)를 곱하는 이유는 대기열에 들어간 작업도 작업 중인 시간을 더해야하므로 wt 길이를 곱해준다.</span></span><br><span class="line">            in_ = out_</span><br><span class="line">            out_ += heapq.heappop(wt)</span><br><span class="line">            cnt += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out_ += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ans // n</span><br></pre></td></tr></table></figure><hr><p>2019.10.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-disk_controller/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Ollivander&#39;s Inventory</title>
      <link>https://jx2lee.github.io/hackerrank-ollivanders_inventory/</link>
      <guid>https://jx2lee.github.io/hackerrank-ollivanders_inventory/</guid>
      <pubDate>Sun, 06 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Ollivander&amp;#39;s Inventory&lt;/code&gt; 문제를 &lt;code&gt;Group by&lt;/code&gt;를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Ollivander&#39;s Inventory</code> 문제를 <code>Group by</code>를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Harry Potter and his friends are at Ollivander’s with Ron, finally replacing Charlie’s old broken wand.</p><p>Hermione decides the best way to choose is by determining the minimum number of gold galleons needed to buy each  <em>non-evil</em>  wand of high power and age. Write a query to print the  <em>id</em>,  <em>age</em>,  <em>coins_needed</em>, and  <em>power</em>  of the wands that Ron’s interested in, sorted in order of descending  <em>power</em>. If more than one wand has same power, sort the result in order of descending  <em>age</em>.</p><p><strong>Input Format</strong></p><p>The following tables contain data on the wands in Ollivander’s inventory:</p><ul><li><p><em>Wands:</em>  The  <em>id</em>  is the id of the wand,  <em>code</em>  is the code of the wand,  <em>coins_needed</em>  is the total number of gold galleons needed to buy the wand, and  <em>power</em>  denotes the quality of the wand (the higher the power, the better the wand is).  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458538092-b2a8163a74-ScreenShot2016-03-08at12.13.39AM.png" alt=""></p></li><li><p><em>Wands_Property:</em>  The  <em>code</em>  is the code of the wand,  <em>age</em>  is the age of the wand, and  <em>is_evil</em>  denotes whether the wand is good for the dark arts. If the value of  <em>is_evil</em>  is  <em>0</em>, it means that the wand is not evil. The mapping between  <em>code</em>  and  <em>age</em>  is one-one, meaning that if there are two pairs,  and  , then  and  .<img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458538221-18c4092b7d-ScreenShot2016-03-08at12.13.53AM.png" alt=""></p></li></ul><hr><p><strong>Sample Input</strong></p><p><em>Wands</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458538559-51bf29644e-ScreenShot2016-03-21at10.34.41AM.png" alt="">  <em>Wands_Property</em>  Table:  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458538583-fd514566f9-ScreenShot2016-03-21at10.34.28AM.png" alt=""></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">9 45 1647 10</span><br><span class="line">12 17 9897 10</span><br><span class="line">1 20 3688 8</span><br><span class="line">15 40 6018 7</span><br><span class="line">19 20 7651 6</span><br><span class="line">11 40 7587 5</span><br><span class="line">10 20 504 5</span><br><span class="line">18 40 3312 3</span><br><span class="line">20 17 5689 3</span><br><span class="line">5 45 6020 2</span><br><span class="line">14 40 5408 1</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>The data for wands of  <em>age 45</em>  (code 1):  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458539700-2f319702ab-ScreenShot2016-03-21at11.23.06AM.png" alt=""></p><ul><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li></ul><p>The data for wands of  <em>age 40</em>  (code 2):  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458539909-ab79f7ff95-ScreenShot2016-03-21at11.23.14AM.png" alt=""></p><ul><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li></ul><p>The data for wands of  <em>age 20</em>  (code 4):  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458540035-d950b9c900-ScreenShot2016-03-21at11.23.25AM.png" alt=""></p><ul><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li></ul><p>The data for wands of  <em>age 17</em>  (code 5):  <img src="https://s3.amazonaws.com/hr-challenge-images/19502/1458540132-79fd7b916b-ScreenShot2016-03-21at11.23.34AM.png" alt=""></p><ul><li>The minimum number of galleons needed for</li><li>The minimum number of galleons needed for</li></ul><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>determining the minimum number of gold galleons needed</code> 부분을 놓쳤다. <code>Wands</code> 테이블에서 <code>code/power</code> 별 coins_needed의 <code>최솟값</code>을 찾은 테이블과 <code>Wands / Wands_property</code> 테이블을 조인하여 <code>order by</code>만 추가하여 쿼리를 완성하면 된다.</p><ul><li>code, power, min(coins_needed) 를 code/power 별 <code>group by</code></li><li>wands/wands_property 테이블과 join <em>(wands 테이블 조인 시 code/coins_needed 일치)</em></li><li><code>order by</code> 로 power/age descending</li></ul><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> w.id, p.age, w.coins_needed, w.power</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> code, <span class="keyword">power</span>, <span class="keyword">min</span>(coins_needed) <span class="keyword">as</span> coins_needed</span><br><span class="line">    <span class="keyword">from</span> wands</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> code, <span class="keyword">power</span>) <span class="keyword">as</span> m</span><br><span class="line"><span class="keyword">join</span> wands <span class="keyword">as</span> w <span class="keyword">on</span> w.code = m.code <span class="keyword">and</span> w.coins_needed = m.coins_needed</span><br><span class="line"><span class="keyword">join</span> wands_property <span class="keyword">as</span> p <span class="keyword">on</span> p.code = m.code</span><br><span class="line"><span class="keyword">where</span> p.is_evil = <span class="number">0</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> m.power <span class="keyword">desc</span>, p.age <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><hr><p>2019.10.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-ollivanders_inventory/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] The Report</title>
      <link>https://jx2lee.github.io/hackerrank-the_report/</link>
      <guid>https://jx2lee.github.io/hackerrank-the_report/</guid>
      <pubDate>Thu, 03 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;The Report&lt;/code&gt; 문제를 &lt;code&gt;Join&lt;/code&gt;을 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>The Report</code> 문제를 <code>Join</code>을 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>You are given two tables: <em>Students</em> and <em>Grades</em>. <em>Students</em> contains three columns <em>ID</em>, <em>Name</em> and <em>Marks</em>.</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12891/1443818166-a5c852caa0-1.png" alt="img"></p><p><em>Grades</em> contains the following data:</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12891/1443818137-69b76d805c-2.png" alt="img"></p><p><em>Ketty</em> gives <em>Eve</em> a task to generate a report containing three columns: <em>Name</em>, <em>Grade</em> and <em>Mark</em>. <em>Ketty</em> doesn’t want the NAMES of those students who received a grade lower than <em>8</em>. The report must be in descending order by grade – i.e. higher grades are entered first. If there is more than one student with the same grade (8-10) assigned to them, order those particular students by their name alphabetically. Finally, if the grade is lower than 8, use “NULL” as their name and list them by their grades in descending order. If there is more than one student with the same grade (1-7) assigned to them, order those particular students by their marks in ascending order.</p><p>Write a query to help Eve.</p><p><strong>Sample Input</strong></p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12891/1443818093-b79f376ec1-3.png" alt="img"></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Maria 10 99</span><br><span class="line">Jane 9 81</span><br><span class="line">Julia 9 88 </span><br><span class="line">Scarlet 8 78</span><br><span class="line">NULL 7 63</span><br><span class="line">NULL 7 68</span><br></pre></td></tr></table></figure><p><strong>Note</strong></p><p>Print “NULL”  as the name if the grade is less than 8.</p><p><strong>Explanation</strong></p><p>Consider the following table with the grades assigned to the students:</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12891/1443818026-0b3af8db30-4.png" alt="img"></p><p>So, the following students got <em>8</em>, <em>9</em> or <em>10</em> grades:</p><ul><li><em>Maria (grade 10)</em></li><li><em>Jane (grade 9)</em></li><li><em>Julia (grade 9)</em></li><li><em>Scarlet (grade 8)</em></li></ul><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>order by</code> 에 name이 <code>NULL</code>인 학생들 중 같은 Grade이면 점수를 <code>오름차순</code> 정렬할 때 헷갈렸다. <code>name</code> 정렬 후 <code>marks</code>로 정렬하면 끝나는 문제. 그리고 처음엔 <code>Union</code>으로 문제를 접근했는데 <code>case</code>문으로 쉽게 풀 수 있었다.</p><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">case</span></span><br><span class="line">        <span class="keyword">when</span> g.grade &lt; <span class="number">8</span> <span class="keyword">then</span> <span class="literal">null</span></span><br><span class="line">        <span class="keyword">else</span> s.name</span><br><span class="line">    <span class="keyword">end</span>, g.grade, s.marks</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    students <span class="keyword">as</span> s</span><br><span class="line"><span class="keyword">join</span> grades <span class="keyword">as</span> g <span class="keyword">on</span> s.marks <span class="keyword">between</span> g.min_mark <span class="keyword">and</span> g.max_mark</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    g.grade <span class="keyword">desc</span>, s.name, s.marks;</span><br></pre></td></tr></table></figure><hr><p>2019.10.04 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-the_report/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Weather Observation Station 20</title>
      <link>https://jx2lee.github.io/hackerrank-weather_observation_station_20/</link>
      <guid>https://jx2lee.github.io/hackerrank-weather_observation_station_20/</guid>
      <pubDate>Tue, 01 Oct 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Weather Observation Station 20&lt;/code&gt; 문제를 &lt;code&gt;사용자 정의 변수&lt;/code&gt;를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Weather Observation Station 20</code> 문제를 <code>사용자 정의 변수</code>를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>A <em>median</em> is defined as a number separating the higher half of a data set from the lower half. Query the <em>median</em> of the <em>Northern Latitudes</em> (<em>LAT_N</em>) from <strong>STATION</strong> and round your answer to  decimal places.</p><p><strong>Input Format</strong></p><p>The <strong>STATION</strong> table is described as follows:</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/9336/1449345840-5f0a551030-Station.jpg" alt="Station.jpg"></p><p>where <em>LAT_N</em> is the northern latitude and <em>LONG_W</em> is the western longitude.</p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>사용자 정의 변수</code>를 이용해 <code>median</code>을 구하는 문제이다.</p><p><code>row index</code>가 1부터 시작하며 <code>LAT_N</code>을 기준으로 <code>sorting</code>된 테이블에서, <code>index</code>가 <code>@ct/2.0, @ct/2.0+1</code> 범위일 경우 조회하는 query를 작성하였다. 여기선 <code>@ct</code>는 median 계산을 위해 테이블 전체 행을 뜻한다.</p><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> @row_id = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">set</span> @ct = (<span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> station);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">round</span>(<span class="keyword">avg</span>(LAT_N), <span class="number">4</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> * <span class="keyword">from</span> station <span class="keyword">order</span> <span class="keyword">by</span> LAT_N) <span class="keyword">as</span> <span class="keyword">sample</span></span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">(<span class="keyword">select</span> @row_id := @row_id + <span class="number">1</span>) <span class="keyword">between</span> @ct/<span class="number">2.0</span> <span class="keyword">and</span> @ct/<span class="number">2.0</span> + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>2019.10.02 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-weather_observation_station_20/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 예산</title>
      <link>https://jx2lee.github.io/programmers-budgets/</link>
      <guid>https://jx2lee.github.io/programmers-budgets/</guid>
      <pubDate>Mon, 30 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;정해진 총액 이하에서 가능한 한 최대 예산을 배정하는 문제를 풀어본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>정해진 총액 이하에서 가능한 한 최대 예산을 배정하는 문제를 풀어본다.</p><a id="more"></a><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><h3 id="문제-설명-1"><a href="#문제-설명-1" class="headerlink" title="문제 설명"></a>문제 설명</h3><p>국가의 역할 중 하나는 여러 지방의 예산요청을 심사하여 국가의 예산을 분배하는 것입니다. 국가예산의 총액은 미리 정해져 있어서 모든 예산요청을 배정해 주기는 어려울 수도 있습니다. 그래서 정해진 총액 이하에서 <strong>가능한 한 최대의</strong> 총 예산을 다음과 같은 방법으로 배정합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 모든 요청이 배정될 수 있는 경우에는 요청한 금액을 그대로 배정합니다.</span><br><span class="line">2. 모든 요청이 배정될 수 없는 경우에는 특정한 정수 상한액을 계산하여 그 이상인 예산요청에는 모두 상한액을 배정합니다. </span><br><span class="line">   상한액 이하의 예산요청에 대해서는 요청한 금액을 그대로 배정합니다.</span><br></pre></td></tr></table></figure><p>예를 들어, 전체 국가예산이 485이고 4개 지방의 예산요청이 각각 120, 110, 140, 150일 때, 상한액을 127로 잡으면 위의 요청들에 대해서 각각 120, 110, 127, 127을 배정하고 그 합이 484로 가능한 최대가 됩니다.<br>각 지방에서 요청하는 예산이 담긴 배열 budgets과 총 예산 M이 매개변수로 주어질 때, 위의 조건을 모두 만족하는 상한액을 return 하도록 solution 함수를 작성해주세요.</p><h3 id="제한-사항"><a href="#제한-사항" class="headerlink" title="제한 사항"></a>제한 사항</h3><ul><li>지방의 수는 3 이상 100,000 이하인 자연수입니다.</li><li>각 지방에서 요청하는 예산은 1 이상 100,000 이하인 자연수입니다.</li><li>총 예산은 <code>지방의 수</code> 이상 1,000,000,000 이하인 자연수입니다.</li></ul><h3 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h3><table><thead><tr><th>budgets</th><th>M</th><th>return</th></tr></thead><tbody><tr><td>[120, 110, 140, 150]</td><td>485</td><td>127</td></tr></tbody></table><p><a href="https://www.digitalculture.or.kr/koi/selectOlymPiadDissentList.do" target="_blank" rel="noopener">출처</a></p><hr><p>※ 공지 - 2019년 3월 15일, 테스트케이스가 강화되었습니다.</p><p>이번 업데이트로 인해 지방의 수가 최대 10,000개에서 100,000개로 늘어났으며, 이에 따라 테스트케이스가 수정되었습니다.</p><p>이로 인해 이전에 통과하던 코드가 더 이상 통과하지 않을 수 있습니다.</p><h2 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h2><p><code>이분 탐색</code>으로 문제를 해결할 수 있다.. <code>left</code>와 <code>rigth</code>의 중간값 <code>mid</code>를 구해 매 번 총액 <code>M</code>을 최대한 맞춘다. 만약 <code>M</code>보다 작으면 <code>left +1</code>, <code>M</code>보다 크면 <code>right -1</code>로 이분 탐색한다.</p><ul><li>변수 설명<ul><li><code>res</code> : <code>left mid right</code>에 따른 총 예산액</li><li><code>left, mid, right</code> : 최소, 최대에 따른 중간값<em>(이분 탐색을 위해)</em></li></ul></li></ul><h2 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h2><h3 id="틀린-코드"><a href="#틀린-코드" class="headerlink" title="틀린 코드"></a>틀린 코드</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(budgets, M)</span>:</span></span><br><span class="line">    sorted_budgets = sorted(budgets)</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> M &gt; <span class="number">0</span>:</span><br><span class="line">        tmp = sorted_budgets[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> tmp &lt; M // len(sorted_budgets):</span><br><span class="line">            res = tmp</span><br><span class="line">            M -= tmp</span><br><span class="line">            sorted_budgets.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res = M // len(sorted_budgets)</span><br><span class="line">            M -= res</span><br><span class="line">            sorted_budgets.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> len(sorted_budgets) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="맞은-코드"><a href="#맞은-코드" class="headerlink" title="맞은 코드"></a>맞은 코드</h3><p><a href="https://codedrive.tistory.com/47" target="_blank" rel="noopener">참고 blog</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(budgets, M)</span>:</span></span><br><span class="line">    left, right, tmp = <span class="number">0</span>, max(budgets), <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> right &gt;= left:</span><br><span class="line">        mid = (left + right) // <span class="number">2</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> budget <span class="keyword">in</span> budgets:</span><br><span class="line">            <span class="keyword">if</span> mid &gt; budget:</span><br><span class="line">                res += budget</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res += mid</span><br><span class="line">        <span class="keyword">if</span> res &gt; M:</span><br><span class="line">            right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            answer = mid</span><br><span class="line">            left = mid + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><hr><p>2019.10.01 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-budgets/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 단어 변환</title>
      <link>https://jx2lee.github.io/programmers-convert_word/</link>
      <guid>https://jx2lee.github.io/programmers-convert_word/</guid>
      <pubDate>Mon, 30 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;특정 기준을 가지고 단어를 변환할 때 최소 횟수를 구하는 문제를 풀어본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>특정 기준을 가지고 단어를 변환할 때 최소 횟수를 구하는 문제를 풀어본다.</p><a id="more"></a><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>두 개의 단어 begin, target과 단어의 집합 words가 있습니다. 아래와 같은 규칙을 이용하여 begin에서 target으로 변환하는 가장 짧은 변환 과정을 찾으려고 합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 한 번에 한 개의 알파벳만 바꿀 수 있습니다.</span><br><span class="line">2. words에 있는 단어로만 변환할 수 있습니다.</span><br></pre></td></tr></table></figure><p>예를 들어 begin이 hit, target가 cog, words가 [hot,dot,dog,lot,log,cog]라면 hit -&gt; hot -&gt; dot -&gt; dog -&gt; cog와 같이 4단계를 거쳐 변환할 수 있습니다.</p><p>두 개의 단어 begin, target과 단어의 집합 words가 매개변수로 주어질 때, 최소 몇 단계의 과정을 거쳐 begin을 target으로 변환할 수 있는지 return 하도록 solution 함수를 작성해주세요.</p><h3 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h3><ul><li>각 단어는 알파벳 소문자로만 이루어져 있습니다.</li><li>각 단어의 길이는 3 이상 10 이하이며 모든 단어의 길이는 같습니다.</li><li>words에는 3개 이상 50개 이하의 단어가 있으며 중복되는 단어는 없습니다.</li><li>begin과 target은 같지 않습니다.</li><li>변환할 수 없는 경우에는 0를 return 합니다.</li></ul><h3 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h3><table><thead><tr><th>begin</th><th>target</th><th>words</th><th>return</th></tr></thead><tbody><tr><td>hit</td><td>cog</td><td>[hot, dot, dog, lot, log, cog]</td><td>4</td></tr><tr><td>hit</td><td>cog</td><td>[hot, dot, dog, lot, log]</td><td>0</td></tr></tbody></table><h3 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h3><p>예제 #1<br>문제에 나온 예와 같습니다.</p><p>예제 #2<br>target인 cog는 words 안에 없기 때문에 변환할 수 없습니다.</p><h2 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h2><p><code>DFS/BFS</code> 문제로 실패하여 블로그를 참고하였다. <code>words</code>가 빈 리스타가 될 때까지 탐색을 통해 <code>문자 한 개만 변형된 단어</code>를 <code>cnt</code>변수를 이용해 찾고, <code>tmp</code>를 계속해서 업데이트 해나간다. 이후 <code>tmp</code>안에 <code>target word</code>가 포함되면 <code>while 횟수</code>를 <code>return</code>하고, 아니면 <code>answer = tmp</code>로 계속해서 찾아나가는 방법으로 풀 수 있다.</p><ul><li>변수<ul><li><code>answer</code> : 탐색을 시작하는 단어를 저장하는 변수</li><li><code>res</code> : 문제의 결괏값</li><li><code>tmp</code> : 변환될 단어들의 후보</li><li><code>cnt</code> : 한 문자만 다른 단어를 뽑기위한 변수 <em>(cnt == 1)</em></li></ul></li></ul><h2 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(begin, target, words)</span>:</span></span><br><span class="line">    answer = [begin]</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> target <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> words:</span><br><span class="line">        <span class="keyword">for</span> ans <span class="keyword">in</span> answer:</span><br><span class="line">            tmp = []</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                cnt = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ans)):</span><br><span class="line">                    <span class="keyword">if</span> ans[i] != word[i]:</span><br><span class="line">                        cnt += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> cnt == <span class="number">2</span>:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span> cnt == <span class="number">1</span>:</span><br><span class="line">                    tmp.append(word)</span><br><span class="line">                    words.remove(word)</span><br><span class="line">        res += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> target <span class="keyword">in</span> tmp:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            answer = tmp</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><hr><p>2019.10.01 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-convert_word/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Type of Triangle</title>
      <link>https://jx2lee.github.io/hackerrank-type_of_triangle/</link>
      <guid>https://jx2lee.github.io/hackerrank-type_of_triangle/</guid>
      <pubDate>Thu, 26 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Type of Triangle&lt;/code&gt; 문제를 &lt;code&gt;case&lt;/code&gt;를 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Type of Triangle</code> 문제를 <code>case</code>를 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>Write a query identifying the <em>type</em> of each record in the <strong>TRIANGLES</strong> table using its three side lengths. Output one of the following statements for each record in the table:</p><ul><li><strong>Equilateral</strong>: It’s a triangle with  sides of equal length.</li><li><strong>Isosceles</strong>: It’s a triangle with  sides of equal length.</li><li><strong>Scalene</strong>: It’s a triangle with  sides of differing lengths.</li><li><strong>Not A Triangle</strong>: The given values of <em>A</em>, <em>B</em>, and <em>C</em> don’t form a triangle.</li></ul><p><strong>Input Format</strong></p><p>The <strong>TRIANGLES</strong> table is described as follows:</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12887/1443815629-ac2a843fb7-1.png" alt="img"></p><p>Each row in the table denotes the lengths of each of a triangle’s three sides.</p><p><strong>Sample Input</strong></p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12887/1443815827-cbfc1ca12b-2.png" alt="img"></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Isosceles</span><br><span class="line">Equilateral</span><br><span class="line">Scalene</span><br><span class="line">Not A Triangle</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>Values in the tuple  form an Isosceles triangle, because .<br>Values in the tuple  form an Equilateral triangle, because . Values in the tuple  form a Scalene triangle, because .<br>Values in the tuple  cannot form a triangle because the combined value of sides  and  is not larger than that of side </p><h1 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h1><p><code>IF</code>문을 사용하려다 <code>select</code>에 <code>case::when-then</code>을 이용하였다. 그리고 <code>Not a triangle</code> 조건을 먼저 주지않고 나중에 준다면<em>(Isosceles 이후에 조건을 삽입)</em> 결과값이 달라지는 오류가 발생한다. <code>case</code>문법은 아래와 같다.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">case [column(선택)]</span><br><span class="line">when ~ then ~</span><br><span class="line">when ~ then ~</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h1 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">case</span></span><br><span class="line">    <span class="keyword">when</span> a=b <span class="keyword">and</span> b=c <span class="keyword">then</span> <span class="string">"Equilateral"</span></span><br><span class="line">    <span class="keyword">when</span> a+b&lt;=c <span class="keyword">then</span> <span class="string">"Not A Triangle"</span></span><br><span class="line">    <span class="keyword">when</span> a+c&lt;=b <span class="keyword">then</span> <span class="string">"Not A Triangle"</span></span><br><span class="line">    <span class="keyword">when</span> b+c&lt;=a <span class="keyword">then</span> <span class="string">"Not A Triangle"</span></span><br><span class="line">    <span class="keyword">when</span> a=b <span class="keyword">and</span> a&lt;&gt;c <span class="keyword">then</span> <span class="string">"Isosceles"</span></span><br><span class="line">    <span class="keyword">when</span> a=c <span class="keyword">and</span> c&lt;&gt;b <span class="keyword">then</span> <span class="string">"Isosceles"</span></span><br><span class="line">    <span class="keyword">when</span> b=c <span class="keyword">and</span> c&lt;&gt;a <span class="keyword">then</span> <span class="string">"Isosceles"</span></span><br><span class="line">    <span class="keyword">when</span> a&lt;&gt;b <span class="keyword">and</span> b&lt;&gt;c <span class="keyword">then</span> <span class="string">"Scalene"</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">from</span> triangles;</span><br></pre></td></tr></table></figure><hr><p>2019.09.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-type_of_triangle/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[SQL] Occupations</title>
      <link>https://jx2lee.github.io/hackerrank-occupations/</link>
      <guid>https://jx2lee.github.io/hackerrank-occupations/</guid>
      <pubDate>Thu, 26 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;code&gt;hackerrank&lt;/code&gt;에서 제공하는 &lt;code&gt;Occupations&lt;/code&gt; 문제를 &lt;code&gt;pivot&lt;/code&gt;을 활용해 해결하였다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p><code>hackerrank</code>에서 제공하는 <code>Occupations</code> 문제를 <code>pivot</code>을 활용해 해결하였다.</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p><a href="https://en.wikipedia.org/wiki/Pivot_table" target="_blank" rel="noopener">Pivot</a> the <em>Occupation</em> column in <strong>OCCUPATIONS</strong> so that each <em>Name</em> is sorted alphabetically and displayed underneath its corresponding <em>Occupation</em>. The output column headers should be <em>Doctor</em>, <em>Professor</em>, <em>Singer</em>, and <em>Actor</em>, respectively.</p><p><strong>Note:</strong> Print <strong>NULL</strong> when there are no more names corresponding to an occupation.</p><p><strong>Input Format</strong></p><p>The <strong>OCCUPATIONS</strong> table is described as follows:</p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12889/1443816414-2a465532e7-1.png" alt="img"></p><p><em>Occupation</em> will only contain one of the following values: <strong>Doctor</strong>, <strong>Professor</strong>, <strong>Singer</strong> or <strong>Actor</strong>.</p><p><strong>Sample Input</strong></p><p><img src="https://s3.amazonaws.com/hr-challenge-images/12890/1443817648-1b2b8add45-2.png" alt="img"></p><p><strong>Sample Output</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Jenny    Ashley     Meera  Jane</span><br><span class="line">Samantha Christeen  Priya  Julia</span><br><span class="line">NULL     Ketty      NULL   Maria</span><br></pre></td></tr></table></figure><p><strong>Explanation</strong></p><p>The first column is an alphabetically ordered list of Doctor names.<br>The second column is an alphabetically ordered list of Professor names.<br>The third column is an alphabetically ordered list of Singer names.<br>The fourth column is an alphabetically ordered list of Actor names.<br>The empty cell data for columns with less than the maximum number of names per occupation (in this case, the Professor and Actor columns) are filled with <strong>NULL</strong> values.</p><h3 id="접근"><a href="#접근" class="headerlink" title="접근"></a>접근</h3><ul><li>변수 설정과<em>(set @~)</em> case문을 이용<ul><li>set @[변수명] = [값]</li><li>case 절은 위 문제 참고</li></ul></li><li>from 절에 <code>min</code>대신 <code>max</code>를 해도 결과는 동일</li></ul><h3 id="해결"><a href="#해결" class="headerlink" title="해결"></a>해결</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> @drow=<span class="number">0</span>, @prow=<span class="number">0</span>, @srow=<span class="number">0</span>, @arow=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">min</span>(doctor), <span class="keyword">min</span>(professor), <span class="keyword">min</span>(singer), <span class="keyword">min</span>(actor)</span><br><span class="line"><span class="keyword">from</span>(</span><br><span class="line">    <span class="keyword">select</span> <span class="keyword">case</span> occupation</span><br><span class="line">        <span class="keyword">when</span> <span class="string">'Doctor'</span>       <span class="keyword">then</span> @drow := @drow + <span class="number">1</span></span><br><span class="line">        <span class="keyword">when</span> <span class="string">'Professor'</span>    <span class="keyword">then</span> @prow := @prow + <span class="number">1</span></span><br><span class="line">        <span class="keyword">when</span> <span class="string">'Singer'</span>       <span class="keyword">then</span> @srow := @srow + <span class="number">1</span></span><br><span class="line">        <span class="keyword">when</span> <span class="string">'Actor'</span>        <span class="keyword">then</span> @arow := @arow + <span class="number">1</span></span><br><span class="line">        <span class="keyword">end</span> <span class="keyword">as</span> <span class="keyword">row</span>,</span><br><span class="line">        <span class="keyword">if</span>(occupation=<span class="string">'Doctor'</span>, <span class="keyword">name</span>, <span class="literal">null</span>) <span class="keyword">as</span> doctor,</span><br><span class="line">        <span class="keyword">if</span>(occupation=<span class="string">'Professor'</span>, <span class="keyword">name</span>, <span class="literal">null</span>) <span class="keyword">as</span> professor,</span><br><span class="line">        <span class="keyword">if</span>(occupation=<span class="string">'Singer'</span>, <span class="keyword">name</span>, <span class="literal">null</span>) <span class="keyword">as</span> singer,</span><br><span class="line">        <span class="keyword">if</span>(occupation=<span class="string">'Actor'</span>, <span class="keyword">name</span>, <span class="literal">null</span>) <span class="keyword">as</span> actor</span><br><span class="line">    <span class="keyword">from</span> occupations</span><br><span class="line">    <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">name</span></span><br><span class="line">) <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">row</span>;</span><br></pre></td></tr></table></figure><hr><p>2019.09.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/hackerrank-occupations/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 가장 먼 노드</title>
      <link>https://jx2lee.github.io/programmers-node/</link>
      <guid>https://jx2lee.github.io/programmers-node/</guid>
      <pubDate>Thu, 26 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;노드를 연결하는 그래프를 작성하고 노드 1에서 가장 멀리 떨어진 노드 갯수를 구하는 문제를 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>노드를 연결하는 그래프를 작성하고 노드 1에서 가장 멀리 떨어진 노드 갯수를 구하는 문제를 풀어본다</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>n개의 노드가 있는 그래프가 있습니다. 각 노드는 1부터 n까지 번호가 적혀있습니다. 1번 노드에서 가장 멀리 떨어진 노드의 갯수를 구하려고 합니다. 가장 멀리 떨어진 노드란 최단경로로 이동했을 때 간선의 개수가 가장 많은 노드들을 의미합니다.</p><p>노드의 개수 n, 간선에 대한 정보가 담긴 2차원 배열 vertex가 매개변수로 주어질 때, 1번 노드로부터 가장 멀리 떨어진 노드가 몇 개인지를 return 하도록 solution 함수를 작성해주세요.</p><h2 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h2><ul><li>노드의 개수 n은 2 이상 20,000 이하입니다.</li><li>간선은 양방향이며 총 1개 이상 50,000개 이하의 간선이 있습니다.</li><li>vertex 배열 각 행 [a, b]는 a번 노드와 b번 노드 사이에 간선이 있다는 의미입니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><table><thead><tr><th>n</th><th>vertex</th><th>return</th></tr></thead><tbody><tr><td>6</td><td>[[3, 6], [4, 3], [3, 2], [1, 3], [1, 2], [2, 4], [5, 2]]</td><td>3</td></tr></tbody></table><h2 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h2><p>예제의 그래프를 표현하면 아래 그림과 같고, 1번 노드에서 가장 멀리 떨어진 노드는 4,5,6번 노드입니다.</p><p><img src="https://grepp-programmers.s3.amazonaws.com/files/ybm/fadbae38bb/dec85ab5-0273-47b3-ba73-fc0b5f6be28a.png" alt="image.png"></p><h1 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h1><p>그래프 관련 문제를 처음 풀어보았다. 어떻게 접근해야 될지를 몰라 <a href="https://codedrive.tistory.com/189" target="_blank" rel="noopener">구글에서 찾은 이 블로그</a>를 우선 참고했다. 해결 방법의 간단한 스케치는 <code>1) 각 노드별 인접한 노드 index 구하기</code>, <code>2) queue를 이용해 방문여부(is_visit)이 False인 경우 True로 바꿔주며 distance, queue를 업데이트</code>, <code>3) distance 변수를 sorting하고 max값을 count하여 return</code> 이다. 좀 더 자세히 살펴보면 아래와 같다.</p><ul><li>변수 설정<ul><li><code>graph</code> : 인접한 노드를 나타내는 변수</li><li><code>distance</code> : 노드 1에서 각 노드<code>index</code> 까지의 거리</li><li><code>is_visit</code> : 방문 여부 <em>(모두 False로 초기화, 노드 1은 True로 바꾸고 시작)</em></li><li><code>queue</code> : 큐 변수</li></ul></li><li>graph 변수 채우기 <em>(연결된 노드 append)</em></li><li>queue가 빈 리스트가 될 때까지<ul><li><code>i</code> : queue의 맨 첫 번째 <code>index</code> 추출</li><li><code>j</code>가 <code>graph[i]</code>안 원소일 때 <em>(for)</em><ul><li>if <code>is_visit[j]</code> : False,<ul><li><code>is_visit[j]</code> = False</li><li><code>queue</code>에 <code>j (노드 index)</code> append</li><li><code>distance</code> update (+1)</li></ul></li></ul></li></ul></li><li><code>distance</code> 정렬 후 첫 번째 값<em>(max)</em> 카운트 값 return</li></ul><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(n, edge)</span>:</span></span><br><span class="line">    graph =[  [] <span class="keyword">for</span> _ <span class="keyword">in</span> range(n + <span class="number">1</span>) ]</span><br><span class="line">    distances = [ <span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n) ]</span><br><span class="line">    is_visit = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    queue = [<span class="number">0</span>]</span><br><span class="line">    is_visit[<span class="number">0</span>] = <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 연결된 node append</span></span><br><span class="line">    <span class="keyword">for</span> (a, b) <span class="keyword">in</span> edge:</span><br><span class="line">        graph[a<span class="number">-1</span>].append(b<span class="number">-1</span>)</span><br><span class="line">        graph[b<span class="number">-1</span>].append(a<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># queue를 이용한 distance 계산</span></span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        i = queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> graph[i]:</span><br><span class="line">            <span class="keyword">if</span> is_visit[j] == <span class="literal">False</span>:</span><br><span class="line">                is_visit[j] = <span class="literal">True</span></span><br><span class="line">                queue.append(j)</span><br><span class="line">                distances[j] = distances[i] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># max distance를 계산한 후 count 결과 return</span></span><br><span class="line">    distances.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">    answer = distances.count(distances[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><hr><p>2019.09.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-node/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 단속카메라</title>
      <link>https://jx2lee.github.io/programmers-camera/</link>
      <guid>https://jx2lee.github.io/programmers-camera/</guid>
      <pubDate>Thu, 26 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;단속카메라를 일정 조건에 맞게 최소로 설치하는 문제를 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>단속카메라를 일정 조건에 맞게 최소로 설치하는 문제를 풀어본다</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>고속도로를 이동하는 모든 차량이 고속도로를 이용하면서 단속용 카메라를 한 번은 만나도록 카메라를 설치하려고 합니다.</p><p>고속도로를 이동하는 차량의 경로 routes가 매개변수로 주어질 때, 모든 차량이 한 번은 단속용 카메라를 만나도록 하려면 최소 몇 대의 카메라를 설치해야 하는지를 return 하도록 solution 함수를 완성하세요.</p><p><strong>제한사항</strong></p><ul><li>차량의 대수는 1대 이상 10,000대 이하입니다.</li><li>routes에는 차량의 이동 경로가 포함되어 있으며 routes[i][0]에는 i번째 차량이 고속도로에 진입한 지점, routes[i][1]에는 i번째 차량이 고속도로에서 나간 지점이 적혀 있습니다.</li><li>차량의 진입/진출 지점에 카메라가 설치되어 있어도 카메라를 만난것으로 간주합니다.</li><li>차량의 진입 지점, 진출 지점은 -30,000 이상 30,000 이하입니다.</li></ul><p><strong>입출력 예</strong></p><table><thead><tr><th>routes</th><th>return</th></tr></thead><tbody><tr><td>[[-20,15], [-14,-5], [-18,-13], [-5,-3]]</td><td>2</td></tr></tbody></table><p><strong>입출력 예 설명</strong></p><p>-5 지점에 카메라를 설치하면 두 번째, 네 번째 차량이 카메라를 만납니다.</p><p>-15 지점에 카메라를 설치하면 첫 번째, 세 번째 차량이 카메라를 만납니다.</p><h1 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h1><p> Greedy 알고리즘으로 쉽게 해결할 수 있는 문제. 입력받은 <code>list</code>를 <code>sorting (도착 지점을 기준으로)</code>하고 <code>tmp</code>변수와 출발지점을 비교해 작다면 해당 범위에 포함되지 않으므로 <code>answer</code>을 추가하며 <code>tmp</code>를 갱신해주면 된다.</p><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><p>아래 코드로 해결하였다. <em>(<a href="[https://ga0n.tistory.com/entry/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EB%8B%A8%EC%86%8D%EC%B9%B4%EB%A9%94%EB%9D%BC](https://ga0n.tistory.com/entry/프로그래머스-단속카메라)">참고</a>)</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(routes)</span>:</span></span><br><span class="line">    routes = sorted(routes, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">    answer = <span class="number">0</span></span><br><span class="line">    tmp = <span class="number">-100000000000</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> route <span class="keyword">in</span> routes:</span><br><span class="line">        <span class="keyword">if</span> tmp &lt; route[<span class="number">0</span>]:</span><br><span class="line">            answer += <span class="number">1</span></span><br><span class="line">            tmp = route[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><hr><p>2019.09.27 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-camera/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 섬 연결하기</title>
      <link>https://jx2lee.github.io/programmers-island/</link>
      <guid>https://jx2lee.github.io/programmers-island/</guid>
      <pubDate>Wed, 25 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;모든 섬을 연결할 때 최소 비용을 구하는 문제를 풀어본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>모든 섬을 연결할 때 최소 비용을 구하는 문제를 풀어본다</p><a id="more"></a><h2 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h2><p>n개의 섬 사이에 다리를 건설하는 비용(costs)이 주어질 때, 최소의 비용으로 모든 섬이 서로 통행 가능하도록 만들 때 필요한 최소 비용을 return 하도록 solution을 완성하세요.</p><p>다리를 여러 번 건너더라도, 도달할 수만 있으면 통행 가능하다고 봅니다. 예를 들어 A 섬과 B 섬 사이에 다리가 있고, B 섬과 C 섬 사이에 다리가 있으면 A 섬과 C 섬은 서로 통행 가능합니다.</p><!-- more --><p><strong>제한사항</strong></p><ul><li>섬의 개수 n은 1 이상 100 이하입니다.</li><li>costs의 길이는 <code>((n-1) * n) / 2</code>이하입니다.</li><li>임의의 i에 대해, costs[i][0] 와 costs[i] [1]에는 다리가 연결되는 두 섬의 번호가 들어있고, costs[i] [2]에는 이 두 섬을 연결하는 다리를 건설할 때 드는 비용입니다.</li><li>같은 연결은 두 번 주어지지 않습니다. 또한 순서가 바뀌더라도 같은 연결로 봅니다. 즉 0과 1 사이를 연결하는 비용이 주어졌을 때, 1과 0의 비용이 주어지지 않습니다.</li><li>모든 섬 사이의 다리 건설 비용이 주어지지 않습니다. 이 경우, 두 섬 사이의 건설이 불가능한 것으로 봅니다.</li><li>연결할 수 없는 섬은 주어지지 않습니다.</li></ul><p><strong>입출력 예</strong></p><table><thead><tr><th>n</th><th>costs</th><th>return</th></tr></thead><tbody><tr><td>4</td><td>[[0,1,1],[0,2,2],[1,2,5],[1,3,1],[2,3,8]]</td><td>4</td></tr></tbody></table><p><strong>입출력 예 설명</strong></p><p>costs를 그림으로 표현하면 다음과 같으며, 이때 초록색 경로로 연결하는 것이 가장 적은 비용으로 모두를 통행할 수 있도록 만드는 방법입니다.</p><p><img src="https://grepp-programmers.s3.amazonaws.com/files/production/13e2952057/f2746a8c-527c-4451-9a73-42129911fe17.png" alt="image.png"></p><h3 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h3><p>어려워 여러 블로그를 참고하였다. <code>conn</code>, <code>answer</code>변수를 반복문을 이용해 풀었다. 아래와 같은 로직으로 구성하였다.</p><ul><li><code>costs</code> 리스트 정렬 후 변수 설정</li><li><code>conn</code> : 연결된 섬, <code>answer</code> : 비용</li><li><code>conn</code>의 길이가 n이 되지 않을 때까지<ul><li><code>tmp</code> : 최소 비교를 위한 변수, <code>idx</code> : <code>costs</code>의 인덱스 <em>(훑어본 cost를 pop하기 위한 변수)</em></li><li><code>costs</code>를 돌며 <em>(for)</em><ul><li><code>costs[i][0] or costs[i][1]</code>이 <code>conn</code> 에 포함되는지 확인</li><li>비용 저장을 위해 <code>tmp</code>를 이용해 <code>costs[i][2]</code>값을 저장하고 <code>idx</code> 저장</li></ul></li><li><code>costs</code>를 한번 다 훑고 <code>answer</code>에 <code>tmp</code>만큼 더한다.</li><li><code>conn</code>에 같은 그룹의 섬들을 저장한다 <em>(append)</em>, 중복 저장이 있을 수 있으니 <code>set</code>으로 저장한 수 <code>list()</code></li><li><code>idx</code>변수를 이용해 <code>costs</code> pop</li></ul></li></ul><p>풀다보면 난이도가 쑥쑥 올라가는 느낌이다. 더 노력해보자. </p><h3 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h3><p>아래 코드로 해결하였다. <a href="https://codedrive.tistory.com/164" target="_blank" rel="noopener">참고</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(n, costs)</span>:</span></span><br><span class="line">    costs.sort()</span><br><span class="line">    conn=[costs[<span class="number">0</span>][<span class="number">0</span>]]</span><br><span class="line">    answer = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> len(conn)!=n:</span><br><span class="line">        tmp=<span class="number">1000000000000000</span></span><br><span class="line">        idx=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(costs)):</span><br><span class="line">            <span class="keyword">if</span> costs[i][<span class="number">0</span>] <span class="keyword">in</span> conn <span class="keyword">or</span> costs[i][<span class="number">1</span>] <span class="keyword">in</span> conn:</span><br><span class="line">                <span class="keyword">if</span> costs[i][<span class="number">0</span>] <span class="keyword">in</span> conn <span class="keyword">and</span> costs[i][<span class="number">1</span>] <span class="keyword">in</span> conn:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> tmp &gt; costs[i][<span class="number">2</span>]:</span><br><span class="line">                    tmp=costs[i][<span class="number">2</span>]</span><br><span class="line">                    idx=i</span><br><span class="line">        answer+=tmp</span><br><span class="line">        conn.append(costs[idx][<span class="number">0</span>])</span><br><span class="line">        conn.append(costs[idx][<span class="number">1</span>])</span><br><span class="line">        conn=list(set(conn))</span><br><span class="line">        costs.pop(idx)</span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><hr><p>2019.09.26 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-island/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 네트워크</title>
      <link>https://jx2lee.github.io/programmers-network/</link>
      <guid>https://jx2lee.github.io/programmers-network/</guid>
      <pubDate>Tue, 24 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;25일부로 백준 대신 &lt;code&gt;프로그래머스&lt;/code&gt; 문제를 풀어본다. 매일 한 문제씩, 풀다가 못풀어서 참고해 푼 문제는 모두 블로그로 남기자&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>25일부로 백준 대신 <code>프로그래머스</code> 문제를 풀어본다. 매일 한 문제씩, 풀다가 못풀어서 참고해 푼 문제는 모두 블로그로 남기자</p><a id="more"></a><h1 id="문제"><a href="#문제" class="headerlink" title="문제"></a>문제</h1><p>네트워크란 컴퓨터 상호 간에 정보를 교환할 수 있도록 연결된 형태를 의미합니다. 예를 들어, 컴퓨터 A와 컴퓨터 B가 직접적으로 연결되어있고, 컴퓨터 B와 컴퓨터 C가 직접적으로 연결되어 있을 때 컴퓨터 A와 컴퓨터 C도 간접적으로 연결되어 정보를 교환할 수 있습니다. 따라서 컴퓨터 A, B, C는 모두 같은 네트워크 상에 있다고 할 수 있습니다.</p><!-- more --><p>컴퓨터의 개수 n, 연결에 대한 정보가 담긴 2차원 배열 computers가 매개변수로 주어질 때, 네트워크의 개수를 return 하도록 solution 함수를 작성하시오.</p><h2 id="제한사항"><a href="#제한사항" class="headerlink" title="제한사항"></a>제한사항</h2><ul><li>컴퓨터의 개수 n은 1 이상 200 이하인 자연수입니다.</li><li>각 컴퓨터는 0부터 <code>n-1</code>인 정수로 표현합니다.</li><li>i번 컴퓨터와 j번 컴퓨터가 연결되어 있으면 computers[i][j]를 1로 표현합니다.</li><li>computer[i][j]는 항상 1입니다.</li></ul><h2 id="입출력-예"><a href="#입출력-예" class="headerlink" title="입출력 예"></a>입출력 예</h2><table><thead><tr><th>n</th><th>computers</th><th>return</th></tr></thead><tbody><tr><td>3</td><td>[[1, 1, 0], [1, 1, 0], [0, 0, 1]]</td><td>2</td></tr><tr><td>3</td><td>[[1, 1, 0], [1, 1, 1], [0, 1, 1]]</td><td>1</td></tr></tbody></table><h2 id="입출력-예-설명"><a href="#입출력-예-설명" class="headerlink" title="입출력 예 설명"></a>입출력 예 설명</h2><p>예제 #1<br>아래와 같이 2개의 네트워크가 있습니다.<br><img src="https://grepp-programmers.s3.amazonaws.com/files/ybm/5b61d6ca97/cc1e7816-b6d7-4649-98e0-e95ea2007fd7.png" alt="image0.png"></p><p>예제 #2<br>아래와 같이 1개의 네트워크가 있습니다.<br><img src="https://grepp-programmers.s3.amazonaws.com/files/ybm/7554746da2/edb61632-59f4-4799-9154-de9ca98c9e55.png" alt="image1.png"></p><h1 id="문제-접근"><a href="#문제-접근" class="headerlink" title="문제 접근"></a>문제 접근</h1><p>처음에는 stack 을 이용하지 않고 문제를 풀어보았다. 하지만 아니나 다를까.. <code>시간초과</code>가 났다. 결국 구글링을 통해 한 블로그를 참고해서 문제를 해결하였다. 로직은 다음과 같다.</p><ul><li>입력받은 <code>n</code>을 통해 <code>구성원이 각자인 각각의 네트워크</code>을 <code>tuple</code>로 생성한다.</li><li><code>i</code>와 <code>j</code>를 roof를 통해 <code>연결되어 있는지 확인(computers[i][j])</code> <ul><li>연결되어 있다면, 두 컴퓨터가 속한 <code>index를 추출</code>한다<em>(idx1, idx2)</em></li><li><code>idx1</code>가 <code>idx2</code>가 다르다면, 하나로 묶어준다(if 뒷부분)</li></ul></li></ul><p><code>hap</code> 변수 생성과 <code>idx1 != idx2</code> 부분이 이해되지 않아 정리하는데 시간이 오래걸렸다. 어쨌든, 양방향으로 연결된 네트워크는 대각선 기준 위쪽만 살펴보면 되기 때문에 아래와 같이 간단히 해결할 수 있었던 것 같다.</p><blockquote><p> <em>(그리고 stack의 중요성..)</em></p></blockquote><h1 id="문제-해결"><a href="#문제-해결" class="headerlink" title="문제 해결"></a>문제 해결</h1><p>아래 코드로 해결하였다</p><p><a href="https://geonlee.tistory.com/54" target="_blank" rel="noopener">참고</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(n, computers)</span>:</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        res.append(&#123;i&#125;)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> computers[i][j] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">for</span> idx,st <span class="keyword">in</span> enumerate(res):</span><br><span class="line">                    <span class="keyword">if</span> i <span class="keyword">in</span> res[idx]:</span><br><span class="line">                        idx1 = idx</span><br><span class="line">                    <span class="keyword">if</span> j <span class="keyword">in</span> res[idx]:</span><br><span class="line">                        idx2 = idx</span><br><span class="line">                <span class="keyword">if</span> idx1 != idx2:</span><br><span class="line">                    hap = res[idx1] | res[idx2]</span><br><span class="line">                    res.pop(min(idx1,idx2))</span><br><span class="line">                    res.pop(max(idx1,idx2))</span><br><span class="line">                    res.append(hap)</span><br><span class="line">    <span class="keyword">return</span> len(res)</span><br></pre></td></tr></table></figure><hr><p>2019.09.25 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/programmers-network/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Install Docker</title>
      <link>https://jx2lee.github.io/cloud-install_docker/</link>
      <guid>https://jx2lee.github.io/cloud-install_docker/</guid>
      <pubDate>Sun, 22 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;도커 개발 환경을 셋업하는 과정을 다룬다. docker client는 윈도우/맥에서 돌리고 docker server를 제어할 수 있지만, docker container는 linux 환경에서 만들고 실행해볼 수 있다. 따라서 docker server를 띄우기 위해서는 가상 머신이나 원격 서버가 필요하다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>도커 개발 환경을 셋업하는 과정을 다룬다. docker client는 윈도우/맥에서 돌리고 docker server를 제어할 수 있지만, docker container는 linux 환경에서 만들고 실행해볼 수 있다. 따라서 docker server를 띄우기 위해서는 가상 머신이나 원격 서버가 필요하다</p><a id="more"></a><h1 id="key-word"><a href="#key-word" class="headerlink" title="key word"></a>key word</h1><p>책에서 다루는 용어들에 대해 정리하면 다음과 같다.</p><ul><li><p>docker client</p><p>대부분의 docker worflow를 관리, 원격 docker server와 통신하는 docker 명령어</p></li><li><p>docker server</p><ul><li>docker 명렁어를 daemon 모드로 사용, 이는 리눅스 시스템을 docker server로 만들게 한다.</li><li>docker client를 통해 container를 배포 / 실행 / 제거</li></ul></li><li><p>docker image</p><ul><li>하나 이상의 파일 시스템 계층</li><li>도커화(리눅스 컨테이너로 생성된)된 앱 실행을 위한 모든 파일들의 meta data 포함</li><li>하나의 docker image -&gt; 여러 host에 카피 가능</li><li>Name, Tag : image의 특정 realease 표시</li></ul></li><li><p>docker container</p><ul><li>docker image에 의해 생성되는 linux container</li><li>특정 container는 단 하나, 동일 image 내 container 다중 생성 가능</li></ul></li><li><p>atomic host(원자적 호스트)</p><ul><li>less, optimized 된 CoreOS나 아토믹 프로젝트 같은 OS의 이미지</li><li>container hosting &amp; OS 업그레이드 지원</li></ul></li></ul><p><img src="https://t1.daumcdn.net/cfile/tistory/2636504256C431531A" alt="Docker Architecture"></p><center>[참고 - Docker Architecture]</center>아래와 같은 Docker 환경을 구성한다.<blockquote><p>docker client : CentOS</p><p>docker server : docker clinet가 설치된 CentOS</p></blockquote><h1 id="Docker-Client"><a href="#Docker-Client" class="headerlink" title="Docker Client"></a>Docker Client</h1><p>리눅스 시스템에서 Docker 설치는 Client만 설치하면 Server도 함께 설치된다. <code>Yum</code> package를 이용해 Docker를 설치한다.</p><h2 id="old-version-삭제"><a href="#old-version-삭제" class="headerlink" title="old version 삭제"></a>old version 삭제</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[tibero@node5 ~]$ sudo yum remove docker \</span><br><span class="line">&gt;                   docker-client \</span><br><span class="line">&gt;                   docker-client-latest \</span><br><span class="line">&gt;                   docker-common \</span><br><span class="line">&gt;                   docker-latest \</span><br><span class="line">&gt;                   docker-latest-logrotate \</span><br><span class="line">&gt;                   docker-logrotate \</span><br><span class="line">&gt;                   docker-engine</span><br><span class="line">[sudo] password <span class="keyword">for</span> tibero: </span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-client</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-client-latest</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-common</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-latest</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-latest-logrotate</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-logrotate</span><br><span class="line">No Match <span class="keyword">for</span> argument: docker-engine</span><br><span class="line">No Packages marked <span class="keyword">for</span> removal</span><br></pre></td></tr></table></figure><h2 id="repository를-이용한-설치"><a href="#repository를-이용한-설치" class="headerlink" title="repository를 이용한 설치"></a>repository를 이용한 설치</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[tibero@node5 ~]$ sudo yum install -y yum-utils \</span><br><span class="line">&gt;   device-mapper-persistent-data \</span><br><span class="line">&gt;   lvm2</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Determining fastest mirrors</span><br><span class="line"> * base: data.aonenetworks.kr</span><br><span class="line"> * extras: data.aonenetworks.kr</span><br><span class="line"> * updates: data.aonenetworks.kr</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Updated:</span><br><span class="line">  device-mapper-persistent-data.x86_64 0:0.8.5-1.el7                             lvm2.x86_64 7:2.02.185-2.el7                             yum-utils.noarch 0:1.1.31-52.el7                            </span><br><span class="line"></span><br><span class="line">Dependency Updated:</span><br><span class="line">  device-mapper.x86_64 7:1.02.158-2.el7       device-mapper-event.x86_64 7:1.02.158-2.el7       device-mapper-event-libs.x86_64 7:1.02.158-2.el7       device-mapper-libs.x86_64 7:1.02.158-2.el7      </span><br><span class="line">  lvm2-libs.x86_64 7:2.02.185-2.el7          </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line">[tibero@node5 ~]$ sudo yum-config-manager \</span><br><span class="line">&gt;     --add-repo \</span><br><span class="line">&gt;     https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">adding repo from: https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">repo saved to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">[tibero@node5 ~]$ sudo yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: data.aonenetworks.kr</span><br><span class="line"> * extras: data.aonenetworks.kr</span><br><span class="line"> * updates: data.aonenetworks.kr</span><br><span class="line">docker-ce-stable                                                                         </span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  containerd.io.x86_64 0:1.2.6-3.3.el7                               docker-ce.x86_64 3:19.03.2-3.el7                               docker-ce-cli.x86_64 1:19.03.2-3.el7                              </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  audit-libs-python.x86_64 0:2.8.5-4.el7        checkpolicy.x86_64 0:2.5-8.el7    container-selinux.noarch 2:2.107-3.el7    libcgroup.x86_64 0:0.41-21.el7    libsemanage-python.x86_64 0:2.5-14.el7   </span><br><span class="line">  policycoreutils-python.x86_64 0:2.5-33.el7    python-IPy.noarch 0:0.75-6.el7    setools-libs.x86_64 0:3.3.8-4.el7        </span><br><span class="line"></span><br><span class="line">Dependency Updated:</span><br><span class="line">  audit.x86_64 0:2.8.5-4.el7                                   audit-libs.x86_64 0:2.8.5-4.el7                                   policycoreutils.x86_64 0:2.5-33.el7                                  </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><h1 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h1><p><code>$ sudo systemctl start docker</code></p><p>for Test,</p><p><code>$ sudo docker run hello-world</code></p><blockquote><p><em>Docker 명령어를 sudo 없이 사용을 원하면 docker 실행권한을 가진 그룹을 생성하여 권한을 부여하면 된다</em></p><p><code>$ sudo groupadd docker</code></p><p><code>$ sudo gpasswd -a $USER docker</code></p></blockquote><h2 id="Docker-Server"><a href="#Docker-Server" class="headerlink" title="Docker Server"></a>Docker Server</h2><p>systemd를 사용해 Docker Daemon(Server)을 실행해보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ sudo systemctl <span class="built_in">enable</span> docker</span><br><span class="line">[sudo] password <span class="keyword">for</span> kuber: </span><br><span class="line">[kuber@node2 ~]$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><h1 id="설치-후-Test"><a href="#설치-후-Test" class="headerlink" title="설치 후 Test"></a>설치 후 Test</h1><p>설치가 잘 되어있는지 확인하는 겸, Docker Daemon(Server)의 최신 공식 컨테이너를 다운받고 bash shell 인스턴스를 실행하기 위해 다음 명령어를 실행해보자.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker run --rm -ti centos:latest /bin/bash</span><br><span class="line">Unable to find image <span class="string">'centos:latest'</span> locally</span><br><span class="line">Trying to pull repository docker.io/library/centos ... </span><br><span class="line">latest: Pulling from docker.io/library/centos</span><br><span class="line">d8d02d457314: Pull complete </span><br><span class="line">Digest: sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6eb</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> docker.io/centos:latest</span><br><span class="line">[root@0f84b088b2e6 /]<span class="comment"># pwd</span></span><br><span class="line">/</span><br><span class="line">[root@0f84b088b2e6 /]<span class="comment"># whoami</span></span><br><span class="line">root</span><br></pre></td></tr></table></figure><hr><p>2019.09.23 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-install_docker/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Docker Image</title>
      <link>https://jx2lee.github.io/cloud-docker_image/</link>
      <guid>https://jx2lee.github.io/cloud-docker_image/</guid>
      <pubDate>Sun, 22 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Docker Image에 대해 알아보자&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Docker Image에 대해 알아보자</p><a id="more"></a><h1 id="Docker-Image"><a href="#Docker-Image" class="headerlink" title="Docker Image"></a>Docker Image</h1><ul><li><p>모든 <code>Docker Container</code>는 <code>Image</code>에 기반하고</p><p><code>Image</code>는 <strong>Docker로 배포하고 실행하기 위한 모든 것의 기반을 제공</strong></p></li></ul><p><code>Image 특징</code></p><ul><li>Container를 실행하려면 docker Image가 필요한데, 이는 <code>공개된 것을 다운로드</code> 하거나 <code>직접 이미지를 생성</code> </li><li>모든 docker Image는 하나 이상의 파일 시스템 계층으로 이루어짐<ul><li>파일 시스템 계층은 이미지 생성을 위해 적용되는 개별 빌드 단계마다 <code>1:1 직접 매핑</code></li></ul></li><li>이미지 관리를 위해 docker는 <code>스토리지 백엔드(Stroage backend)</code>에 크게 의존<ul><li>이미지를 구성하는 파일 시스템 계층을 만들고 관리하기 위해 리눅스 파일 시스템과 통신하는 역할</li><li>AUFS, BTRFS, 디바이스-매퍼, 오버레이 등<ul><li>빠른 이미지 관리를 위해 <code>CoW(Copy-on-Write)</code> 시스템 제공</li></ul></li></ul></li></ul><h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><p><code>Dockerfile</code>은 이미지 생성에 필요한 모든 단계를 기술한 파일로, 보통 App의 소스 코드 저장의 root 디렉토리에 포함된다.  구조 설명을 위해 <em>Node.js 기반 애플리케이션을 위한 컨테이너</em>를 만드는 예제의 Dockerfile를 살펴본다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">FROM node:11.11.0</span><br><span class="line"></span><br><span class="line">LABEL <span class="string">"maintainer"</span>=<span class="string">"anna@example.com"</span></span><br><span class="line">LABEL <span class="string">"rating"</span>=<span class="string">"Five Stars"</span> <span class="string">"class"</span>=<span class="string">"First Class"</span></span><br><span class="line"></span><br><span class="line">USER root</span><br><span class="line"></span><br><span class="line">ENV AP /data/app</span><br><span class="line">ENV SCPATH /etc/supervisor/conf.d</span><br><span class="line"></span><br><span class="line">RUN apt-get -y update</span><br><span class="line"></span><br><span class="line"><span class="comment"># The daemons</span></span><br><span class="line">RUN apt-get -y install supervisor</span><br><span class="line">RUN mkdir -p /var/<span class="built_in">log</span>/supervisor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Supervisor Configuration</span></span><br><span class="line">ADD ./supervisord/conf.d/* <span class="variable">$SCPATH</span>/</span><br><span class="line"></span><br><span class="line"><span class="comment"># Application Code</span></span><br><span class="line">ADD *.js* <span class="variable">$AP</span>/</span><br><span class="line"></span><br><span class="line">WORKDIR <span class="variable">$AP</span></span><br><span class="line"></span><br><span class="line">RUN npm install</span><br><span class="line"></span><br><span class="line">CMD [<span class="string">"supervisord"</span>, <span class="string">"-n"</span>]</span><br></pre></td></tr></table></figure><p>파일 각 라인은 도커에 의해 저장되는 새 이미지 계층을 만든다. 이렇게 설계한 것은 새로운 이미지를 빌드 할 때 <code>변경된 계층만</code>을 새로 빌드하기 위함이다. 각 라인을 차례대로 훑어본다.</p><p><strong>FROM node:11.11.0</strong></p><p>이 부분은  <code>특정 노드 버젼 (node.11.11.0)</code>으로 고정한 우분투 리눅스 이미지를 제공한다는 뜻이다. 이처럼 도커 허브를 통해 노드를 위한 공식 이미지를 받을 수 있고, <code>일반적인 리눅스 이미지</code>에서도 빌드 가능하다.</p><p><strong>LABEL “maintainer”=”<a href="mailto:anna@example.com">anna@example.com</a>“ (LABEL “rating”=”Five Stars” “class”=”First Class”)</strong></p><p><code>Image</code>나 <code>Container</code>에 <code>라벨 (Label)</code>을 적용하는 기능이다. <code>key-value</code>형태로 메타데이터에 추가할 수 있고, 이미지 빌드 후 <code>docker inspect</code> 명령어로 확인이 가능하다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker inspect <span class="built_in">test</span>/docker-node-hello</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"Id"</span>: <span class="string">"sha256:fd425ed5d292360c4b20bb193c402e4fb939b73e07a7f7b6f600e31c9d3a63f8"</span>,</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">            <span class="string">"Image"</span>: <span class="string">"sha256:40ce3ed86b2ce0c74ba5d6de3ec99fca6982ef43355956502bf7adb62b973d05"</span>,</span><br><span class="line">            <span class="string">"Volumes"</span>: null,</span><br><span class="line">            <span class="string">"WorkingDir"</span>: <span class="string">"/data/app"</span>,</span><br><span class="line">            <span class="string">"Entrypoint"</span>: null,</span><br><span class="line">            <span class="string">"OnBuild"</span>: [],</span><br><span class="line">            <span class="string">"Labels"</span>: &#123;</span><br><span class="line">                <span class="string">"class"</span>: <span class="string">"First Class"</span>,</span><br><span class="line">                <span class="string">"maintainer"</span>: <span class="string">"anna@example.com"</span>,</span><br><span class="line">                <span class="string">"rating"</span>: <span class="string">"Five Stars"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br></pre></td></tr></table></figure><p><strong>USER root</strong></p><p>기본적으로<code>docker Container 내 모든 프로세스를 root</code>로 실행하지만, 때에 따라 USER 명령어로 <code>특정 사용자</code>로 지정할 수 있다.</p><blockquote><p> <em>(Container가 호스트 커널 위에서 동작하므로 잠재적 보안 위협이 있을 수 있다. root 보단 특정 사용자 계정으로 실행해야 한다고 권고한다.)</em></p></blockquote><p>** ENV AP(SCPATH) /data/app( /etc/supervisor/conf.d) **</p><p>shell 환경 변수 설정 단계</p><p><strong>RUN ~</strong></p><p><code>파일/디렉터리 구조를 만들고</code> <code>요구되는 소프트웨어를 설치</code>하기 위한 단계로, 위 ENV 단계에서 설정한 환경변수로 간략하게 작성할 수 있다.</p><p>RUN apt-get -y update</p><p>RUN apt-get -y install supervisor<br>RUN mkdir -p /var/log/supervisor</p><blockquote><p> <em>(yum/apt-get update의 경우 빌드 시간이 오래걸릴 수 있다. 이렇게 Dockerfile내 명시하는 것이 아닌 업데이트가 적용된 기본 리눅스 이미지 위에 빌드할 수 있도록 하는 것이 좋다고 권장한다</em>)</p></blockquote><p><strong>ADD ./supervisord/conf.d/* $SCPATH/ (ADD <em>.js</em> $AP/)</strong></p><p><code>로컬 파일 시스템의 파일</code>을 <code>Image로 카피</code>하는 단계이다. <code>코드</code>나 필요한 <code>보조 파일</code>들을 카피하는데 주로 쓰인다.</p><p><strong>WORKDIR $AP</strong></p><p>작업 디렉토리를 변경하는 단계이다. 이처럼 빌드 시 변경되는 사항의 경우, <code>Dockerfile 작성 시 최대한 뒤쪽으로 작성하기를 권장한다.</code>왜냐면 이미지를 새로 빌드하면 처음으로 바뀐 부분부터 새로 빌드되기 때문이다.</p><p><strong>CMD [“supervisord”, “-n”]</strong></p><p>Container 안에서 실행하고자 하는 프로세스를 띄우는 명령어를 작성하는 단계이다. 커뮤니티 내에서 많은 논란이 있었지만 <code>컨테이너 내 하나의 프로세스만 실행</code>하는 것이 가장 좋다고 말한다. <code>컨테이너는 단일 기능만을 제공한다</code>는 철학(?)에 기초한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 conf.d]$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE                               COMMAND             CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">8affdbc03b3e        example/docker-node-hello:lastest   <span class="string">"supervisord -n"</span>    22 hours ago        Up 26 minutes       0.0.0.0:8080-&gt;8080/tcp   romantic_haibt</span><br></pre></td></tr></table></figure><h1 id="Image-Build"><a href="#Image-Build" class="headerlink" title="Image Build"></a>Image Build</h1><blockquote><p> 위 Dockerfile을 기반으로 한 이미지를 빌드해보고자 한다. git을 이용해 예제 애플리케이션 저장소를 복제해온다.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ git <span class="built_in">clone</span> https://github.com/spkane/docker-node-hello.git</span><br><span class="line">Cloning into <span class="string">'docker-node-hello'</span>...</span><br><span class="line">remote: Enumerating objects: 47, <span class="keyword">done</span>.</span><br><span class="line">remote: Total 47 (delta 0), reused 0 (delta 0), pack-reused 47</span><br><span class="line">Unpacking objects: 100% (47/47), <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line">[kuber@node2 ~]$ <span class="built_in">cd</span> docker-node-hello/</span><br><span class="line">[kuber@node2 docker-node-hello]$</span><br></pre></td></tr></table></figure><p>git 디렉토리를 제외한 파일들을 살펴보면 다음과 같다. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ tree -a -I .git</span><br><span class="line">.</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── .dockerignore</span><br><span class="line">├── .gitignore</span><br><span class="line">├── index.js</span><br><span class="line">├── Makefile</span><br><span class="line">├── package.json</span><br><span class="line">├── README.md</span><br><span class="line">├── supervisord</span><br><span class="line">│   └── conf.d</span><br><span class="line">│       ├── node.conf</span><br><span class="line">│       └── supervisord.conf</span><br><span class="line">└── Vagrantfile</span><br></pre></td></tr></table></figure><blockquote><p><em><code>.dockerignore</code> : docker Image 빌드 시 도커 호스트에 업로드하고 싶지 않은 파일이나 디렉토리를 지정하는 파일</em></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ cat .dockerignore </span><br><span class="line">.git</span><br></pre></td></tr></table></figure><ul><li><code>package.json</code> : Node.js 애플리케이션 정의 및 의존성 나열 파일</li><li><code>index.js</code> : 애플리케이션 메인 소스 코드</li><li><code>supervisord</code> : 애플리케이션 시작 및 모니터링이 가능한 supervisord을 위한 설정 파일이 포함된 폴더</li></ul><p>그럼 이제 Image를 빌드해보도록 한다. 명령어에 쓰이는 자세한 옵션들은 <a href="http://bit.ly/1THKRk0" target="_blank" rel="noopener">공식문서</a>를 참고하면 된다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ docker build -t example/docker-node-hello:lastest .</span><br><span class="line">Sending build context to Docker daemon 15.87 kB</span><br><span class="line">Step 1/14 : FROM node:11.11.0</span><br><span class="line">Trying to pull repository docker.io/library/node ... </span><br><span class="line">11.11.0: Pulling from docker.io/library/node</span><br><span class="line">22dbe790f715: Pull complete </span><br><span class="line">0250231711a0: Pull complete </span><br><span class="line">6fba9447437b: Pull complete </span><br><span class="line">c2b4d327b352: Pull complete </span><br><span class="line">270e1baa5299: Pull complete </span><br><span class="line">08ba2f9dd763: Pull complete </span><br><span class="line">edf54285ab13: Pull complete </span><br><span class="line">4d751c169397: Pull complete </span><br><span class="line">Digest: sha256:065610e9b9567dfecf10f45677f4d372a864a74a67a7b2089f5f513606e28ede</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> docker.io/node:11.11.0</span><br><span class="line"> ---&gt; 9ff38e3a6d9d</span><br><span class="line">Step 2/14 : LABEL <span class="string">"maintainer"</span> <span class="string">"anna@example.com"</span></span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> d0c3d1590e1f</span><br><span class="line"> ---&gt; b4855e6ce77c</span><br><span class="line">Removing intermediate container d0c3d1590e1f</span><br><span class="line">Step 3/14 : LABEL <span class="string">"rating"</span> <span class="string">"Five Stars"</span> <span class="string">"class"</span> <span class="string">"First Class"</span></span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 04a73c43a44a</span><br><span class="line"> ---&gt; 2ebbef69d1b3</span><br><span class="line">Removing intermediate container 04a73c43a44a</span><br><span class="line">Step 4/14 : USER root</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 5de276a155e2</span><br><span class="line"> ---&gt; 8ad740a32fdd</span><br><span class="line">Removing intermediate container 5de276a155e2</span><br><span class="line">Step 5/14 : ENV AP /data/app</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> aa77a9763782</span><br><span class="line"> ---&gt; 45925bd0fb66</span><br><span class="line">Removing intermediate container aa77a9763782</span><br><span class="line">Step 6/14 : ENV SCPATH /etc/supervisor/conf.d</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 931030d51457</span><br><span class="line"> ---&gt; a2975676fd6d</span><br><span class="line">Removing intermediate container 931030d51457</span><br><span class="line">Step 7/14 : RUN apt-get -y update</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> ecc80b77c428</span><br><span class="line"></span><br><span class="line">Ign:1 http://deb.debian.org/debian stretch InRelease</span><br><span class="line">Get:2 http://deb.debian.org/debian stretch-updates InRelease [91.0 kB]</span><br><span class="line">Get:3 http://deb.debian.org/debian stretch Release [118 kB]</span><br><span class="line">Get:4 http://security.debian.org/debian-security stretch/updates InRelease [94.3 kB]</span><br><span class="line">Get:5 http://deb.debian.org/debian stretch-updates/main amd64 Packages [27.4 kB]</span><br><span class="line">Get:6 http://security.debian.org/debian-security stretch/updates/main amd64 Packages [506 kB]</span><br><span class="line">Get:7 http://deb.debian.org/debian stretch Release.gpg [2365 B]</span><br><span class="line">Get:8 http://deb.debian.org/debian stretch/main amd64 Packages [7086 kB]</span><br><span class="line">Fetched 7925 kB <span class="keyword">in</span> 3s (2531 kB/s)</span><br><span class="line">Reading package lists...</span><br><span class="line"> ---&gt; 37d8e3e4a4b4</span><br><span class="line">Removing intermediate container ecc80b77c428</span><br><span class="line">Step 8/14 : RUN apt-get -y install supervisor</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 74da13fa61de</span><br><span class="line"></span><br><span class="line">Reading package lists...</span><br><span class="line">Building dependency tree...</span><br><span class="line">Reading state information...</span><br><span class="line">The following additional packages will be installed:</span><br><span class="line">  python-meld3 python-pkg-resources</span><br><span class="line">Suggested packages:</span><br><span class="line">  python-setuptools supervisor-doc</span><br><span class="line">The following NEW packages will be installed:</span><br><span class="line">  python-meld3 python-pkg-resources supervisor</span><br><span class="line">0 upgraded, 3 newly installed, 0 to remove and 57 not upgraded.</span><br><span class="line">Need to get 483 kB of archives.</span><br><span class="line">After this operation, 2157 kB of additional disk space will be used.</span><br><span class="line">Get:1 http://deb.debian.org/debian stretch/main amd64 python-pkg-resources all 33.1.1-1 [166 kB]</span><br><span class="line">Get:2 http://deb.debian.org/debian stretch/main amd64 python-meld3 all 1.0.2-2 [37.3 kB]</span><br><span class="line">Get:3 http://deb.debian.org/debian stretch/main amd64 supervisor all 3.3.1-1+deb9u1 [280 kB]</span><br><span class="line">debconf: delaying package configuration, since apt-utils is not installed</span><br><span class="line">Fetched 483 kB <span class="keyword">in</span> 0s (488 kB/s)</span><br><span class="line">Selecting previously unselected package python-pkg-resources.</span><br><span class="line">(Reading database ... 29978 files and directories currently installed.)</span><br><span class="line">Preparing to unpack .../python-pkg-resources_33.1.1-1_all.deb ...</span><br><span class="line">Unpacking python-pkg-resources (33.1.1-1) ...</span><br><span class="line">Selecting previously unselected package python-meld3.</span><br><span class="line">Preparing to unpack .../python-meld3_1.0.2-2_all.deb ...</span><br><span class="line">Unpacking python-meld3 (1.0.2-2) ...</span><br><span class="line">Selecting previously unselected package supervisor.</span><br><span class="line">Preparing to unpack .../supervisor_3.3.1-1+deb9u1_all.deb ...</span><br><span class="line">Unpacking supervisor (3.3.1-1+deb9u1) ...</span><br><span class="line">Setting up python-meld3 (1.0.2-2) ...</span><br><span class="line">Setting up python-pkg-resources (33.1.1-1) ...</span><br><span class="line">Setting up supervisor (3.3.1-1+deb9u1) ...</span><br><span class="line">invoke-rc.d: could not determine current runlevel</span><br><span class="line">invoke-rc.d: policy-rc.d denied execution of start.</span><br><span class="line"> ---&gt; d66e13271f30</span><br><span class="line">Removing intermediate container 74da13fa61de</span><br><span class="line">Step 9/14 : RUN mkdir -p /var/<span class="built_in">log</span>/supervisor</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> f85e1c0267de</span><br><span class="line"></span><br><span class="line"> ---&gt; 9979f514ad99</span><br><span class="line">Removing intermediate container f85e1c0267de</span><br><span class="line">Step 10/14 : ADD ./supervisord/conf.d/* <span class="variable">$SCPATH</span>/</span><br><span class="line"> ---&gt; 6db6cac86654</span><br><span class="line">Removing intermediate container d565d65027c7</span><br><span class="line">Step 11/14 : ADD *.js* <span class="variable">$AP</span>/</span><br><span class="line"> ---&gt; 3a8554a9e86d</span><br><span class="line">Removing intermediate container f60af33566be</span><br><span class="line">Step 12/14 : WORKDIR <span class="variable">$AP</span></span><br><span class="line"> ---&gt; 7437cca985ff</span><br><span class="line">Removing intermediate container 6b1e8ae1aec2</span><br><span class="line">Step 13/14 : RUN npm install</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> e1038f1c1b6a</span><br><span class="line"></span><br><span class="line">npm WARN deprecated connect@2.7.9: connect 2.x series is deprecated</span><br><span class="line">npm notice created a lockfile as package-lock.json. You should commit this file.</span><br><span class="line">added 18 packages from 15 contributors and audited 34 packages <span class="keyword">in</span> 3.641s</span><br><span class="line">found 16 vulnerabilities (5 low, 5 moderate, 6 high)</span><br><span class="line">  run `npm audit fix` to fix them, or `npm audit` <span class="keyword">for</span> details</span><br><span class="line"> ---&gt; 40ce3ed86b2c</span><br><span class="line">Removing intermediate container e1038f1c1b6a</span><br><span class="line">Step 14/14 : CMD supervisord -n</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> dd4b1488e1a7</span><br><span class="line"> ---&gt; fd425ed5d292</span><br><span class="line">Removing intermediate container dd4b1488e1a7</span><br><span class="line">Successfully built fd425ed5d292</span><br></pre></td></tr></table></figure><h1 id="Run-Image"><a href="#Run-Image" class="headerlink" title="Run Image"></a>Run Image</h1><p>Image 빌드가 성공하면 아래와 같이 Image를 실행해본다. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 example/docker-node-hello:lastest </span><br><span class="line">8affdbc03b3ec66745ef5cb9e90f5d1f71b46c93932b706317b744fbb7212371</span><br><span class="line"></span><br><span class="line"><span class="keyword">in</span> Web browser,</span><br><span class="line">Hello World. Wish you were here.</span><br></pre></td></tr></table></figure><p>위 명령은 아래와 같다.</p><ul><li><code>example/docker-node-hello:lastest 태그를 가진 이미지</code>로부터</li><li><code>백그라운드에 실행 컨테이너</code>로 만들고 (-d)</li><li><code>8080 port 를 docker 호스트의 8080 port에 매핑</code> (-p 8080:8080)</li></ul><p>그럼 실제 웹이 잘 띄워졌는지 확인하기 위해 docker server의 ip를 확인하고 접속해본다. (로컬=서버이므로 해당 아이피:8080 으로 접속하면 보인다)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello World. Wish you were here.</span><br></pre></td></tr></table></figure><h2 id="환경-변수"><a href="#환경-변수" class="headerlink" title="환경 변수"></a>환경 변수</h2><p><code>index.js</code>를 살펴보자. $WHO 는 Hello의 대상이 되는 앱이 사용하는 변수임을 확인할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// Constants</span><br><span class="line">var DEFAULT_PORT = 8080;</span><br><span class="line">var DEFAULT_WHO = <span class="string">"World"</span>;</span><br><span class="line">var PORT = process.env.PORT || DEFAULT_PORT;</span><br><span class="line">var WHO = process.env.WHO || DEFAULT_WHO;</span><br><span class="line"></span><br><span class="line">// App</span><br><span class="line">var app = express();</span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="keyword">function</span> (req, res) &#123;</span><br><span class="line">  res.send(<span class="string">'Hello '</span> + WHO + <span class="string">'. Wish you were here.\n'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>그럼 Container를 띄울 때 환경변수를 넘겨 Hello 대상을 변경해보도록 한다. 우선 띄워져 있는 Container를 확인한 후 중지한다. 중지하는 방법은 CONTAINER ID와 NAMES를 이용하는 두 가지 방법이 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE                               COMMAND             CREATED              STATUS              PORTS                    NAMES</span><br><span class="line">8affdbc03b3e        example/docker-node-hello:lastest   <span class="string">"supervisord -n"</span>    About a minute ago   Up About a minute   0.0.0.0:8080-&gt;8080/tcp   romantic_haibt</span><br><span class="line">[kuber@node2 docker-node-hello]$ docker stop 8affdbc03b3e(or docker stop romantic_haibt)</span><br><span class="line">8affdbc03b3e</span><br><span class="line">[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 example/docker-node-hello:lastest </span><br><span class="line">a412191bdcdb7b55e687b44dedc0707164fff784c0e1c64f1ce11a22afe64b2a</span><br><span class="line">[kuber@node2 docker-node-hello]$ docker stop priceless_lovelace</span><br><span class="line">priceless_lovelace</span><br><span class="line">[kuber@node2 docker-node-hello]$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br></pre></td></tr></table></figure><p>run 명령어에 -e 를 추가하여 재시작한다. (WHO : Jaejun Lee)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 docker-node-hello]$ docker run -d -p 8080:8080 -e WHO=<span class="string">"Jaejun Lee"</span> example/docker-node-hello:lastest </span><br><span class="line">389f5be3ee7c2020ecacbd032a5ffa048339d0bdee66666e6dedc8e74e992e78</span><br></pre></td></tr></table></figure><p>web으로 접속하여 확인해본다.</p><p><code>Hello World. Wish you were here.</code></p><h1 id="Image-저장"><a href="#Image-저장" class="headerlink" title="Image 저장"></a>Image 저장</h1><p>Image도 만들었겠다, 배포를 원하는 docker 호스트에서 쉽게 접근할 수 있는 곳에다가 저장해야 한다. 이곳을 Image 빌드와 Image 실행 사이의 <code>명백한 핸드오프 포인트(hand-off point)</code>라고 한다.</p><p>보통 Image를 Server에서 직접 빌드하고 실행하지 않는다. 대개 Image 저장소에서 Image를 끌어와 하나 이상의 Docker Server에 실행할 수 있게끔 배포한다. 손쉽게 이미지를 끌어오기 위해 Image를 저장하는 몇 가지 방법에 대해 살펴보자</p><p><strong>공개 registry</strong></p><p><code>공개 Image들을 저장하기 위한 Image registry</code>를 제공한다(<a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a>). Linux 배포판, WordPress등 다양한 Image가 존재한다.</p><p><strong>비공개 registry</strong></p><p>Image를 인터넷을 통해 공개하지 않고 <code>내부적으로 Docker Image를 관리하는 방법</code>도 존재한다.</p><p><strong>registry 인증</strong></p><p>Container Image를 저장하는 registry와의 통신은 필수적이다. 저장하는 과정에서 권한을 요구하는데, Docker는 자동화를 위해 Image 다운 요청을 받는 경우 사용자를 대신해 로그인 정보를 저장하고 이를 사용한다. default registry는 앞에서 언급한 공개 Image가 저장되어 있는 registry 이다.</p><p><strong>Docker Hub 계정 생성 후 로그인</strong></p><p><a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a>에 접속하여 가입한 후 로그인을 해보도록 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker login</span><br><span class="line">Login with your Docker ID to push and pull images from Docker Hub. If you don<span class="string">'t have a Docker ID, head over to https://hub.docker.com to create one.</span></span><br><span class="line"><span class="string">Username: jaejunlee  </span></span><br><span class="line"><span class="string">Password: </span></span><br><span class="line"><span class="string">Login Succeeded</span></span><br></pre></td></tr></table></figure><p>로그인이 성공되면, <code>~/.docker/confing.json</code>라는 파일이 생성되는데, 나의 로그인 정보를 캐시하기 위함이다. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ cat ~/.docker/config.json </span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"auths"</span>: &#123;</span><br><span class="line"><span class="string">"https://index.docker.io/v1/"</span>: &#123;</span><br><span class="line"><span class="string">"auth"</span>: <span class="string">"amFlanVubGVlOndvd25zbGQ5NDg5"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이러한 정보를 담고 있는 파일은 <code>registry에 접근하고자 할 때 Docker는 이를 참고해 연결을 시도</code>한다. 사용을 다 한 이후에 만약 로그아웃을 하게된다면, <code>파일이 비어있음</code>을 확인할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker <span class="built_in">logout</span></span><br><span class="line">Removing login credentials <span class="keyword">for</span> https://index.docker.io/v1/</span><br><span class="line">[kuber@node2 ~]$ cat ~/.docker/config.json </span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"auths"</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="registry에-Image-저장"><a href="#registry에-Image-저장" class="headerlink" title="registry에 Image 저장"></a>registry에 Image 저장</h1><p>앞서 Image build 시 우리는 <code>docker build -t example/docker-node-hello:lastest .</code>명령어를 사용했다. 이는 공개 registry 의 example/docker-node-hello 이미지를 빌드한 것인데, 만약 로컬에서 생성한 이미지의 경우 아무 이름이나<em>(보통 사용자/그룹 이용)</em> 사용 가능하다.</p><p><code>tag</code>명령어를 통해 이미지의 태그를 변경할 수 있다.</p><blockquote><p>이미지 태그명은 docker 사용자 아이디로 설정하여야 추후에 push/pull이 가능하다</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker tag <span class="built_in">test</span>/docker-node-hello:latest jaejunlee/docker-node-hello:latest</span><br><span class="line">[kuber@node2 ~]$ docker images</span><br><span class="line">REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">example/docker-node-hello   lastest             fd425ed5d292        2 days ago          928 MB</span><br><span class="line">jaejunlee/docker-node-hello    latest              fd425ed5d292        2 days ago          928 MB</span><br><span class="line"><span class="built_in">test</span>/docker-node-hello      latest              fd425ed5d292        2 days ago          928 MB</span><br><span class="line">docker.io/centos            latest              67fa590cfc1c        5 weeks ago         202 MB</span><br><span class="line">docker.io/node              11.11.0             9ff38e3a6d9d        6 months ago        904 MB</span><br></pre></td></tr></table></figure><p>이번엔 그럼 tag를 바꾼 이미지를 push <em>(공개 registry)</em> 해보도록 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[kuber@node2 ~]$ docker push jaejunlee/docker-node-hello-test:latest</span><br><span class="line">The push refers to a repository [docker.io/jaejunlee/docker-node-hello-test]</span><br><span class="line">a233ae287464: Pushed </span><br><span class="line">8f9ee22c1347: Pushed </span><br><span class="line">ce283841f218: Pushed </span><br><span class="line">f8fc35d38ecc: Pushed </span><br><span class="line">cb7a837507c0: Pushed </span><br><span class="line">4ebe27287e94: Pushed </span><br><span class="line">abdde7643382: Pushed </span><br><span class="line">909542b1bce2: Pushed </span><br><span class="line">7de462056991: Pushed </span><br><span class="line">3443d6cf0f1f: Pushed </span><br><span class="line">f3a38968d075: Pushed </span><br><span class="line">a327787b3c73: Pushed </span><br><span class="line">5bb0785f2eee: Pushed </span><br><span class="line">latest: digest: sha256:98a38e1a53a9473ab1b083099d29d70d9a05d5f924533b378e70555b1f1714a3 size: 3055</span><br></pre></td></tr></table></figure><p><code>Docker Hub</code>에 접속하여 제대로 <code>push</code> 되었는지 확인해보도록 한다.</p><p><em>(<a href="https://cloud.docker.com/u/jaejunlee/repository/docker/jaejunlee/docker-node-hello-test" target="_blank" rel="noopener">https://cloud.docker.com/u/jaejunlee/repository/docker/jaejunlee/docker-node-hello-test</a>)</em></p><hr><p>2019.09.23 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-docker_image/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 동적 인수 지정 시 None과 docstring 활용</title>
      <link>https://jx2lee.github.io/python-better_way_20/</link>
      <guid>https://jx2lee.github.io/python-better_way_20/</guid>
      <pubDate>Wed, 18 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;아래 동적 인수를 활용하는 함수 (이벤트 발생 시각을 포함하는 log 함수) 를 생각해보자.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>아래 동적 인수를 활용하는 함수 (이벤트 발생 시각을 포함하는 log 함수) 를 생각해보자.</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_log</span><span class="params">(mes, date=datetime.now<span class="params">()</span>)</span>:</span></span><br><span class="line">    print(<span class="string">'%s: %s'</span>%(date, mes))</span><br><span class="line"></span><br><span class="line">get_log(<span class="string">'Hi there!'</span>)</span><br><span class="line">time.sleep(<span class="number">0.1</span>)</span><br><span class="line">get_log(<span class="string">'Hi again!'</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">2019</span><span class="number">-09</span><span class="number">-19</span> <span class="number">08</span>:<span class="number">28</span>:<span class="number">26.737742</span>: Hi there!</span><br><span class="line"><span class="number">2019</span><span class="number">-09</span><span class="number">-19</span> <span class="number">08</span>:<span class="number">28</span>:<span class="number">26.737742</span>: Hi again!</span><br></pre></td></tr></table></figure><p>원하는 함수 결과는 0.1초 이후 타임스탬프가 찍혀야 하는데 같지 않은가!! 이는 함수를 정의할 때 <code>date</code>변수가 default로 그 시간을 가져가기 때문에 원하는 결과값을 얻지 못한다. 즉, <code>재평가</code>하지 않는다. 이를 해결하기 위해서는 어떻게 해야하는가?</p><p><strong>default 를 None으로 설정하고 docstring(문서화) 하자!</strong></p><p> 함수 정의 시 기본 값을 None으로 설정하고 이에 작용 원리와 변수를 나타내도록 문서화해보면 아래와 같다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_log</span><span class="params">(mes, date=None)</span>:</span></span><br><span class="line">    <span class="string">"""Log a message with a timestamp.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        mes : message to print</span></span><br><span class="line"><span class="string">        date : datetime of whe the message occured.</span></span><br><span class="line"><span class="string">            Defaults to the present time.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    date = datetime.now() <span class="keyword">if</span> date <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> date</span><br><span class="line">    print(<span class="string">'%s: %s'</span>%(date, mes))</span><br><span class="line"></span><br><span class="line">get_log(<span class="string">'Hi there!'</span>)</span><br><span class="line">time.sleep(<span class="number">0.1</span>)</span><br><span class="line">get_log(<span class="string">'Hi again!'</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">2019</span><span class="number">-09</span><span class="number">-19</span> <span class="number">08</span>:<span class="number">35</span>:<span class="number">17.079609</span>: Hi there!</span><br><span class="line"><span class="number">2019</span><span class="number">-09</span><span class="number">-19</span> <span class="number">08</span>:<span class="number">35</span>:<span class="number">17.180161</span>: Hi again!</span><br></pre></td></tr></table></figure><p>타임스탬프가 바뀐것을 확인하였다! 이처럼 None을 사용하는 방법은 인수가 <code>수정 가능(Mutable)</code>할 때 중요하다고 한다. 예를 들어 아래 함수를 살펴보자</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(data, default=&#123;&#125;)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> json.loads(data)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> default</span><br><span class="line">    </span><br><span class="line">test1 = decode(<span class="string">'hi'</span>)</span><br><span class="line">test1[<span class="string">'t'</span>]=<span class="number">10</span></span><br><span class="line">test2 = decode(<span class="string">'hii'</span>)</span><br><span class="line">test2[<span class="string">'t1'</span>]=<span class="number">100</span></span><br><span class="line">print(<span class="string">'test1: '</span>, test1)</span><br><span class="line">print(<span class="string">'test2: '</span>, test2)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">test1:  &#123;<span class="string">'t'</span>: <span class="number">10</span>, <span class="string">'t1'</span>: <span class="number">100</span>&#125;</span><br><span class="line">test2:  &#123;<span class="string">'t'</span>: <span class="number">10</span>, <span class="string">'t1'</span>: <span class="number">100</span>&#125;</span><br></pre></td></tr></table></figure><p>이 함수도 마찬가지로 <code>get_log</code> 함수와 같은 문제가 존재한다. 원했던 결과는 각각 test1/test2 에는 try부분이 실행되지 않기 때문에 print 되는 default 가 하나씩 찍혔어야 한다. 이처럼 문제가 발생하는 원인은 <code>함수 인자로 설정한 dictionary가 decode 호출에서 공유하기 때문이다.</code>이를 해결할 수 있는 것은 <code>default 인수를 None으로 받고 문서화하면 된다.</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updated_decode</span><span class="params">(data, default=None)</span>:</span></span><br><span class="line">    <span class="string">"""Load JSON data from a string.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data : JSON data to decode</span></span><br><span class="line"><span class="string">        default : Value to return if decoding fails.</span></span><br><span class="line"><span class="string">            Defaults to an empty dictionary.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    <span class="keyword">if</span> default <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        default = &#123;&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> json.loads(data)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> default</span><br><span class="line"></span><br><span class="line">test1 = updated_decode(<span class="string">'hi'</span>)</span><br><span class="line">test1[<span class="string">'t'</span>]=<span class="number">10</span></span><br><span class="line">test2 = updated_decode(<span class="string">'hii'</span>)</span><br><span class="line">test2[<span class="string">'t1'</span>]=<span class="number">100</span></span><br><span class="line">print(<span class="string">'test1: '</span>, test1)</span><br><span class="line">print(<span class="string">'test2: '</span>, test2)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">test1:  &#123;<span class="string">'t'</span>: <span class="number">10</span>&#125;</span><br><span class="line">test2:  &#123;<span class="string">'t1'</span>: <span class="number">100</span>&#125;</span><br></pre></td></tr></table></figure><p><strong>Summary</strong></p><ul><li>함수의 기본 인수는 모듈 로드 시점에 함수 정의 과정에서 딱 한 번만 평가된다.</li><li>함수의 기본 인수가 동적인 경우에는 <code>기본값으로 None</code>을 사용하자. 이후 <code>docstring에 실제 기본 동작을 문서화</code>하자</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.09.19 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_20/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 키워드 인수 활용</title>
      <link>https://jx2lee.github.io/python-better_way_19/</link>
      <guid>https://jx2lee.github.io/python-better_way_19/</guid>
      <pubDate>Tue, 17 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;다른 프로그래밍 언어와 마찬가지로 함수 호출 시 인수를 위치로 전달이 가능하다. 아래 함수를 보자&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>다른 프로그래밍 언어와 마찬가지로 함수 호출 시 인수를 위치로 전달이 가능하다. 아래 함수를 보자</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remainder</span><span class="params">(num, div)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> num % div</span><br><span class="line"></span><br><span class="line">print(remainder(<span class="number">20</span>, <span class="number">7</span>))</span><br><span class="line">print(remainder(<span class="number">20</span>, div=<span class="number">7</span>))</span><br><span class="line">print(remainder(num=<span class="number">20</span>, div=<span class="number">7</span>))</span><br><span class="line">print(remainder(div=<span class="number">7</span>, num=<span class="number">20</span>))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"></span><br><span class="line">print(remainder(num=<span class="number">20</span>, <span class="number">7</span>))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">SyntaxError: positional argument follows keyword argument</span><br></pre></td></tr></table></figure><p>위 네 개 print는 제대로 작동하지만, 아래의 경우 위치인수를 키워드 인수 뒤에 배치할 경우 에러가 발생한다. 키워드 인수는 다음 세 가지 중요한 이점이 있다고 한다.</p><p><strong>함수 호출을 명확하게 이해할 수 있다</strong></p><p>키워드 인수를 사용하면 각각의 목적으로 어떤 parameter를 사용했는지 곧바로 명확하게 알 수 있다.</p><p><strong>default 값 설정이 가능</strong></p><p>입력 인수를 기본 <code>default</code>로 설정할 수 있다. 아래 코드를 보자</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_rate</span><span class="params">(wgt, time, period=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (wgt / time) * period</span><br><span class="line"></span><br><span class="line">wgt = <span class="number">0.5</span></span><br><span class="line">time = <span class="number">3</span></span><br><span class="line">flow = get_rate(wgt, time)</span><br><span class="line">print(<span class="string">'%.3f kg per second'</span> % flow)</span><br><span class="line">flow = get_rate(wgt, time, period=<span class="number">3600</span>)</span><br><span class="line">print(<span class="string">'%.3f kg per second'</span> % flow)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">0.167</span> kg per second</span><br></pre></td></tr></table></figure><p><code>period</code> 인수를 default 1로 설정하였다. 첫 번재 호출에서는 period를 사용하지 않아 자동으로 1로 입력받고, 두 번째 호출에서는 <code>3600</code>을 전달받아 호출하였다. 이처럼 <code>코드가 깔끔해진다.</code></p><p><strong>기존 호출 코드와 호환성을 유지-함수의 파라미터 확장이 가능</strong></p><p>이는 딱히 예제가 필요없을 것 같아 말로 풀겠다. #2 와 비슷한 항목으로 기본 default 인수를 설정하면 파라미터 확장이 용이함을 확인할 수 있다. 이 책에서 주의할 점은 선택적 인수를 위치로 넘기면 어떤 인수인지 어려울 수 있다고 한다. 이때 가장 좋은 방법으로는 <code>항상 키워드 이름으로 선택적 인수를 지정하고 위치 인수로는 아예 넘기지 않게 하는 것</code>을 <code>권장</code>한다.</p><p><strong>Summary</strong></p><ul><li>함수의 인자를 위치나 키워드로 지정이 가능하다</li><li>키워드 인수를 사용하여 위치 인수만으로 이해하기 어려운 문제를 해결할 수 있다</li><li>키워드 인수에 default 값을 지정하면 확장이 가능하다</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.09.18 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_19/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 가변 위치 인수 활용</title>
      <link>https://jx2lee.github.io/python-better_way_18/</link>
      <guid>https://jx2lee.github.io/python-better_way_18/</guid>
      <pubDate>Tue, 17 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;선택적 위치 인수, &lt;em&gt;\&lt;/em&gt;args* 불리는 star args는 함수의 호출을 더 명확하고 가독성을 높인다. 다음 아래 함수를 보자&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>선택적 위치 인수, <em>\</em>args* 불리는 star args는 함수의 호출을 더 명확하고 가독성을 높인다. 다음 아래 함수를 보자</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_log</span><span class="params">(mes, val)</span>:</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> val:</span><br><span class="line">print(mes)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">val_str = <span class="string">', '</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> val)</span><br><span class="line">print(<span class="string">'%s %s'</span>%(mes, val_str))</span><br><span class="line"></span><br><span class="line">get_log(<span class="string">'My numbers are'</span>, [<span class="number">1.2</span>])</span><br><span class="line">get_log(<span class="string">'Hi there'</span>, [])</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">My numbers are <span class="number">1.2</span></span><br><span class="line">Hi there</span><br></pre></td></tr></table></figure><p><code>허나, 굳이 로그를 남길 값이 없을 때 빈 리스트를 넣어주는 것은 참으로 불편한 짓이다.</code> 이러한 불편함을 해소하기 위해 * 기호를 마지막 파라미터에 붙이면 이 변수는 <code>선택적</code>이다. 다음 함수를 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_log</span><span class="params">(mes, *val)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> val:</span><br><span class="line">        print(mes)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        val_str = <span class="string">', '</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> val)</span><br><span class="line">        print(<span class="string">'%s %s'</span>%(mes, val_str))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">My numbers are [<span class="number">1.2</span>]</span><br><span class="line">Hi there</span><br></pre></td></tr></table></figure><p>굳이 빈 리스트를 넣어주지 않아도 함수가 <code>알아서</code> 작동한다. <code>하지만</code> 가변 개수의 위치 변수는 다음 두 가지 문제를 가지고 있다고 한다.</p><p><strong>return 값이 항상 튜플로 반환</strong></p><p><code>generator</code>로 생성된 모든 값을 담으므로 메모리를 많이 차지하는 문제점이 있다. 아래 코드를 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_generator</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_func</span><span class="params">(*args)</span>:</span></span><br><span class="line">    print(args)</span><br><span class="line">    </span><br><span class="line">it = _generator()</span><br><span class="line">get_func(*it)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure><p>위와 같이 입력 수가 적다면은 가장 좋은 방법이기도 하다. 하지만 입력 수가 많다면 위와 같이 *args 방법은 비효율적일 것이다.</p><p><strong>나중에 함수를 고칠 때 새 위치 인수 추가 불가능</strong></p><p>코드는 바뀔 수 있다. 하지만 star agrs를 사용한다면 코드 수정 시 아래와 같은 문제가 발생할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_log</span><span class="params">(seq, mes, *val)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> val:</span><br><span class="line">        print(<span class="string">'%s: %s'</span>%(seq, mes))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        val_str = <span class="string">', '</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> val)</span><br><span class="line">        print(<span class="string">'%s: %s: %s'</span>%(seq, mes, val_str))</span><br><span class="line"></span><br><span class="line">get_log(<span class="number">1</span>, <span class="string">'My numbers are'</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">get_log(<span class="string">'Hi there'</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">1</span>: My numbers are: <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">Hi there: <span class="number">1</span>: <span class="number">2</span></span><br></pre></td></tr></table></figure><p>첫 번째 호출과 두 번째 return 값이 다른 이유는, <code>mes</code>를 서로 다르게(‘My numbers are’, 1) 받았기 때문이다. 이러한 문제가 생길 가능성을 없애기 위해서는 *agrs 를 받는 함수를 확장할 때 키워드 전용(keyword-only) 인수를 사용해야한다. <strong>이는 Better Way 21</strong>에서 다루도록 한다.</p><p><strong>Summary</strong></p><ul><li>*args 를 이용해 함수에서 가변 개수의 인수를 사용할 수 있다</li><li>*과 <code>generator</code>를 함께 사용한다면 메모리가 부족할 수 있다</li><li>*args 를 이용해 만든 함수를 확장할 때 <code>버그</code>가 생길 수 있다</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.09.18 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_18/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 리스트를 반환하는 대신 제네레이터</title>
      <link>https://jx2lee.github.io/python-better_way_16/</link>
      <guid>https://jx2lee.github.io/python-better_way_16/</guid>
      <pubDate>Thu, 12 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;결과 생성 함수에서 택할 수 있는 가장 간단한 방법은 리스트를 반환하는 것이다. 예로, 문자열에 포함된 모든 단어의 인덱스를 출력하고자 한다. append 함수를 이용해 리스트를 반환하는 코드를 작성할 수 있다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>결과 생성 함수에서 택할 수 있는 가장 간단한 방법은 리스트를 반환하는 것이다. 예로, 문자열에 포함된 모든 단어의 인덱스를 출력하고자 한다. append 함수를 이용해 리스트를 반환하는 코드를 작성할 수 있다.</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_word_index</span><span class="params">(text)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">if</span> text:</span><br><span class="line">        result.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> idx, wd <span class="keyword">in</span> enumerate(text):</span><br><span class="line">        <span class="keyword">if</span> wd == <span class="string">' '</span>:</span><br><span class="line">            result.append(idx + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = <span class="string">'Four score and seven years ago...'</span></span><br><span class="line">result = get_word_index(test)</span><br><span class="line">print(result)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">0</span>, <span class="number">5</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">21</span>, <span class="number">27</span>]</span><br></pre></td></tr></table></figure><p>하지만 이 함수는 두 가지 문제점이 있다고 한다</p><h1 id="코드가-복잡하고-깔끔하지-않다"><a href="#코드가-복잡하고-깔끔하지-않다" class="headerlink" title="코드가 복잡하고 깔끔하지 않다"></a>코드가 복잡하고 깔끔하지 않다</h1><blockquote><ul><li>새로운 결과를 생성할 때마다 append 메소드를 호출</li><li>결과 리스트를 생성하는데 한 줄, 반환하는 데도 한 줄..<br>작성한 코드는 전체 130개 있지만 그 중에서 중요한 문자는 75개 정도이다. 이러한 함수를 효율적으로 작성하는 방법은 <code>제네레이터(generator)</code>를 사용하는 것이다. 실제로 실행하지 않고 바로 <code>이터레이터(iterator)</code>를 반환한다. <code>이터레이터(iterator</code>는 제네레이터가 다음 <code>yield</code> 표현식으로 진행한다. 제네레이터에서 yield에 전달한 값을 이터레이터가 호출하는 쪽에서 반환한다.<br><br><code>get_word_index</code>함수를 제네레이터 함수로 수정하면 다음과 같다.<br></li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_word_index_2</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> text:</span><br><span class="line">        <span class="keyword">yield</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> idx, wd <span class="keyword">in</span> enumerate(text):</span><br><span class="line">        <span class="keyword">if</span> wd == <span class="string">' '</span>:</span><br><span class="line">            <span class="keyword">yield</span> idx + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">test = <span class="string">'Four score and seven years ago...'</span></span><br><span class="line">result = list(get_word_index(test))</span><br><span class="line">print(result)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">0</span>, <span class="number">5</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">21</span>, <span class="number">27</span>]</span><br></pre></td></tr></table></figure><p>get_word_index 함수와는 다르게, index_2 함수는 return 되는 iterator를 list로 넘겨주면 된다.<br></p><h1 id="반환-전-모든-결과를-리스트에-저장한다"><a href="#반환-전-모든-결과를-리스트에-저장한다" class="headerlink" title="반환 전 모든 결과를 리스트에 저장한다"></a>반환 전 모든 결과를 리스트에 저장한다</h1><blockquote><p>입력이 매우 많다면 <code>메모리 고갈</code> -&gt; <code>다운</code>되는 원인이 된다.<br><br>다음은 file에서 한 줄씩 읽어와 단어의 index를 반환하는 함수를 generator를 사용해 작성해보자<br></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_file</span><span class="params">(handle)</span>:</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> handle:</span><br><span class="line">        <span class="keyword">yield</span> res</span><br><span class="line">    <span class="keyword">for</span> wd <span class="keyword">in</span> lune:</span><br><span class="line">        offset += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> wd == <span class="string">' '</span>:</span><br><span class="line">            <span class="keyword">yield</span> res</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> islice</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./address.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    it = index_file(f)</span><br><span class="line">    results = islice(it, <span class="number">0</span>)</span><br><span class="line">    print(list(result))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">0</span>, <span class="number">5</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">21</span>, <span class="number">27</span>]</span><br></pre></td></tr></table></figure><p><code>islice는 itertools 라이브러리에 있는 함수로, 반복 가능한 객체(iterator)를 slice하는 함수이다.</code>위 함수 작성 시 유의사항은 반환되는 iterator에서 재사용할 수 없다는 사실을 호출하는 쪽에서 반드시 알아야 한다. 이는 Better Way 17에서 다룰 예정이다.<br></p><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><ul><li>제네레이터를 사용하는 것이 누적된 결과의 리스트를 return 하는 것보다 <code>보기 이쁘다</code></li><li>generator 함수 return = <code>yield로 전달된 값들의 집.합</code></li><li>generator는 모든 입출력을 메모리에 저장하지 않는다</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.09.13 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_16/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 인수를 순회할 때는 방어적으로</title>
      <link>https://jx2lee.github.io/python-better_way_17/</link>
      <guid>https://jx2lee.github.io/python-better_way_17/</guid>
      <pubDate>Thu, 12 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;입력값으로 리스트를 받는 함수를 생각해보자. 이때 리스트를 여러 번 순회해야 할 때가 종종 있다.&lt;br&gt;예를 들어 각 도시의 방문자 수가 list로 구성되고, 각 도시에서 전체 여행자 중 몇 퍼센트를 차지하는지 return 하는 함수를 작성해보면 다음과 같다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>입력값으로 리스트를 받는 함수를 생각해보자. 이때 리스트를 여러 번 순회해야 할 때가 종종 있다.<br>예를 들어 각 도시의 방문자 수가 list로 구성되고, 각 도시에서 전체 여행자 중 몇 퍼센트를 차지하는지 return 하는 함수를 작성해보면 다음과 같다.</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_pop</span><span class="params">(n)</span>:</span></span><br><span class="line">    tot = sum(n)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> n:</span><br><span class="line">        per = <span class="number">100</span> * val / tot</span><br><span class="line">        result.append(per)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">v = [<span class="number">15</span>, <span class="number">35</span>, <span class="number">80</span>]</span><br><span class="line">portions = normalize_pop(v)</span><br><span class="line">print(portions)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">11.538461538461538</span>, <span class="number">26.923076923076923</span>, <span class="number">61.53846153846154</span>]</span><br></pre></td></tr></table></figure><p>위와 같이 리스트를 input으로 받지 않고 file로 받는 함수를 생각해보면 generator를 이용해 아래와 같이 작성할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">yield</span> int(line)</span><br><span class="line"></span><br><span class="line">it = read_file(<span class="string">'./numbers.txt'</span>)</span><br><span class="line">portions = normalize_pop(it)</span><br><span class="line">print(portions)</span><br><span class="line"><span class="comment"># 과연 결과는?</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[] <span class="comment"># ???</span></span><br></pre></td></tr></table></figure><p>껍데기만 나오는 이유는, <code>iterator는 결과를 한 번 생성, 즉 한 바퀴를 다 돌고나면 재생성하지 않는</code> 성질을 갖는다.<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">it = read_file(<span class="string">'./numbers.txt'</span>)</span><br><span class="line">print(list(it), <span class="string">'first'</span>)</span><br><span class="line">print(list(it), <span class="string">'second'</span>) <span class="comment"># second만 print, 이미 소진!</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">15</span>, <span class="number">35</span>, <span class="number">80</span>] first</span><br><span class="line">[] second</span><br></pre></td></tr></table></figure><p>StopIteration이라는 에러를 뱉어낼 줄 알았지만 그러한 결과는 알려주지 않는다. 따라서 위와 같은 해결을 위한 방안은 다음과 같이 크게 ?가지로 해결할 수 있다.<br></p><p><strong>case1) iterator를 list로 저장</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_pop_2</span><span class="params">(n)</span>:</span></span><br><span class="line">    n = list(n) <span class="comment"># iterator to list!</span></span><br><span class="line">    tot = sum(n)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> n:</span><br><span class="line">        per = <span class="number">100</span> * val / tot</span><br><span class="line">        result.append(per)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">it = read_file(<span class="string">'./numbers.txt'</span>)</span><br><span class="line">portions = normalize_pop_2(it)</span><br><span class="line">print(portions)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">11.538461538461538</span>, <span class="number">26.923076923076923</span>, <span class="number">61.53846153846154</span>]</span><br></pre></td></tr></table></figure><ul><li>하지만 이 방법의 경우 만약 list로 저장되는 iterator가 크다면 문제가 발생<ul><li>큰 iterator -&gt; 큰 list 저장 -&gt; 메모리 고갈 -&gt; 다운!</li></ul></li><li><code>solution</code> : 호출 때마다 새 iterator 반환..?</li></ul><p><strong>case2) 호출 때마다 iterator 반환</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_pop_3</span><span class="params">(iter_)</span>:</span></span><br><span class="line">    tot = sum(iter_())</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> iter_():</span><br><span class="line">        per = <span class="number">100</span> * val / tot</span><br><span class="line">        result.append(per)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">portions = normalize_pop_3(<span class="keyword">lambda</span>: read_file(<span class="string">'./numbers.txt'</span>))</span><br><span class="line">print(portions)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">11.538461538461538</span>, <span class="number">26.923076923076923</span>, <span class="number">61.53846153846154</span>]</span><br></pre></td></tr></table></figure><ul><li><code>매번</code> iterator를 생성해야함</li><li>입력값을 <code>lambda</code>를 이용해야함<br>위 방법은 세련되지 못한다고 책에서 말한다. 이에 마지막으로 <code>iterator protocol을 구현한 새 컨테이너 클래스</code>로 작성하는 것을 추천한다.<br></li></ul><p><em>Iterator protocol ?</em><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">readVisits</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        self.path = path</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(self.path) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">yield</span> int(line)</span><br><span class="line"></span><br><span class="line">v = readVisits(<span class="string">'./numbers.txt'</span>)</span><br><span class="line">portions = normalize_pop(v)</span><br><span class="line">print(portions)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">11.538461538461538</span>, <span class="number">26.923076923076923</span>, <span class="number">61.53846153846154</span>]</span><br></pre></td></tr></table></figure><ul><li>normalize_pop 내 sum을 위해 <code>__iter__</code> 를 호출</li><li>normalize_pop 내 정규화하는 과정에서 또한 <code>__iter__</code> 을 호출<br>이 방법의 유일한 단점은 입력 데이터를 여러 번 읽어낸다는 것이다. 이 해결을 위해서는 입력값이 iterator일 경우 예외를 일으킨다.<br></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">readVisits</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        self.path = path</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(self.path) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">yield</span> int(line)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_pop_final</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> iter(n) <span class="keyword">is</span> iter(n):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">'Must input be container'</span>)</span><br><span class="line">    tot = sum(n)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> n:</span><br><span class="line">        per = <span class="number">100</span> * val / tot</span><br><span class="line">        result.append(per)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">v = [<span class="number">15</span>, <span class="number">35</span>, <span class="number">80</span>]</span><br><span class="line">normalize_pop_final(v) <span class="comment"># no error</span></span><br><span class="line">v = readVisits(<span class="string">'./numbers.txt'</span>)</span><br><span class="line">normalize_pop_final(v) <span class="comment"># no error</span></span><br><span class="line">it = iter(v)</span><br><span class="line">normalize_pop_final(v)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">TypeError: Must input be container</span><br></pre></td></tr></table></figure><p><code>normalize_pop_final</code>은 전체를 복사하고 싶지 않지만 입력값을 여러 번 순회해야 할 때 사용하면 좋다.</p><p><strong>Summary</strong></p><ul><li>입력값을 여러 번 순회하는 함수는 주의하자</li><li><code>iterator protocol</code> : 컨테이너와 iterator가 내장함수 iter/next와 for 루프 및 관련 포현식과 상호 작용하는 방법을 정의한다</li><li><code>__iter__</code> 메서드를 generator로 구현하면 자신만의 iterable container type을 쉽게 정의할 수 있다</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.09.13 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_17/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Cloud] Kubernetes 개념 및 아키텍쳐</title>
      <link>https://jx2lee.github.io/cloud-introduction_to_kubernetes/</link>
      <guid>https://jx2lee.github.io/cloud-introduction_to_kubernetes/</guid>
      <pubDate>Thu, 05 Sep 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;공유 및 세미나를 위해 Kubernetes를 정리&lt;/p&gt;
&lt;p&gt;최근 제품 관련하여 쿠버네티스 지식이 필요하여 세미나를 재시작 하여 팀원분이 발표한 자료를 바탕으로 내용을 추가/수정 하였다. &lt;em&gt;(2020/01/10)&lt;/em&gt;&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>공유 및 세미나를 위해 Kubernetes를 정리</p><p>최근 제품 관련하여 쿠버네티스 지식이 필요하여 세미나를 재시작 하여 팀원분이 발표한 자료를 바탕으로 내용을 추가/수정 하였다. <em>(2020/01/10)</em></p><a id="more"></a><h1 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h1><h2 id="애플리케이션과-그-실행에-필요한-Library-Binary-구성-파일-등을-패키지로-묶어-배포하는-것"><a href="#애플리케이션과-그-실행에-필요한-Library-Binary-구성-파일-등을-패키지로-묶어-배포하는-것" class="headerlink" title="애플리케이션과 그 실행에 필요한 Library, Binary, 구성 파일 등을 패키지로 묶어 배포하는 것"></a>애플리케이션과 그 실행에 필요한 Library, Binary, 구성 파일 등을 패키지로 묶어 배포하는 것</h2><ul><li><p>컨테이너로 불리는 이유는 프로세스들을 컨테이너화 하여 같은 리눅스 호스트를 쓰지만 격리되어 운영하기 때문</p><ul><li>프로세스를 격리하는 방법으로는 리눅스에서 컨트롤 그룹 <em>Cgroups</em> 과 리눅스 네임스페이스를 이용한 LXC <em>(LInuX Containers)</em></li></ul></li><li><p>운영체제 레벨 가상화</p><p><img src="/image/containers.png" alt=""></p><ul><li>별도의 운영체에서 프로세스가 실행되는 가상머신과 달리 컨테이너에서 실행하는 프로세스는 호스트의 운영체제 내부에서 실행하는 구조</li></ul><p><img src="/image/containers_overhead.png" alt=""></p><ul><li>훨씬 가볍고 운영체제 커널을 공유하며 시작이 빠름</li><li>운영체제 전체 부팅보다 메모리를 덜 사용</li></ul></li></ul><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>Docker는 컨테이너 기술 중 하나로 여러 컴퓨터에 쉽게 이식 가능하게 하는 시스템</p><p><img src="/image/docker.png" alt=""></p><ul><li>Docker 파일을 생성하여 *”어떤 SW를 컨테이너에 담아 구동할 것이다”* 명시하고 빌드</li><li>이후 docker image에 맞게 docker container 위에 생성</li></ul><h1 id="Kubernetes-K8s"><a href="#Kubernetes-K8s" class="headerlink" title="Kubernetes (K8s)"></a>Kubernetes <em>(K8s)</em></h1><ul><li>오픈소스 컨테이너 클러스터 관리 도구</li><li>Declarative Orchestration</li><li>단순 실행이 아닌 컨테이너의 실행 스케쥴 관리<ul><li>컨테이너 배치, 스케일링, 운영 자동화 관리</li></ul></li><li>Docker와 Kubernetes 관계<ul><li>Docker : 컨테이너 운송 (빌딩 블록)</li><li>Kubernetes : 컨테이너 운송을 어우르는 물류 시스템</li></ul></li></ul><h1 id="Master-amp-Node"><a href="#Master-amp-Node" class="headerlink" title="Master &amp; Node"></a>Master &amp; Node</h1><p><img src="/image/k8s-master_node.png" alt="Master &amp; Node"></p><ul><li><p>클러스터 전체를 관리하는 Master와 컨테이너가 배포되는 머신 <em>(가상 or 물리적 머신)</em> 인 Node로 </p></li><li></li></ul><h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><ul><li>관리자만 접속하여 보안 설정이 필요</li><li>마스터 다운이 발생하면 클러스터 관리에 장애가 생기므로 보통 3대로 구성하여 클러스터 구성<ul><li>소규모 환경에서는 마스터와 노드를 분리하지 않고 같은 서버에 구성</li></ul></li><li>관리의 측면도 있지만 클러스터 전체 리소스 배분을 위해 파드를 띄울 수 있게 설정이 가능 <em>(taint)</em></li></ul><h3 id="Master-component"><a href="#Master-component" class="headerlink" title="Master component"></a>Master component</h3><p><img src="/image/k8s-node.png" alt=""></p><p><code>API server</code></p><ul><li>kubectl 요청 및 내부 모듈의 요청 처리</li><li>권한 체크를 통한 요청 허용 및 거부</li><li>실제로는 key-value로 저장된 Etcd에 저장된 데이터를 토대로 조회</li><li>RESTful API 제공</li></ul><p><code>Etcd</code></p><ul><li>Kubernetes cluster의 DB 역할을 하는 서버로 설정값이나 cluster 상태를 저장</li><li>etcd라는 분산형 key/value 스토어 오픈소스 이용</li><li>Etcd 백업을 통해 클러스터 상태 복구가 가능</li><li><strong>API 서버와만 통신</strong></li></ul><p><code>kube scheduler</code></p><ul><li>할당이 필요한 Pod를 여러 조건(source, label)에 따라 적절한 노드에 할당해주는 모듈</li></ul><p><code>kube controller-manager</code></p><ul><li>K8s 대부분의 object <em>(Pod, ReplicaSet)</em> 상태 관리</li></ul><p><code>Cloud controller-manager</code></p><ul><li>AWS, GCE, Azure 등의 클라우드에 특화된 모듈</li><li>노드 추가 및 삭제, 로드 밸런서와 볼륨 연결 기능</li></ul><h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2><ul><li>Pod를 생성하고 네트워크와 볼륨을 설정</li><li>실제 컨테이너가 생성되는 서버<ul><li>각 서버에 라벨을 붙여 사용목적에 따라 나눌 수 있음</li></ul></li></ul><h3 id="Node-component"><a href="#Node-component" class="headerlink" title="Node component"></a>Node component</h3><p><img src="/image/k8s-node.png" alt=""></p><p><code>kubelet</code></p><ul><li>노드에 배포되는 에이전트로<ul><li>노드에 할당한 Pod 생명주기 관리</li><li>Pod 안 컨테이너 상태를 체크하고 주기적으로 Master에 전달</li></ul></li><li>Master의 API서버와 통신 및 노드가 수행해야 할 명령 수행</li></ul><p><code>kube-proxy</code></p><ul><li>kubelet이 pod를 관리한다면 kube-proxy는 Pod로 연결되는 네트워크를 관리 (네트워크 트래픽 분산)</li></ul><h1 id="K8s-Object"><a href="#K8s-Object" class="headerlink" title="K8s Object"></a>K8s Object</h1><p>Kubernets는 상태를 관리하기 위한 대상을 Object라 칭하며 크게 기본 오브젝트와 컨트롤러로 구분</p><h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><ul><li>Kubernetes의 <code>최소 실행 단위</code></li><li>Kubernetes는 컨테이너를 개별적으로 배포하는 것이 아니라 <code>Pod 단위로 배포</code></li><li>항상 같은 Node 위에서 실행되어야 하는 컨테이너들<ul><li>Pod 내 <code>네트워크 환경(IP, Port)</code>과 <code>디스크(Volume) 공유</code><ul><li>A Container(Port 8080)와 B Container(Port 7001)가 하나의 Pod로 배포되었을때, localhost를 통해 통신이 가능</li><li>디스크를 공유하고 있기 때문에 다른 두 성격의 컨테이너를 배포할 때 타 컨테이너의 파일을 읽을 수 있음</li></ul></li><li>YAML / JSON 형식으로 선언(config)</li></ul></li><li>Volume<ul><li>Container 재시작에 상관없이 파일을 영구적으로 저장해야하는 스토리지</li><li>Container의 외장 디스크라 생각하고, Pod이 기동할 때 컨테이너에서 마운트해 사용</li></ul></li></ul><p><img src="/image/k8s-pod.png" alt=""></p><h2 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h2><ul><li><p>Pod를 여러 개 복제하여 관리하는 오브젝트</p></li><li><p>Pod를 생성하고 개수를 유지하려면 ReplicaSet 오브젝트를 사용해야함</p><ul><li>복제 수, 레이블, 생성할 Pod의 템플릿 포함</li></ul></li><li><p>직접적으로 사용하기 보단 <strong>Deployment</strong> 등 다른 오브젝트에 의해 사용되는 경우가 많음)</p><p><img src="/image/k8s-replicaset.png" alt=""></p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://bcho.tistory.com/1256?category=731548" target="_blank" rel="noopener">https://bcho.tistory.com/1256?category=731548</a></li><li><a href="https://www.slideshare.net/ext/devfair-kubernetes-101?qid=5ea32175-424b-4cda-b7b8-ccc96f01e7a5&v=&b=&from_search=7" target="_blank" rel="noopener">(https://www.slideshare.net/ext/devfair-kubernetes-101?qid=5ea32175-424b-4cda-b7b8-ccc96f01e7a5&amp;v=&amp;b=&amp;from_search=7</a></li><li><a href="https://kubernetes.io/docs/concepts/architecture/cloud-controller/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/architecture/cloud-controller/</a></li></ol><hr><p>2019.09.06 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/cloud-introduction_to_kubernetes/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Etc] Sebastian Ruder Interview</title>
      <link>https://jx2lee.github.io/etc-sebastian_interview/</link>
      <guid>https://jx2lee.github.io/etc-sebastian_interview/</guid>
      <pubDate>Sun, 18 Aug 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Sebastian Ruder 의 인터뷰를 정리하였다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;세바스찬 루더&lt;ul&gt;
&lt;li&gt;github : (&lt;a href=&quot;https://github.com/sebastianruder&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/sebastianruder&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;blog   : (&lt;a href=&quot;http://ruder.io/#open&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://ruder.io/#open&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;핫한 NLP 연구자&lt;/li&gt;
&lt;li&gt;AYLIEN에서 리서치 사이언티스트로 일하며 현재 PhD 학생
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Sebastian Ruder 의 인터뷰를 정리하였다</p><ul><li>세바스찬 루더<ul><li>github : (<a href="https://github.com/sebastianruder" target="_blank" rel="noopener">https://github.com/sebastianruder</a>)</li><li>blog   : (<a href="http://ruder.io/#open" target="_blank" rel="noopener">http://ruder.io/#open</a>)</li><li>핫한 NLP 연구자</li><li>AYLIEN에서 리서치 사이언티스트로 일하며 현재 PhD 학생<a id="more"></a></li></ul></li></ul><h1 id="QnA"><a href="#QnA" class="headerlink" title="QnA"></a>QnA</h1><h2 id="NLP-초심자들에게-조언을-해줄-수-있겠는가"><a href="#NLP-초심자들에게-조언을-해줄-수-있겠는가" class="headerlink" title="NLP 초심자들에게 조언을 해줄 수 있겠는가?"></a>NLP 초심자들에게 조언을 해줄 수 있겠는가?</h2><p>NLP-progress(<a href="http://nlpprogress.com/" target="_blank" rel="noopener">http://nlpprogress.com/</a>) 같은 곳에서 <strong>관심이 가는 분야</strong>를 찾아라. 만일 당신이 리서치에 관심이 있다면, 다른 사람이 하지 않은 <strong>특정한 세부 주제</strong>를 찾아보도록 노력하라. 예를 들어 감정 분석이라면 영화 리뷰 분석을 하지 말고 대화를 분석하라. 요약이라면 뉴스 기사를 요약하지 말고 의학 저널을 요약하라. 그 분야와 관련된 논문들을 읽고, 가장 첨단의 기술이 어떠한 지를 이해하라. 당신이 직접 돌려볼 수 있는 <strong>오픈 소스 구현이 있는 분야이면 더 좋다.</strong></p><p>어떻게 이러한 작업이 돌아가는지를 잘 알게 되었을 때, <strong>연구를 위해서 그 논문에서 당신을 놀라게한 점이 있었는지를 잘 생각해보아라.</strong> 그 모델이 어떠한 오류를 저질렀는 지를 이해하려 노력하고, 어떻게 하면 이를 줄여볼 수 있을지 생각하라. 어떠한 모델이 특정한 종류의 정보를 잘 잡아 내는 지를 측정하는 <strong>오류 절제 평가를 해보거나 합성 모델을 사용</strong>해보면 좋다.</p><p>만일 당신이 그 문제를 더 도전적으로, 혹은 현실적으로 해결해볼 수 있는 아이디어가 있다면, <strong>데이터 셋을 만들고 현존하는 모델에 적용</strong>해보라. 그리고 다시 그 <strong>데이터 셋을 당신의 언어로 만들어보라. 그리고 그 모델이 역시 잘 작동하는 지를 확인</strong>하라.</p><h2 id="흔히-NLP-분야가-컴퓨터-비전에-비해-뒤쳐졌다고들-한다-현재의-상황에-대해서-어떻게-생각하는가-NLP-현업자로-뛰어들기에-좋은-시기인가"><a href="#흔히-NLP-분야가-컴퓨터-비전에-비해-뒤쳐졌다고들-한다-현재의-상황에-대해서-어떻게-생각하는가-NLP-현업자로-뛰어들기에-좋은-시기인가" class="headerlink" title="흔히 NLP 분야가 컴퓨터 비전에 비해 뒤쳐졌다고들 한다. 현재의 상황에 대해서 어떻게 생각하는가? NLP 현업자로 뛰어들기에 좋은 시기인가?"></a>흔히 NLP 분야가 컴퓨터 비전에 비해 뒤쳐졌다고들 한다. 현재의 상황에 대해서 어떻게 생각하는가? NLP 현업자로 뛰어들기에 좋은 시기인가?</h2><p>나는 지금이 NLP에 뛰어들기 좋은 시기라 생각한다. 수 년전과 비교하면 성숙기에 접어들었다고 본다. 단순히 워드 임베딩이나 기존에 나온 모델들을 사용하는 것에 제한되지 않고, <strong>다양한 부품들로 당신만의 모델을 만들 수 있는 것</strong>이다. 이를 테면 다른 신경망 층들, 사전 학습된 표현들, 부가적인 로스의 사용 등이 있다. 또한 POS 태깅, 감정 분석 등 고전적인 문제들이 거의 해결되고 있다는 커뮤니티의 반응도 있다. 그러므로 우리는 더 어려운 문제들에서 발전을 이루어야만 한다. 이를테면 <strong>“진짜” 자연어를 이해하고 생성해내는 일반화된 모델</strong>이 있다.</p><p>이러한 문제들을 풀기 위해선 나는 새로운 사람들의 관점과 아이디어들이 필요하다고 생각한다. 덧붙여 우리는 이제 분류나 문장 라벨링 등의 작업을 꽤 높은 정확도로 수행하는 모델들을 학습할 수 있으니, 이러한 모델들을 다른 언어에 적용해 볼 수 있는 기회가 많이 있다. 만일 당신이 또 다른 언어의 사용자라면, 당신은 다른 사람들이 모델 학습과 평가에 사용할 수 있는 <strong>데이터 셋을 만드는 것</strong> 만으로도 큰 변화를 만들어 낼 수 있을 것이다.</p><h2 id="DL-ML-분야에서-많은-job-들이-석박사나-연구-경험을-요구한다-머신-러닝을-커리어-패스로-고려하는-독자들을-위해서-연구-경험이-반드시-필요하다고-생각하는가"><a href="#DL-ML-분야에서-많은-job-들이-석박사나-연구-경험을-요구한다-머신-러닝을-커리어-패스로-고려하는-독자들을-위해서-연구-경험이-반드시-필요하다고-생각하는가" class="headerlink" title="DL/ML 분야에서 많은 job 들이 석박사나 연구 경험을 요구한다. 머신 러닝을 커리어 패스로 고려하는 독자들을 위해서, 연구 경험이 반드시 필요하다고 생각하는가?"></a>DL/ML 분야에서 많은 job 들이 석박사나 연구 경험을 요구한다. 머신 러닝을 커리어 패스로 고려하는 독자들을 위해서, 연구 경험이 반드시 필요하다고 생각하는가?</h2><p>나는 리서치 경험이 당신이 특정 모델에 대해서 잘 알고 있는지, 창의적인지, 새로운 해결방안을 생각해 낼 수 있을 만큼 혁신적인지를 측정하는 좋은 지표라고 생각한다. 그러나 이러한 스킬들을 익히기 위해서 <strong>PhD나 리서치 펠로우십을 취득할 필요는 없다.</strong> 능동적으로 움직이고, 흥미있는 분야에 대해서 배우고 문제를 해결하고, 모델을 개선하고, 당신의 경험을 글로 쓰는 것은 이러한 스킬들을 키우고 증명하는 좋은 방법이다. 현재의 ML 환경에서 당신은 완전히 새로운 문제를 풀도록 요구되어지지 않는다. <strong>ML이나 데이터 사이언스 대회에 참여하는 것도 비슷하게 당신이 ML 모델을 어떻게 실용적으로 적용하는지를 증명하는데 도움</strong>이 된다.</p><h2 id="리서치-분야의-폭발적인-성장을-놓고-봤을-때-가장-첨단의-기술들에-대해서-어떻게-따라갈-수-있는가"><a href="#리서치-분야의-폭발적인-성장을-놓고-봤을-때-가장-첨단의-기술들에-대해서-어떻게-따라갈-수-있는가" class="headerlink" title="리서치 분야의 폭발적인 성장을 놓고 봤을 때, 가장 첨단의 기술들에 대해서 어떻게 따라갈 수 있는가?"></a>리서치 분야의 폭발적인 성장을 놓고 봤을 때, 가장 첨단의 기술들에 대해서 어떻게 따라갈 수 있는가?</h2><p>나는 매일 arXiv의 업데이트를 확인한다. 관련 논문들을 내 읽기 목록에 추가한 뒤에 한번에 읽는다. 제프 딘은 최근 Deep Learning Indaba에서 <strong>열 개 논문의 abstract를 읽는 것이 한 개 논문을 깊이 있게 읽는 것 보다 낫다고 한다.</strong> 왜냐면 언제든 되돌아가서 특정 논문을 깊이 있게 읽는 것은 가능하기 때문이다.”고 말했다. 그의 말에 동의하며, <strong>최대한 넓게 읽어라.</strong> 그래서 당신이 목록화 할 수 있고 나중에 영감을 받을 수 있도록 하라. 좋은 문서 관리 시스템을 갖는 것도 핵심이다. 나는 Mendeley를 사용해왔다. 최근에는 Arxiv Sanity Preserver(<a href="http://www.arxiv-sanity.com/recommend" target="_blank" rel="noopener">http://www.arxiv-sanity.com/recommend</a>) 를 사용한다.</p><h2 id="어떻게-시작하게-되었는가-특히-왜-딥-러닝과-NLP에-관심을-갖게-되었는가"><a href="#어떻게-시작하게-되었는가-특히-왜-딥-러닝과-NLP에-관심을-갖게-되었는가" class="headerlink" title="어떻게 시작하게 되었는가? 특히 왜 딥 러닝과 NLP에 관심을 갖게 되었는가?"></a>어떻게 시작하게 되었는가? 특히 왜 딥 러닝과 NLP에 관심을 갖게 되었는가?</h2><p>고등학생 때부터 언어와 수학에 관심이 있었고, 여러 대회에 참가했었다. 내 학업을 위해서 나는 수학의 논리와 언어의 창의성을 결합하고 싶었다. 그러나 그런 분야가 존재하는 지 몰랐다. 그 떄 전산 언어학이라는, 컴퓨터 과학과 언어학이 적절하게 교차하는 분야를 접하게 되었다. 그래서 독일 대학에서 전산 언어학 학사를 땄다. 학부생 시절에 머신 러닝을 접하게 되었고, 인턴쉽과 온라인 강의들을 통해 최대한 지식을 습득했다. word2vec에 대해 들은건 학부를 마친 2015년이었다. PhD를 시작하면서 딥 러닝에 대해 알게 되었고, 이 분야에 더욱 흥미를 가지게 되었다.</p><h2 id="산업과-리서치-중에서-리서치를-택한-이유가-있는가"><a href="#산업과-리서치-중에서-리서치를-택한-이유가-있는가" class="headerlink" title="산업과 리서치 중에서 리서치를 택한 이유가 있는가?"></a>산업과 리서치 중에서 리서치를 택한 이유가 있는가?</h2><p>졸업 이후에 스타트업에서 산업 경험을 쌓고자 했다. PhD는 내가 항상 꿈꾸던 것이었지만, 그 당시에는 심각하게 생각하지 않았다. 듀블린의 NLP 스타트업 Aylien에서 일하면서 그들은 나에게 고용이 보장된 PhD 프로그램을 소개해 주었고, 나에게 잘 들어맞는다고 생각했다. 회사에서 일하면서 동시에 연구를 하는 것은 매우 힘들었지만, 결국 나에게 돌아오는 것은 많았다. 가장 중요하게도, 내 회사와 잘 맞았다.</p><h2 id="지금까지-연구자로-3년간-일해왔다-이-기간동안-당신의-최애-프로젝트는-무엇이었는가"><a href="#지금까지-연구자로-3년간-일해왔다-이-기간동안-당신의-최애-프로젝트는-무엇이었는가" class="headerlink" title="지금까지 연구자로 3년간 일해왔다. 이 기간동안 당신의 최애 프로젝트는 무엇이었는가?"></a>지금까지 연구자로 3년간 일해왔다. 이 기간동안 당신의 최애 프로젝트는 무엇이었는가?</h2><p>배움의 관점에서는 <strong>잘 알지 못하는 분야에 뛰어드는 것</strong>과 <strong>논문들을 읽는 것</strong>, 그리고 <strong>훌륭한 사람들과 협업</strong>하는 것이다. 이러한 맥락에서 코펜하겐 대학에서 진행했던 multi-task learning 프로젝트가 굉장히 자극이 되는 경험이었다.<br>영향력의 관점에서는 fastai, 제레미 (fast ai 창립자)와 협업하면서 그들이 어떻게 우리의 언어 모델을 유용하게 사용하는지를 본 것이다.</p><h2 id="당신은-매우-훌륭한-블로그를-관리했다-기술적인-글들을-효과적으로-쓸-수-있는-팁들이-있는가"><a href="#당신은-매우-훌륭한-블로그를-관리했다-기술적인-글들을-효과적으로-쓸-수-있는-팁들이-있는가" class="headerlink" title="당신은 매우 훌륭한 블로그를 관리했다. 기술적인 글들을 효과적으로 쓸 수 있는 팁들이 있는가?"></a>당신은 매우 훌륭한 블로그를 관리했다. 기술적인 글들을 효과적으로 쓸 수 있는 팁들이 있는가?</h2><p>나는 내 자신이 특정한 주제에 대해서 더 잘 이해하기 위해서 블로그를 쓸 때 아주 좋았던 경험이 있다. 만일 당신이 어떤 주제에 대하여 많은 리서치를 하거나 직관을 얻고 싶다면, <strong>포스트를 작성하는 것을 고려</strong>해보아라. 그리고 이것은 훗날 누군가의 학습을 더욱 빠르게 도와줄 것이다. 연구 논문에서는 지면이 부족하여 충분히 글로써 설명해내지 못하는 측면들이 있다. 블로그 포스팅은 기술들을 더 접근하기 쉽게 설명하는 아주 좋은 방법이다.</p><p><strong>블로그의 좋은 점은 완벽하지 않아도 좋다</strong>는 점이다. 당신은 이를 커뮤니케이션 능력을 향상시키기 위해 사용해도 좋고, 당신의 아이디어에 대한 피드백을 얻기 위해 사용해도 좋다. 글을 쓰는 관점에서는, 가장 중요한 것은 명확하기 위해 노력해야한다는 것이다. <strong>애매 모호하지 않고 데이터가 보여주는 것에 대해서만 써라.</strong> 만일 의심스럽다면 명확하게 no라고 말하라.</p><p>당신의 초고에 대해서도 당신의 친구들이나 동료들의 피드백을 들어라. <em>100% 완벽하게 만들려고 애쓰지 말아라.</em> 그러나 <strong>만족할 만한 수준까지는 끌어올려야한다.</strong> 공개 버튼을 누를 때 걱정이되는 것은 당연한 것이니 도망치지 말라. 무언가를 퍼블리싱 한다는 것은 장기적인 관점에서 분명 가치가 있다.<br></p><h2 id="딥-러닝이-어려운-분야라는-생각에-시작하기-망설이는-초보자들을-위해-해주고-싶은-말은"><a href="#딥-러닝이-어려운-분야라는-생각에-시작하기-망설이는-초보자들을-위해-해주고-싶은-말은" class="headerlink" title="딥 러닝이 어려운 분야라는 생각에 시작하기 망설이는 초보자들을 위해 해주고 싶은 말은?"></a>딥 러닝이 어려운 분야라는 생각에 시작하기 망설이는 초보자들을 위해 해주고 싶은 말은?</h2><p>아무도 당신에게 넌 할 수 없어라고 말할 수 없다. 온라인 수업들을 듣고 이해하라. 기본적인 지식들에 익숙해지면 시간이 될 때마다 <strong>영감을 위해 논문</strong>들을 읽어라. <strong>흥미로운 분야를 선택</strong>하고, <strong>라이브러리를 선택하고 진행</strong>해보라. 당신이 의미있는 문제를 풀기 위해서는 반드시 거대한 컴퓨터가 있어야 된다는 생각을 버려라. 특히 NLP 분야에서는 <em>라벨링 된 예시의 수가 적은 문제</em>들이 많이 있다. 당신이 하고 있고 배우고 있는 것에 대해서 써라.</p><p><em>비슷한 관심사가 있는 사람들을 만나라.</em> 커뮤니티에 참여하고, 특히 fast ai는 좀 쩐다. 트위터를 하라. 트위터는 훌륭한 ML 커뮤니티이다. 당신은 탑 연구자들로부터 이메일보다 빨리 답장을 받을 수도 있다. 멘토를 찾으라. 만일 누군가에게 조언을 구하기 위해 이메일을 쓴다면, 그들이 바쁘다는 것을 고려하라. 존중하고 다른 이들을 도와라. 칭찬을 많이 하고, 비평할 때는 조심스럽게 하라.</p><h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><hr><p>2019.08.09 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/etc-sebastian_interview/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Etc] How to Read Research Papers</title>
      <link>https://jx2lee.github.io/etc-how_to_read_research/</link>
      <guid>https://jx2lee.github.io/etc-how_to_read_research/</guid>
      <pubDate>Thu, 08 Aug 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;Siraj Raval의 research paper를 효율적으로 보는 방법에 대해 설명한다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>Siraj Raval의 research paper를 효율적으로 보는 방법에 대해 설명한다</p><a id="more"></a><p><code>Siraj</code>는 다행히 학위 소지자가 아니다. 즉, 학위 소지자가 아니어도 충분히 research 논문을 이해할 수 있고 접할 수 있다. <code>Siraj</code>는 다양한 분야의 논문을 즐겨 읽는다고 한다.</p><p><code>Siraj</code>는 다음과 같이 세 단계 프로세스로 논문을 이해하고 읽는다고 한다. 이 방식으로 일주일에 약 10-20편의 논문을 소화한다고 한다. 가장 중요한 것은 <strong>포기하지 않는 마음가짐</strong>이며, 이해가 되지 않는 부분은 <strong>커뮤니티에서 discussion</strong>해야 한다고 말한다.</p><h1 id="3-PASS-Approach"><a href="#3-PASS-Approach" class="headerlink" title="3-PASS Approach"></a>3-PASS Approach</h1><h2 id="논문을-가볍게-파악"><a href="#논문을-가볍게-파악" class="headerlink" title="논문을 가볍게 파악"></a>논문을 가볍게 파악</h2><ul><li>논문 제목 / Abstract 먼저 읽기</li><li><code>Introduction</code> 신중히 읽기</li><li>Section / Sub-section의 경우 <strong>타이틀만 읽고 PASS</strong></li><li><code>Conclusion</code> 신중히 읽기<ul><li>이외 수학적인 부분은 완전히 무시</li><li>1단계에서는 수학적인 부분은 PASS</li></ul></li><li>googling을 통해 다른 사람들이 리뷰한 내용을 살펴보고 내 의견과 비교해보기 (<code>using reddit</code>)</li></ul><h2 id="High-level-이해"><a href="#High-level-이해" class="headerlink" title="High-level 이해"></a>High-level 이해</h2><ul><li>1단계보다 더 <code>deep</code>하게 읽기</li><li>문장을 모두 이해할 수 있도록</li><li>수식을 정확히 이해하지는 않으나 원리는 이해하고 넘어가기</li><li>소스코드가 있다면 소스 및 문서를 읽어보고 코드 실행 및 재현해보기</li></ul><h2 id="수식을-통해-이해"><a href="#수식을-통해-이해" class="headerlink" title="수식을 통해 이해"></a>수식을 통해 이해</h2><ul><li>지금까지 이해한 내용을 문서로 정리하여 누군가에게 설명이 가능할 정도로 정리하기</li><li>수식을 스스로 풀어보고 <strong>완벽히</strong> 이해하기</li><li>수식의 내용을 스스로 프로그래밍하며 <strong>수식 완벽히</strong> 이해하기</li></ul><h1 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h1><p>정말 어려운 과정이지만 정말 효과적인 방법인 것 같다. 특히, 우리가 무심코 넘어가는 <strong>수식 완벽히 이해</strong>하기는 처음에는 어렵고 귀찮을 수 있지만 논문을 정확히 이해하고 이를 활용할 수 있는 지식을 쌓을 수 있을 것 같다. 이러한 프로세스도 도움이 되지만 <strong>나만의 논문 읽는 노하우</strong>를 익히고 싶다.</p><hr><p>2019.08.09 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/etc-how_to_read_research/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] 클로저가 변수 스코프와 상호 작용하는 방법</title>
      <link>https://jx2lee.github.io/python-better_way_15/</link>
      <guid>https://jx2lee.github.io/python-better_way_15/</guid>
      <pubDate>Wed, 07 Aug 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;클로저가 변수 스포크와 상호 작용하는 방법에 대해 알아본다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>클로저가 변수 스포크와 상호 작용하는 방법에 대해 알아본다.</p><a id="more"></a><p>숫자 list를 정렬할 때 일정 숫자들을 먼저 정렬하고자 한다. 이는 <code>사용자 인터페이스를 표현</code>하거나, <code>중요 메세지 또는 예외 이벤트를 먼저 보여줄 때</code> 유용하다. 일반적인 방법으로는 list의 sort method에 helper function을 key 변수로 넘기는 것이다. helper function의 return 값은 숫자를 정렬하는 사용된다.</p><p>다음 코드를 확인해보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sort_priority</span><span class="params">(values, group)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> group:</span><br><span class="line">      <span class="keyword">return</span> (<span class="number">0</span>, x)</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>, x)</span><br><span class="line"></span><br><span class="line">numbers = [<span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">6</span>]</span><br><span class="line">group = &#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>&#125;</span><br><span class="line">sort_priority(numbers, group)</span><br><span class="line">print(numbers)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</span><br></pre></td></tr></table></figure><p>위 함수가 동작하는 이유는 다음과 같다.</p><ul><li><strong>python은 closure를 지원</strong>, closure란 자신이 정의된 스코프에 있는 변수를 참조하는 함수다. 이 때문에 <strong>helper function이 sort_priority의 group에 접근</strong>할 수 있다.</li></ul><p><strong>summary</strong></p><ul><li>None을 반환하는 함수는 None 이나 다른 값이 조건식에서 False로 평가되기 때문에 쉽게 오류를 범할 수 있다.</li><li>특별한 상황을 알릴 때는 None 대신 예외를 일으키자.</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.08.08 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_15/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Python] None을 반환하기보다 예외 발생</title>
      <link>https://jx2lee.github.io/python-better_way_14/</link>
      <guid>https://jx2lee.github.io/python-better_way_14/</guid>
      <pubDate>Mon, 05 Aug 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;함수를 이용해 None을 반환하기보다는 예외를 일으키는 방법에 대해 알아본다&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>함수를 이용해 None을 반환하기보다는 예외를 일으키는 방법에 대해 알아본다</p><a id="more"></a><p>파이썬 프로그래머들은 보통 None값에 특별한 의미를 부여하는 경우가 있다. 예를 들어 나눗셈을 수행하는 헬퍼함수를 생각해보자. 0으로 나누는 경우는 존재하지 않기 때문에 None을 반환하는 게 자연스럽다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">divide</span><span class="params">(a,b)</span>:</span></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">return</span> a / b</span><br><span class="line">  <span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>반환 값을 다음과 같이 해석할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = divide(x, y)</span><br><span class="line"><span class="keyword">if</span> result <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">  print(<span class="string">'Invalid inputs'</span>)</span><br></pre></td></tr></table></figure><p>하지만 <code>분자가 0, 즉 나누는 숫자를 0으로 하면?</code><br><br>이런 경우 if문으로 결과를 평가할 때 문제가 될 수 있다.조건을 None이 아닌 False로 검사할 수 있기 때문이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x, y = <span class="number">0</span>, <span class="number">5</span></span><br><span class="line">result = divide(x, y)</span><br><span class="line"><span class="keyword">if</span> no result:</span><br><span class="line">  print(<span class="string">'Invalid inputs'</span>) <span class="comment"># wrong!</span></span><br></pre></td></tr></table></figure><p>위 예는 <code>None에 특별한 의미를 부여할 때</code> 파이썬 코드에서 흔히 하느 실수라고 한다.<br><br>이러한 실수를 방지하기 위한 방법은 두 가지로 설명한다.</p><h1 id="반환-값을-두-개로-나눠-튜플에-담자"><a href="#반환-값을-두-개로-나눠-튜플에-담자" class="headerlink" title="반환 값을 두 개로 나눠 튜플에 담자"></a>반환 값을 두 개로 나눠 튜플에 담자</h1><p>튜플의 첫 value는 성공/실패 여부를 알려준다. 두 번째 값은 계산된 실제 결과다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">divide</span><span class="params">(a, b)</span>:</span></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span>, a / b</span><br><span class="line">  <span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">success, result = divide(x, y)</span><br><span class="line"><span class="keyword">if</span> no success:</span><br><span class="line">  print(<span class="string">'Invalid inputs'</span>)</span><br></pre></td></tr></table></figure><p>허나 이 방법은 튜플 첫 값을 쉽게 무시할 수 있다(<code>가령 _을 이용해 무시 가능</code>).<br><br>겉보기에느 잘못된 것 같지 않지만 <code>그냥 None을 반환하는 것만큼 나쁘다.</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">_, result = divide(x, y)</span><br><span class="line"><span class="keyword">if</span> no result:</span><br><span class="line">  print(<span class="string">'Invalid inputs'</span>)</span><br></pre></td></tr></table></figure><h1 id="절대로-None을-반환하지-말자-gt-호출-함수에서-예외-일으키기"><a href="#절대로-None을-반환하지-말자-gt-호출-함수에서-예외-일으키기" class="headerlink" title="절대로 None을 반환하지 말자! -&gt; 호출 함수에서 예외 일으키기"></a>절대로 None을 반환하지 말자! -&gt; 호출 함수에서 예외 일으키기</h1><p>저자는 <strong>None을 절대로 반환하지 않는</strong> 방법을 추천한다. 즉, <strong>호출하는 함수 내에서 예외를 일으켜</strong><br><br><code>ZeroDivisionError을 ValueError</code>로 변경하는 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">divide</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> a / b</span><br><span class="line">    <span class="keyword">except</span> ZeroDivisionError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid inputs'</span>) <span class="keyword">from</span> e</span><br></pre></td></tr></table></figure><p>위와 같이 함수를 정의하면 함수의 반환 값을 <code>조건식으로 검사할 필요가 없다.</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x, y = <span class="number">0</span>, <span class="number">10</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = divide(x, y)</span><br><span class="line"><span class="keyword">except</span> ValueError:</span><br><span class="line">    print(<span class="string">'Invalid inputs'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Result is %.1f'</span> % result)</span><br></pre></td></tr></table></figure><h1 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h1><ul><li>None을 반환하는 함수는 None 이나 다른 값이 조건식에서 False로 평가되기 때문에 쉽게 오류를 범할 수 있다.</li><li>특별한 상황을 알릴 때는 None 대신 예외를 일으키자.</li></ul><p>참조 : (<a href="http://www.yes24.com/Product/goods/25138160" target="_blank" rel="noopener">http://www.yes24.com/Product/goods/25138160</a>)</p><hr><p>2019.08.07 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/python-better_way_14/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Database] Connect to Tibero using Python</title>
      <link>https://jx2lee.github.io/database-connect_to_tibero_using_python/</link>
      <guid>https://jx2lee.github.io/database-connect_to_tibero_using_python/</guid>
      <pubDate>Thu, 01 Aug 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;p&gt;docker image로 띄운 Python 에서 Tibero 에 접근하는 방법을 다룬다.&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<p>docker image로 띄운 Python 에서 Tibero 에 접근하는 방법을 다룬다.</p><a id="more"></a><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="python-은-이미-설치된-것을-전제"><a href="#python-은-이미-설치된-것을-전제" class="headerlink" title="python 은 이미 설치된 것을 전제"></a>python 은 이미 설치된 것을 전제</h2><h2 id="iodbc"><a href="#iodbc" class="headerlink" title="iodbc"></a>iodbc</h2><ul><li>Container에 tibero client가 설치되어 있다고 가정<ul><li>tibero client가 없다면 서버에 있는 tibero6 복사</li><li>tbdsn.tbr 에 호스트를 참조하고자하는 Tibero ip로 변경</li><li>$TB_HOME/client/lib(또는 $TB_HOME/client/lib32) 디렉터리에 libtbodbc.so 파일이 존재하는지 확인</li></ul></li><li><a href="http://iodbc.org" target="_blank" rel="noopener">http://iodbc.org</a> 에서 다운로드</li></ul><p>tar 파일을 설치 디렉토리에 옮긴 후 make를 이용해 build 한다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ./configure --prefix=/app/odbc/iodbc --<span class="built_in">disable</span>-gui</span><br><span class="line">$ make</span><br><span class="line">$ make install</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">$ file /app/odbc/lib/libtbodbc.so</span><br><span class="line">$ file /app/odbc/lib/libiodbcinst.so.2.1.18</span><br></pre></td></tr></table></figure><h2 id="unixODBC-devel"><a href="#unixODBC-devel" class="headerlink" title="unixODBC-devel"></a>unixODBC-devel</h2><p><code>apt-get install unixodbc-dev</code></p><h1 id="profile"><a href="#profile" class="headerlink" title="~/.profile"></a>~/.profile</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Tibero RDBMS 6 Client ENV ##</span></span><br><span class="line"><span class="built_in">export</span> TB_HOME=/app/tibero6</span><br><span class="line"><span class="built_in">export</span> TB_SID=tibero</span><br><span class="line"><span class="built_in">export</span> TB_PROF_DIR=<span class="variable">$TB_HOME</span>/bin/prof</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$TB_HOME</span>/bin:<span class="variable">$TB_HOME</span>/client/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$TB_HOME</span>/lib:<span class="variable">$TB_HOME</span>/client/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> TB_NLS_LANG=UTF8</span><br><span class="line"><span class="built_in">export</span> TBCLI_WCHAR_TYPE=UCS2</span><br><span class="line"></span><br><span class="line"><span class="comment">## IODBC ENV ##</span></span><br><span class="line"><span class="built_in">export</span> IODBC_HOME=/app/odbc/iodbc</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$IODBC_HOME</span>/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$IODBC_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h1 id="Set-DSN"><a href="#Set-DSN" class="headerlink" title="Set DSN"></a>Set DSN</h1><p><code>$HOME/odbc.ini</code> 파일을 아래와 같이 수정한다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[ODBC Data Sources]</span><br><span class="line">tibero6 = Tibero6 ODBC driver</span><br><span class="line">[ODBC]</span><br><span class="line">Trace = 1</span><br><span class="line">TraceFile = /tmp/odbc.trace</span><br><span class="line">[tibero6]</span><br><span class="line">Driver = /app/tibero6/client/lib/libtbodbc.so</span><br><span class="line">Description = Tibero6 ODBC Datasource</span><br><span class="line">SID = tibero156 <span class="comment"># tbdsn.tbr 파일에 설정한 DSN 정보</span></span><br><span class="line">User = erp</span><br><span class="line">Password = xxxxx</span><br></pre></td></tr></table></figure><p><code>isql</code>를 통해 접속이 되는지 확인하고 조회해본다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ isql -v tibero6</span><br><span class="line">+---------------------------------------+</span><br><span class="line">| Connected!                            |</span><br><span class="line">|                                       |</span><br><span class="line">| sql-statement                         |</span><br><span class="line">| <span class="built_in">help</span> [tablename]                      |</span><br><span class="line">| quit                                  |</span><br><span class="line">|                                       |</span><br><span class="line">+---------------------------------------+</span><br><span class="line">SQL&gt; select count(*) from BPRJT00T;</span><br><span class="line">+------------------------------------------------------+</span><br><span class="line">| COUNT(*)                                             |</span><br><span class="line">+------------------------------------------------------+</span><br><span class="line">| 56125                                                |</span><br><span class="line">+------------------------------------------------------+</span><br><span class="line">SQLRowCount returns 1</span><br><span class="line">1 rows fetched</span><br></pre></td></tr></table></figure><h1 id="py"><a href="#py" class="headerlink" title=".py"></a>.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyodbc</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># db connection</span></span><br><span class="line">    dbuser = <span class="string">'erp'</span></span><br><span class="line">    dbpw = <span class="string">'tibero'</span></span><br><span class="line"></span><br><span class="line">    conn = pyodbc.connect(<span class="string">'DSN=tibero6;UID='</span> + dbuser + <span class="string">';PWD='</span> + dbpw)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line"></span><br><span class="line">    stmt = <span class="string">"SELECT COUNT(*) FROM BPRJT00T;"</span></span><br><span class="line">    rows = cur.execute(stmt)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">        <span class="keyword">print</span> (row)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># db connection close</span></span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">    print(ex)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ff5f929d7f7f:~<span class="comment"># python3 test2.py </span></span><br><span class="line">(56125.0, )</span><br></pre></td></tr></table></figure><blockquote><p><em>.py 스크립트를 실행하면 정상적으로 연결되지만, Notebook을 이용하면 Data Source를 찾지 못한다는 에러를 뱉어낸다. 이는 추후에 해결하고 따로 포스팅 할 예정이다</em></p></blockquote><hr><p>2019.08.02 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/database-connect_to_tibero_using_python/#disqus_thread</comments>
    </item>
    
    <item>
      <title>[Machine Learning] Understanding Hyperparameter</title>
      <link>https://jx2lee.github.io/ml-introduction_to_grid_search/</link>
      <guid>https://jx2lee.github.io/ml-introduction_to_grid_search/</guid>
      <pubDate>Mon, 01 Jul 2019 15:00:00 GMT</pubDate>
      <description>
      
        &lt;h1 id=&quot;Hyperparameter-란&quot;&gt;&lt;a href=&quot;#Hyperparameter-란&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter 란?&quot;&gt;&lt;/a&gt;Hyperparameter 란?&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Wiki에 따르면 &lt;em&gt;학습이 시작되기 전 설정된 변수&lt;/em&gt; 라고 정의&lt;/li&gt;
&lt;li&gt;즉, 학습 이전 initialized variable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;학습 parameter는 크게 &lt;strong&gt;Model parameter&lt;/strong&gt; 와 &lt;strong&gt;Hyperparameter&lt;/strong&gt; 로 구분&lt;/p&gt;
      
      </description>
      
      
      <content:encoded><![CDATA[<h1 id="Hyperparameter-란"><a href="#Hyperparameter-란" class="headerlink" title="Hyperparameter 란?"></a>Hyperparameter 란?</h1><ul><li>Wiki에 따르면 <em>학습이 시작되기 전 설정된 변수</em> 라고 정의</li><li>즉, 학습 이전 initialized variable</li></ul><p>학습 parameter는 크게 <strong>Model parameter</strong> 와 <strong>Hyperparameter</strong> 로 구분</p><a id="more"></a><h1 id="Model-parameters"><a href="#Model-parameters" class="headerlink" title="Model parameters"></a>Model parameters</h1><p><strong>Model paramters</strong>는 ML model에 의해 학습할 데이터의 속성으로 모델이 학습됨과 동시에 학습하는 parameter를 의미한다. 예로 <strong>Weight</strong>과 <strong>Biases</strong>를 <strong>Model parameter</strong>라 부른다.</p><h1 id="Model-Hyperparameters"><a href="#Model-Hyperparameters" class="headerlink" title="Model Hyperparameters"></a>Model Hyperparameters</h1><p><strong>Model Hyperparameters</strong>는 ML model의 전체 학습 과정을 관리하는 속성이다. Model parameter과는 다르게 <em>학습 도중 변하지 않는</em>것이 특징이다.</p><ul><li>Learning Rate</li><li>Epochs</li><li>Hidden Layers(Units)</li><li>Activation functions</li></ul><p><a href="https://www.slideshare.net/AliceZheng3/evaluating-machine-learning-models-a-beginners-guide" target="_blank" rel="noopener">model_parameter</a></p><h1 id="Hyperparameter가-왜-필요한가"><a href="#Hyperparameter가-왜-필요한가" class="headerlink" title="Hyperparameter가 왜 필요한가?"></a>Hyperparameter가 왜 필요한가?</h1><p><strong>Hyperparamter</strong>는 training algorithm 동작을 직접 제어, 모델 성능에 중요한 영향을 미친다. “적절한 Hyperparameter 선택은 algorithm을 빛나게 만든다” (A good choice of hyperparameters can really make an algorithm shine) 이라는 말도 있다.<br>Hyperparameter가 중요한 이유는 예를 들어 Learning rate이 너무 낮게되면 모델 패턴을 놓칠 수 있고, 높으면 충돌이 발생할 수 있다. 즉 학습이 제대로 이루어지지 않을 수 있는 문제가 발생한다. 이에 적절한 Hyperparameter 선택은 다음과 같은 이점이 있다.</p><ul><li>효율적인 매개 변수 공간</li><li>여러 실험(experiment)들을 손쉬운 관리</li></ul><h1 id="Hyperparameters-최적화-기법-Optimisation-Techniques"><a href="#Hyperparameters-최적화-기법-Optimisation-Techniques" class="headerlink" title="Hyperparameters 최적화 기법 (Optimisation Techniques)"></a>Hyperparameters 최적화 기법 (Optimisation Techniques)</h1><p><strong>ML에서 최적의 Hyperparameter를 찾는 과정</strong>을 <strong>Hyperparameter optimisation</strong>이라 한다. 기법들은 크게 다음과 같다.</p><ul><li>Grid Search</li><li>Random Search</li><li>Bayesian Optimisation</li></ul><blockquote><p><em>20190702 기준으로는 Grid Search 만 다루고 나중에 시간이 된다면 나머지 기법도 정리할 예정이다</em></p></blockquote><h2 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h2><p><strong>Grid Search</strong>는 Hyperparameter 를 찾는 가장 전통적인 방법이다. 모든 조합을 고려해 <strong>최적의 set</strong>를 찾아내는 약간 무식한 방법이다. Grid Search 는 보통 2개의 Hyperparamter 조합을 만든다. (본 게시글엔 Learning Rate / Number of Layers 로 되어있다)</p><p>Grid Search는 두 개의 Hyperparameter를 이용해 모든 조합을 만들어 학습하고 <strong>Cross Validation</strong> 기술을 사용해 성능을 측정한다.</p><p><a href="http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf" target="_blank" rel="noopener">grid search</a></p><p>Grid Search는 사용하기 간편하지만 <strong>curse of dimensionality(차원의 저주)</strong>라는 문제를 안고 있다. Training data의 dimension이 높으면 그만큼 생기는 Hyperparamter 조합도 많아져 <strong>차원의 저주</strong>가 발생한다.</p><hr><p>2019.07.02 made by <em>jaejun.lee</em></p>]]></content:encoded>
      
      <comments>https://jx2lee.github.io/ml-introduction_to_grid_search/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
